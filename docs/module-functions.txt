# Module Functions Documentation

## Module: migrations.env
**File:** `migrations/env.py`

**Imports:**
- alembic.context
- flask.current_app
- logging
- logging.config.fileConfig

**Functions:**

### `def get_engine()`

**Line:** 18

---

### `def get_engine_url()`

**Line:** 27

---

### `def get_metadata()`

**Line:** 48

---

### `def run_migrations_offline()`

**Description:**
Run migrations in 'offline' mode.

This configures the context with just a URL
and not an Engine, though an Engine is acceptable
here as well.  By skipping the Engine creation
we don't even need a DBAPI to be available.

Calls to context.execute() here emit the given string to the
script output.

**Line:** 54

---

### `def run_migrations_online()`

**Description:**
Run migrations in 'online' mode.

In this scenario we need to create an Engine
and associate a connection with the context.

**Line:** 75

---


## Module: run_tests
**File:** `run_tests.py`

**Imports:**
- pathlib.Path
- src.app.create_app
- src.app.database.db
- src.app.services.auth_service.AuthService
- subprocess
- sys

**Functions:**

### `def run_tests()`

**Description:**
Run the test suite and display results.

**Line:** 8

---

### `def run_quick_test()`

**Description:**
Run a quick smoke test of the authentication system.

**Line:** 46

---


## Module: scripts.production_setup
**File:** `scripts/production_setup.py`

**Imports:**
- os
- pathlib.Path
- subprocess
- sys

**Functions:**

### `def create_production_env()`

**Description:**
Create production environment file.

**Line:** 16

---

### `def create_dockerfile()`

**Description:**
Create Dockerfile for containerized deployment.

**Line:** 64

---

### `def create_docker_compose()`

**Description:**
Create Docker Compose file for full stack deployment.

**Line:** 113

---

### `def create_nginx_config()`

**Description:**
Create Nginx configuration for reverse proxy.

**Line:** 175

---

### `def create_systemd_service()`

**Description:**
Create systemd service file for Linux deployment.

**Line:** 256

---

### `def create_requirements_prod()`

**Description:**
Create production requirements file.

**Line:** 286

---

### `def create_health_check()`

**Description:**
Create health check endpoint.

**Line:** 313

---

### `def main()`

**Description:**
Set up production environment.

**Line:** 385

---


## Module: scripts.seed_words
**File:** `scripts/seed_words.py`

**Imports:**
- app.create_app
- app.database.db
- app.models.game.GameMode
- app.models.game.WordList
- argparse
- json
- logging
- os
- pathlib.Path
- sys
- typing.Dict
- typing.List
- typing.Set
- typing.Tuple

**Functions:**

### `def main()`

**Description:**
Main entry point for the seeding script.

**Line:** 308

---


## Module: scripts.setup_database
**File:** `scripts/setup_database.py`

**Imports:**
- app.create_app
- app.database.db
- app.database.indexes.apply_database_optimizations
- app.database.indexes.get_query_performance_tips
- app.utils.caching.CacheManager
- argparse
- pathlib.Path
- sys

**Functions:**

### `def setup_database()`

**Description:**
Set up database with optimizations.

**Line:** 20

---

### `def main()`

**Description:**
Main entry point.

**Line:** 44

---


## Module: simple_test
**File:** `simple_test.py`

**Imports:**
- src.app.create_app
- src.app.models.user.User
- src.app.services.auth_service.AuthService

**Functions:**

### `def test_user_model()`

**Description:**
Test User model without database.

**Line:** 4

---

### `def test_auth_service_logic()`

**Description:**
Test authentication service logic without database.

**Line:** 40

---

### `def test_flask_app_creation()`

**Description:**
Test Flask app creation without database connection.

**Line:** 68

---

### `def main()`

**Description:**
Run all tests.

**Line:** 98

---


## Module: src.app.__init__
**File:** `src/app/__init__.py`

**Imports:**
- api.auth.auth_bp
- api.game.game_bp
- api.health.health_bp
- api.stats.stats_bp
- config.get_flask_config
- database.init_db
- flask.Flask
- flask.jsonify
- flask_cors.CORS
- flask_jwt_extended.JWTManager
- flask_limiter.Limiter
- flask_limiter.util.get_remote_address
- logging
- middleware.rate_limiting.RateLimitConfig
- middleware.security.SecurityMiddleware
- routes.main.main_bp
- typing.Optional

**Functions:**

### `def create_app(config_name: Optional[str] = None) -> Flask`

**Description:**
Create and configure Flask application.

Args:
config_name: Configuration environment name

Returns:
Configured Flask application instance

**Line:** 18

---

### `def init_extensions(app: Flask) -> None`

**Description:**
Initialize Flask extensions.

Args:
app: Flask application instance

**Line:** 55

---

### `def register_blueprints(app: Flask) -> None`

**Description:**
Register application blueprints.

Args:
app: Flask application instance

**Line:** 88

---

### `def register_error_handlers(app: Flask) -> None`

**Description:**
Register global error handlers.

Args:
app: Flask application instance

**Line:** 111

---

### `def configure_logging(app: Flask) -> None`

**Description:**
Configure application logging.

Args:
app: Flask application instance

**Line:** 146

---

### `def print_routes(app: Flask) -> None`

**Description:**
Print all registered routes for debugging.

**Line:** 163

---


## Module: src.app.api.auth
**File:** `src/app/api/auth.py`

**Imports:**
- flask.Blueprint
- flask.g
- flask.jsonify
- flask.make_response
- flask.request
- flask_jwt_extended.create_access_token
- flask_jwt_extended.create_refresh_token
- flask_jwt_extended.get_jwt_identity
- flask_jwt_extended.jwt_required
- flask_jwt_extended.set_access_cookies
- flask_jwt_extended.set_refresh_cookies
- pydantic.BaseModel
- pydantic.ValidationError
- services.auth_service.AuthService
- utils.responses.error_response
- utils.responses.success_response
- utils.validation.validate_json

**Functions:**

### `def register()`

**Decorators:**
- `@auth_bp.route(...)`
- `@validate_json(...)`

**Description:**
Register a new user.

Returns:
JSON response with user data and tokens

**Line:** 33

---

### `def login()`

**Decorators:**
- `@auth_bp.route(...)`
- `@validate_json(...)`

**Description:**
Authenticate user and return tokens.

Returns:
JSON response with user data and tokens

**Line:** 68

---

### `def refresh()`

**Decorators:**
- `@auth_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Refresh access token using refresh token.

Returns:
JSON response with new access token

**Line:** 103

---

### `def get_current_user()`

**Decorators:**
- `@auth_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Get current authenticated user information.

Returns:
JSON response with current user data

**Line:** 129

---


## Module: src.app.api.game
**File:** `src/app/api/game.py`

**Imports:**
- datetime.date
- datetime.datetime
- flask.Blueprint
- flask.request
- flask_jwt_extended.get_jwt_identity
- flask_jwt_extended.jwt_required
- logging
- models.game.GameMode
- services.game_service.GameService
- services.word_validation_service.WordValidationService
- utils.responses.error_response
- utils.responses.success_response
- utils.validation.validate_json

**Functions:**

### `def get_daily_puzzle(game_mode: str)`

**Decorators:**
- `@game_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Get today's daily puzzle for the specified game mode.

Args:
game_mode: Game mode ('classic' or 'disney')

Returns:
JSON response with puzzle and session information

**Line:** 26

---

### `def submit_guess()`

**Decorators:**
- `@game_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Submit a guess for the current game session.

Expected JSON body:
{
"word": "HELLO",
"session_id": 123
}

Returns:
JSON response with guess result and updated game state

**Line:** 73

---

### `def get_game_session(session_id: int)`

**Decorators:**
- `@game_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Get game session details.

Args:
session_id: Game session ID

Returns:
JSON response with session information

**Line:** 117

---

### `def validate_word()`

**Decorators:**
- `@game_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Validate if a word can be used as a guess.

Expected JSON body:
{
"word": "HELLO",
"game_mode": "classic"
}

Returns:
JSON response with validation result

**Line:** 149

---

### `def get_game_history(game_mode: str)`

**Decorators:**
- `@game_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Get user's game history for a specific mode.

Args:
game_mode: Game mode ('classic' or 'disney')

Query parameters:
limit: Maximum number of games to return (default: 10, max: 50)

Returns:
JSON response with game history

**Line:** 194

---

### `def get_game_modes()`

**Decorators:**
- `@game_bp.route(...)`

**Description:**
Get available game modes.

Returns:
JSON response with available game modes

**Line:** 241

---

### `def get_game_status(game_mode: str)`

**Decorators:**
- `@game_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Get current game status for a user in a specific mode.

Args:
game_mode: Game mode ('classic' or 'disney')

Returns:
JSON response with current game status

**Line:** 273

---


## Module: src.app.api.health
**File:** `src/app/api/health.py`

**Imports:**
- database.db
- flask.Blueprint
- flask.jsonify
- models.game.GameSession
- models.user.User
- utils.caching.CacheManager

**Functions:**

### `def health_check()`

**Decorators:**
- `@health_bp.route(...)`

**Description:**
Health check endpoint for load balancers and monitoring.

**Line:** 10

---

### `def metrics()`

**Decorators:**
- `@health_bp.route(...)`

**Description:**
Basic metrics endpoint for monitoring.

**Line:** 32

---


## Module: src.app.api.stats
**File:** `src/app/api/stats.py`

**Imports:**
- flask.Blueprint
- flask.request
- flask_jwt_extended.get_jwt_identity
- flask_jwt_extended.jwt_required
- logging
- models.game.GameMode
- services.statistics_service.StatisticsService
- utils.responses.error_response
- utils.responses.success_response

**Functions:**

### `def get_user_stats(user_id: int)`

**Decorators:**
- `@stats_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Get user statistics for all game modes.

Args:
user_id: User ID to get stats for

Query parameters:
mode: Specific game mode ('classic' or 'disney') - optional

Returns:
JSON response with user statistics

**Line:** 22

---

### `def get_my_stats()`

**Decorators:**
- `@stats_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Get current user's statistics for all game modes.

Query parameters:
mode: Specific game mode ('classic' or 'disney') - optional

Returns:
JSON response with user statistics

**Line:** 78

---

### `def get_leaderboard(game_mode: str)`

**Decorators:**
- `@stats_bp.route(...)`

**Description:**
Get leaderboard for a specific game mode.

Args:
game_mode: Game mode ('classic' or 'disney')

Query parameters:
metric: Ranking metric ('win_percentage', 'total_wins', 'current_streak') - default: 'win_percentage'
limit: Number of users to return (default: 10, max: 50)

Returns:
JSON response with leaderboard data

**Line:** 117

---

### `def get_global_stats(game_mode: str)`

**Decorators:**
- `@stats_bp.route(...)`

**Description:**
Get global statistics for a specific game mode.

Args:
game_mode: Game mode ('classic' or 'disney')

Returns:
JSON response with global statistics

**Line:** 170

---

### `def get_user_rank(game_mode: str)`

**Decorators:**
- `@stats_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Get current user's rank for a specific game mode.

Args:
game_mode: Game mode ('classic' or 'disney')

Query parameters:
metric: Ranking metric ('win_percentage', 'total_wins', 'current_streak') - default: 'win_percentage'

Returns:
JSON response with user's rank information

**Line:** 200

---

### `def get_streak_analysis(game_mode: str)`

**Decorators:**
- `@stats_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Get current user's streak analysis for a specific game mode.

Args:
game_mode: Game mode ('classic' or 'disney')

Returns:
JSON response with streak analysis

**Line:** 245

---

### `def get_stats_summary()`

**Decorators:**
- `@stats_bp.route(...)`

**Description:**
Get summary of statistics across all game modes.

Returns:
JSON response with statistics summary

**Line:** 278

---

### `def _filter_public_stats(stats: dict) -> dict`

**Description:**
Filter user stats to show only public information.

Args:
stats: Full user statistics dictionary

Returns:
Filtered statistics dictionary with only public info

**Line:** 313

---

### `def _filter_public_all_stats(all_stats: dict) -> dict`

**Description:**
Filter all user stats to show only public information.

Args:
all_stats: Full user statistics dictionary for all modes

Returns:
Filtered statistics dictionary with only public info

**Line:** 333

---


## Module: src.app.config.settings
**File:** `src/app/config/settings.py`

**Imports:**
- datetime.timedelta
- functools.lru_cache
- pydantic.Field
- pydantic_settings.BaseSettings
- typing.Optional

**Functions:**

### `def get_settings() -> Settings`

**Decorators:**
- `@lru_cache(...)`

**Description:**
Get cached settings instance.

**Line:** 50

---

### `def get_flask_config() -> dict`

**Description:**
Convert Pydantic settings to Flask config dict.

**Line:** 55

---


## Module: src.app.database.connection
**File:** `src/app/database/connection.py`

**Imports:**
- config.get_flask_config
- flask.Flask
- flask_migrate.Migrate
- flask_sqlalchemy.SQLAlchemy
- models.User
- typing.Optional

**Functions:**

### `def init_db(app: Flask) -> None`

**Description:**
Initialize database with Flask application.

Args:
app: Flask application instance

**Line:** 16

---

### `def get_db_session()`

**Description:**
Get database session for dependency injection.

Returns:
SQLAlchemy database session

**Line:** 35

---


## Module: src.app.database.indexes
**File:** `src/app/database/indexes.py`

**Imports:**
- models.game.DailyWord
- models.game.GameSession
- models.game.UserStats
- models.game.WordList
- models.user.User
- sqlalchemy.Index
- sqlalchemy.text

**Functions:**

### `def create_performance_indexes(db)`

**Description:**
Create database indexes for better query performance.

**Line:** 8

---

### `def create_database_views(db)`

**Description:**
Create database views for complex queries.

**Line:** 131

---

### `def apply_database_optimizations(db)`

**Description:**
Apply all database optimizations.

**Line:** 207

---

### `def get_query_performance_tips()`

**Description:**
Get query performance optimization tips.

**Line:** 237

---


## Module: src.app.routes.main
**File:** `src/app/routes/main.py`

**Imports:**
- flask.Blueprint
- flask.redirect
- flask.render_template
- flask.request
- flask.url_for
- flask_jwt_extended.get_jwt_identity
- flask_jwt_extended.jwt_required
- flask_jwt_extended.verify_jwt_in_request

**Functions:**

### `def index()`

**Decorators:**
- `@main_bp.route(...)`

**Description:**
Home page - redirect based on authentication status.

**Line:** 11

---

### `def auth_login()`

**Decorators:**
- `@main_bp.route(...)`

**Description:**
Login page.

**Line:** 26

---

### `def auth_register()`

**Decorators:**
- `@main_bp.route(...)`

**Description:**
Registration page.

**Line:** 41

---

### `def game()`

**Decorators:**
- `@main_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Main game page.

**Line:** 57

---

### `def stats()`

**Decorators:**
- `@main_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Statistics page.

**Line:** 68

---

### `def history()`

**Decorators:**
- `@main_bp.route(...)`
- `@jwt_required(...)`

**Description:**
Game history page.

**Line:** 79

---


## Module: src.app.utils.caching
**File:** `src/app/utils/caching.py`

**Imports:**
- datetime.datetime
- datetime.timedelta
- flask.current_app
- flask.g
- functools.wraps
- hashlib
- json
- time
- typing.Any
- typing.Callable
- typing.Dict
- typing.Optional

**Functions:**

### `def cache_key(*args, **kwargs) -> str`

**Description:**
Generate cache key from arguments.

**Line:** 75

---

### `def cached(ttl: int = 300, key_prefix: str = '')`

**Description:**
Decorator for caching function results.

**Line:** 81

---

### `def cache_daily_puzzle(game_mode: str, date: str)`

**Description:**
Cache daily puzzle for better performance.

**Line:** 104

---

### `def set_daily_puzzle_cache(game_mode: str, date: str, puzzle_data: Any)`

**Description:**
Set daily puzzle cache (expires at end of day).

**Line:** 110

---

### `def cache_user_stats(user_id: int, game_mode: str = None)`

**Description:**
Cache user statistics.

**Line:** 122

---

### `def set_user_stats_cache(user_id: int, stats_data: Any, game_mode: str = None, ttl: int = 600)`

**Description:**
Set user statistics cache.

**Line:** 132

---

### `def invalidate_user_stats_cache(user_id: int)`

**Description:**
Invalidate user statistics cache after game completion.

**Line:** 142

---

### `def cache_leaderboard(game_mode: str, metric: str, limit: int = 10)`

**Description:**
Cache leaderboard data.

**Line:** 150

---

### `def set_leaderboard_cache(game_mode: str, metric: str, limit: int, leaderboard_data: Any, ttl: int = 300)`

**Description:**
Set leaderboard cache.

**Line:** 156

---

### `def cache_word_validation(word: str, game_mode: str)`

**Description:**
Cache word validation results.

**Line:** 162

---

### `def set_word_validation_cache(word: str, game_mode: str, is_valid: bool, ttl: int = 86400)`

**Description:**
Set word validation cache (cache for 24 hours).

**Line:** 168

---


## Module: src.app.utils.responses
**File:** `src/app/utils/responses.py`

**Imports:**
- flask.jsonify
- typing.Any
- typing.Dict
- typing.Optional

**Functions:**

### `def success_response(data: Any = None, status_code: int = 200) -> tuple`

**Description:**
Create standardized success response.

Args:
data: Response data to include
status_code: HTTP status code

Returns:
Tuple of (JSON response, status code)

**Line:** 7

---

### `def error_response(message: str, status_code: int = 400, details: Optional[Dict] = None) -> tuple`

**Description:**
Create standardized error response.

Args:
message: Error message
status_code: HTTP status code
details: Additional error details

Returns:
Tuple of (JSON response, status code)

**Line:** 25

---

### `def paginated_response(items: list, page: int, per_page: int, total: int) -> Dict[(str, Any)]`

**Description:**
Create paginated response data.

Args:
items: List of items for current page
page: Current page number
per_page: Items per page
total: Total number of items

Returns:
Paginated response data structure

**Line:** 48

---


## Module: src.app.utils.validation
**File:** `src/app/utils/validation.py`

**Imports:**
- flask.g
- flask.jsonify
- flask.request
- functools.wraps
- pydantic.BaseModel
- pydantic.ValidationError
- responses.error_response
- typing.Any
- typing.Callable
- typing.Type

**Functions:**

### `def validate_json(model_class: Type[BaseModel]) -> Callable`

**Description:**
Decorator to validate JSON request data using Pydantic model.

Args:
model_class: Pydantic model class for validation

Returns:
Decorator function

**Line:** 12

---

### `def validate_query_params(model_class: Type[BaseModel]) -> Callable`

**Description:**
Decorator to validate query parameters using Pydantic model.

Args:
model_class: Pydantic model class for validation

Returns:
Decorator function

**Line:** 60

---


## Module: tests.conftest
**File:** `tests/conftest.py`

**Imports:**
- pytest
- src.app.create_app
- src.app.database.db
- src.app.models.User

**Functions:**

### `def app()`

**Decorators:**
- `@pytest.fixture`

**Description:**
Create application for testing.

**Line:** 10

---

### `def client(app)`

**Decorators:**
- `@pytest.fixture`

**Description:**
Create test client.

**Line:** 28

---

### `def runner(app)`

**Decorators:**
- `@pytest.fixture`

**Description:**
Create test CLI runner.

**Line:** 34

---

### `def sample_user_data()`

**Decorators:**
- `@pytest.fixture`

**Description:**
Sample user data for testing.

**Line:** 40

---

### `def created_user(app, sample_user_data)`

**Decorators:**
- `@pytest.fixture`

**Description:**
Create a user in the database for testing.

**Line:** 50

---

### `def auth_headers(client, sample_user_data)`

**Decorators:**
- `@pytest.fixture`

**Description:**
Get authentication headers with JWT token.

**Line:** 68

---

### `def auth_client(client, auth_headers)`

**Decorators:**
- `@pytest.fixture`

**Description:**
Client with authentication headers set.

**Line:** 81

---


## Module: venv2.libthon3.12.site-packages._pytest._argcomplete
**File:** `venv2/lib/python3.12/site-packages/_pytest/_argcomplete.py`

**Imports:**
- argcomplete.completers
- argparse
- glob.glob
- os
- sys
- typing.Any
- typing.List
- typing.Optional

**Functions:**

### `def try_argcomplete(parser: argparse.ArgumentParser) -> None`

**Line:** 108

---

### `def try_argcomplete(parser: argparse.ArgumentParser) -> None`

**Line:** 113

---


## Module: venv2.libthon3.12.site-packages._pytest._code.code
**File:** `venv2/lib/python3.12/site-packages/_pytest/_code/code.py`

**Imports:**
- _pytest
- _pytest._code.source.Source
- _pytest._code.source.findsource
- _pytest._code.source.getrawcode
- _pytest._code.source.getstatementrange_ast
- _pytest._io.TerminalWriter
- _pytest._io.saferepr.safeformat
- _pytest._io.saferepr.saferepr
- _pytest.compat.final
- _pytest.compat.get_real_func
- _pytest.deprecated.check_ispytest
- _pytest.pathlib.absolutepath
- _pytest.pathlib.bestrelpath
- ast
- dataclasses
- exceptiongroup.BaseExceptionGroup
- inspect
- inspect.CO_VARARGS
- inspect.CO_VARKEYWORDS
- io.StringIO
- os
- pathlib.Path
- pluggy
- re
- sys
- traceback
- traceback.format_exception_only
- types.CodeType
- types.FrameType
- types.TracebackType
- typing.Any
- typing.Callable
- typing.ClassVar
- typing.Dict
- typing.Generic
- typing.Iterable
- typing.List
- typing.Mapping
- typing.Optional
- typing.Pattern
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.overload
- typing_extensions.Final
- typing_extensions.Literal
- typing_extensions.SupportsIndex

**Functions:**

### `def getfslineno(obj: object) -> Tuple[(Union[str, Path], int)]`

**Description:**
Return source location (path, lineno) for the given object.

If the source cannot be determined return ("", -1).

The line number is 0-based.

**Line:** 1265

---

### `def filter_traceback(entry: TracebackEntry) -> bool`

**Description:**
Return True if a TracebackEntry instance should be included in tracebacks.

We hide traceback entries of:

* dynamically generated code (no code to show up for it);
* internal traceback from pytest or its internal libraries, py and pluggy.

**Line:** 1311

---


## Module: venv2.libthon3.12.site-packages._pytest._code.source
**File:** `venv2/lib/python3.12/site-packages/_pytest/_code/source.py`

**Imports:**
- ast
- bisect.bisect_right
- inspect
- textwrap
- tokenize
- types
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Optional
- typing.Tuple
- typing.Union
- typing.overload
- warnings

**Functions:**

### `def findsource(obj) -> Tuple[(Optional[Source], int)]`

**Line:** 119

---

### `def getrawcode(obj: object, trycall: bool = True) -> types.CodeType`

**Description:**
Return code object for given function.

**Line:** 129

---

### `def deindent(lines: Iterable[str]) -> List[str]`

**Line:** 142

---

### `def get_statement_startend2(lineno: int, node: ast.AST) -> Tuple[(int, Optional[int])]`

**Line:** 146

---

### `def getstatementrange_ast(lineno: int, source: Source, assertion: bool = False, astnode: Optional[ast.AST] = None) -> Tuple[(ast.AST, int, int)]`

**Line:** 173

---


## Module: venv2.libthon3.12.site-packages._pytest._io.saferepr
**File:** `venv2/lib/python3.12/site-packages/_pytest/_io/saferepr.py`

**Imports:**
- pprint
- reprlib
- typing.Any
- typing.Dict
- typing.IO
- typing.Optional

**Functions:**

### `def _try_repr_or_str(obj: object) -> str`

**Line:** 9

---

### `def _format_repr_exception(exc: BaseException, obj: object) -> str`

**Line:** 18

---

### `def _ellipsize(s: str, maxsize: int) -> str`

**Line:** 30

---

### `def safeformat(obj: object) -> str`

**Description:**
Return a pretty printed string for the given object.

Failing __repr__ functions of user instances will be represented
with a short exception info.

**Line:** 86

---

### `def saferepr(obj: object, maxsize: Optional[int] = DEFAULT_REPR_MAX_SIZE, use_ascii: bool = False) -> str`

**Description:**
Return a size-limited safe repr-string for the given object.

Failing __repr__ functions of user instances will be represented
with a short exception info and 'saferepr' generally takes
care to never raise exceptions itself.

This function is a wrapper around the Repr/reprlib functionality of the
stdlib.

**Line:** 102

---

### `def saferepr_unlimited(obj: object, use_ascii: bool = True) -> str`

**Description:**
Return an unlimited-size safe repr-string for the given object.

As with saferepr, failing __repr__ functions of user instances
will be represented with a short exception info.

This function is a wrapper around simple repr.

Note: a cleaner solution would be to alter ``saferepr``this way
when maxsize=None, but that might affect some other code.

**Line:** 118

---

### `def _pformat_dispatch(object: object, indent: int = 1, width: int = 80, depth: Optional[int] = None, compact: bool = False) -> str`

**Line:** 170

---


## Module: venv2.libthon3.12.site-packages._pytest._io.terminalwriter
**File:** `venv2/lib/python3.12/site-packages/_pytest/_io/terminalwriter.py`

**Imports:**
- _pytest.compat.final
- _pytest.config.exceptions.UsageError
- colorama
- os
- pygments.formatters.terminal.TerminalFormatter
- pygments.highlight
- pygments.lexers.python.PythonLexer
- pygments.util
- shutil
- sys
- typing.Optional
- typing.Sequence
- typing.TextIO
- wcwidth.wcswidth

**Functions:**

### `def get_terminal_width() -> int`

**Line:** 16

---

### `def should_do_markup(file: TextIO) -> bool`

**Line:** 26

---


## Module: venv2.libthon3.12.site-packages._pytest._io.wcwidth
**File:** `venv2/lib/python3.12/site-packages/_pytest/_io/wcwidth.py`

**Imports:**
- functools.lru_cache
- unicodedata

**Functions:**

### `def wcwidth(c: str) -> int`

**Decorators:**
- `@lru_cache(...)`

**Description:**
Determine how many columns are needed to display a character in a terminal.

Returns -1 if the character is not printable.
Returns 0, 1 or 2 for other characters.

**Line:** 6

---

### `def wcswidth(s: str) -> int`

**Description:**
Determine how many columns are needed to display a string in a terminal.

Returns -1 if the string contains non-printable characters.

**Line:** 44

---


## Module: venv2.libthon3.12.site-packages._pytest._py.error
**File:** `venv2/lib/python3.12/site-packages/_pytest/_py/error.py`

**Imports:**
- __future__.annotations
- errno
- os
- sys
- typing.Callable
- typing.TYPE_CHECKING
- typing.TypeVar
- typing_extensions.ParamSpec

**Functions:**

### `def __getattr__(attr: str) -> type[Error]`

**Line:** 108

---


## Module: venv2.libthon3.12.site-packages._pytest._py.path
**File:** `venv2/lib/python3.12/site-packages/_pytest/_py/path.py`

**Imports:**
- __future__.annotations
- _code.source.getrawcode
- atexit
- contextlib.contextmanager
- fnmatch
- grp
- hashlib
- importlib.util
- io
- os
- os.path.abspath
- os.path.dirname
- os.path.exists
- os.path.isabs
- os.path.isdir
- os.path.isfile
- os.path.islink
- os.path.normpath
- pickle
- posixpath
- pwd
- shutil
- stat.S_ISDIR
- stat.S_ISLNK
- stat.S_ISREG
- subprocess.PIPE
- subprocess.Popen
- sys
- tempfile
- types
- typing.Any
- typing.Callable
- typing.Literal
- typing.TYPE_CHECKING
- typing.cast
- typing.overload
- uuid
- warnings

**Functions:**

### `def map_as_list(func, iter)`

**Line:** 200

---

### `def getuserid(user)`

**Line:** 252

---

### `def getgroupid(group)`

**Line:** 260

---

### `def copymode(src, dest)`

**Description:**
Copy permission from src to dst.

**Line:** 1437

---

### `def copystat(src, dest)`

**Description:**
Copy permission,  last modification time,
last access time, and flags from src to dst.

**Line:** 1444

---

### `def copychunked(src, dest)`

**Line:** 1452

---

### `def isimportable(name)`

**Line:** 1469

---


## Module: venv2.libthon3.12.site-packages._pytest.assertion.__init__
**File:** `venv2/lib/python3.12/site-packages/_pytest/assertion/__init__.py`

**Imports:**
- _pytest.assertion.rewrite
- _pytest.assertion.rewrite.assertstate_key
- _pytest.assertion.truncate
- _pytest.assertion.util
- _pytest.config.Config
- _pytest.config.argparsing.Parser
- _pytest.config.hookimpl
- _pytest.main.Session
- _pytest.nodes.Item
- sys
- typing.Any
- typing.Generator
- typing.List
- typing.Optional
- typing.TYPE_CHECKING

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 22

---

### `def register_assert_rewrite(*names: str) -> None`

**Description:**
Register one or more module names to be rewritten on import.

This function will make sure that this module or all modules inside
the package will get their assert statements rewritten.
Thus you should make sure to call this before the module is
actually imported, usually in your __init__.py if you are a plugin
using a package.

:param names: The module names to register.

**Line:** 47

---

### `def install_importhook(config: Config) -> rewrite.AssertionRewritingHook`

**Description:**
Try to install the rewrite hook, raise SystemError if it fails.

**Line:** 89

---

### `def pytest_collection(session: 'Session') -> None`

**Line:** 105

---

### `def pytest_runtest_protocol(item: Item) -> Generator[(None, None, None)]`

**Decorators:**
- `@hookimpl(...)`

**Description:**
Setup the pytest_assertrepr_compare and pytest_assertion_pass hooks.

The rewrite module will use util._reprcompare if it exists to use custom
reporting via the pytest_assertrepr_compare hook.  This sets up this custom
comparison for the test.

**Line:** 116

---

### `def pytest_sessionfinish(session: 'Session') -> None`

**Line:** 171

---

### `def pytest_assertrepr_compare(config: Config, op: str, left: Any, right: Any) -> Optional[List[str]]`

**Line:** 178

---


## Module: venv2.libthon3.12.site-packages._pytest.assertion.rewrite
**File:** `venv2/lib/python3.12/site-packages/_pytest/assertion/rewrite.py`

**Imports:**
- _pytest._io.saferepr.DEFAULT_REPR_MAX_SIZE
- _pytest._io.saferepr.saferepr
- _pytest._version.version
- _pytest.assertion.AssertionState
- _pytest.assertion.util
- _pytest.assertion.util.format_explanation
- _pytest.config.Config
- _pytest.main.Session
- _pytest.pathlib.absolutepath
- _pytest.pathlib.fnmatch_ex
- _pytest.stash.StashKey
- _pytest.warning_types.PytestAssertRewriteWarning
- ast
- collections.defaultdict
- errno
- functools
- importlib.abc
- importlib.abc.TraversableResources
- importlib.machinery
- importlib.readers.FileReader
- importlib.resources.abc.TraversableResources
- importlib.resources.readers.FileReader
- importlib.util
- io
- itertools
- marshal
- os
- pathlib.Path
- pathlib.PurePath
- struct
- sys
- tokenize
- types
- typing.Callable
- typing.Dict
- typing.IO
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- warnings

**Functions:**

### `def _write_pyc_fp(fp: IO[bytes], source_stat: os.stat_result, co: types.CodeType) -> None`

**Line:** 311

---

### `def _write_pyc(state: 'AssertionState', co: types.CodeType, source_stat: os.stat_result, pyc: Path) -> bool`

**Line:** 329

---

### `def _rewrite_test(fn: Path, config: Config) -> Tuple[(os.stat_result, types.CodeType)]`

**Description:**
Read and rewrite *fn* and return the code object.

**Line:** 354

---

### `def _read_pyc(source: Path, pyc: Path, trace: Callable[([str], None)] = lambda x: None) -> Optional[types.CodeType]`

**Description:**
Possibly read a pytest pyc containing rewritten code.

Return rewritten code if successful or None if not.

**Line:** 365

---

### `def rewrite_asserts(mod: ast.Module, source: bytes, module_path: Optional[str] = None, config: Optional[Config] = None) -> None`

**Description:**
Rewrite the assert statements in mod.

**Line:** 414

---

### `def _saferepr(obj: object) -> str`

**Description:**
Get a safe repr of an object for assertion error messages.

The assertion formatting (util.format_explanation()) requires
newlines to be escaped since they are a special character for it.
Normally assertion.util.format_explanation() does this but for a
custom repr it is possible to contain one of the special escape
sequences, especially '\n{' and '\n}' are likely to be present in
JSON reprs.

**Line:** 424

---

### `def _get_maxsize_for_saferepr(config: Optional[Config]) -> Optional[int]`

**Description:**
Get `maxsize` configuration for saferepr based on the given config object.

**Line:** 438

---

### `def _format_assertmsg(obj: object) -> str`

**Description:**
Format the custom assertion message given.

For strings this simply replaces newlines with '\n~' so that
util.format_explanation() will preserve them instead of escaping
newlines.  For other objects saferepr() is used first.

**Line:** 448

---

### `def _should_repr_global_name(obj: object) -> bool`

**Line:** 470

---

### `def _format_boolop(explanations: Iterable[str], is_or: bool) -> str`

**Line:** 480

---

### `def _call_reprcompare(ops: Sequence[str], results: Sequence[bool], expls: Sequence[str], each_obj: Sequence[object]) -> str`

**Line:** 485

---

### `def _call_assertion_pass(lineno: int, orig: str, expl: str) -> None`

**Line:** 505

---

### `def _check_if_assertion_pass_impl() -> bool`

**Description:**
Check if any plugins implement the pytest_assertion_pass hook
in order not to generate explanation unnecessarily (might be expensive).

**Line:** 510

---

### `def traverse_node(node: ast.AST) -> Iterator[ast.AST]`

**Description:**
Recursively yield node and all its children in depth-first order.

**Line:** 545

---

### `def _get_assertion_exprs(src: bytes) -> Dict[(int, str)]`

**Decorators:**
- `@functools.lru_cache(...)`

**Description:**
Return a mapping from {lineno: "assertion test expression"}.

**Line:** 553

---

### `def try_makedirs(cache_dir: Path) -> bool`

**Description:**
Attempt to create the given directory and sub-directories exist.

Returns True if successful or if it already exists.

**Line:** 1178

---

### `def get_cache_dir(file_path: Path) -> Path`

**Description:**
Return the cache directory to write .pyc files for the given .py file path.

**Line:** 1200

---


## Module: venv2.libthon3.12.site-packages._pytest.assertion.truncate
**File:** `venv2/lib/python3.12/site-packages/_pytest/assertion/truncate.py`

**Imports:**
- _pytest.assertion.util
- _pytest.nodes.Item
- typing.List
- typing.Optional

**Functions:**

### `def truncate_if_required(explanation: List[str], item: Item, max_length: Optional[int] = None) -> List[str]`

**Description:**
Truncate this assertion explanation if the given test item is eligible.

**Line:** 18

---

### `def _should_truncate_item(item: Item) -> bool`

**Description:**
Whether or not this test item is eligible for truncation.

**Line:** 27

---

### `def _truncate_explanation(input_lines: List[str], max_lines: Optional[int] = None, max_chars: Optional[int] = None) -> List[str]`

**Description:**
Truncate given list of strings that makes up the assertion explanation.

Truncates to either 8 lines, or 640 characters - whichever the input reaches
first, taking the truncation explanation into account. The remaining lines
will be replaced by a usage message.

**Line:** 33

---

### `def _truncate_by_char_count(input_lines: List[str], max_chars: int) -> List[str]`

**Line:** 100

---


## Module: venv2.libthon3.12.site-packages._pytest.assertion.util
**File:** `venv2/lib/python3.12/site-packages/_pytest/assertion/util.py`

**Imports:**
- _pytest._code
- _pytest._io.saferepr._pformat_dispatch
- _pytest._io.saferepr.saferepr
- _pytest._io.saferepr.saferepr_unlimited
- _pytest.config.Config
- _pytest.outcomes
- _pytest.python_api.ApproxBase
- collections.abc
- dataclasses
- difflib
- difflib.ndiff
- os
- pprint
- typing.AbstractSet
- typing.Any
- typing.Callable
- typing.Iterable
- typing.List
- typing.Mapping
- typing.Optional
- typing.Sequence
- unicodedata.normalize

**Functions:**

### `def format_explanation(explanation: str) -> str`

**Description:**
Format an explanation.

Normally all embedded newlines are escaped, however there are
three exceptions: \n{, \n} and \n~.  The first two are intended
cover nested explanations, see function and attribute explanations
for examples (.visit_Call(), visit_Attribute()).  The last one is
for when one explanation needs to span multiple lines, e.g. when
displaying diffs.

**Line:** 36

---

### `def _split_explanation(explanation: str) -> List[str]`

**Description:**
Return a list of individual lines in the explanation.

This will return a list of lines split on '\n{', '\n}' and '\n~'.
Any other newlines will be escaped and appear in the line as the
literal '\n' characters.

**Line:** 51

---

### `def _format_lines(lines: Sequence[str]) -> List[str]`

**Description:**
Format the individual lines.

This will replace the '{', '}' and '~' characters of our mini formatting
language with the proper 'where ...', 'and ...' and ' + ...' text, taking
care of indentation along the way.

Return a list of formatted lines.

**Line:** 68

---

### `def issequence(x: Any) -> bool`

**Line:** 103

---

### `def istext(x: Any) -> bool`

**Line:** 107

---

### `def isdict(x: Any) -> bool`

**Line:** 111

---

### `def isset(x: Any) -> bool`

**Line:** 115

---

### `def isnamedtuple(obj: Any) -> bool`

**Line:** 119

---

### `def isdatacls(obj: Any) -> bool`

**Line:** 123

---

### `def isattrs(obj: Any) -> bool`

**Line:** 127

---

### `def isiterable(obj: Any) -> bool`

**Line:** 131

---

### `def has_default_eq(obj: object) -> bool`

**Description:**
Check if an instance of an object contains the default eq

First, we check if the object's __eq__ attribute has __code__,
if so, we check the equally of the method code filename (__code__.co_filename)
to the default one generated by the dataclass and attr module
for dataclasses the default co_filename is <string>, for attrs class, the __eq__ should contain "attrs eq generated"

**Line:** 139

---

### `def assertrepr_compare(config, op: str, left: Any, right: Any, use_ascii: bool = False) -> Optional[List[str]]`

**Description:**
Return specialised explanations for some operators/operands.

**Line:** 160

---

### `def _compare_eq_any(left: Any, right: Any, verbose: int = 0) -> List[str]`

**Line:** 212

---

### `def _diff_text(left: str, right: str, verbose: int = 0) -> List[str]`

**Description:**
Return the explanation for the diff between text.

Unless --verbose is used this will skip leading and trailing
characters which are identical to keep the diff minimal.

**Line:** 247

---

### `def _surrounding_parens_on_own_lines(lines: List[str]) -> None`

**Description:**
Move opening/closing parenthesis/bracket to own lines.

**Line:** 295

---

### `def _compare_eq_iterable(left: Iterable[Any], right: Iterable[Any], verbose: int = 0) -> List[str]`

**Line:** 307

---

### `def _compare_eq_sequence(left: Sequence[Any], right: Sequence[Any], verbose: int = 0) -> List[str]`

**Line:** 338

---

### `def _compare_eq_set(left: AbstractSet[Any], right: AbstractSet[Any], verbose: int = 0) -> List[str]`

**Line:** 391

---

### `def _compare_eq_dict(left: Mapping[(Any, Any)], right: Mapping[(Any, Any)], verbose: int = 0) -> List[str]`

**Line:** 408

---

### `def _compare_eq_cls(left: Any, right: Any, verbose: int) -> List[str]`

**Line:** 449

---

### `def _notin_text(term: str, text: str, verbose: int = 0) -> List[str]`

**Line:** 500

---

### `def running_on_ci() -> bool`

**Description:**
Check if we're currently running on a CI system.

**Line:** 519

---


## Module: venv2.libthon3.12.site-packages._pytest.cacheprovider
**File:** `venv2/lib/python3.12/site-packages/_pytest/cacheprovider.py`

**Imports:**
- _pytest._io.TerminalWriter
- _pytest.compat.final
- _pytest.config.Config
- _pytest.config.ExitCode
- _pytest.config.argparsing.Parser
- _pytest.config.hookimpl
- _pytest.deprecated.check_ispytest
- _pytest.fixtures.FixtureRequest
- _pytest.fixtures.fixture
- _pytest.main.Session
- _pytest.main.wrap_session
- _pytest.nodes
- _pytest.nodes.File
- _pytest.python.Package
- _pytest.reports.TestReport
- _pytest.warning_types.PytestCacheWarning
- dataclasses
- json
- os
- pathlib.Path
- pathlib.resolve_from_str
- pathlib.rm_rf
- pprint.pformat
- reports.CollectReport
- typing.Dict
- typing.Generator
- typing.Iterable
- typing.List
- typing.Optional
- typing.Set
- typing.Union
- warnings

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 454

---

### `def pytest_cmdline_main(config: Config) -> Optional[Union[(int, ExitCode)]]`

**Line:** 516

---

### `def pytest_configure(config: Config) -> None`

**Decorators:**
- `@hookimpl(...)`

**Line:** 525

---

### `def cache(request: FixtureRequest) -> Cache`

**Decorators:**
- `@fixture`

**Description:**
Return a cache object that can persist state between testing sessions.

cache.get(key, default)
cache.set(key, value)

Keys must be ``/`` separated strings, where the first part is usually the
name of your plugin or application to avoid clashes with other cache users.

Values can be any object handled by the json stdlib module.

**Line:** 532

---

### `def pytest_report_header(config: Config) -> Optional[str]`

**Description:**
Display cachedir with --cache-show and if non-default.

**Line:** 547

---

### `def cacheshow(config: Config, session: Session) -> int`

**Line:** 563

---


## Module: venv2.libthon3.12.site-packages._pytest.capture
**File:** `venv2/lib/python3.12/site-packages/_pytest/capture.py`

**Imports:**
- _pytest.compat.final
- _pytest.config.Config
- _pytest.config.argparsing.Parser
- _pytest.config.hookimpl
- _pytest.deprecated.check_ispytest
- _pytest.fixtures.SubRequest
- _pytest.fixtures.fixture
- _pytest.nodes.Collector
- _pytest.nodes.File
- _pytest.nodes.Item
- abc
- collections
- colorama
- contextlib
- io
- io.UnsupportedOperation
- os
- sys
- tempfile.TemporaryFile
- types.TracebackType
- typing.Any
- typing.AnyStr
- typing.BinaryIO
- typing.Generator
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.List
- typing.NamedTuple
- typing.Optional
- typing.TYPE_CHECKING
- typing.TextIO
- typing.Tuple
- typing.Type
- typing.Union
- typing_extensions.Final
- typing_extensions.Literal

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 45

---

### `def _colorama_workaround() -> None`

**Description:**
Ensure colorama is imported so that it attaches to the correct stdio
handles on Windows.

colorama uses the terminal on import time. So if something does the
first import of colorama while I/O capture is active, colorama will
fail in various ways.

**Line:** 64

---

### `def _windowsconsoleio_workaround(stream: TextIO) -> None`

**Description:**
Workaround for Windows Unicode console handling.

Python 3.6 implemented Unicode console handling for Windows. This works
by reading/writing to the raw console handle using
``{Read,Write}ConsoleW``.

The problem is that we are going to ``dup2`` over the stdio file
descriptors when doing ``FDCapture`` and this will ``CloseHandle`` the
handles used by Python to write to the console. Though there is still some
weirdness and the console handle seems to only be closed randomly and not
on the first call to ``CloseHandle``, or maybe it gets reopened with the
same handle value when we suspend capturing.

The workaround in this case will reopen stdio with a different fd which
also means a different handle by replicating the logic in
"Py_lifecycle.c:initstdio/create_stdio".

:param stream:
In practice ``sys.stdout`` or ``sys.stderr``, but given
here as parameter for unittesting purposes.

See https://github.com/pytest-dev/py/issues/103.

**Line:** 79

---

### `def pytest_load_initial_conftests(early_config: Config)`

**Decorators:**
- `@hookimpl(...)`

**Line:** 136

---

### `def _get_multicapture(method: '_CaptureMethod') -> MultiCapture[str]`

**Line:** 690

---

### `def capsys(request: SubRequest) -> Generator[(CaptureFixture[str], None, None)]`

**Decorators:**
- `@fixture`

**Description:**
Enable text capturing of writes to ``sys.stdout`` and ``sys.stderr``.

The captured output is made available via ``capsys.readouterr()`` method
calls, which return a ``(out, err)`` namedtuple.
``out`` and ``err`` will be ``text`` objects.

Returns an instance of :class:`CaptureFixture[str] <pytest.CaptureFixture>`.

Example:

.. code-block:: python

def test_output(capsys):
print("hello")
captured = capsys.readouterr()
assert captured.out == "hello\n"

**Line:** 973

---

### `def capsysbinary(request: SubRequest) -> Generator[(CaptureFixture[bytes], None, None)]`

**Decorators:**
- `@fixture`

**Description:**
Enable bytes capturing of writes to ``sys.stdout`` and ``sys.stderr``.

The captured output is made available via ``capsysbinary.readouterr()``
method calls, which return a ``(out, err)`` namedtuple.
``out`` and ``err`` will be ``bytes`` objects.

Returns an instance of :class:`CaptureFixture[bytes] <pytest.CaptureFixture>`.

Example:

.. code-block:: python

def test_output(capsysbinary):
print("hello")
captured = capsysbinary.readouterr()
assert captured.out == b"hello\n"

**Line:** 1001

---

### `def capfd(request: SubRequest) -> Generator[(CaptureFixture[str], None, None)]`

**Decorators:**
- `@fixture`

**Description:**
Enable text capturing of writes to file descriptors ``1`` and ``2``.

The captured output is made available via ``capfd.readouterr()`` method
calls, which return a ``(out, err)`` namedtuple.
``out`` and ``err`` will be ``text`` objects.

Returns an instance of :class:`CaptureFixture[str] <pytest.CaptureFixture>`.

Example:

.. code-block:: python

def test_system_echo(capfd):
os.system('echo "hello"')
captured = capfd.readouterr()
assert captured.out == "hello\n"

**Line:** 1029

---

### `def capfdbinary(request: SubRequest) -> Generator[(CaptureFixture[bytes], None, None)]`

**Decorators:**
- `@fixture`

**Description:**
Enable bytes capturing of writes to file descriptors ``1`` and ``2``.

The captured output is made available via ``capfd.readouterr()`` method
calls, which return a ``(out, err)`` namedtuple.
``out`` and ``err`` will be ``byte`` objects.

Returns an instance of :class:`CaptureFixture[bytes] <pytest.CaptureFixture>`.

Example:

.. code-block:: python

def test_system_echo(capfdbinary):
os.system('echo "hello"')
captured = capfdbinary.readouterr()
assert captured.out == b"hello\n"

**Line:** 1057

---


## Module: venv2.libthon3.12.site-packages._pytest.compat
**File:** `venv2/lib/python3.12/site-packages/_pytest/compat.py`

**Imports:**
- __future__.annotations
- _pytest._io.saferepr.saferepr
- _pytest.outcomes.TEST_OUTCOME
- _pytest.outcomes.fail
- dataclasses
- enum
- functools
- functools.cached_property
- importlib.metadata
- importlib_metadata
- inspect
- inspect.Parameter
- inspect.signature
- os
- pathlib.Path
- py
- sys
- typing.Any
- typing.Callable
- typing.Generic
- typing.NoReturn
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.final
- typing.overload
- typing_extensions.Final
- typing_extensions.final

**Functions:**

### `def legacy_path(path: str | os.PathLike[str]) -> LEGACY_PATH`

**Description:**
Internal wrapper to prepare lazy proxies for legacy_path instances

**Line:** 48

---

### `def _format_args(func: Callable[(..., Any)]) -> str`

**Line:** 69

---

### `def is_generator(func: object) -> bool`

**Line:** 73

---

### `def iscoroutinefunction(func: object) -> bool`

**Description:**
Return True if func is a coroutine function (a function defined with async
def syntax, and doesn't contain yield), or a function decorated with
@asyncio.coroutine.

Note: copied and modified from Python 3.5's builtin couroutines.py to avoid
importing asyncio directly, which in turns also initializes the "logging"
module as a side-effect (see issue #8).

**Line:** 78

---

### `def is_async_function(func: object) -> bool`

**Description:**
Return True if the given function seems to be an async function or
an async generator.

**Line:** 90

---

### `def getlocation(function, curdir: str | None = None) -> str`

**Line:** 96

---

### `def num_mock_patch_args(function) -> int`

**Description:**
Return number of arguments used up by mock arguments (if any).

**Line:** 110

---

### `def getfuncargnames(function: Callable[(..., Any)], name: str = '', is_method: bool = False, cls: type | None = None) -> tuple[(str, ...)]`

**Description:**
Return the names of a function's mandatory arguments.

Should return the names of all function arguments that:
* Aren't bound to an instance or type as in instance or class methods.
* Don't have default values.
* Aren't bound with functools.partial.
* Aren't replaced with mocks.

The is_method and cls arguments indicate that the function should
be treated as a bound method even though it's not unless, only in
the case of cls, the function is a static method.

The name parameter should be the original name in which the function was collected.

**Line:** 129

---

### `def get_default_arg_names(function: Callable[(..., Any)]) -> tuple[(str, ...)]`

**Line:** 199

---

### `def _translate_non_printable(s: str) -> str`

**Line:** 219

---

### `def _bytes_to_ascii(val: bytes) -> str`

**Line:** 226

---

### `def ascii_escaped(val: bytes | str) -> str`

**Description:**
If val is pure ASCII, return it as an str, otherwise, escape
bytes objects into a sequence of escaped bytes:

b'\xc3\xb4\xc5\xd6' -> r'\xc3\xb4\xc5\xd6'

and escapes unicode objects into a sequence of escaped unicode
ids, e.g.:

r'4\nV\U00043efa\x0eMXWB\x1e\u3028\u15fd\xcd\U0007d944'

Note:
The obvious "v.decode('unicode-escape')" will return
valid UTF-8 unicode if it finds them in bytes, but we
want to return escaped bytes for any byte, even if they match
a UTF-8 string.

**Line:** 230

---

### `def get_real_func(obj)`

**Description:**
Get the real function object of the (possibly) wrapped object by
functools.wraps or functools.partial.

**Line:** 266

---

### `def get_real_method(obj, holder)`

**Description:**
Attempt to obtain the real function object that might be wrapping
``obj``, while at the same time returning a bound method to ``holder`` if
the original object was a bound method.

**Line:** 295

---

### `def getimfunc(func)`

**Line:** 309

---

### `def safe_getattr(object: Any, name: str, default: Any) -> Any`

**Description:**
Like getattr but return default upon any Exception or any OutcomeException.

Attribute access can potentially fail for 'evil' Python objects.
See issue #214.
It catches OutcomeException because of #2490 (issue #580), new outcomes
are derived from BaseException instead of Exception (for more details
check #2707).

**Line:** 316

---

### `def safe_isclass(obj: object) -> bool`

**Description:**
Ignore any exception via isinstance on Python 3.

**Line:** 333

---

### `def final(f)`

**Line:** 350

---

### `def get_user_id() -> int | None`

**Description:**
Return the current process's real user id or None if it could not be
determined.

:return: The user id or None if it could not be determined.

**Line:** 382

---

### `def assert_never(value: NoReturn) -> NoReturn`

**Line:** 434

---


## Module: venv2.libthon3.12.site-packages._pytest.config.__init__
**File:** `venv2/lib/python3.12/site-packages/_pytest/config/__init__.py`

**Imports:**
- _pytest._code
- _pytest._code.ExceptionInfo
- _pytest._code.code._TracebackStyle
- _pytest._code.filter_traceback
- _pytest._io.TerminalWriter
- _pytest.assertion
- _pytest.cacheprovider.Cache
- _pytest.compat.final
- _pytest.compat.importlib_metadata
- _pytest.deprecated
- _pytest.helpconfig.showversion
- _pytest.hookspec
- _pytest.outcomes.Skipped
- _pytest.outcomes.fail
- _pytest.pathlib.ImportMode
- _pytest.pathlib.absolutepath
- _pytest.pathlib.bestrelpath
- _pytest.pathlib.import_path
- _pytest.pathlib.resolve_package_path
- _pytest.pathlib.safe_exists
- _pytest.stash.Stash
- _pytest.terminal.TerminalReporter
- _pytest.warning_types.PytestConfigWarning
- _pytest.warning_types.warn_explicit_for
- argparse
- argparsing.Argument
- argparsing.FILE_OR_DIR
- argparsing.Parser
- builtins
- collections.abc
- compat.PathAwareHookProxy
- copy
- dataclasses
- enum
- exceptions.PrintHelp
- exceptions.UsageError
- findpaths.determine_setup
- functools.lru_cache
- glob
- inspect
- os
- packaging.requirements.InvalidRequirement
- packaging.requirements.Requirement
- packaging.version.Version
- pathlib.Path
- pluggy.HookimplMarker
- pluggy.HookspecMarker
- pluggy.PluginManager
- pytest
- re
- shlex
- sys
- textwrap.dedent
- types
- types.FunctionType
- types.TracebackType
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generator
- typing.IO
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.TextIO
- typing.Tuple
- typing.Type
- typing.Union
- typing.cast
- warnings

**Functions:**

### `def filter_traceback_for_conftest_import_failure(entry: _pytest._code.TracebackEntry) -> bool`

**Description:**
Filter tracebacks entries which point to pytest internals or importlib.

Make a special case for importlib because we use it to import test modules and conftest files
in _pytest.pathlib.import_path.

**Line:** 124

---

### `def main(args: Optional[Union[(List[str], 'os.PathLike[str]')]] = None, plugins: Optional[Sequence[Union[(str, _PluggyPlugin)]]] = None) -> Union[(int, ExitCode)]`

**Description:**
Perform an in-process test run.

:param args:
List of command line arguments. If `None` or not given, defaults to reading
arguments directly from the process command line (:data:`sys.argv`).
:param plugins: List of plugin objects to be auto-registered during initialization.

:returns: An exit code.

**Line:** 135

---

### `def console_main() -> int`

**Description:**
The CLI entry point of pytest.

This function is not meant for programmable use; use `main()` instead.

**Line:** 185

---

### `def filename_arg(path: str, optname: str) -> str`

**Description:**
Argparse type validator for filename arguments.

:path: Path of filename.
:optname: Name of the option.

**Line:** 207

---

### `def directory_arg(path: str, optname: str) -> str`

**Description:**
Argparse type validator for directory arguments.

:path: Path of directory.
:optname: Name of the option.

**Line:** 218

---

### `def get_config(args: Optional[List[str]] = None, plugins: Optional[Sequence[Union[(str, _PluggyPlugin)]]] = None) -> 'Config'`

**Line:** 272

---

### `def get_plugin_manager() -> 'PytestPluginManager'`

**Description:**
Obtain a new instance of the
:py:class:`pytest.PytestPluginManager`, with default plugins
already loaded.

This function can be used by integration with other tools, like hooking
into pytest to run tests into an IDE.

**Line:** 297

---

### `def _prepareconfig(args: Optional[Union[(List[str], 'os.PathLike[str]')]] = None, plugins: Optional[Sequence[Union[(str, _PluggyPlugin)]]] = None) -> 'Config'`

**Line:** 308

---

### `def _get_directory(path: Path) -> Path`

**Description:**
Get the directory of a path - itself if already a directory.

**Line:** 340

---

### `def _get_legacy_hook_marks(method: Any, hook_type: str, opt_names: Tuple[(str, ...)]) -> Dict[(str, bool)]`

**Line:** 348

---

### `def _get_plugin_specs_as_list(specs: Union[(None, types.ModuleType, str, Sequence[str])]) -> List[str]`

**Description:**
Parse a plugins specification into a list of plugin names.

**Line:** 794

---

### `def _ensure_removed_sysmodule(modname: str) -> None`

**Line:** 816

---

### `def _iter_rewritable_modules(package_files: Iterable[str]) -> Iterator[str]`

**Description:**
Given an iterable of file names in a source distribution, return the "names" that should
be marked for assertion rewrite.

For example the package "pytest_mock/__init__.py" should be added as "pytest_mock" in
the assertion rewrite mechanism.

This function has to deal with dist-info based distributions and egg based distributions
(which are still very much in use for "editable" installs).

Here are the file names as seen in a dist-info based distribution:

pytest_mock/__init__.py
pytest_mock/_version.py
pytest_mock/plugin.py
pytest_mock.egg-info/PKG-INFO

Here are the file names as seen in an egg based distribution:

src/pytest_mock/__init__.py
src/pytest_mock/_version.py
src/pytest_mock/plugin.py
src/pytest_mock.egg-info/PKG-INFO
LICENSE
setup.py

We have to take in account those two distribution flavors in order to determine which
names should be considered for assertion rewriting.

More information:
https://github.com/pytest-dev/pytest-mock/issues/167

**Line:** 831

---

### `def _assertion_supported() -> bool`

**Line:** 1661

---

### `def create_terminal_writer(config: Config, file: Optional[TextIO] = None) -> TerminalWriter`

**Description:**
Create a TerminalWriter instance configured according to the options
in the config object.

Every code which requires a TerminalWriter object and has access to a
config object should use this function.

**Line:** 1670

---

### `def _strtobool(val: str) -> bool`

**Description:**
Convert a string representation of truth to True or False.

True values are 'y', 'yes', 't', 'true', 'on', and '1'; false values
are 'n', 'no', 'f', 'false', 'off', and '0'.  Raises ValueError if
'val' is anything else.

.. note:: Copied from distutils.util.

**Line:** 1694

---

### `def parse_warning_filter(arg: str, escape: bool) -> Tuple[('warnings._ActionKind', str, Type[Warning], str, int)]`

**Decorators:**
- `@lru_cache(...)`

**Description:**
Parse a warnings filter string.

This is copied from warnings._setoption with the following changes:

* Does not apply the filter.
* Escaping is optional.
* Raises UsageError so we get nice error messages on failure.

**Line:** 1713

---

### `def _resolve_warning_category(category: str) -> Type[Warning]`

**Description:**
Copied from warnings._getcategory, but changed so it lets exceptions (specially ImportErrors)
propagate so we can get access to their tracebacks (#9218).

**Line:** 1784

---

### `def apply_warning_filters(config_filters: Iterable[str], cmdline_filters: Iterable[str]) -> None`

**Description:**
Applies pytest-configured filters to the warnings module

**Line:** 1806

---


## Module: venv2.libthon3.12.site-packages._pytest.config.findpaths
**File:** `venv2/lib/python3.12/site-packages/_pytest/config/findpaths.py`

**Imports:**
- _pytest.outcomes.fail
- _pytest.pathlib.absolutepath
- _pytest.pathlib.commonpath
- _pytest.pathlib.safe_exists
- exceptions.UsageError
- iniconfig
- os
- pathlib.Path
- sys
- tomli
- tomllib
- typing.Dict
- typing.Iterable
- typing.List
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union

**Functions:**

### `def _parse_ini_config(path: Path) -> iniconfig.IniConfig`

**Description:**
Parse the given generic '.ini' file using legacy IniConfig parser, returning
the parsed object.

Raise UsageError if the file cannot be parsed.

**Line:** 25

---

### `def load_config_dict_from_file(filepath: Path) -> Optional[Dict[(str, Union[str, List[str]])]]`

**Description:**
Load pytest configuration from the given file path, if supported.

Return None if the file does not contain valid pytest configuration.

**Line:** 37

---

### `def locate_config(args: Iterable[Path]) -> Tuple[(Optional[Path], Optional[Path], Dict[str, Union[str, List[str]]])]`

**Description:**
Search in the list of arguments for a valid ini-file for pytest,
and return a tuple of (rootdir, inifile, cfg-dict).

**Line:** 93

---

### `def get_common_ancestor(paths: Iterable[Path]) -> Path`

**Line:** 120

---

### `def get_dirs_from_args(args: Iterable[str]) -> List[Path]`

**Line:** 143

---

### `def determine_setup(inifile: Optional[str], args: Sequence[str], rootdir_cmd_arg: Optional[str] = None, config: Optional['Config'] = None) -> Tuple[(Path, Optional[Path], Dict[str, Union[str, List[str]]])]`

**Line:** 168

---

### `def is_fs_root(p: Path) -> bool`

**Description:**
Return True if the given path is pointing to the root of the
file system ("/" on Unix and "C:\\" on Windows for example).

**Line:** 213

---


## Module: venv2.libthon3.12.site-packages._pytest.debugging
**File:** `venv2/lib/python3.12/site-packages/_pytest/debugging.py`

**Imports:**
- _pytest._code.ExceptionInfo
- _pytest.capture.CaptureManager
- _pytest.config
- _pytest.config.Config
- _pytest.config.ConftestImportFailure
- _pytest.config.PytestPluginManager
- _pytest.config.argparsing.Parser
- _pytest.config.exceptions.UsageError
- _pytest.config.hookimpl
- _pytest.nodes.Node
- _pytest.outcomes
- _pytest.reports.BaseReport
- _pytest.runner.CallInfo
- argparse
- doctest.UnexpectedException
- functools
- pdb
- sys
- types
- typing.Any
- typing.Callable
- typing.Generator
- typing.List
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.Union
- unittest

**Functions:**

### `def _validate_usepdb_cls(value: str) -> Tuple[(str, str)]`

**Description:**
Validate syntax of --pdbcls option.

**Line:** 33

---

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 44

---

### `def pytest_configure(config: Config) -> None`

**Line:** 68

---

### `def wrap_pytest_function_for_tracing(pyfuncitem)`

**Description:**
Change the Python function object of the given Function item by a
wrapper which actually enters pdb before calling the python function
itself, effectively leaving the user in the pdb prompt in the first
statement of the function.

**Line:** 313

---

### `def maybe_wrap_pytest_function_for_tracing(pyfuncitem)`

**Description:**
Wrap the given pytestfunct item for tracing support if --trace was given in
the command line.

**Line:** 332

---

### `def _enter_pdb(node: Node, excinfo: ExceptionInfo[BaseException], rep: BaseReport) -> BaseReport`

**Line:** 339

---

### `def _postmortem_traceback(excinfo: ExceptionInfo[BaseException]) -> types.TracebackType`

**Line:** 370

---

### `def post_mortem(t: types.TracebackType) -> None`

**Line:** 386

---


## Module: venv2.libthon3.12.site-packages._pytest.deprecated
**File:** `venv2/lib/python3.12/site-packages/_pytest/deprecated.py`

**Imports:**
- _pytest.warning_types.PytestDeprecationWarning
- _pytest.warning_types.PytestRemovedIn8Warning
- _pytest.warning_types.UnformattedWarning
- warnings.warn

**Functions:**

### `def check_ispytest(ispytest: bool) -> None`

**Line:** 144

---


## Module: venv2.libthon3.12.site-packages._pytest.doctest
**File:** `venv2/lib/python3.12/site-packages/_pytest/doctest.py`

**Imports:**
- _pytest._code.code.ExceptionInfo
- _pytest._code.code.ReprFileLocation
- _pytest._code.code.TerminalRepr
- _pytest._io.TerminalWriter
- _pytest.compat.safe_getattr
- _pytest.config.Config
- _pytest.config.argparsing.Parser
- _pytest.fixtures.FixtureRequest
- _pytest.fixtures.fixture
- _pytest.nodes.Collector
- _pytest.nodes.Item
- _pytest.outcomes
- _pytest.outcomes.OutcomeException
- _pytest.outcomes.skip
- _pytest.pathlib.fnmatch_ex
- _pytest.pathlib.import_path
- _pytest.python.Module
- _pytest.python_api.approx
- _pytest.warning_types.PytestWarning
- bdb
- contextlib.contextmanager
- doctest
- functools
- inspect
- os
- pathlib.Path
- platform
- re
- sys
- traceback
- types
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generator
- typing.Iterable
- typing.List
- typing.Optional
- typing.Pattern
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.Union
- warnings

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 70

---

### `def pytest_unconfigure() -> None`

**Line:** 120

---

### `def pytest_collect_file(file_path: Path, parent: Collector) -> Optional[Union[('DoctestModule', 'DoctestTextfile')]]`

**Line:** 126

---

### `def _is_setup_py(path: Path) -> bool`

**Line:** 143

---

### `def _is_doctest(config: Config, path: Path, parent: Collector) -> bool`

**Line:** 150

---

### `def _is_main_py(path: Path) -> bool`

**Line:** 157

---

### `def _init_runner_class() -> Type['doctest.DocTestRunner']`

**Line:** 180

---

### `def _get_runner(checker: Optional['doctest.OutputChecker'] = None, verbose: Optional[bool] = None, optionflags: int = 0, continue_on_failure: bool = True) -> 'doctest.DocTestRunner'`

**Line:** 233

---

### `def _get_flag_lookup() -> Dict[(str, int)]`

**Line:** 383

---

### `def get_optionflags(parent)`

**Line:** 399

---

### `def _get_continue_on_failure(config)`

**Line:** 408

---

### `def _check_all_skipped(test: 'doctest.DocTest') -> None`

**Description:**
Raise pytest.skip() if all examples in the given DocTest have the SKIP
option set.

**Line:** 449

---

### `def _is_mocked(obj: object) -> bool`

**Description:**
Return if an object is possibly a mock object by checking the
existence of a highly improbable attribute.

**Line:** 459

---

### `def _patch_unwrap_mock_aware() -> Generator[(None, None, None)]`

**Decorators:**
- `@contextmanager`

**Description:**
Context manager which replaces ``inspect.unwrap`` with a version
that's aware of mock objects and doesn't recurse into them.

**Line:** 469

---

### `def _setup_fixtures(doctest_item: DoctestItem) -> FixtureRequest`

**Description:**
Used by DoctestTextfile and DoctestItem to setup fixture information.

**Line:** 594

---

### `def _init_checker_class() -> Type['doctest.OutputChecker']`

**Line:** 610

---

### `def _get_checker() -> 'doctest.OutputChecker'`

**Description:**
Return a doctest.OutputChecker subclass that supports some
additional options:

* ALLOW_UNICODE and ALLOW_BYTES options to ignore u'' and b''
prefixes (respectively) in string literals. Useful when the same
doctest should run in Python 2 and Python 3.

* NUMBER to ignore floating-point differences smaller than the
precision of the literal number in the doctest.

An inner class is used to avoid importing "doctest" at the module
level.

**Line:** 698

---

### `def _get_allow_unicode_flag() -> int`

**Description:**
Register and return the ALLOW_UNICODE flag.

**Line:** 718

---

### `def _get_allow_bytes_flag() -> int`

**Description:**
Register and return the ALLOW_BYTES flag.

**Line:** 725

---

### `def _get_number_flag() -> int`

**Description:**
Register and return the NUMBER flag.

**Line:** 732

---

### `def _get_report_choice(key: str) -> int`

**Description:**
Return the actual `doctest` module flag value.

We want to do it as late as possible to avoid importing `doctest` and all
its dependencies when parsing options, as it adds overhead and breaks tests.

**Line:** 739

---

### `def doctest_namespace() -> Dict[(str, Any)]`

**Decorators:**
- `@fixture(...)`

**Description:**
Fixture that returns a :py:class:`dict` that will be injected into the
namespace of doctests.

Usually this fixture is used in conjunction with another ``autouse`` fixture:

.. code-block:: python

@pytest.fixture(autouse=True)
def add_np(doctest_namespace):
doctest_namespace["np"] = numpy

For more details: :ref:`doctest_namespace`.

**Line:** 757

---


## Module: venv2.libthon3.12.site-packages._pytest.faulthandler
**File:** `venv2/lib/python3.12/site-packages/_pytest/faulthandler.py`

**Imports:**
- _pytest.config.Config
- _pytest.config.argparsing.Parser
- _pytest.nodes.Item
- _pytest.stash.StashKey
- faulthandler
- os
- pytest
- sys
- typing.Generator

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 16

---

### `def pytest_configure(config: Config) -> None`

**Line:** 24

---

### `def pytest_unconfigure(config: Config) -> None`

**Line:** 32

---

### `def get_stderr_fileno() -> int`

**Line:** 45

---

### `def get_timeout_config_value(config: Config) -> float`

**Line:** 60

---

### `def pytest_runtest_protocol(item: Item) -> Generator[(None, None, None)]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 65

---

### `def pytest_enter_pdb() -> None`

**Decorators:**
- `@pytest.hookimpl(...)`

**Description:**
Cancel any traceback dumping due to timeout before entering pdb.

**Line:** 81

---

### `def pytest_exception_interact() -> None`

**Decorators:**
- `@pytest.hookimpl(...)`

**Description:**
Cancel any traceback dumping due to an interactive exception being
raised.

**Line:** 89

---


## Module: venv2.libthon3.12.site-packages._pytest.fixtures
**File:** `venv2/lib/python3.12/site-packages/_pytest/fixtures.py`

**Imports:**
- _pytest
- _pytest._code.code.FormattedExcinfo
- _pytest._code.code.TerminalRepr
- _pytest._code.getfslineno
- _pytest._io.TerminalWriter
- _pytest.compat.NOTSET
- _pytest.compat.NotSetType
- _pytest.compat._PytestWrapper
- _pytest.compat._format_args
- _pytest.compat.assert_never
- _pytest.compat.final
- _pytest.compat.get_real_func
- _pytest.compat.get_real_method
- _pytest.compat.getfuncargnames
- _pytest.compat.getimfunc
- _pytest.compat.getlocation
- _pytest.compat.is_generator
- _pytest.compat.overload
- _pytest.compat.safe_getattr
- _pytest.config.Config
- _pytest.config._PluggyPlugin
- _pytest.config.argparsing.Parser
- _pytest.deprecated.YIELD_FIXTURE
- _pytest.deprecated.check_ispytest
- _pytest.main.Session
- _pytest.mark.Mark
- _pytest.mark.ParameterSet
- _pytest.mark.structures.MarkDecorator
- _pytest.nodes
- _pytest.outcomes.TEST_OUTCOME
- _pytest.outcomes.fail
- _pytest.outcomes.skip
- _pytest.pathlib.absolutepath
- _pytest.pathlib.bestrelpath
- _pytest.python
- _pytest.python.CallSpec2
- _pytest.python.Metafunc
- _pytest.python.Package
- _pytest.scope.HIGH_SCOPES
- _pytest.scope.Scope
- _pytest.scope._ScopeName
- _pytest.stash.StashKey
- collections.defaultdict
- collections.deque
- contextlib.suppress
- dataclasses
- functools
- inspect
- os
- pathlib.Path
- sys
- types.TracebackType
- typing.Any
- typing.Callable
- typing.Deque
- typing.Dict
- typing.Generator
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.List
- typing.MutableMapping
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- warnings

**Functions:**

### `def pytest_sessionstart(session: 'Session') -> None`

**Line:** 112

---

### `def get_scope_package(node: nodes.Item, fixturedef: 'FixtureDef[object]') -> Optional[Union[(nodes.Item, nodes.Collector)]]`

**Line:** 116

---

### `def get_scope_node(node: nodes.Node, scope: Scope) -> Optional[Union[(nodes.Item, nodes.Collector)]]`

**Line:** 133

---

### `def add_funcarg_pseudo_fixture_def(collector: nodes.Collector, metafunc: 'Metafunc', fixturemanager: 'FixtureManager') -> None`

**Line:** 156

---

### `def getfixturemarker(obj: object) -> Optional['FixtureFunctionMarker']`

**Description:**
Return fixturemarker or None if it doesn't exist or raised
exceptions.

**Line:** 226

---

### `def get_parametrized_fixture_keys(item: nodes.Item, scope: Scope) -> Iterator[_Key]`

**Description:**
Return list of keys for all parametrized arguments which match
the specified scope.

**Line:** 239

---

### `def reorder_items(items: Sequence[nodes.Item]) -> List[nodes.Item]`

**Line:** 275

---

### `def fix_cache_order(item: nodes.Item, argkeys_cache: Dict[(Scope, Dict[nodes.Item, Dict[_Key, None]])], items_by_argkey: Dict[(Scope, Dict[_Key, 'Deque[nodes.Item]'])]) -> None`

**Line:** 295

---

### `def reorder_items_atscope(items: Dict[(nodes.Item, None)], argkeys_cache: Dict[(Scope, Dict[nodes.Item, Dict[_Key, None]])], items_by_argkey: Dict[(Scope, Dict[_Key, 'Deque[nodes.Item]'])], scope: Scope) -> Dict[(nodes.Item, None)]`

**Line:** 305

---

### `def get_direct_param_fixture_func(request: 'FixtureRequest') -> Any`

**Line:** 351

---

### `def fail_fixturefunc(fixturefunc, msg: str) -> NoReturn`

**Line:** 879

---

### `def call_fixture_func(fixturefunc: '_FixtureFunc[FixtureValue]', request: FixtureRequest, kwargs) -> FixtureValue`

**Line:** 886

---

### `def _teardown_yield_fixture(fixturefunc, it) -> None`

**Description:**
Execute the teardown of a fixture function by advancing the iterator
after the yield and ensure the iteration ends (if not it means there is
more than one yield in the function).

**Line:** 906

---

### `def _eval_scope_callable(scope_callable: 'Callable[[str, Config], _ScopeName]', fixture_name: str, config: Config) -> '_ScopeName'`

**Line:** 918

---

### `def resolve_fixture_function(fixturedef: FixtureDef[FixtureValue], request: FixtureRequest) -> '_FixtureFunc[FixtureValue]'`

**Description:**
Get the actual callable that can be called to obtain the fixture
value, dealing with unittest-specific instances and bound methods.

**Line:** 1081

---

### `def pytest_fixture_setup(fixturedef: FixtureDef[FixtureValue], request: SubRequest) -> FixtureValue`

**Description:**
Execution of fixture setup.

**Line:** 1108

---

### `def _ensure_immutable_ids(ids: Optional[Union[(Sequence[Optional[object]], Callable[[Any], Optional[object]])]]) -> Optional[Union[(Tuple[Optional[object], ...], Callable[[Any], Optional[object]])]]`

**Line:** 1137

---

### `def _params_converter(params: Optional[Iterable[object]]) -> Optional[Tuple[(object, ...)]]`

**Line:** 1147

---

### `def wrap_function_to_error_out_if_called_directly(function: FixtureFunction, fixture_marker: 'FixtureFunctionMarker') -> FixtureFunction`

**Description:**
Wrap the given fixture function so we can raise an error about it being called directly,
instead of used as an argument in a test function.

**Line:** 1153

---

### `def fixture(fixture_function: FixtureFunction, scope: 'Union[_ScopeName, Callable[[str, Config], _ScopeName]]' = Ellipsis, params: Optional[Iterable[object]] = Ellipsis, autouse: bool = Ellipsis, ids: Optional[Union[(Sequence[Optional[object]], Callable[[Any], Optional[object]])]] = Ellipsis, name: Optional[str] = Ellipsis) -> FixtureFunction`

**Decorators:**
- `@overload`

**Line:** 1220

---

### `def fixture(fixture_function: None = Ellipsis, scope: 'Union[_ScopeName, Callable[[str, Config], _ScopeName]]' = Ellipsis, params: Optional[Iterable[object]] = Ellipsis, autouse: bool = Ellipsis, ids: Optional[Union[(Sequence[Optional[object]], Callable[[Any], Optional[object]])]] = Ellipsis, name: Optional[str] = None) -> FixtureFunctionMarker`

**Decorators:**
- `@overload`

**Line:** 1235

---

### `def fixture(fixture_function: Optional[FixtureFunction] = None, scope: 'Union[_ScopeName, Callable[[str, Config], _ScopeName]]' = 'function', params: Optional[Iterable[object]] = None, autouse: bool = False, ids: Optional[Union[(Sequence[Optional[object]], Callable[[Any], Optional[object]])]] = None, name: Optional[str] = None) -> Union[(FixtureFunctionMarker, FixtureFunction)]`

**Description:**
Decorator to mark a fixture factory function.

This decorator can be used, with or without parameters, to define a
fixture function.

The name of the fixture function can later be referenced to cause its
invocation ahead of running tests: test modules or classes can use the
``pytest.mark.usefixtures(fixturename)`` marker.

Test functions can directly use fixture names as input arguments in which
case the fixture instance returned from the fixture function will be
injected.

Fixtures can provide their values to test functions using ``return`` or
``yield`` statements. When using ``yield`` the code block after the
``yield`` statement is executed as teardown code regardless of the test
outcome, and must yield exactly once.

:param scope:
The scope for which this fixture is shared; one of ``"function"``
(default), ``"class"``, ``"module"``, ``"package"`` or ``"session"``.

This parameter may also be a callable which receives ``(fixture_name, config)``
as parameters, and must return a ``str`` with one of the values mentioned above.

See :ref:`dynamic scope` in the docs for more information.

:param params:
An optional list of parameters which will cause multiple invocations
of the fixture function and all of the tests using it. The current
parameter is available in ``request.param``.

:param autouse:
If True, the fixture func is activated for all tests that can see it.
If False (the default), an explicit reference is needed to activate
the fixture.

:param ids:
Sequence of ids each corresponding to the params so that they are
part of the test id. If no ids are provided they will be generated
automatically from the params.

:param name:
The name of the fixture. This defaults to the name of the decorated
function. If a fixture is used in the same module in which it is
defined, the function name of the fixture will be shadowed by the
function arg that requests the fixture; one way to resolve this is to
name the decorated function ``fixture_<fixturename>`` and then use
``@pytest.fixture(name='<fixturename>')``.

**Line:** 1249

---

### `def yield_fixture(fixture_function = None, scope = 'function', params = None, autouse = False, ids = None, name = None, *args)`

**Description:**
(Return a) decorator to mark a yield-fixture factory function.

.. deprecated:: 3.0
Use :py:func:`pytest.fixture` directly instead.

**Line:** 1326

---

### `def pytestconfig(request: FixtureRequest) -> Config`

**Decorators:**
- `@fixture(...)`

**Description:**
Session-scoped fixture that returns the session's :class:`pytest.Config`
object.

Example::

def test_foo(pytestconfig):
if pytestconfig.getoption("verbose") > 0:
...

**Line:** 1353

---

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 1367

---


## Module: venv2.libthon3.12.site-packages._pytest.freeze_support
**File:** `venv2/lib/python3.12/site-packages/_pytest/freeze_support.py`

**Imports:**
- _pytest
- os
- pkgutil
- types
- typing.Iterator
- typing.List
- typing.Union

**Functions:**

### `def freeze_includes() -> List[str]`

**Description:**
Return a list of module names used by pytest that should be
included by cx_freeze.

**Line:** 9

---

### `def _iter_all_modules(package: Union[(str, types.ModuleType)], prefix: str = '') -> Iterator[str]`

**Description:**
Iterate over the names of all modules that can be found in the given
package, recursively.

>>> import _pytest
>>> list(_iter_all_modules(_pytest))
['_pytest._argcomplete', '_pytest._code.code', ...]

**Line:** 18

---


## Module: venv2.libthon3.12.site-packages._pytest.helpconfig
**File:** `venv2/lib/python3.12/site-packages/_pytest/helpconfig.py`

**Imports:**
- _pytest.config.Config
- _pytest.config.ExitCode
- _pytest.config.PrintHelp
- _pytest.config.argparsing.Parser
- _pytest.terminal.TerminalReporter
- argparse.Action
- os
- pytest
- sys
- textwrap
- typing.List
- typing.Optional
- typing.Union

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 45

---

### `def pytest_cmdline_parse()`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 102

---

### `def showversion(config: Config) -> None`

**Line:** 133

---

### `def pytest_cmdline_main(config: Config) -> Optional[Union[(int, ExitCode)]]`

**Line:** 148

---

### `def showhelp(config: Config) -> None`

**Line:** 160

---

### `def getpluginversioninfo(config: Config) -> List[str]`

**Line:** 240

---

### `def pytest_report_header(config: Config) -> List[str]`

**Line:** 252

---


## Module: venv2.libthon3.12.site-packages._pytest.hookspec
**File:** `venv2/lib/python3.12/site-packages/_pytest/hookspec.py`

**Imports:**
- _pytest._code.code.ExceptionInfo
- _pytest._code.code.ExceptionRepr
- _pytest.compat.LEGACY_PATH
- _pytest.config.Config
- _pytest.config.ExitCode
- _pytest.config.PytestPluginManager
- _pytest.config._PluggyPlugin
- _pytest.config.argparsing.Parser
- _pytest.deprecated.WARNING_CMDLINE_PREPARSE_HOOK
- _pytest.fixtures.FixtureDef
- _pytest.fixtures.SubRequest
- _pytest.main.Session
- _pytest.nodes.Collector
- _pytest.nodes.Item
- _pytest.outcomes.Exit
- _pytest.python.Class
- _pytest.python.Function
- _pytest.python.Metafunc
- _pytest.python.Module
- _pytest.reports.CollectReport
- _pytest.reports.TestReport
- _pytest.runner.CallInfo
- _pytest.terminal.TerminalReporter
- _pytest.terminal.TestShortLogReport
- pathlib.Path
- pdb
- pluggy.HookspecMarker
- typing.Any
- typing.Dict
- typing.List
- typing.Mapping
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- typing_extensions.Literal
- warnings

**Functions:**

### `def pytest_addhooks(pluginmanager: 'PytestPluginManager') -> None`

**Decorators:**
- `@hookspec(...)`

**Description:**
Called at plugin registration time to allow adding new hooks via a call to
``pluginmanager.add_hookspecs(module_or_class, prefix)``.

:param pytest.PytestPluginManager pluginmanager: The pytest plugin manager.

.. note::
This hook is incompatible with ``hookwrapper=True``.

**Line:** 56

---

### `def pytest_plugin_registered(plugin: '_PluggyPlugin', manager: 'PytestPluginManager') -> None`

**Decorators:**
- `@hookspec(...)`

**Description:**
A new pytest plugin got registered.

:param plugin: The plugin module or instance.
:param pytest.PytestPluginManager manager: pytest plugin manager.

.. note::
This hook is incompatible with ``hookwrapper=True``.

**Line:** 68

---

### `def pytest_addoption(parser: 'Parser', pluginmanager: 'PytestPluginManager') -> None`

**Decorators:**
- `@hookspec(...)`

**Description:**
Register argparse-style options and ini-style config values,
called once at the beginning of a test run.

.. note::

This function should be implemented only in plugins or ``conftest.py``
files situated at the tests root directory due to how pytest
:ref:`discovers plugins during startup <pluginorder>`.

:param pytest.Parser parser:
To add command line options, call
:py:func:`parser.addoption(...) <pytest.Parser.addoption>`.
To add ini-file values call :py:func:`parser.addini(...)
<pytest.Parser.addini>`.

:param pytest.PytestPluginManager pluginmanager:
The pytest plugin manager, which can be used to install :py:func:`hookspec`'s
or :py:func:`hookimpl`'s and allow one plugin to call another plugin's hooks
to change how command line options are added.

Options can later be accessed through the
:py:class:`config <pytest.Config>` object, respectively:

- :py:func:`config.getoption(name) <pytest.Config.getoption>` to
retrieve the value of a command line option.

- :py:func:`config.getini(name) <pytest.Config.getini>` to retrieve
a value read from an ini-style file.

The config object is passed around on many internal objects via the ``.config``
attribute or can be retrieved as the ``pytestconfig`` fixture.

.. note::
This hook is incompatible with ``hookwrapper=True``.

**Line:** 82

---

### `def pytest_configure(config: 'Config') -> None`

**Decorators:**
- `@hookspec(...)`

**Description:**
Allow plugins and conftest files to perform initial configuration.

This hook is called for every plugin and initial conftest file
after command line options have been parsed.

After that, the hook is called for other conftest files as they are
imported.

.. note::
This hook is incompatible with ``hookwrapper=True``.

:param pytest.Config config: The pytest config object.

**Line:** 121

---

### `def pytest_cmdline_parse(pluginmanager: 'PytestPluginManager', args: List[str]) -> Optional['Config']`

**Decorators:**
- `@hookspec(...)`

**Description:**
Return an initialized :class:`~pytest.Config`, parsing the specified args.

Stops at first non-None result, see :ref:`firstresult`.

.. note::
This hook will only be called for plugin classes passed to the
``plugins`` arg when using `pytest.main`_ to perform an in-process
test run.

:param pluginmanager: The pytest plugin manager.
:param args: List of arguments passed on the command line.
:returns: A pytest config object.

**Line:** 144

---

### `def pytest_cmdline_preparse(config: 'Config', args: List[str]) -> None`

**Decorators:**
- `@hookspec(...)`

**Description:**
(**Deprecated**) modify command line arguments before option parsing.

This hook is considered deprecated and will be removed in a future pytest version. Consider
using :hook:`pytest_load_initial_conftests` instead.

.. note::
This hook will not be called for ``conftest.py`` files, only for setuptools plugins.

:param config: The pytest config object.
:param args: Arguments passed on the command line.

**Line:** 163

---

### `def pytest_cmdline_main(config: 'Config') -> Optional[Union[('ExitCode', int)]]`

**Decorators:**
- `@hookspec(...)`

**Description:**
Called for performing the main command line action. The default
implementation will invoke the configure hooks and runtest_mainloop.

Stops at first non-None result, see :ref:`firstresult`.

:param config: The pytest config object.
:returns: The exit code.

**Line:** 178

---

### `def pytest_load_initial_conftests(early_config: 'Config', parser: 'Parser', args: List[str]) -> None`

**Description:**
Called to implement the loading of initial conftest files ahead
of command line option parsing.

.. note::
This hook will not be called for ``conftest.py`` files, only for setuptools plugins.

:param early_config: The pytest config object.
:param args: Arguments passed on the command line.
:param parser: To add command line options.

**Line:** 189

---

### `def pytest_collection(session: 'Session') -> Optional[object]`

**Decorators:**
- `@hookspec(...)`

**Description:**
Perform the collection phase for the given session.

Stops at first non-None result, see :ref:`firstresult`.
The return value is not used, but only stops further processing.

The default collection phase is this (see individual hooks for full details):

1. Starting from ``session`` as the initial collector:

1. ``pytest_collectstart(collector)``
2. ``report = pytest_make_collect_report(collector)``
3. ``pytest_exception_interact(collector, call, report)`` if an interactive exception occurred
4. For each collected node:

1. If an item, ``pytest_itemcollected(item)``
2. If a collector, recurse into it.

5. ``pytest_collectreport(report)``

2. ``pytest_collection_modifyitems(session, config, items)``

1. ``pytest_deselected(items)`` for any deselected items (may be called multiple times)

3. ``pytest_collection_finish(session)``
4. Set ``session.items`` to the list of collected items
5. Set ``session.testscollected`` to the number of collected items

You can implement this hook to only perform some action before collection,
for example the terminal plugin uses it to start displaying the collection
counter (and returns `None`).

:param session: The pytest session object.

**Line:** 210

---

### `def pytest_collection_modifyitems(session: 'Session', config: 'Config', items: List['Item']) -> None`

**Description:**
Called after collection has been performed. May filter or re-order
the items in-place.

:param session: The pytest session object.
:param config: The pytest config object.
:param items: List of item objects.

**Line:** 246

---

### `def pytest_collection_finish(session: 'Session') -> None`

**Description:**
Called after collection has been performed and modified.

:param session: The pytest session object.

**Line:** 258

---

### `def pytest_ignore_collect(collection_path: Path, path: 'LEGACY_PATH', config: 'Config') -> Optional[bool]`

**Decorators:**
- `@hookspec(...)`

**Description:**
Return True to prevent considering this path for collection.

This hook is consulted for all files and directories prior to calling
more specific hooks.

Stops at first non-None result, see :ref:`firstresult`.

:param collection_path: The path to analyze.
:param path: The path to analyze (deprecated).
:param config: The pytest config object.

.. versionchanged:: 7.0.0
The ``collection_path`` parameter was added as a :class:`pathlib.Path`
equivalent of the ``path`` parameter. The ``path`` parameter
has been deprecated.

**Line:** 266

---

### `def pytest_collect_file(file_path: Path, path: 'LEGACY_PATH', parent: 'Collector') -> 'Optional[Collector]'`

**Description:**
Create a :class:`~pytest.Collector` for the given path, or None if not relevant.

The new node needs to have the specified ``parent`` as a parent.

:param file_path: The path to analyze.
:param path: The path to collect (deprecated).

.. versionchanged:: 7.0.0
The ``file_path`` parameter was added as a :class:`pathlib.Path`
equivalent of the ``path`` parameter. The ``path`` parameter
has been deprecated.

**Line:** 287

---

### `def pytest_collectstart(collector: 'Collector') -> None`

**Description:**
Collector starts collecting.

:param collector:
The collector.

**Line:** 307

---

### `def pytest_itemcollected(item: 'Item') -> None`

**Description:**
We just collected a test item.

:param item:
The item.

**Line:** 315

---

### `def pytest_collectreport(report: 'CollectReport') -> None`

**Description:**
Collector finished collecting.

:param report:
The collect report.

**Line:** 323

---

### `def pytest_deselected(items: Sequence['Item']) -> None`

**Description:**
Called for deselected test items, e.g. by keyword.

May be called multiple times.

:param items:
The items.

**Line:** 331

---

### `def pytest_make_collect_report(collector: 'Collector') -> 'Optional[CollectReport]'`

**Decorators:**
- `@hookspec(...)`

**Description:**
Perform :func:`collector.collect() <pytest.Collector.collect>` and return
a :class:`~pytest.CollectReport`.

Stops at first non-None result, see :ref:`firstresult`.

:param collector:
The collector.

**Line:** 342

---

### `def pytest_pycollect_makemodule(module_path: Path, path: 'LEGACY_PATH', parent) -> Optional['Module']`

**Decorators:**
- `@hookspec(...)`

**Description:**
Return a :class:`pytest.Module` collector or None for the given path.

This hook will be called for each matching test module path.
The :hook:`pytest_collect_file` hook needs to be used if you want to
create test modules for files that do not match as a test module.

Stops at first non-None result, see :ref:`firstresult`.

:param module_path: The path of the module to collect.
:param path: The path of the module to collect (deprecated).

.. versionchanged:: 7.0.0
The ``module_path`` parameter was added as a :class:`pathlib.Path`
equivalent of the ``path`` parameter.

The ``path`` parameter has been deprecated in favor of ``fspath``.

**Line:** 359

---

### `def pytest_pycollect_makeitem(collector: Union[('Module', 'Class')], name: str, obj: object) -> Union[(None, 'Item', 'Collector', List[Union['Item', 'Collector']])]`

**Decorators:**
- `@hookspec(...)`

**Description:**
Return a custom item/collector for a Python object in a module, or None.

Stops at first non-None result, see :ref:`firstresult`.

:param collector:
The module/class collector.
:param name:
The name of the object in the module/class.
:param obj:
The object.
:returns:
The created items/collectors.

**Line:** 382

---

### `def pytest_pyfunc_call(pyfuncitem: 'Function') -> Optional[object]`

**Decorators:**
- `@hookspec(...)`

**Description:**
Call underlying test function.

Stops at first non-None result, see :ref:`firstresult`.

:param pyfuncitem:
The function item.

**Line:** 401

---

### `def pytest_generate_tests(metafunc: 'Metafunc') -> None`

**Description:**
Generate (multiple) parametrized calls to a test function.

:param metafunc:
The :class:`~pytest.Metafunc` helper for the test function.

**Line:** 411

---

### `def pytest_make_parametrize_id(config: 'Config', val: object, argname: str) -> Optional[str]`

**Decorators:**
- `@hookspec(...)`

**Description:**
Return a user-friendly string representation of the given ``val``
that will be used by @pytest.mark.parametrize calls, or None if the hook
doesn't know about ``val``.

The parameter name is available as ``argname``, if required.

Stops at first non-None result, see :ref:`firstresult`.

:param config: The pytest config object.
:param val: The parametrized value.
:param str argname: The automatic parameter name produced by pytest.

**Line:** 420

---

### `def pytest_runtestloop(session: 'Session') -> Optional[object]`

**Decorators:**
- `@hookspec(...)`

**Description:**
Perform the main runtest loop (after collection finished).

The default hook implementation performs the runtest protocol for all items
collected in the session (``session.items``), unless the collection failed
or the ``collectonly`` pytest option is set.

If at any point :py:func:`pytest.exit` is called, the loop is
terminated immediately.

If at any point ``session.shouldfail`` or ``session.shouldstop`` are set, the
loop is terminated after the runtest protocol for the current item is finished.

:param session: The pytest session object.

Stops at first non-None result, see :ref:`firstresult`.
The return value is not used, but only stops further processing.

**Line:** 443

---

### `def pytest_runtest_protocol(item: 'Item', nextitem: 'Optional[Item]') -> Optional[object]`

**Decorators:**
- `@hookspec(...)`

**Description:**
Perform the runtest protocol for a single test item.

The default runtest protocol is this (see individual hooks for full details):

- ``pytest_runtest_logstart(nodeid, location)``

- Setup phase:
- ``call = pytest_runtest_setup(item)`` (wrapped in ``CallInfo(when="setup")``)
- ``report = pytest_runtest_makereport(item, call)``
- ``pytest_runtest_logreport(report)``
- ``pytest_exception_interact(call, report)`` if an interactive exception occurred

- Call phase, if the the setup passed and the ``setuponly`` pytest option is not set:
- ``call = pytest_runtest_call(item)`` (wrapped in ``CallInfo(when="call")``)
- ``report = pytest_runtest_makereport(item, call)``
- ``pytest_runtest_logreport(report)``
- ``pytest_exception_interact(call, report)`` if an interactive exception occurred

- Teardown phase:
- ``call = pytest_runtest_teardown(item, nextitem)`` (wrapped in ``CallInfo(when="teardown")``)
- ``report = pytest_runtest_makereport(item, call)``
- ``pytest_runtest_logreport(report)``
- ``pytest_exception_interact(call, report)`` if an interactive exception occurred

- ``pytest_runtest_logfinish(nodeid, location)``

:param item: Test item for which the runtest protocol is performed.
:param nextitem: The scheduled-to-be-next test item (or None if this is the end my friend).

Stops at first non-None result, see :ref:`firstresult`.
The return value is not used, but only stops further processing.

**Line:** 464

---

### `def pytest_runtest_logstart(nodeid: str, location: Tuple[(str, Optional[int], str)]) -> None`

**Description:**
Called at the start of running the runtest protocol for a single item.

See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.

:param nodeid: Full node ID of the item.
:param location: A tuple of ``(filename, lineno, testname)``
where ``filename`` is a file path relative to ``config.rootpath``
and ``lineno`` is 0-based.

**Line:** 501

---

### `def pytest_runtest_logfinish(nodeid: str, location: Tuple[(str, Optional[int], str)]) -> None`

**Description:**
Called at the end of running the runtest protocol for a single item.

See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.

:param nodeid: Full node ID of the item.
:param location: A tuple of ``(filename, lineno, testname)``
where ``filename`` is a file path relative to ``config.rootpath``
and ``lineno`` is 0-based.

**Line:** 515

---

### `def pytest_runtest_setup(item: 'Item') -> None`

**Description:**
Called to perform the setup phase for a test item.

The default implementation runs ``setup()`` on ``item`` and all of its
parents (which haven't been setup yet). This includes obtaining the
values of fixtures required by the item (which haven't been obtained
yet).

:param item:
The item.

**Line:** 529

---

### `def pytest_runtest_call(item: 'Item') -> None`

**Description:**
Called to run the test for test item (the call phase).

The default implementation calls ``item.runtest()``.

:param item:
The item.

**Line:** 542

---

### `def pytest_runtest_teardown(item: 'Item', nextitem: Optional['Item']) -> None`

**Description:**
Called to perform the teardown phase for a test item.

The default implementation runs the finalizers and calls ``teardown()``
on ``item`` and all of its parents (which need to be torn down). This
includes running the teardown phase of fixtures required by the item (if
they go out of scope).

:param item:
The item.
:param nextitem:
The scheduled-to-be-next test item (None if no further test item is
scheduled). This argument is used to perform exact teardowns, i.e.
calling just enough finalizers so that nextitem only needs to call
setup functions.

**Line:** 552

---

### `def pytest_runtest_makereport(item: 'Item', call: 'CallInfo[None]') -> Optional['TestReport']`

**Decorators:**
- `@hookspec(...)`

**Description:**
Called to create a :class:`~pytest.TestReport` for each of
the setup, call and teardown runtest phases of a test item.

See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.

:param item: The item.
:param call: The :class:`~pytest.CallInfo` for the phase.

Stops at first non-None result, see :ref:`firstresult`.

**Line:** 571

---

### `def pytest_runtest_logreport(report: 'TestReport') -> None`

**Description:**
Process the :class:`~pytest.TestReport` produced for each
of the setup, call and teardown runtest phases of an item.

See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.

**Line:** 586

---

### `def pytest_report_to_serializable(config: 'Config', report: Union[('CollectReport', 'TestReport')]) -> Optional[Dict[(str, Any)]]`

**Decorators:**
- `@hookspec(...)`

**Description:**
Serialize the given report object into a data structure suitable for
sending over the wire, e.g. converted to JSON.

:param config: The pytest config object.
:param report: The report.

**Line:** 595

---

### `def pytest_report_from_serializable(config: 'Config', data: Dict[(str, Any)]) -> Optional[Union[('CollectReport', 'TestReport')]]`

**Decorators:**
- `@hookspec(...)`

**Description:**
Restore a report object previously serialized with
:hook:`pytest_report_to_serializable`.

:param config: The pytest config object.

**Line:** 608

---

### `def pytest_fixture_setup(fixturedef: 'FixtureDef[Any]', request: 'SubRequest') -> Optional[object]`

**Decorators:**
- `@hookspec(...)`

**Description:**
Perform fixture setup execution.

:param fixturdef:
The fixture definition object.
:param request:
The fixture request object.
:returns:
The return value of the call to the fixture function.

Stops at first non-None result, see :ref:`firstresult`.

.. note::
If the fixture function returns None, other implementations of
this hook function will continue to be called, according to the
behavior of the :ref:`firstresult` option.

**Line:** 625

---

### `def pytest_fixture_post_finalizer(fixturedef: 'FixtureDef[Any]', request: 'SubRequest') -> None`

**Description:**
Called after fixture teardown, but before the cache is cleared, so
the fixture result ``fixturedef.cached_result`` is still available (not
``None``).

:param fixturdef:
The fixture definition object.
:param request:
The fixture request object.

**Line:** 646

---

### `def pytest_sessionstart(session: 'Session') -> None`

**Description:**
Called after the ``Session`` object has been created and before performing collection
and entering the run test loop.

:param session: The pytest session object.

**Line:** 665

---

### `def pytest_sessionfinish(session: 'Session', exitstatus: Union[(int, 'ExitCode')]) -> None`

**Description:**
Called after whole test run finished, right before returning the exit status to the system.

:param session: The pytest session object.
:param exitstatus: The status which pytest will return to the system.

**Line:** 673

---

### `def pytest_unconfigure(config: 'Config') -> None`

**Description:**
Called before test process is exited.

:param config: The pytest config object.

**Line:** 684

---

### `def pytest_assertrepr_compare(config: 'Config', op: str, left: object, right: object) -> Optional[List[str]]`

**Description:**
Return explanation for comparisons in failing assert expressions.

Return None for no custom explanation, otherwise return a list
of strings. The strings will be joined by newlines but any newlines
*in* a string will be escaped. Note that all but the first line will
be indented slightly, the intention is for the first line to be a summary.

:param config: The pytest config object.
:param op: The operator, e.g. `"=="`, `"!="`, `"not in"`.
:param left: The left operand.
:param right: The right operand.

**Line:** 696

---

### `def pytest_assertion_pass(item: 'Item', lineno: int, orig: str, expl: str) -> None`

**Description:**
Called whenever an assertion passes.

.. versionadded:: 5.0

Use this hook to do some processing after a passing assertion.
The original assertion information is available in the `orig` string
and the pytest introspected assertion information is available in the
`expl` string.

This hook must be explicitly enabled by the ``enable_assertion_pass_hook``
ini-file option:

.. code-block:: ini

[pytest]
enable_assertion_pass_hook=true

You need to **clean the .pyc** files in your project directory and interpreter libraries
when enabling this option, as assertions will require to be re-written.

:param item: pytest item object of current test.
:param lineno: Line number of the assert statement.
:param orig: String with the original assertion.
:param expl: String with the assert explanation.

**Line:** 713

---

### `def pytest_report_header(config: 'Config', start_path: Path, startdir: 'LEGACY_PATH') -> Union[(str, List[str])]`

**Description:**
Return a string or list of strings to be displayed as header info for terminal reporting.

:param config: The pytest config object.
:param start_path: The starting dir.
:param startdir: The starting dir (deprecated).

.. note::

Lines returned by a plugin are displayed before those of plugins which
ran before it.
If you want to have your line(s) displayed first, use
:ref:`trylast=True <plugin-hookorder>`.

.. note::

This function should be implemented only in plugins or ``conftest.py``
files situated at the tests root directory due to how pytest
:ref:`discovers plugins during startup <pluginorder>`.

.. versionchanged:: 7.0.0
The ``start_path`` parameter was added as a :class:`pathlib.Path`
equivalent of the ``startdir`` parameter. The ``startdir`` parameter
has been deprecated.

**Line:** 746

---

### `def pytest_report_collectionfinish(config: 'Config', start_path: Path, startdir: 'LEGACY_PATH', items: Sequence['Item']) -> Union[(str, List[str])]`

**Description:**
Return a string or list of strings to be displayed after collection
has finished successfully.

These strings will be displayed after the standard "collected X items" message.

.. versionadded:: 3.2

:param config: The pytest config object.
:param start_path: The starting dir.
:param startdir: The starting dir (deprecated).
:param items: List of pytest items that are going to be executed; this list should not be modified.

.. note::

Lines returned by a plugin are displayed before those of plugins which
ran before it.
If you want to have your line(s) displayed first, use
:ref:`trylast=True <plugin-hookorder>`.

.. versionchanged:: 7.0.0
The ``start_path`` parameter was added as a :class:`pathlib.Path`
equivalent of the ``startdir`` parameter. The ``startdir`` parameter
has been deprecated.

**Line:** 775

---

### `def pytest_report_teststatus(report: Union[('CollectReport', 'TestReport')], config: 'Config') -> 'TestShortLogReport | Tuple[str, str, Union[str, Tuple[str, Mapping[str, bool]]]]'`

**Decorators:**
- `@hookspec(...)`

**Description:**
Return result-category, shortletter and verbose word for status
reporting.

The result-category is a category in which to count the result, for
example "passed", "skipped", "error" or the empty string.

The shortletter is shown as testing progresses, for example ".", "s",
"E" or the empty string.

The verbose word is shown as testing progresses in verbose mode, for
example "PASSED", "SKIPPED", "ERROR" or the empty string.

pytest may style these implicitly according to the report outcome.
To provide explicit styling, return a tuple for the verbose word,
for example ``"rerun", "R", ("RERUN", {"yellow": True})``.

:param report: The report object whose status is to be returned.
:param config: The pytest config object.
:returns: The test status.

Stops at first non-None result, see :ref:`firstresult`.

**Line:** 808

---

### `def pytest_terminal_summary(terminalreporter: 'TerminalReporter', exitstatus: 'ExitCode', config: 'Config') -> None`

**Description:**
Add a section to terminal summary reporting.

:param terminalreporter: The internal terminal reporter object.
:param exitstatus: The exit status that will be reported back to the OS.
:param config: The pytest config object.

.. versionadded:: 4.2
The ``config`` parameter.

**Line:** 835

---

### `def pytest_warning_recorded(warning_message: 'warnings.WarningMessage', when: "Literal['config', 'collect', 'runtest']", nodeid: str, location: Optional[Tuple[(str, int, str)]]) -> None`

**Decorators:**
- `@hookspec(...)`

**Description:**
Process a warning captured by the internal pytest warnings plugin.

:param warning_message:
The captured warning. This is the same object produced by :py:func:`warnings.catch_warnings`, and contains
the same attributes as the parameters of :py:func:`warnings.showwarning`.

:param when:
Indicates when the warning was captured. Possible values:

* ``"config"``: during pytest configuration/initialization stage.
* ``"collect"``: during test collection.
* ``"runtest"``: during test execution.

:param nodeid:
Full id of the item.

:param location:
When available, holds information about the execution context of the captured
warning (filename, linenumber, function). ``function`` evaluates to <module>
when the execution context is at the module level.

.. versionadded:: 6.0

**Line:** 852

---

### `def pytest_markeval_namespace(config: 'Config') -> Dict[(str, Any)]`

**Description:**
Called when constructing the globals dictionary used for
evaluating string conditions in xfail/skipif markers.

This is useful when the condition for a marker requires
objects that are expensive or impossible to obtain during
collection time, which is required by normal boolean
conditions.

.. versionadded:: 6.2

:param config: The pytest config object.
:returns: A dictionary of additional globals to add.

**Line:** 888

---

### `def pytest_internalerror(excrepr: 'ExceptionRepr', excinfo: 'ExceptionInfo[BaseException]') -> Optional[bool]`

**Description:**
Called for internal errors.

Return True to suppress the fallback handling of printing an
INTERNALERROR message directly to sys.stderr.

:param excrepr: The exception repr object.
:param excinfo: The exception info.

**Line:** 911

---

### `def pytest_keyboard_interrupt(excinfo: 'ExceptionInfo[Union[KeyboardInterrupt, Exit]]') -> None`

**Description:**
Called for keyboard interrupt.

:param excinfo: The exception info.

**Line:** 925

---

### `def pytest_exception_interact(node: Union[('Item', 'Collector')], call: 'CallInfo[Any]', report: Union[('CollectReport', 'TestReport')]) -> None`

**Description:**
Called when an exception was raised which can potentially be
interactively handled.

May be called during collection (see :hook:`pytest_make_collect_report`),
in which case ``report`` is a :class:`CollectReport`.

May be called during runtest of an item (see :hook:`pytest_runtest_protocol`),
in which case ``report`` is a :class:`TestReport`.

This hook is not called if the exception that was raised is an internal
exception like ``skip.Exception``.

:param node:
The item or collector.
:param call:
The call information. Contains the exception.
:param report:
The collection or test report.

**Line:** 934

---

### `def pytest_enter_pdb(config: 'Config', pdb: 'pdb.Pdb') -> None`

**Description:**
Called upon pdb.set_trace().

Can be used by plugins to take special action just before the python
debugger enters interactive mode.

:param config: The pytest config object.
:param pdb: The Pdb instance.

**Line:** 960

---

### `def pytest_leave_pdb(config: 'Config', pdb: 'pdb.Pdb') -> None`

**Description:**
Called when leaving pdb (e.g. with continue after pdb.set_trace()).

Can be used by plugins to take special action just after the python
debugger leaves interactive mode.

:param config: The pytest config object.
:param pdb: The Pdb instance.

**Line:** 971

---


## Module: venv2.libthon3.12.site-packages._pytest.junitxml
**File:** `venv2/lib/python3.12/site-packages/_pytest/junitxml.py`

**Imports:**
- _pytest._code.code.ExceptionRepr
- _pytest._code.code.ReprFileLocation
- _pytest.config.Config
- _pytest.config.argparsing.Parser
- _pytest.config.filename_arg
- _pytest.fixtures.FixtureRequest
- _pytest.nodes
- _pytest.reports.TestReport
- _pytest.stash.StashKey
- _pytest.terminal.TerminalReporter
- _pytest.timing
- _pytest.warning_types.PytestExperimentalApiWarning
- _pytest.warning_types.PytestWarning
- datetime.datetime
- functools
- os
- platform
- pytest
- re
- typing.Callable
- typing.Dict
- typing.List
- typing.Match
- typing.Optional
- typing.Tuple
- typing.Union
- xml.etree.ElementTree

**Functions:**

### `def bin_xml_escape(arg: object) -> str`

**Description:**
Visually escape invalid XML characters.

For example, transforms
'hello\aworld\b'
into
'hello#x07world#x08'
Note that the #xABs are *not* XML escapes - missing the ampersand &#xAB.
The idea is to escape visually for the user rather than for XML itself.

**Line:** 40

---

### `def merge_family(left, right) -> None`

**Line:** 67

---

### `def _warn_incompatibility_with_xunit2(request: FixtureRequest, fixture_name: str) -> None`

**Description:**
Emit a PytestWarning about the given fixture being incompatible with newer xunit revisions.

**Line:** 264

---

### `def record_property(request: FixtureRequest) -> Callable[([str, object], None)]`

**Decorators:**
- `@pytest.fixture`

**Description:**
Add extra properties to the calling test.

User properties become part of the test report and are available to the
configured reporters, like JUnit XML.

The fixture is callable with ``name, value``. The value is automatically
XML-encoded.

Example::

def test_function(record_property):
record_property("example_key", 1)

**Line:** 282

---

### `def record_xml_attribute(request: FixtureRequest) -> Callable[([str, object], None)]`

**Decorators:**
- `@pytest.fixture`

**Description:**
Add extra xml attributes to the tag for the calling test.

The fixture is callable with ``name, value``. The value is
automatically XML-encoded.

**Line:** 305

---

### `def _check_record_param_type(param: str, v: str) -> None`

**Description:**
Used by record_testsuite_property to check that the given parameter name is of the proper
type.

**Line:** 333

---

### `def record_testsuite_property(request: FixtureRequest) -> Callable[([str, object], None)]`

**Decorators:**
- `@pytest.fixture(...)`

**Description:**
Record a new ``<property>`` tag as child of the root ``<testsuite>``.

This is suitable to writing global information regarding the entire test
suite, and is compatible with ``xunit2`` JUnit family.

This is a ``session``-scoped fixture which is called with ``(name, value)``. Example:

.. code-block:: python

def test_foo(record_testsuite_property):
record_testsuite_property("ARCH", "PPC")
record_testsuite_property("STORAGE_TYPE", "CEPH")

:param name:
The property name.
:param value:
The property value. Will be converted to a string.

.. warning::

Currently this fixture **does not work** with the
`pytest-xdist <https://github.com/pytest-dev/pytest-xdist>`__ plugin. See
:issue:`7767` for details.

**Line:** 343

---

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 382

---

### `def pytest_configure(config: Config) -> None`

**Line:** 429

---

### `def pytest_unconfigure(config: Config) -> None`

**Line:** 446

---

### `def mangle_test_address(address: str) -> List[str]`

**Line:** 453

---


## Module: venv2.libthon3.12.site-packages._pytest.legacypath
**File:** `venv2/lib/python3.12/site-packages/_pytest/legacypath.py`

**Imports:**
- _pytest.cacheprovider.Cache
- _pytest.compat.LEGACY_PATH
- _pytest.compat.final
- _pytest.compat.legacy_path
- _pytest.config.Config
- _pytest.config.PytestPluginManager
- _pytest.config.hookimpl
- _pytest.deprecated.check_ispytest
- _pytest.fixtures.FixtureRequest
- _pytest.fixtures.fixture
- _pytest.main.Session
- _pytest.monkeypatch.MonkeyPatch
- _pytest.nodes.Collector
- _pytest.nodes.Item
- _pytest.nodes.Node
- _pytest.pytester.HookRecorder
- _pytest.pytester.Pytester
- _pytest.pytester.RunResult
- _pytest.terminal.TerminalReporter
- _pytest.tmpdir.TempPathFactory
- dataclasses
- iniconfig.SectionWrapper
- pathlib.Path
- pexpect
- shlex
- subprocess
- typing.List
- typing.Optional
- typing.TYPE_CHECKING
- typing.Union
- typing_extensions.Final

**Functions:**

### `def Cache_makedir(self: Cache, name: str) -> LEGACY_PATH`

**Description:**
Return a directory path object with the given name.

Same as :func:`mkdir`, but returns a legacy py path instance.

**Line:** 332

---

### `def FixtureRequest_fspath(self: FixtureRequest) -> LEGACY_PATH`

**Description:**
(deprecated) The file system path of the test module which collected this test.

**Line:** 340

---

### `def TerminalReporter_startdir(self: TerminalReporter) -> LEGACY_PATH`

**Description:**
The directory from which pytest was invoked.

Prefer to use ``startpath`` which is a :class:`pathlib.Path`.

:type: LEGACY_PATH

**Line:** 345

---

### `def Config_invocation_dir(self: Config) -> LEGACY_PATH`

**Description:**
The directory from which pytest was invoked.

Prefer to use :attr:`invocation_params.dir <InvocationParams.dir>`,
which is a :class:`pathlib.Path`.

:type: LEGACY_PATH

**Line:** 355

---

### `def Config_rootdir(self: Config) -> LEGACY_PATH`

**Description:**
The path to the :ref:`rootdir <rootdir>`.

Prefer to use :attr:`rootpath`, which is a :class:`pathlib.Path`.

:type: LEGACY_PATH

**Line:** 366

---

### `def Config_inifile(self: Config) -> Optional[LEGACY_PATH]`

**Description:**
The path to the :ref:`configfile <configfiles>`.

Prefer to use :attr:`inipath`, which is a :class:`pathlib.Path`.

:type: Optional[LEGACY_PATH]

**Line:** 376

---

### `def Session_stardir(self: Session) -> LEGACY_PATH`

**Description:**
The path from which pytest was invoked.

Prefer to use ``startpath`` which is a :class:`pathlib.Path`.

:type: LEGACY_PATH

**Line:** 386

---

### `def Config__getini_unknown_type(self, name: str, type: str, value: Union[(str, List[str])])`

**Line:** 396

---

### `def Node_fspath(self: Node) -> LEGACY_PATH`

**Description:**
(deprecated) returns a legacy_path copy of self.path

**Line:** 409

---

### `def Node_fspath_set(self: Node, value: LEGACY_PATH) -> None`

**Line:** 414

---

### `def pytest_load_initial_conftests(early_config: Config) -> None`

**Decorators:**
- `@hookimpl(...)`

**Description:**
Monkeypatch legacy path attributes in several classes, as early as possible.

**Line:** 419

---

### `def pytest_configure(config: Config) -> None`

**Decorators:**
- `@hookimpl`

**Description:**
Installs the LegacyTmpdirPlugin if the ``tmpdir`` plugin is also installed.

**Line:** 451

---

### `def pytest_plugin_registered(plugin: object, manager: PytestPluginManager) -> None`

**Decorators:**
- `@hookimpl`

**Line:** 474

---


## Module: venv2.libthon3.12.site-packages._pytest.logging
**File:** `venv2/lib/python3.12/site-packages/_pytest/logging.py`

**Imports:**
- _pytest._io.TerminalWriter
- _pytest.capture.CaptureManager
- _pytest.compat.final
- _pytest.config.Config
- _pytest.config.UsageError
- _pytest.config._strtobool
- _pytest.config.argparsing.Parser
- _pytest.config.create_terminal_writer
- _pytest.config.hookimpl
- _pytest.deprecated.check_ispytest
- _pytest.fixtures.FixtureRequest
- _pytest.fixtures.fixture
- _pytest.main.Session
- _pytest.nodes
- _pytest.stash.StashKey
- _pytest.terminal.TerminalReporter
- contextlib.contextmanager
- contextlib.nullcontext
- datetime.datetime
- datetime.timedelta
- datetime.timezone
- io
- io.StringIO
- logging
- logging.LogRecord
- os
- pathlib.Path
- re
- typing.AbstractSet
- typing.Dict
- typing.Generator
- typing.List
- typing.Mapping
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing_extensions.Literal

**Functions:**

### `def _remove_ansi_escape_sequences(text: str) -> str`

**Line:** 56

---

### `def get_option_ini(config: Config, *names: str)`

**Line:** 229

---

### `def pytest_addoption(parser: Parser) -> None`

**Description:**
Add options to control log capturing.

**Line:** 238

---

### `def caplog(request: FixtureRequest) -> Generator[(LogCaptureFixture, None, None)]`

**Decorators:**
- `@fixture`

**Description:**
Access and control log capturing.

Captured logs are available through the following properties/methods::

* caplog.messages        -> list of format-interpolated log messages
* caplog.text            -> string containing formatted log output
* caplog.records         -> list of logging.LogRecord instances
* caplog.record_tuples   -> list of (logger_name, level, message) tuples
* caplog.clear()         -> clear captured records and formatted log output string

**Line:** 570

---

### `def get_log_level_for_setting(config: Config, *setting_names: str) -> Optional[int]`

**Line:** 586

---

### `def pytest_configure(config: Config) -> None`

**Decorators:**
- `@hookimpl(...)`

**Line:** 611

---


## Module: venv2.libthon3.12.site-packages._pytest.main
**File:** `venv2/lib/python3.12/site-packages/_pytest/main.py`

**Imports:**
- _pytest._code
- _pytest.compat.final
- _pytest.compat.overload
- _pytest.config.Config
- _pytest.config.ExitCode
- _pytest.config.PytestPluginManager
- _pytest.config.UsageError
- _pytest.config.argparsing.Parser
- _pytest.config.directory_arg
- _pytest.config.hookimpl
- _pytest.fixtures.FixtureManager
- _pytest.nodes
- _pytest.outcomes.exit
- _pytest.pathlib.absolutepath
- _pytest.pathlib.bestrelpath
- _pytest.pathlib.fnmatch_ex
- _pytest.pathlib.safe_exists
- _pytest.pathlib.visit
- _pytest.python.Package
- _pytest.reports.CollectReport
- _pytest.reports.TestReport
- _pytest.runner.SetupState
- _pytest.runner.collect_one_node
- argparse
- config.compat.PathAwareHookProxy
- dataclasses
- fnmatch
- functools
- importlib
- os
- pathlib.Path
- sys
- typing.Callable
- typing.Dict
- typing.FrozenSet
- typing.Iterator
- typing.List
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.Union
- typing_extensions.Literal

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 51

---

### `def validate_basetemp(path: str) -> str`

**Line:** 233

---

### `def wrap_session(config: Config, doit: Callable[([Config, 'Session'], Optional[Union[int, ExitCode]])]) -> Union[(int, ExitCode)]`

**Description:**
Skeleton command line program.

**Line:** 258

---

### `def pytest_cmdline_main(config: Config) -> Union[(int, ExitCode)]`

**Line:** 317

---

### `def _main(config: Config, session: 'Session') -> Optional[Union[(int, ExitCode)]]`

**Description:**
Default command line protocol for initialization, session,
running tests and reporting.

**Line:** 321

---

### `def pytest_collection(session: 'Session') -> None`

**Line:** 334

---

### `def pytest_runtestloop(session: 'Session') -> bool`

**Line:** 338

---

### `def _in_venv(path: Path) -> bool`

**Description:**
Attempt to detect if ``path`` is the root of a Virtual Environment by
checking for the existence of the appropriate activate script.

**Line:** 358

---

### `def pytest_ignore_collect(collection_path: Path, config: Config) -> Optional[bool]`

**Line:** 378

---

### `def pytest_collection_modifyitems(items: List[nodes.Item], config: Config) -> None`

**Line:** 413

---

### `def search_pypath(module_name: str) -> str`

**Description:**
Search sys.path for the given a dotted module name, and return its file system path.

**Line:** 849

---

### `def resolve_collection_argument(invocation_path: Path, arg: str, as_pypath: bool = False) -> Tuple[(Path, List[str])]`

**Description:**
Parse path arguments optionally containing selection parts and return (fspath, names).

Command-line arguments can point to files and/or directories, and optionally contain
parts for specific tests selection, for example:

"pkg/tests/test_foo.py::TestClass::test_foo"

This function ensures the path exists, and returns a tuple:

(Path("/full/path/to/pkg/tests/test_foo.py"), ["TestClass", "test_foo"])

When as_pypath is True, expects that the command-line argument actually contains
module paths instead of file-system paths:

"pkg.tests.test_foo::TestClass::test_foo"

In which case we search sys.path for a matching module, and then return the *path* to the
found module.

If the path doesn't exist, raise UsageError.
If the path is a directory and selection parts are present, raise UsageError.

**Line:** 866

---


## Module: venv2.libthon3.12.site-packages._pytest.mark.__init__
**File:** `venv2/lib/python3.12/site-packages/_pytest/mark/__init__.py`

**Imports:**
- _pytest.config
- _pytest.config.Config
- _pytest.config.ExitCode
- _pytest.config.UsageError
- _pytest.config.argparsing.Parser
- _pytest.config.hookimpl
- _pytest.nodes.Item
- _pytest.stash.StashKey
- dataclasses
- expression.Expression
- expression.ParseError
- pytest
- structures.EMPTY_PARAMETERSET_OPTION
- structures.MARK_GEN
- structures.Mark
- structures.MarkDecorator
- structures.MarkGenerator
- structures.ParameterSet
- structures.get_empty_parameterset_mark
- typing.AbstractSet
- typing.Collection
- typing.List
- typing.Optional
- typing.TYPE_CHECKING
- typing.Union

**Functions:**

### `def param(marks: Union[(MarkDecorator, Collection[Union[MarkDecorator, Mark]])] = (), id: Optional[str] = None, *values: object) -> ParameterSet`

**Description:**
Specify a parameter in `pytest.mark.parametrize`_ calls or
:ref:`parametrized fixtures <fixture-parametrize-marks>`.

.. code-block:: python

@pytest.mark.parametrize(
"test_input,expected",
[
("3+5", 8),
pytest.param("6*9", 42, marks=pytest.mark.xfail),
],
)
def test_eval(test_input, expected):
assert eval(test_input) == expected

:param values: Variable args of the values of the parameter set, in order.
:param marks: A single mark or a list of marks to be applied to this parameter set.
:param id: The id to attribute to this parameter set.

**Line:** 43

---

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 70

---

### `def pytest_cmdline_main(config: Config) -> Optional[Union[(int, ExitCode)]]`

**Decorators:**
- `@hookimpl(...)`

**Line:** 113

---

### `def deselect_by_keyword(items: 'List[Item]', config: Config) -> None`

**Line:** 185

---

### `def deselect_by_mark(items: 'List[Item]', config: Config) -> None`

**Line:** 225

---

### `def _parse_expression(expr: str, exc_message: str) -> Expression`

**Line:** 243

---

### `def pytest_collection_modifyitems(items: 'List[Item]', config: Config) -> None`

**Line:** 250

---

### `def pytest_configure(config: Config) -> None`

**Line:** 255

---

### `def pytest_unconfigure(config: Config) -> None`

**Line:** 268

---


## Module: venv2.libthon3.12.site-packages._pytest.mark.expression
**File:** `venv2/lib/python3.12/site-packages/_pytest/mark/expression.py`

**Imports:**
- ast
- dataclasses
- enum
- re
- sys
- types
- typing.Callable
- typing.Iterator
- typing.Mapping
- typing.NoReturn
- typing.Optional
- typing.Sequence

**Functions:**

### `def expression(s: Scanner) -> ast.Expression`

**Line:** 139

---

### `def expr(s: Scanner) -> ast.expr`

**Line:** 148

---

### `def and_expr(s: Scanner) -> ast.expr`

**Line:** 156

---

### `def not_expr(s: Scanner) -> ast.expr`

**Line:** 164

---


## Module: venv2.libthon3.12.site-packages._pytest.mark.structures
**File:** `venv2/lib/python3.12/site-packages/_pytest/mark/structures.py`

**Imports:**
- _code.getfslineno
- _pytest.config.Config
- _pytest.deprecated.check_ispytest
- _pytest.outcomes.fail
- _pytest.scope._ScopeName
- _pytest.warning_types.PytestUnknownMarkWarning
- collections.abc
- compat.NOTSET
- compat.NotSetType
- compat.ascii_escaped
- compat.final
- dataclasses
- inspect
- nodes.Collector
- nodes.Node
- typing.Any
- typing.Callable
- typing.Collection
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.MutableMapping
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.overload
- warnings

**Functions:**

### `def istestfunc(func) -> bool`

**Line:** 41

---

### `def get_empty_parameterset_mark(config: Config, argnames: Sequence[str], func) -> 'MarkDecorator'`

**Line:** 45

---

### `def get_unpacked_marks(obj: Union[(object, type)], consider_mro: bool = True) -> List[Mark]`

**Description:**
Obtain the unpacked marks that are stored on an object.

If obj is a class and consider_mro is true, return marks applied to
this class and all of its super-classes in MRO order. If consider_mro
is false, only return marks applied directly to this class.

**Line:** 361

---

### `def normalize_mark_list(mark_list: Iterable[Union[(Mark, MarkDecorator)]]) -> Iterable[Mark]`

**Description:**
Normalize an iterable of Mark or MarkDecorator objects into a list of marks
by retrieving the `mark` attribute on MarkDecorator instances.

:param mark_list: marks to normalize
:returns: A new list of the extracted Mark objects

**Line:** 394

---

### `def store_mark(obj, mark: Mark) -> None`

**Description:**
Store a Mark on an object.

This is used to implement the Mark declarations/decorators correctly.

**Line:** 411

---


## Module: venv2.libthon3.12.site-packages._pytest.monkeypatch
**File:** `venv2/lib/python3.12/site-packages/_pytest/monkeypatch.py`

**Imports:**
- _pytest.compat.final
- _pytest.fixtures.fixture
- _pytest.warning_types.PytestWarning
- contextlib.contextmanager
- importlib.invalidate_caches
- inspect
- os
- pkg_resources.fixup_namespace_packages
- re
- sys
- typing.Any
- typing.Generator
- typing.List
- typing.Mapping
- typing.MutableMapping
- typing.Optional
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.overload
- warnings

**Functions:**

### `def monkeypatch() -> Generator[('MonkeyPatch', None, None)]`

**Decorators:**
- `@fixture`

**Description:**
A convenient fixture for monkey-patching.

The fixture provides these methods to modify objects, dictionaries, or
:data:`os.environ`:

* :meth:`monkeypatch.setattr(obj, name, value, raising=True) <pytest.MonkeyPatch.setattr>`
* :meth:`monkeypatch.delattr(obj, name, raising=True) <pytest.MonkeyPatch.delattr>`
* :meth:`monkeypatch.setitem(mapping, name, value) <pytest.MonkeyPatch.setitem>`
* :meth:`monkeypatch.delitem(obj, name, raising=True) <pytest.MonkeyPatch.delitem>`
* :meth:`monkeypatch.setenv(name, value, prepend=None) <pytest.MonkeyPatch.setenv>`
* :meth:`monkeypatch.delenv(name, raising=True) <pytest.MonkeyPatch.delenv>`
* :meth:`monkeypatch.syspath_prepend(path) <pytest.MonkeyPatch.syspath_prepend>`
* :meth:`monkeypatch.chdir(path) <pytest.MonkeyPatch.chdir>`
* :meth:`monkeypatch.context() <pytest.MonkeyPatch.context>`

All modifications will be undone after the requesting test function or
fixture has finished. The ``raising`` parameter determines if a :class:`KeyError`
or :class:`AttributeError` will be raised if the set/deletion operation does not have the
specified target.

To undo modifications done by the fixture in a contained scope,
use :meth:`context() <pytest.MonkeyPatch.context>`.

**Line:** 30

---

### `def resolve(name: str) -> object`

**Line:** 59

---

### `def annotated_getattr(obj: object, name: str, ann: str) -> object`

**Line:** 87

---

### `def derive_importpath(import_path: str, raising: bool) -> Tuple[(str, object)]`

**Line:** 99

---


## Module: venv2.libthon3.12.site-packages._pytest.nodes
**File:** `venv2/lib/python3.12/site-packages/_pytest/nodes.py`

**Imports:**
- _pytest._code
- _pytest._code.code.ExceptionInfo
- _pytest._code.code.TerminalRepr
- _pytest._code.code.Traceback
- _pytest._code.code._TracebackStyle
- _pytest._code.getfslineno
- _pytest.compat.LEGACY_PATH
- _pytest.compat.cached_property
- _pytest.config.Config
- _pytest.config.ConftestImportFailure
- _pytest.deprecated.FSCOLLECTOR_GETHOOKPROXY_ISINITPATH
- _pytest.deprecated.NODE_CTOR_FSPATH_ARG
- _pytest.fixtures.FixtureLookupError
- _pytest.main.Session
- _pytest.mark.MARK_GEN
- _pytest.mark.structures.Mark
- _pytest.mark.structures.MarkDecorator
- _pytest.mark.structures.NodeKeywords
- _pytest.outcomes.fail
- _pytest.pathlib.absolutepath
- _pytest.pathlib.commonpath
- _pytest.stash.Stash
- _pytest.warning_types.PytestWarning
- inspect.signature
- os
- pathlib.Path
- typing.Any
- typing.Callable
- typing.Iterable
- typing.Iterator
- typing.List
- typing.MutableMapping
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- warning_types.PytestDeprecationWarning
- warnings

**Functions:**

### `def iterparentnodeids(nodeid: str) -> Iterator[str]`

**Description:**
Return the parent node IDs of a given node ID, inclusive.

For the node ID

"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_source"

the result would be

""
"testing"
"testing/code"
"testing/code/test_excinfo.py"
"testing/code/test_excinfo.py::TestFormattedExcinfo"
"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_source"

Note that / components are only considered until the first ::.

**Line:** 52

---

### `def _check_path(path: Path, fspath: LEGACY_PATH) -> None`

**Line:** 97

---

### `def _imply_path(node_type: Type['Node'], path: Optional[Path], fspath: Optional[LEGACY_PATH]) -> Path`

**Line:** 105

---

### `def get_fslocation_from_item(node: 'Node') -> Tuple[(Union[str, Path], Optional[int])]`

**Description:**
Try to extract the actual location from a node, depending on available attributes:

* "location": a pair (path, lineno)
* "obj": a Python object that the node wraps.
* "fspath": just a path

:rtype: A tuple of (str|Path, int) with filename and 0-based line number.

**Line:** 509

---

### `def _check_initialpaths_for_relpath(session: 'Session', path: Path) -> Optional[str]`

**Line:** 574

---


## Module: venv2.libthon3.12.site-packages._pytest.nose
**File:** `venv2/lib/python3.12/site-packages/_pytest/nose.py`

**Imports:**
- _pytest.config.hookimpl
- _pytest.deprecated.NOSE_SUPPORT
- _pytest.fixtures.getfixturemarker
- _pytest.nodes.Item
- _pytest.python.Function
- _pytest.unittest.TestCaseFunction
- warnings

**Functions:**

### `def pytest_runtest_setup(item: Item) -> None`

**Decorators:**
- `@hookimpl(...)`

**Line:** 13

---

### `def call_optional(obj: object, name: str, nodeid: str) -> bool`

**Line:** 33

---


## Module: venv2.libthon3.12.site-packages._pytest.outcomes
**File:** `venv2/lib/python3.12/site-packages/_pytest/outcomes.py`

**Imports:**
- _pytest.config.UsageError
- _pytest.deprecated.KEYWORD_MSG_ARG
- packaging.version.Version
- pytest.UsageError
- sys
- typing.Any
- typing.Callable
- typing.Generic
- typing.NoReturn
- typing.Optional
- typing.Type
- typing.TypeVar
- typing.cast
- typing_extensions.Protocol
- warnings

**Functions:**

### `def _with_exception(exception_type: _ET) -> Callable[([_F], _WithException[_F, _ET])]`

**Line:** 103

---

### `def exit(reason: str = '', returncode: Optional[int] = None, msg: Optional[str] = None) -> NoReturn`

**Decorators:**
- `@_with_exception(...)`

**Description:**
Exit testing process.

:param reason:
The message to show as the reason for exiting pytest.  reason has a default value
only because `msg` is deprecated.

:param returncode:
Return code to be used when exiting pytest.

:param msg:
Same as ``reason``, but deprecated. Will be removed in a future version, use ``reason`` instead.

**Line:** 116

---

### `def skip(reason: str = '', allow_module_level: bool = False, msg: Optional[str] = None) -> NoReturn`

**Decorators:**
- `@_with_exception(...)`

**Description:**
Skip an executing test with the given message.

This function should be called only during testing (setup, call or teardown) or
during collection by using the ``allow_module_level`` flag.  This function can
be called in doctests as well.

:param reason:
The message to show the user as reason for the skip.

:param allow_module_level:
Allows this function to be called at module level.
Raising the skip exception at module level will stop
the execution of the module and prevent the collection of all tests in the module,
even those defined before the `skip` call.

Defaults to False.

:param msg:
Same as ``reason``, but deprecated. Will be removed in a future version, use ``reason`` instead.

.. note::
It is better to use the :ref:`pytest.mark.skipif ref` marker when
possible to declare a test to be skipped under certain conditions
like mismatching platforms or dependencies.
Similarly, use the ``# doctest: +SKIP`` directive (see :py:data:`doctest.SKIP`)
to skip a doctest statically.

**Line:** 147

---

### `def fail(reason: str = '', pytrace: bool = True, msg: Optional[str] = None) -> NoReturn`

**Decorators:**
- `@_with_exception(...)`

**Description:**
Explicitly fail an executing test with the given message.

:param reason:
The message to show the user as reason for the failure.

:param pytrace:
If False, msg represents the full failure information and no
python traceback will be reported.

:param msg:
Same as ``reason``, but deprecated. Will be removed in a future version, use ``reason`` instead.

**Line:** 183

---

### `def _resolve_msg_to_reason(func_name: str, reason: str, msg: Optional[str] = None) -> str`

**Description:**
Handles converting the deprecated msg parameter if provided into
reason, raising a deprecation warning.  This function will be removed
when the optional msg argument is removed from here in future.

:param str func_name:
The name of the offending function, this is formatted into the deprecation message.

:param str reason:
The reason= passed into either pytest.fail() or pytest.skip()

:param str msg:
The msg= passed into either pytest.fail() or pytest.skip().  This will
be converted into reason if it is provided to allow pytest.skip(msg=) or
pytest.fail(msg=) to continue working in the interim period.

:returns:
The value to use as reason.

**Line:** 201

---

### `def xfail(reason: str = '') -> NoReturn`

**Decorators:**
- `@_with_exception(...)`

**Description:**
Imperatively xfail an executing test or setup function with the given reason.

This function should be called only during testing (setup, call or teardown).

:param reason:
The message to show the user as reason for the xfail.

.. note::
It is better to use the :ref:`pytest.mark.xfail ref` marker when
possible to declare a test to be xfailed under certain conditions
like known bugs or missing features.

**Line:** 242

---

### `def importorskip(modname: str, minversion: Optional[str] = None, reason: Optional[str] = None) -> Any`

**Description:**
Import and return the requested module ``modname``, or skip the
current test if the module cannot be imported.

:param modname:
The name of the module to import.
:param minversion:
If given, the imported module's ``__version__`` attribute must be at
least this minimal version, otherwise the test is still skipped.
:param reason:
If given, this reason is shown as the message when the module cannot
be imported.

:returns:
The imported module. This should be assigned to its canonical name.

Example::

docutils = pytest.importorskip("docutils")

**Line:** 259

---


## Module: venv2.libthon3.12.site-packages._pytest.pastebin
**File:** `venv2/lib/python3.12/site-packages/_pytest/pastebin.py`

**Imports:**
- _pytest.config.Config
- _pytest.config.argparsing.Parser
- _pytest.config.create_terminal_writer
- _pytest.stash.StashKey
- _pytest.terminal.TerminalReporter
- io.StringIO
- pytest
- re
- tempfile
- typing.IO
- typing.Union
- urllib.parse.urlencode
- urllib.request.urlopen

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 18

---

### `def pytest_configure(config: Config) -> None`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 32

---

### `def pytest_unconfigure(config: Config) -> None`

**Line:** 52

---

### `def create_new_paste(contents: Union[(str, bytes)]) -> str`

**Description:**
Create a new paste using the bpaste.net service.

:contents: Paste contents string.
:returns: URL to the pasted contents, or an error message.

**Line:** 69

---

### `def pytest_terminal_summary(terminalreporter: TerminalReporter) -> None`

**Line:** 94

---


## Module: venv2.libthon3.12.site-packages._pytest.pathlib
**File:** `venv2/lib/python3.12/site-packages/_pytest/pathlib.py`

**Imports:**
- _pytest.compat.assert_never
- _pytest.outcomes.skip
- _pytest.warning_types.PytestWarning
- atexit
- contextlib
- enum.Enum
- errno.EBADF
- errno.ELOOP
- errno.ENOENT
- errno.ENOTDIR
- fnmatch
- functools.partial
- importlib.util
- itertools
- os
- os.path.expanduser
- os.path.expandvars
- os.path.isabs
- os.path.sep
- pathlib.Path
- pathlib.PurePath
- posixpath.sep
- shutil
- stat
- sys
- types
- types.ModuleType
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Optional
- typing.Set
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- uuid
- warnings

**Functions:**

### `def _ignore_error(exception)`

**Line:** 59

---

### `def get_lock_path(path: _AnyPurePath) -> _AnyPurePath`

**Line:** 66

---

### `def on_rm_rf_error(func, path: str, excinfo: Union[(BaseException, Tuple[Type[BaseException], BaseException, Optional[types.TracebackType]])], start_path: Path) -> bool`

**Description:**
Handle known read-only errors during rmtree.

The returned value is used only by our own tests.

**Line:** 70

---

### `def ensure_extended_length_path(path: Path) -> Path`

**Description:**
Get the extended-length version of a path (Windows).

On Windows, by default, the maximum length of a path (MAX_PATH) is 260
characters, and operations on paths longer than that fail. But it is possible
to overcome this by converting the path to "extended-length" form before
performing the operation:
https://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file#maximum-path-length-limitation

On Windows, this function returns the extended-length absolute version of path.
On other platforms it returns path unchanged.

**Line:** 133

---

### `def get_extended_length_path_str(path: str) -> str`

**Description:**
Convert a path to a Windows extended length path.

**Line:** 151

---

### `def rm_rf(path: Path) -> None`

**Description:**
Remove the path contents recursively, even if some elements
are read-only.

**Line:** 163

---

### `def find_prefixed(root: Path, prefix: str) -> Iterator[Path]`

**Description:**
Find all elements in root that begin with the prefix, case insensitive.

**Line:** 174

---

### `def extract_suffixes(iter: Iterable[PurePath], prefix: str) -> Iterator[str]`

**Description:**
Return the parts of the paths following the prefix.

:param iter: Iterator over path names.
:param prefix: Expected prefix of the path names.

**Line:** 182

---

### `def find_suffixes(root: Path, prefix: str) -> Iterator[str]`

**Description:**
Combine find_prefixes and extract_suffixes.

**Line:** 193

---

### `def parse_num(maybe_num) -> int`

**Description:**
Parse number path suffixes, returns -1 on error.

**Line:** 198

---

### `def _force_symlink(root: Path, target: Union[(str, PurePath)], link_to: Union[(str, Path)]) -> None`

**Description:**
Helper to create the current symlink.

It's full of race conditions that are reasonably OK to ignore
for the context of best effort linking to the latest test run.

The presumption being that in case of much parallelism
the inaccuracy is going to be acceptable.

**Line:** 206

---

### `def make_numbered_dir(root: Path, prefix: str, mode: int = 448) -> Path`

**Description:**
Create a directory with an increased number as suffix for the given prefix.

**Line:** 228

---

### `def create_cleanup_lock(p: Path) -> Path`

**Description:**
Create a lock to prevent premature folder cleanup.

**Line:** 249

---

### `def register_cleanup_lock_removal(lock_path: Path, register = atexit.register)`

**Description:**
Register a cleanup function for removing a lock, by default on atexit.

**Line:** 266

---

### `def maybe_delete_a_numbered_dir(path: Path) -> None`

**Description:**
Remove a numbered directory if its lock can be obtained and it does
not seem to be in use.

**Line:** 283

---

### `def ensure_deletable(path: Path, consider_lock_dead_if_created_before: float) -> bool`

**Description:**
Check if `path` is deletable based on whether the lock file is expired.

**Line:** 311

---

### `def try_cleanup(path: Path, consider_lock_dead_if_created_before: float) -> None`

**Description:**
Try to cleanup a folder if we can ensure it's deletable.

**Line:** 339

---

### `def cleanup_candidates(root: Path, prefix: str, keep: int) -> Iterator[Path]`

**Description:**
List candidates for numbered directories to be removed - follows py.path.

**Line:** 345

---

### `def cleanup_dead_symlinks(root: Path)`

**Line:** 357

---

### `def cleanup_numbered_dir(root: Path, prefix: str, keep: int, consider_lock_dead_if_created_before: float) -> None`

**Description:**
Cleanup for lock driven numbered directories.

**Line:** 364

---

### `def make_numbered_dir_with_cleanup(root: Path, prefix: str, keep: int, lock_timeout: float, mode: int) -> Path`

**Description:**
Create a numbered dir with a cleanup lock and remove old ones.

**Line:** 378

---

### `def resolve_from_str(input: str, rootpath: Path) -> Path`

**Line:** 411

---

### `def fnmatch_ex(pattern: str, path: Union[(str, 'os.PathLike[str]')]) -> bool`

**Description:**
A port of FNMatcher from py.path.common which works with PurePath() instances.

The difference between this algorithm and PurePath.match() is that the
latter matches "**" glob expressions for each part of the path, while
this algorithm uses the whole path instead.

For example:
"tests/foo/bar/doc/test_foo.py" matches pattern "tests/**/doc/test*.py"
with this algorithm, but not with PurePath.match().

This algorithm was ported to keep backward-compatibility with existing
settings which assume paths match according this logic.

References:
* https://bugs.python.org/issue29249
* https://bugs.python.org/issue34731

**Line:** 420

---

### `def parts(s: str) -> Set[str]`

**Line:** 456

---

### `def symlink_or_skip(src, dst, **kwargs)`

**Description:**
Make a symlink, or skip the test in case symlinks are not supported.

**Line:** 461

---

### `def import_path(p: Union[(str, 'os.PathLike[str]')], mode: Union[(str, ImportMode)] = ImportMode.prepend, root: Path) -> ModuleType`

**Description:**
Import and return a module from the given path, which can be a file (a module) or
a directory (a package).

The import mechanism used is controlled by the `mode` parameter:

* `mode == ImportMode.prepend`: the directory containing the module (or package, taking
`__init__.py` files into account) will be put at the *start* of `sys.path` before
being imported with `importlib.import_module`.

* `mode == ImportMode.append`: same as `prepend`, but the directory will be appended
to the end of `sys.path`, if not already in `sys.path`.

* `mode == ImportMode.importlib`: uses more fine control mechanisms provided by `importlib`
to import the module, which avoids having to muck with `sys.path` at all. It effectively
allows having same-named test modules in different places.

:param root:
Used as an anchor when mode == ImportMode.importlib to obtain
a unique name for the module being imported so it can safely be stored
into ``sys.modules``.

:raises ImportPathMismatchError:
If after importing the given `path` and the module `__file__`
are different. Only raised in `prepend` and `append` modes.

**Line:** 486

---

### `def _is_same(f1: str, f2: str) -> bool`

**Line:** 599

---

### `def _is_same(f1: str, f2: str) -> bool`

**Line:** 604

---

### `def module_name_from_path(path: Path, root: Path) -> str`

**Description:**
Return a dotted module name based on the given path, anchored on root.

For example: path="projects/src/tests/test_foo.py" and root="/projects", the
resulting module name will be "src.tests.test_foo".

**Line:** 608

---

### `def insert_missing_modules(modules: Dict[(str, ModuleType)], module_name: str) -> None`

**Description:**
Used by ``import_path`` to create intermediate modules when using mode=importlib.

When we want to import a module as "src.tests.test_foo" for example, we need
to create empty modules "src" and "src.tests" after inserting "src.tests.test_foo",
otherwise "src.tests.test_foo" is not importable by ``__import__``.

**Line:** 634

---

### `def resolve_package_path(path: Path) -> Optional[Path]`

**Description:**
Return the Python package path by looking for the last
directory upwards which still contains an __init__.py.

Returns None if it can not be determined.

**Line:** 675

---

### `def scandir(path: Union[(str, 'os.PathLike[str]')]) -> List['os.DirEntry[str]']`

**Description:**
Scan a directory recursively, in breadth-first order.

The returned entries are sorted.

**Line:** 692

---

### `def visit(path: Union[(str, 'os.PathLike[str]')], recurse: Callable[(['os.DirEntry[str]'], bool)]) -> Iterator['os.DirEntry[str]']`

**Description:**
Walk a directory recursively, in breadth-first order.

The `recurse` predicate determines whether a directory is recursed.

Entries at each directory level are sorted.

**Line:** 713

---

### `def absolutepath(path: Union[(Path, str)]) -> Path`

**Description:**
Convert a path to an absolute path using os.path.abspath.

Prefer this over Path.resolve() (see #6523).
Prefer this over Path.absolute() (not public, doesn't normalize).

**Line:** 729

---

### `def commonpath(path1: Path, path2: Path) -> Optional[Path]`

**Description:**
Return the common part shared with the other path, or None if there is
no common part.

If one path is relative and one is absolute, returns None.

**Line:** 738

---

### `def bestrelpath(directory: Path, dest: Path) -> str`

**Description:**
Return a string which is a relative path from directory to dest such
that directory/bestrelpath == dest.

The paths must be either both absolute or both relative.

If no such path can be determined, returns dest.

**Line:** 750

---

### `def copytree(source: Path, target: Path) -> None`

**Description:**
Recursively copy a source directory to target.

**Line:** 781

---

### `def safe_exists(p: Path) -> bool`

**Description:**
Like Path.exists(), but account for input arguments that might be too long (#11394).

**Line:** 797

---


## Module: venv2.libthon3.12.site-packages._pytest.recwarn
**File:** `venv2/lib/python3.12/site-packages/_pytest/recwarn.py`

**Imports:**
- _pytest.compat.final
- _pytest.compat.overload
- _pytest.deprecated.WARNS_NONE_ARG
- _pytest.deprecated.check_ispytest
- _pytest.fixtures.fixture
- _pytest.outcomes.fail
- pprint.pformat
- re
- types.TracebackType
- typing.Any
- typing.Callable
- typing.Generator
- typing.Iterator
- typing.List
- typing.Optional
- typing.Pattern
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- warnings

**Functions:**

### `def recwarn() -> Generator[('WarningsRecorder', None, None)]`

**Decorators:**
- `@fixture`

**Description:**
Return a :class:`WarningsRecorder` instance that records all warnings emitted by test functions.

See https://docs.pytest.org/en/latest/how-to/capture-warnings.html for information
on warning categories.

**Line:** 30

---

### `def deprecated_call(match: Optional[Union[(str, Pattern[str])]] = Ellipsis) -> 'WarningsRecorder'`

**Decorators:**
- `@overload`

**Line:** 43

---

### `def deprecated_call(func: Callable[(..., T)], *args: Any, **kwargs: Any) -> T`

**Decorators:**
- `@overload`

**Line:** 50

---

### `def deprecated_call(func: Optional[Callable[(..., Any)]] = None, *args: Any, **kwargs: Any) -> Union[('WarningsRecorder', Any)]`

**Description:**
Assert that code produces a ``DeprecationWarning`` or ``PendingDeprecationWarning``.

This function can be used as a context manager::

>>> import warnings
>>> def api_call_v2():
...     warnings.warn('use v3 of this api', DeprecationWarning)
...     return 200

>>> import pytest
>>> with pytest.deprecated_call():
...    assert api_call_v2() == 200

It can also be used by passing a function and ``*args`` and ``**kwargs``,
in which case it will ensure calling ``func(*args, **kwargs)`` produces one of
the warnings types above. The return value is the return value of the function.

In the context manager form you may use the keyword argument ``match`` to assert
that the warning matches a text or regex.

The context manager produces a list of :class:`warnings.WarningMessage` objects,
one for each warning raised.

**Line:** 56

---

### `def warns(expected_warning: Union[(Type[Warning], Tuple[Type[Warning], ...])] = Ellipsis, match: Optional[Union[(str, Pattern[str])]] = Ellipsis) -> 'WarningsChecker'`

**Decorators:**
- `@overload`

**Line:** 89

---

### `def warns(expected_warning: Union[(Type[Warning], Tuple[Type[Warning], ...])], func: Callable[(..., T)], *args: Any, **kwargs: Any) -> T`

**Decorators:**
- `@overload`

**Line:** 98

---

### `def warns(expected_warning: Union[(Type[Warning], Tuple[Type[Warning], ...])] = Warning, match: Optional[Union[(str, Pattern[str])]] = None, *args: Any, **kwargs: Any) -> Union[('WarningsChecker', Any)]`

**Description:**
Assert that code raises a particular class of warning.

Specifically, the parameter ``expected_warning`` can be a warning class or sequence
of warning classes, and the code inside the ``with`` block must issue at least one
warning of that class or classes.

This helper produces a list of :class:`warnings.WarningMessage` objects, one for
each warning raised (regardless of whether it is an ``expected_warning`` or not).

This function can be used as a context manager, which will capture all the raised
warnings inside it::

>>> import pytest
>>> with pytest.warns(RuntimeWarning):
...    warnings.warn("my warning", RuntimeWarning)

In the context manager form you may use the keyword argument ``match`` to assert
that the warning matches a text or regex::

>>> with pytest.warns(UserWarning, match='must be 0 or None'):
...     warnings.warn("value must be 0 or None", UserWarning)

>>> with pytest.warns(UserWarning, match=r'must be \d+$'):
...     warnings.warn("value must be 42", UserWarning)

>>> with pytest.warns(UserWarning, match=r'must be \d+$'):
...     warnings.warn("this is not here", UserWarning)
Traceback (most recent call last):
...
Failed: DID NOT WARN. No warnings of type ...UserWarning... were emitted...

**Using with** ``pytest.mark.parametrize``

When using :ref:`pytest.mark.parametrize ref` it is possible to parametrize tests
such that some runs raise a warning and others do not.

This could be achieved in the same way as with exceptions, see
:ref:`parametrizing_conditional_raising` for an example.

**Line:** 107

---


## Module: venv2.libthon3.12.site-packages._pytest.reports
**File:** `venv2/lib/python3.12/site-packages/_pytest/reports.py`

**Imports:**
- _pytest._code.code.ExceptionChainRepr
- _pytest._code.code.ExceptionInfo
- _pytest._code.code.ExceptionRepr
- _pytest._code.code.ReprEntry
- _pytest._code.code.ReprEntryNative
- _pytest._code.code.ReprExceptionInfo
- _pytest._code.code.ReprFileLocation
- _pytest._code.code.ReprFuncArgs
- _pytest._code.code.ReprLocals
- _pytest._code.code.ReprTraceback
- _pytest._code.code.TerminalRepr
- _pytest._io.TerminalWriter
- _pytest.compat.final
- _pytest.config.Config
- _pytest.nodes.Collector
- _pytest.nodes.Item
- _pytest.outcomes.skip
- _pytest.runner.CallInfo
- dataclasses
- io.StringIO
- os
- pprint.pprint
- typing.Any
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.NoReturn
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing_extensions.Literal

**Functions:**

### `def getworkerinfoline(node)`

**Line:** 44

---

### `def _report_unserialization_failure(type_name: str, report_class: Type[BaseReport], reportdict) -> NoReturn`

**Line:** 229

---

### `def pytest_report_to_serializable(report: Union[(CollectReport, TestReport)]) -> Optional[Dict[(str, Any)]]`

**Line:** 444

---

### `def pytest_report_from_serializable(data: Dict[(str, Any)]) -> Optional[Union[(CollectReport, TestReport)]]`

**Line:** 455

---

### `def _report_to_json(report: BaseReport) -> Dict[(str, Any)]`

**Description:**
Return the contents of this report as a dict of builtin entries,
suitable for serialization.

This was originally the serialize_report() function from xdist (ca03269).

**Line:** 469

---

### `def _report_kwargs_from_json(reportdict: Dict[(str, Any)]) -> Dict[(str, Any)]`

**Description:**
Return **kwargs that can be used to construct a TestReport or
CollectReport instance.

This was originally the serialize_report() function from xdist (ca03269).

**Line:** 542

---


## Module: venv2.libthon3.12.site-packages._pytest.runner
**File:** `venv2/lib/python3.12/site-packages/_pytest/runner.py`

**Imports:**
- _pytest._code.code.ExceptionChainRepr
- _pytest._code.code.ExceptionInfo
- _pytest._code.code.TerminalRepr
- _pytest.compat.final
- _pytest.config.argparsing.Parser
- _pytest.deprecated.check_ispytest
- _pytest.main.Session
- _pytest.nodes.Collector
- _pytest.nodes.Item
- _pytest.nodes.Node
- _pytest.outcomes.Exit
- _pytest.outcomes.OutcomeException
- _pytest.outcomes.Skipped
- _pytest.outcomes.TEST_OUTCOME
- _pytest.terminal.TerminalReporter
- _pytest.timing
- bdb
- dataclasses
- exceptiongroup.BaseExceptionGroup
- os
- reports.BaseReport
- reports.CollectErrorRepr
- reports.CollectReport
- reports.TestReport
- sys
- typing.Callable
- typing.Dict
- typing.Generic
- typing.List
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing_extensions.Literal

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 50

---

### `def pytest_terminal_summary(terminalreporter: 'TerminalReporter') -> None`

**Line:** 71

---

### `def pytest_sessionstart(session: 'Session') -> None`

**Line:** 103

---

### `def pytest_sessionfinish(session: 'Session') -> None`

**Line:** 107

---

### `def pytest_runtest_protocol(item: Item, nextitem: Optional[Item]) -> bool`

**Line:** 111

---

### `def runtestprotocol(item: Item, log: bool = True, nextitem: Optional[Item] = None) -> List[TestReport]`

**Line:** 119

---

### `def show_test_item(item: Item) -> None`

**Description:**
Show test function, parameters and the fixtures of the test item.

**Line:** 143

---

### `def pytest_runtest_setup(item: Item) -> None`

**Line:** 155

---

### `def pytest_runtest_call(item: Item) -> None`

**Line:** 160

---

### `def pytest_runtest_teardown(item: Item, nextitem: Optional[Item]) -> None`

**Line:** 180

---

### `def _update_current_test_var(item: Item, when: Optional["Literal['setup', 'call', 'teardown']"]) -> None`

**Description:**
Update :envvar:`PYTEST_CURRENT_TEST` to reflect the current item and stage.

If ``when`` is None, delete ``PYTEST_CURRENT_TEST`` from the environment.

**Line:** 186

---

### `def pytest_report_teststatus(report: BaseReport) -> Optional[Tuple[(str, str, str)]]`

**Line:** 203

---

### `def call_and_report(item: Item, when: "Literal['setup', 'call', 'teardown']", log: bool = True, **kwds) -> TestReport`

**Line:** 219

---

### `def check_interactive_exception(call: 'CallInfo[object]', report: BaseReport) -> bool`

**Description:**
Check whether the call raised an exception that should be reported as
interactive.

**Line:** 232

---

### `def call_runtest_hook(item: Item, when: "Literal['setup', 'call', 'teardown']", **kwds) -> 'CallInfo[None]'`

**Line:** 247

---

### `def pytest_runtest_makereport(item: Item, call: CallInfo[None]) -> TestReport`

**Line:** 367

---

### `def pytest_make_collect_report(collector: Collector) -> CollectReport`

**Line:** 371

---

### `def collect_one_node(collector: Collector) -> CollectReport`

**Line:** 544

---


## Module: venv2.libthon3.12.site-packages._pytest.setuponly
**File:** `venv2/lib/python3.12/site-packages/_pytest/setuponly.py`

**Imports:**
- _pytest._io.saferepr.saferepr
- _pytest.config.Config
- _pytest.config.ExitCode
- _pytest.config.argparsing.Parser
- _pytest.fixtures.FixtureDef
- _pytest.fixtures.SubRequest
- _pytest.scope.Scope
- pytest
- typing.Generator
- typing.Optional
- typing.Union

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 15

---

### `def pytest_fixture_setup(fixturedef: FixtureDef[object], request: SubRequest) -> Generator[(None, None, None)]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 32

---

### `def pytest_fixture_post_finalizer(fixturedef: FixtureDef[object]) -> None`

**Line:** 51

---

### `def _show_fixture_action(fixturedef: FixtureDef[object], msg: str) -> None`

**Line:** 60

---

### `def pytest_cmdline_main(config: Config) -> Optional[Union[(int, ExitCode)]]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 94

---


## Module: venv2.libthon3.12.site-packages._pytest.setupplan
**File:** `venv2/lib/python3.12/site-packages/_pytest/setupplan.py`

**Imports:**
- _pytest.config.Config
- _pytest.config.ExitCode
- _pytest.config.argparsing.Parser
- _pytest.fixtures.FixtureDef
- _pytest.fixtures.SubRequest
- pytest
- typing.Optional
- typing.Union

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 12

---

### `def pytest_fixture_setup(fixturedef: FixtureDef[object], request: SubRequest) -> Optional[object]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 24

---

### `def pytest_cmdline_main(config: Config) -> Optional[Union[(int, ExitCode)]]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 36

---


## Module: venv2.libthon3.12.site-packages._pytest.skipping
**File:** `venv2/lib/python3.12/site-packages/_pytest/skipping.py`

**Imports:**
- _pytest.config.Config
- _pytest.config.argparsing.Parser
- _pytest.config.hookimpl
- _pytest.mark.structures.Mark
- _pytest.nodes.Item
- _pytest.outcomes.fail
- _pytest.outcomes.skip
- _pytest.outcomes.xfail
- _pytest.reports.BaseReport
- _pytest.runner.CallInfo
- _pytest.stash.StashKey
- collections.abc.Mapping
- dataclasses
- os
- platform
- pytest
- sys
- traceback
- typing.Generator
- typing.Optional
- typing.Tuple
- typing.Type

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 26

---

### `def pytest_configure(config: Config) -> None`

**Line:** 45

---

### `def evaluate_condition(item: Item, mark: Mark, condition: object) -> Tuple[(bool, str)]`

**Description:**
Evaluate a single skipif/xfail condition.

If an old-style string condition is given, it is eval()'d, otherwise the
condition is bool()'d. If this fails, an appropriately formatted pytest.fail
is raised.

Returns (result, reason). The reason is only relevant if the result is True.

**Line:** 84

---

### `def evaluate_skip_marks(item: Item) -> Optional[Skip]`

**Description:**
Evaluate skip and skipif marks on item, returning Skip if triggered.

**Line:** 166

---

### `def evaluate_xfail_marks(item: Item) -> Optional[Xfail]`

**Description:**
Evaluate xfail marks on item, returning Xfail if triggered.

**Line:** 206

---

### `def pytest_runtest_setup(item: Item) -> None`

**Decorators:**
- `@hookimpl(...)`

**Line:** 236

---

### `def pytest_runtest_call(item: Item) -> Generator[(None, None, None)]`

**Decorators:**
- `@hookimpl(...)`

**Line:** 247

---

### `def pytest_runtest_makereport(item: Item, call: CallInfo[None])`

**Decorators:**
- `@hookimpl(...)`

**Line:** 264

---

### `def pytest_report_teststatus(report: BaseReport) -> Optional[Tuple[(str, str, str)]]`

**Line:** 291

---


## Module: venv2.libthon3.12.site-packages._pytest.stepwise
**File:** `venv2/lib/python3.12/site-packages/_pytest/stepwise.py`

**Imports:**
- _pytest.cacheprovider.Cache
- _pytest.config.Config
- _pytest.config.argparsing.Parser
- _pytest.main.Session
- _pytest.nodes
- _pytest.reports.TestReport
- pytest
- typing.List
- typing.Optional
- typing.TYPE_CHECKING

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 18

---

### `def pytest_configure(config: Config) -> None`

**Decorators:**
- `@pytest.hookimpl`

**Line:** 40

---

### `def pytest_sessionfinish(session: Session) -> None`

**Line:** 48

---


## Module: venv2.libthon3.12.site-packages._pytest.terminal
**File:** `venv2/lib/python3.12/site-packages/_pytest/terminal.py`

**Imports:**
- _pytest._code.ExceptionInfo
- _pytest._code.code.ExceptionRepr
- _pytest._io.TerminalWriter
- _pytest._io.wcwidth.wcswidth
- _pytest._version
- _pytest.assertion.util.running_on_ci
- _pytest.compat.final
- _pytest.config
- _pytest.config.Config
- _pytest.config.ExitCode
- _pytest.config._PluggyPlugin
- _pytest.config.argparsing.Parser
- _pytest.config.hookimpl
- _pytest.main.Session
- _pytest.nodes
- _pytest.nodes.Item
- _pytest.nodes.Node
- _pytest.pathlib.absolutepath
- _pytest.pathlib.bestrelpath
- _pytest.reports.BaseReport
- _pytest.reports.CollectReport
- _pytest.reports.TestReport
- _pytest.timing
- _pytest.warnings.warning_record_to_str
- argparse
- collections.Counter
- dataclasses
- datetime
- functools.partial
- inspect
- pathlib.Path
- platform
- pluggy
- sys
- textwrap
- typing.Any
- typing.Callable
- typing.ClassVar
- typing.Dict
- typing.Generator
- typing.List
- typing.Mapping
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.TextIO
- typing.Tuple
- typing.Union
- typing.cast
- typing_extensions.Literal
- warnings

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 136

---

### `def pytest_configure(config: Config) -> None`

**Line:** 260

---

### `def getreportopt(config: Config) -> str`

**Line:** 272

---

### `def pytest_report_teststatus(report: BaseReport) -> Tuple[(str, str, str)]`

**Decorators:**
- `@hookimpl(...)`

**Line:** 298

---

### `def _get_node_id_with_markup(tw: TerminalWriter, config: Config, rep: BaseReport)`

**Line:** 1324

---

### `def _format_trimmed(format: str, msg: str, available_width: int) -> Optional[str]`

**Description:**
Format msg into format, ellipsizing it if doesn't fit in available_width.

Returns None if even the ellipsis can't fit.

**Line:** 1334

---

### `def _get_line_with_reprcrash_message(config: Config, rep: BaseReport, tw: TerminalWriter, word_markup: Dict[(str, bool)]) -> str`

**Description:**
Get summary line for a report, trying to add reprcrash message.

**Line:** 1359

---

### `def _folded_skips(startpath: Path, skipped: Sequence[CollectReport]) -> List[Tuple[(int, str, Optional[int], str)]]`

**Line:** 1387

---

### `def pluralize(count: int, noun: str) -> Tuple[(int, str)]`

**Line:** 1427

---

### `def _plugin_nameversions(plugininfo) -> List[str]`

**Line:** 1440

---

### `def format_session_duration(seconds: float) -> str`

**Description:**
Format the given seconds in a human readable manner to show in the final summary.

**Line:** 1454

---

### `def _get_raw_skip_reason(report: TestReport) -> str`

**Description:**
Get the reason string of a skip/xfail/xpass test report.

The string is just the part given by the user.

**Line:** 1463

---


## Module: venv2.libthon3.12.site-packages._pytest.threadexception
**File:** `venv2/lib/python3.12/site-packages/_pytest/threadexception.py`

**Imports:**
- pytest
- threading
- traceback
- types.TracebackType
- typing.Any
- typing.Callable
- typing.Generator
- typing.Optional
- typing.Type
- warnings

**Functions:**

### `def thread_exception_runtest_hook() -> Generator[(None, None, None)]`

**Line:** 60

---

### `def pytest_runtest_setup() -> Generator[(None, None, None)]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 77

---

### `def pytest_runtest_call() -> Generator[(None, None, None)]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 82

---

### `def pytest_runtest_teardown() -> Generator[(None, None, None)]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 87

---


## Module: venv2.libthon3.12.site-packages._pytest.tmpdir
**File:** `venv2/lib/python3.12/site-packages/_pytest/tmpdir.py`

**Imports:**
- _pytest.compat.final
- _pytest.compat.get_user_id
- _pytest.config.Config
- _pytest.config.ExitCode
- _pytest.config.argparsing.Parser
- _pytest.config.hookimpl
- _pytest.deprecated.check_ispytest
- _pytest.fixtures.FixtureRequest
- _pytest.fixtures.fixture
- _pytest.monkeypatch.MonkeyPatch
- _pytest.nodes.Item
- _pytest.reports.CollectReport
- _pytest.stash.StashKey
- dataclasses
- getpass
- os
- pathlib.LOCK_TIMEOUT
- pathlib.Path
- pathlib.cleanup_dead_symlinks
- pathlib.make_numbered_dir
- pathlib.make_numbered_dir_with_cleanup
- pathlib.rm_rf
- re
- shutil.rmtree
- tempfile
- typing.Any
- typing.Dict
- typing.Generator
- typing.Optional
- typing.TYPE_CHECKING
- typing.Union
- typing_extensions.Literal

**Functions:**

### `def get_user() -> Optional[str]`

**Description:**
Return the current user name, or None if getuser() does not work
in the current environment (see #1010).

**Line:** 204

---

### `def pytest_configure(config: Config) -> None`

**Description:**
Create a TempPathFactory and attach it to the config object.

This is to comply with existing plugins which expect the handler to be
available at pytest_configure time, but ideally should be moved entirely
to the tmp_path_factory session fixture.

**Line:** 216

---

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 229

---

### `def tmp_path_factory(request: FixtureRequest) -> TempPathFactory`

**Decorators:**
- `@fixture(...)`

**Description:**
Return a :class:`pytest.TempPathFactory` instance for the test session.

**Line:** 245

---

### `def _mk_tmp(request: FixtureRequest, factory: TempPathFactory) -> Path`

**Line:** 251

---

### `def tmp_path(request: FixtureRequest, tmp_path_factory: TempPathFactory) -> Generator[(Path, None, None)]`

**Decorators:**
- `@fixture`

**Description:**
Return a temporary directory path object which is unique to each test
function invocation, created as a sub directory of the base temporary
directory.

By default, a new base temporary directory is created each test session,
and old bases are removed after 3 sessions, to aid in debugging.
This behavior can be configured with :confval:`tmp_path_retention_count` and
:confval:`tmp_path_retention_policy`.
If ``--basetemp`` is used then it is cleared each session. See :ref:`base
temporary directory`.

The returned object is a :class:`pathlib.Path` object.

**Line:** 260

---

### `def pytest_sessionfinish(session, exitstatus: Union[(int, ExitCode)])`

**Description:**
After each session, remove base directory if all the tests passed,
the policy is "failed", and the basetemp is not specified by a user.

**Line:** 293

---

### `def pytest_runtest_makereport(item: Item, call)`

**Decorators:**
- `@hookimpl(...)`

**Line:** 319

---


## Module: venv2.libthon3.12.site-packages._pytest.unittest
**File:** `venv2/lib/python3.12/site-packages/_pytest/unittest.py`

**Imports:**
- _pytest._code
- _pytest.compat.getimfunc
- _pytest.compat.is_async_function
- _pytest.config.hookimpl
- _pytest.debugging.maybe_wrap_pytest_function_for_tracing
- _pytest.fixtures.FixtureRequest
- _pytest.nodes.Collector
- _pytest.nodes.Item
- _pytest.outcomes.exit
- _pytest.outcomes.fail
- _pytest.outcomes.skip
- _pytest.outcomes.xfail
- _pytest.python.Class
- _pytest.python.Function
- _pytest.python.Module
- _pytest.runner.CallInfo
- _pytest.scope.Scope
- pytest
- sys
- traceback
- twisted.trial.itrial.IReporter
- twisted.trial.unittest
- types
- typing.Any
- typing.Callable
- typing.Generator
- typing.Iterable
- typing.List
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.Union
- unittest
- unittest.TestLoader
- zope.interface.classImplements

**Functions:**

### `def pytest_pycollect_makeitem(collector: Union[(Module, Class)], name: str, obj: object) -> Optional['UnitTestCase']`

**Line:** 44

---

### `def _make_xunit_fixture(obj: type, setup_name: str, teardown_name: str, cleanup_name: Optional[str], scope: Scope, pass_self: bool)`

**Line:** 122

---

### `def pytest_runtest_makereport(item: Item, call: CallInfo[None]) -> None`

**Decorators:**
- `@hookimpl(...)`

**Line:** 350

---

### `def pytest_runtest_protocol(item: Item) -> Generator[(None, None, None)]`

**Decorators:**
- `@hookimpl(...)`

**Line:** 380

---

### `def check_testcase_implements_trial_reporter(done: List[int] = []) -> None`

**Line:** 409

---

### `def _is_skipped(obj) -> bool`

**Description:**
Return True if the given object has been marked with @unittest.skip.

**Line:** 419

---


## Module: venv2.libthon3.12.site-packages._pytest.unraisableexception
**File:** `venv2/lib/python3.12/site-packages/_pytest/unraisableexception.py`

**Imports:**
- pytest
- sys
- traceback
- types.TracebackType
- typing.Any
- typing.Callable
- typing.Generator
- typing.Optional
- typing.Type
- warnings

**Functions:**

### `def unraisable_exception_runtest_hook() -> Generator[(None, None, None)]`

**Line:** 62

---

### `def pytest_runtest_setup() -> Generator[(None, None, None)]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 82

---

### `def pytest_runtest_call() -> Generator[(None, None, None)]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 87

---

### `def pytest_runtest_teardown() -> Generator[(None, None, None)]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 92

---


## Module: venv2.libthon3.12.site-packages._pytest.warning_types
**File:** `venv2/lib/python3.12/site-packages/_pytest/warning_types.py`

**Imports:**
- _pytest.compat.final
- dataclasses
- inspect
- types.FunctionType
- typing.Any
- typing.Generic
- typing.Type
- typing.TypeVar
- warnings

**Functions:**

### `def warn_explicit_for(method: FunctionType, message: PytestWarning) -> None`

**Description:**
Issue the warning :param:`message` for the definition of the given :param:`method`

this helps to log warnings for functions defined prior to finding an issue with them
(like hook wrappers being marked in a legacy mechanism)

**Line:** 148

---


## Module: venv2.libthon3.12.site-packages._pytest.warnings
**File:** `venv2/lib/python3.12/site-packages/_pytest/warnings.py`

**Imports:**
- _pytest.config.Config
- _pytest.config.apply_warning_filters
- _pytest.config.parse_warning_filter
- _pytest.main.Session
- _pytest.nodes.Item
- _pytest.terminal.TerminalReporter
- contextlib.contextmanager
- pytest
- sys
- tracemalloc
- typing.Generator
- typing.Optional
- typing.TYPE_CHECKING
- typing_extensions.Literal
- warnings

**Functions:**

### `def pytest_configure(config: Config) -> None`

**Line:** 20

---

### `def catch_warnings_for_item(config: Config, ihook, when: "Literal['config', 'collect', 'runtest']", item: Optional[Item]) -> Generator[(None, None, None)]`

**Decorators:**
- `@contextmanager`

**Description:**
Context manager that catches warnings generated in the contained execution block.

``item`` can be None if we are not in the context of an item execution.

Each warning captured triggers the ``pytest_warning_recorded`` hook.

**Line:** 29

---

### `def warning_record_to_str(warning_message: warnings.WarningMessage) -> str`

**Description:**
Convert a warnings.WarningMessage to a string.

**Line:** 74

---

### `def pytest_runtest_protocol(item: Item) -> Generator[(None, None, None)]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 105

---

### `def pytest_collection(session: Session) -> Generator[(None, None, None)]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 113

---

### `def pytest_terminal_summary(terminalreporter: TerminalReporter) -> Generator[(None, None, None)]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 122

---

### `def pytest_sessionfinish(session: Session) -> Generator[(None, None, None)]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 133

---

### `def pytest_load_initial_conftests(early_config: 'Config') -> Generator[(None, None, None)]`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 142

---


## Module: venv2.libthon3.12.site-packages._pytesttester
**File:** `venv2/lib/python3.12/site-packages/_pytest/pytester.py`

**Imports:**
- _pytest._code.Source
- _pytest.capture._get_multicapture
- _pytest.compat.NOTSET
- _pytest.compat.NotSetType
- _pytest.compat.final
- _pytest.config
- _pytest.config.Config
- _pytest.config.ExitCode
- _pytest.config.PytestPluginManager
- _pytest.config._PluggyPlugin
- _pytest.config.argparsing.Parser
- _pytest.config.get_config
- _pytest.config.hookimpl
- _pytest.config.main
- _pytest.deprecated.check_ispytest
- _pytest.fixtures.FixtureRequest
- _pytest.fixtures.fixture
- _pytest.main.Session
- _pytest.monkeypatch.MonkeyPatch
- _pytest.nodes.Collector
- _pytest.nodes.Item
- _pytest.outcomes.fail
- _pytest.outcomes.importorskip
- _pytest.outcomes.skip
- _pytest.pathlib.bestrelpath
- _pytest.pathlib.copytree
- _pytest.pathlib.make_numbered_dir
- _pytest.pytester_assertions.assert_outcomes
- _pytest.pytester_assertions.assertoutcome
- _pytest.reports.CollectReport
- _pytest.reports.TestReport
- _pytest.timing
- _pytest.tmpdir.TempPathFactory
- _pytest.warning_types.PytestWarning
- collections.abc
- contextlib
- fnmatch.fnmatch
- gc
- importlib
- iniconfig.IniConfig
- iniconfig.SectionWrapper
- io.StringIO
- locale
- os
- pathlib.Path
- pexpect
- platform
- re
- shutil
- subprocess
- sys
- traceback
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generator
- typing.IO
- typing.Iterable
- typing.List
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.TextIO
- typing.Tuple
- typing.Type
- typing.Union
- typing.overload
- typing_extensions.Final
- typing_extensions.Literal
- weakref.WeakKeyDictionary

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 87

---

### `def pytest_configure(config: Config) -> None`

**Line:** 112

---

### `def _pytest(request: FixtureRequest) -> 'PytestArg'`

**Decorators:**
- `@fixture`

**Description:**
Return a helper which offers a gethookrecorder(hook) method which
returns a HookRecorder instance which helps to make assertions about called
hooks.

**Line:** 195

---

### `def get_public_names(values: Iterable[str]) -> List[str]`

**Description:**
Only return names from iterator values without a leading underscore.

**Line:** 212

---

### `def linecomp() -> 'LineComp'`

**Decorators:**
- `@fixture`

**Description:**
A :class: `LineComp` instance for checking that an input linearly
contains a sequence of strings.

**Line:** 465

---

### `def LineMatcher_fixture(request: FixtureRequest) -> Type['LineMatcher']`

**Decorators:**
- `@fixture(...)`

**Description:**
A reference to the :class: `LineMatcher`.

This is instantiable with a list of lines (without their trailing newlines).
This is useful for testing large texts, such as the output of commands.

**Line:** 472

---

### `def pytester(request: FixtureRequest, tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch) -> 'Pytester'`

**Decorators:**
- `@fixture`

**Description:**
Facilities to write tests/configuration files, execute pytest in isolation, and match
against expected output, perfect for black-box testing of pytest plugins.

It attempts to isolate the test run from external factors as much as possible, modifying
the current working directory to ``path`` and environment variables during initialization.

It is particularly useful for testing plugins. It is similar to the :fixture:`tmp_path`
fixture but provides methods which aid in testing pytest itself.

**Line:** 482

---

### `def _sys_snapshot() -> Generator[(None, None, None)]`

**Decorators:**
- `@fixture`

**Line:** 499

---

### `def _config_for_test() -> Generator[(Config, None, None)]`

**Decorators:**
- `@fixture`

**Line:** 508

---


## Module: venv2.libthon3.12.site-packages._pytesttester_assertions
**File:** `venv2/lib/python3.12/site-packages/_pytest/pytester_assertions.py`

**Imports:**
- _pytest.reports.CollectReport
- _pytest.reports.TestReport
- typing.Dict
- typing.Optional
- typing.Sequence
- typing.Tuple
- typing.Union

**Functions:**

### `def assertoutcome(outcomes: Tuple[(Sequence[TestReport], Sequence[Union[CollectReport, TestReport]], Sequence[Union[CollectReport, TestReport]])], passed: int = 0, skipped: int = 0, failed: int = 0) -> None`

**Line:** 16

---

### `def assert_outcomes(outcomes: Dict[(str, int)], passed: int = 0, skipped: int = 0, failed: int = 0, errors: int = 0, xpassed: int = 0, xfailed: int = 0, warnings: Optional[int] = None, deselected: Optional[int] = None) -> None`

**Description:**
Assert that the specified outcomes appear with the respective
numbers (0 means it didn't occur) in the text output from a test run.

**Line:** 38

---


## Module: venv2.libthon3.12.site-packages._pytestthon
**File:** `venv2/lib/python3.12/site-packages/_pytest/python.py`

**Imports:**
- _pytest
- _pytest._code.code.ExceptionInfo
- _pytest._code.code.TerminalRepr
- _pytest._code.code.Traceback
- _pytest._code.filter_traceback
- _pytest._code.getfslineno
- _pytest._io.TerminalWriter
- _pytest._io.saferepr.saferepr
- _pytest.compat.LEGACY_PATH
- _pytest.compat.NOTSET
- _pytest.compat.STRING_TYPES
- _pytest.compat.ascii_escaped
- _pytest.compat.assert_never
- _pytest.compat.final
- _pytest.compat.get_default_arg_names
- _pytest.compat.get_real_func
- _pytest.compat.getimfunc
- _pytest.compat.getlocation
- _pytest.compat.is_async_function
- _pytest.compat.is_generator
- _pytest.compat.safe_getattr
- _pytest.compat.safe_isclass
- _pytest.config
- _pytest.config.Config
- _pytest.config.ExitCode
- _pytest.config.argparsing.Parser
- _pytest.config.hookimpl
- _pytest.deprecated.INSTANCE_COLLECTOR
- _pytest.deprecated.NOSE_SUPPORT_METHOD
- _pytest.deprecated.check_ispytest
- _pytest.fixtures
- _pytest.fixtures.FuncFixtureInfo
- _pytest.main.Session
- _pytest.main.wrap_session
- _pytest.mark.MARK_GEN
- _pytest.mark.ParameterSet
- _pytest.mark.structures.Mark
- _pytest.mark.structures.MarkDecorator
- _pytest.mark.structures.get_unpacked_marks
- _pytest.mark.structures.normalize_mark_list
- _pytest.nodes
- _pytest.outcomes.fail
- _pytest.outcomes.skip
- _pytest.pathlib.ImportPathMismatchError
- _pytest.pathlib.bestrelpath
- _pytest.pathlib.fnmatch_ex
- _pytest.pathlib.import_path
- _pytest.pathlib.parts
- _pytest.pathlib.visit
- _pytest.scope.Scope
- _pytest.scope._ScopeName
- _pytest.warning_types.PytestCollectionWarning
- _pytest.warning_types.PytestReturnNotNoneWarning
- _pytest.warning_types.PytestUnhandledCoroutineWarning
- collections.Counter
- collections.defaultdict
- dataclasses
- enum
- fnmatch
- functools.partial
- inspect
- itertools
- os
- pathlib.Path
- sys
- types
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generator
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.Optional
- typing.Pattern
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- typing_extensions.Literal
- warnings

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 92

---

### `def pytest_cmdline_main(config: Config) -> Optional[Union[(int, ExitCode)]]`

**Line:** 138

---

### `def pytest_generate_tests(metafunc: 'Metafunc') -> None`

**Line:** 148

---

### `def pytest_configure(config: Config) -> None`

**Line:** 153

---

### `def async_warn_and_skip(nodeid: str) -> None`

**Line:** 173

---

### `def pytest_pyfunc_call(pyfuncitem: 'Function') -> Optional[object]`

**Decorators:**
- `@hookimpl(...)`

**Line:** 188

---

### `def pytest_collect_file(file_path: Path, parent: nodes.Collector) -> Optional['Module']`

**Line:** 207

---

### `def path_matches_patterns(path: Path, patterns: Iterable[str]) -> bool`

**Description:**
Return whether path matches any of the patterns in the list of globs given.

**Line:** 222

---

### `def pytest_pycollect_makemodule(module_path: Path, parent) -> 'Module'`

**Line:** 227

---

### `def pytest_pycollect_makeitem(collector: Union[('Module', 'Class')], name: str, obj: object) -> Union[(None, nodes.Item, nodes.Collector, List[Union[nodes.Item, nodes.Collector]])]`

**Decorators:**
- `@hookimpl(...)`

**Line:** 236

---

### `def _call_with_optional_argument(func, arg) -> None`

**Description:**
Call the given function with the given argument if func accepts one argument, otherwise
calls func without arguments.

**Line:** 770

---

### `def _get_first_non_fixture_func(obj: object, names: Iterable[str]) -> Optional[object]`

**Description:**
Return the attribute from the given object to be used as a setup/teardown
xunit-style function, but only if not marked as a fixture to avoid calling it twice.

**Line:** 782

---

### `def __getattr__(name: str) -> object`

**Line:** 929

---

### `def hasinit(obj: object) -> bool`

**Line:** 936

---

### `def hasnew(obj: object) -> bool`

**Line:** 943

---

### `def _find_parametrized_scope(argnames: Sequence[str], arg2fixturedefs: Mapping[(str, Sequence[fixtures.FixtureDef[object]])], indirect: Union[(bool, Sequence[str])]) -> Scope`

**Description:**
Find the most appropriate scope for a parametrized call based on its arguments.

When there's at least one direct argument, always use "function" scope.

When a test function is parametrized and all its arguments are indirect
(e.g. fixtures), return the most narrow scope based on the fixtures used.

Related to issue #1832, based on code posted by @Kingdread.

**Line:** 1502

---

### `def _ascii_escaped_by_config(val: Union[(str, bytes)], config: Optional[Config]) -> str`

**Line:** 1534

---

### `def _pretty_fixture_path(func) -> str`

**Line:** 1547

---

### `def show_fixtures_per_test(config)`

**Line:** 1557

---

### `def _show_fixtures_per_test(config: Config, session: Session) -> None`

**Line:** 1563

---

### `def showfixtures(config: Config) -> Union[(int, ExitCode)]`

**Line:** 1613

---

### `def _showfixtures_main(config: Config, session: Session) -> None`

**Line:** 1619

---

### `def write_docstring(tw: TerminalWriter, doc: str, indent: str = '    ') -> None`

**Line:** 1674

---


## Module: venv2.libthon3.12.site-packages._pytestthon_api
**File:** `venv2/lib/python3.12/site-packages/_pytest/python_api.py`

**Imports:**
- _pytest._code
- _pytest.compat.STRING_TYPES
- _pytest.compat.final
- _pytest.compat.overload
- _pytest.outcomes.fail
- collections.abc.Collection
- collections.abc.Sized
- decimal.Decimal
- itertools
- math
- numbers.Complex
- numpy
- numpy.ndarray
- pprint
- sys
- types.TracebackType
- typing.Any
- typing.Callable
- typing.ContextManager
- typing.List
- typing.Mapping
- typing.Optional
- typing.Pattern
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast

**Functions:**

### `def _non_numeric_type_error(value, at: Optional[str]) -> TypeError`

**Line:** 34

---

### `def _compare_approx(full_object: object, message_data: Sequence[Tuple[(str, str, str)]], number_of_elements: int, different_ids: Sequence[object], max_abs_diff: float, max_rel_diff: float) -> List[str]`

**Line:** 43

---

### `def _recursive_sequence_map(f, x)`

**Description:**
Recursively map a function over a sequence of arbitrary depth

**Line:** 136

---

### `def approx(expected, rel = None, abs = None, nan_ok: bool = False) -> ApproxBase`

**Description:**
Assert that two numbers (or two ordered sequences of numbers) are equal to each other
within some tolerance.

Due to the :doc:`python:tutorial/floatingpoint`, numbers that we
would intuitively expect to be equal are not always so::

>>> 0.1 + 0.2 == 0.3
False

This problem is commonly encountered when writing tests, e.g. when making
sure that floating-point values are what you expect them to be.  One way to
deal with this problem is to assert that two floating-point numbers are
equal to within some appropriate tolerance::

>>> abs((0.1 + 0.2) - 0.3) < 1e-6
True

However, comparisons like this are tedious to write and difficult to
understand.  Furthermore, absolute comparisons like the one above are
usually discouraged because there's no tolerance that works well for all
situations.  ``1e-6`` is good for numbers around ``1``, but too small for
very big numbers and too big for very small ones.  It's better to express
the tolerance as a fraction of the expected value, but relative comparisons
like that are even more difficult to write correctly and concisely.

The ``approx`` class performs floating-point comparisons using a syntax
that's as intuitive as possible::

>>> from pytest import approx
>>> 0.1 + 0.2 == approx(0.3)
True

The same syntax also works for ordered sequences of numbers::

>>> (0.1 + 0.2, 0.2 + 0.4) == approx((0.3, 0.6))
True

``numpy`` arrays::

>>> import numpy as np                                                          # doctest: +SKIP
>>> np.array([0.1, 0.2]) + np.array([0.2, 0.4]) == approx(np.array([0.3, 0.6])) # doctest: +SKIP
True

And for a ``numpy`` array against a scalar::

>>> import numpy as np                                         # doctest: +SKIP
>>> np.array([0.1, 0.2]) + np.array([0.2, 0.1]) == approx(0.3) # doctest: +SKIP
True

Only ordered sequences are supported, because ``approx`` needs
to infer the relative position of the sequences without ambiguity. This means
``sets`` and other unordered sequences are not supported.

Finally, dictionary *values* can also be compared::

>>> {'a': 0.1 + 0.2, 'b': 0.2 + 0.4} == approx({'a': 0.3, 'b': 0.6})
True

The comparison will be true if both mappings have the same keys and their
respective values match the expected tolerances.

**Tolerances**

By default, ``approx`` considers numbers within a relative tolerance of
``1e-6`` (i.e. one part in a million) of its expected value to be equal.
This treatment would lead to surprising results if the expected value was
``0.0``, because nothing but ``0.0`` itself is relatively close to ``0.0``.
To handle this case less surprisingly, ``approx`` also considers numbers
within an absolute tolerance of ``1e-12`` of its expected value to be
equal.  Infinity and NaN are special cases.  Infinity is only considered
equal to itself, regardless of the relative tolerance.  NaN is not
considered equal to anything by default, but you can make it be equal to
itself by setting the ``nan_ok`` argument to True.  (This is meant to
facilitate comparing arrays that use NaN to mean "no data".)

Both the relative and absolute tolerances can be changed by passing
arguments to the ``approx`` constructor::

>>> 1.0001 == approx(1)
False
>>> 1.0001 == approx(1, rel=1e-3)
True
>>> 1.0001 == approx(1, abs=1e-3)
True

If you specify ``abs`` but not ``rel``, the comparison will not consider
the relative tolerance at all.  In other words, two numbers that are within
the default relative tolerance of ``1e-6`` will still be considered unequal
if they exceed the specified absolute tolerance.  If you specify both
``abs`` and ``rel``, the numbers will be considered equal if either
tolerance is met::

>>> 1 + 1e-8 == approx(1)
True
>>> 1 + 1e-8 == approx(1, abs=1e-12)
False
>>> 1 + 1e-8 == approx(1, rel=1e-6, abs=1e-12)
True

You can also use ``approx`` to compare nonnumeric types, or dicts and
sequences containing nonnumeric types, in which case it falls back to
strict equality. This can be useful for comparing dicts and sequences that
can contain optional values::

>>> {"required": 1.0000005, "optional": None} == approx({"required": 1, "optional": None})
True
>>> [None, 1.0000005] == approx([None,1])
True
>>> ["foo", 1.0000005] == approx([None,1])
False

If you're thinking about using ``approx``, then you might want to know how
it compares to other good ways of comparing floating-point numbers.  All of
these algorithms are based on relative and absolute tolerances and should
agree for the most part, but they do have meaningful differences:

- ``math.isclose(a, b, rel_tol=1e-9, abs_tol=0.0)``:  True if the relative
tolerance is met w.r.t. either ``a`` or ``b`` or if the absolute
tolerance is met.  Because the relative tolerance is calculated w.r.t.
both ``a`` and ``b``, this test is symmetric (i.e.  neither ``a`` nor
``b`` is a "reference value").  You have to specify an absolute tolerance
if you want to compare to ``0.0`` because there is no tolerance by
default.  More information: :py:func:`math.isclose`.

- ``numpy.isclose(a, b, rtol=1e-5, atol=1e-8)``: True if the difference
between ``a`` and ``b`` is less that the sum of the relative tolerance
w.r.t. ``b`` and the absolute tolerance.  Because the relative tolerance
is only calculated w.r.t. ``b``, this test is asymmetric and you can
think of ``b`` as the reference value.  Support for comparing sequences
is provided by :py:func:`numpy.allclose`.  More information:
:std:doc:`numpy:reference/generated/numpy.isclose`.

- ``unittest.TestCase.assertAlmostEqual(a, b)``: True if ``a`` and ``b``
are within an absolute tolerance of ``1e-7``.  No relative tolerance is
considered , so this function is not appropriate for very large or very
small numbers.  Also, it's only available in subclasses of ``unittest.TestCase``
and it's ugly because it doesn't follow PEP8.  More information:
:py:meth:`unittest.TestCase.assertAlmostEqual`.

- ``a == pytest.approx(b, rel=1e-6, abs=1e-12)``: True if the relative
tolerance is met w.r.t. ``b`` or if the absolute tolerance is met.
Because the relative tolerance is only calculated w.r.t. ``b``, this test
is asymmetric and you can think of ``b`` as the reference value.  In the
special case that you explicitly specify an absolute tolerance but not a
relative tolerance, only the absolute tolerance is considered.

.. note::

``approx`` can handle numpy arrays, but we recommend the
specialised test helpers in :std:doc:`numpy:reference/routines.testing`
if you need support for comparisons, NaNs, or ULP-based tolerances.

To match strings using regex, you can use
`Matches <https://github.com/asottile/re-assert#re_assertmatchespattern-str-args-kwargs>`_
from the
`re_assert package <https://github.com/asottile/re-assert>`_.

.. warning::

.. versionchanged:: 3.2

In order to avoid inconsistent behavior, :py:exc:`TypeError` is
raised for ``>``, ``>=``, ``<`` and ``<=`` comparisons.
The example below illustrates the problem::

assert approx(0.1) > 0.1 + 1e-10  # calls approx(0.1).__gt__(0.1 + 1e-10)
assert 0.1 + 1e-10 > approx(0.1)  # calls approx(0.1).__lt__(0.1 + 1e-10)

In the second example one expects ``approx(0.1).__le__(0.1 + 1e-10)``
to be called. But instead, ``approx(0.1).__lt__(0.1 + 1e-10)`` is used to
comparison. This is because the call hierarchy of rich comparisons
follows a fixed behavior. More information: :py:meth:`object.__ge__`

.. versionchanged:: 3.7.1
``approx`` raises ``TypeError`` when it encounters a dict value or
sequence element of nonnumeric type.

.. versionchanged:: 6.1.0
``approx`` falls back to strict equality for nonnumeric types instead
of raising ``TypeError``.

**Line:** 527

---

### `def _is_numpy_array(obj: object) -> bool`

**Description:**
Return true if the given object is implicitly convertible to ndarray,
and numpy is already imported.

**Line:** 754

---

### `def _as_numpy_array(obj: object) -> Optional['ndarray']`

**Description:**
Return an ndarray if the given object is implicitly convertible to ndarray,
and numpy is already imported, otherwise None.

**Line:** 762

---

### `def raises(expected_exception: Union[(Type[E], Tuple[Type[E], ...])], match: Optional[Union[(str, Pattern[str])]] = Ellipsis) -> 'RaisesContext[E]'`

**Decorators:**
- `@overload`

**Line:** 787

---

### `def raises(expected_exception: Union[(Type[E], Tuple[Type[E], ...])], func: Callable[(..., Any)], *args: Any, **kwargs: Any) -> _pytest._code.ExceptionInfo[E]`

**Decorators:**
- `@overload`

**Line:** 796

---

### `def raises(expected_exception: Union[(Type[E], Tuple[Type[E], ...])], *args: Any, **kwargs: Any) -> Union[('RaisesContext[E]', _pytest._code.ExceptionInfo[E])]`

**Description:**
Assert that a code block/function call raises an exception.

:param typing.Type[E] | typing.Tuple[typing.Type[E], ...] expected_exception:
The expected exception type, or a tuple if one of multiple possible
exception types are expected.
:kwparam str | typing.Pattern[str] | None match:
If specified, a string containing a regular expression,
or a regular expression object, that is tested against the string
representation of the exception using :func:`re.search`.

To match a literal string that may contain :ref:`special characters
<re-syntax>`, the pattern can first be escaped with :func:`re.escape`.

(This is only used when :py:func:`pytest.raises` is used as a context manager,
and passed through to the function otherwise.
When using :py:func:`pytest.raises` as a function, you can use:
``pytest.raises(Exc, func, match="passed on").match("my pattern")``.)

.. currentmodule:: _pytest._code

Use ``pytest.raises`` as a context manager, which will capture the exception of the given
type::

>>> import pytest
>>> with pytest.raises(ZeroDivisionError):
...    1/0

If the code block does not raise the expected exception (``ZeroDivisionError`` in the example
above), or no exception at all, the check will fail instead.

You can also use the keyword argument ``match`` to assert that the
exception matches a text or regex::

>>> with pytest.raises(ValueError, match='must be 0 or None'):
...     raise ValueError("value must be 0 or None")

>>> with pytest.raises(ValueError, match=r'must be \d+$'):
...     raise ValueError("value must be 42")

The context manager produces an :class:`ExceptionInfo` object which can be used to inspect the
details of the captured exception::

>>> with pytest.raises(ValueError) as exc_info:
...     raise ValueError("value must be 42")
>>> assert exc_info.type is ValueError
>>> assert exc_info.value.args[0] == "value must be 42"

.. note::

When using ``pytest.raises`` as a context manager, it's worthwhile to
note that normal context manager rules apply and that the exception
raised *must* be the final line in the scope of the context manager.
Lines of code after that, within the scope of the context manager will
not be executed. For example::

>>> value = 15
>>> with pytest.raises(ValueError) as exc_info:
...     if value > 10:
...         raise ValueError("value must be <= 10")
...     assert exc_info.type is ValueError  # this will not execute

Instead, the following approach must be taken (note the difference in
scope)::

>>> with pytest.raises(ValueError) as exc_info:
...     if value > 10:
...         raise ValueError("value must be <= 10")
...
>>> assert exc_info.type is ValueError

**Using with** ``pytest.mark.parametrize``

When using :ref:`pytest.mark.parametrize ref`
it is possible to parametrize tests such that
some runs raise an exception and others do not.

See :ref:`parametrizing_conditional_raising` for an example.

**Legacy form**

It is possible to specify a callable by passing a to-be-called lambda::

>>> raises(ZeroDivisionError, lambda: 1/0)
<ExceptionInfo ...>

or you can specify an arbitrary callable with arguments::

>>> def f(x): return 1/x
...
>>> raises(ZeroDivisionError, f, 0)
<ExceptionInfo ...>
>>> raises(ZeroDivisionError, f, x=0)
<ExceptionInfo ...>

The form above is fully supported but discouraged for new code because the
context manager form is regarded as more readable and less error-prone.

.. note::
Similar to caught exception objects in Python, explicitly clearing
local references to returned ``ExceptionInfo`` objects can
help the Python interpreter speed up its garbage collection.

Clearing those references breaks a reference cycle
(``ExceptionInfo`` --> caught exception --> frame stack raising
the exception --> current frame stack --> local variables -->
``ExceptionInfo``) which makes Python keep all objects referenced
from that cycle (including all local variables in the current
frame) alive until the next cyclic garbage collection run.
More detailed information can be found in the official Python
documentation for :ref:`the try statement <python:try>`.

**Line:** 805

---


## Module: venv2.libthon3.12.site-packages._pytestthon_path
**File:** `venv2/lib/python3.12/site-packages/_pytest/python_path.py`

**Imports:**
- pytest
- pytest.Config
- pytest.Parser
- sys

**Functions:**

### `def pytest_addoption(parser: Parser) -> None`

**Line:** 8

---

### `def pytest_load_initial_conftests(early_config: Config) -> None`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 13

---

### `def pytest_unconfigure(config: Config) -> None`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 20

---


## Module: venv2.libthon3.12.site-packages.alembic.autogenerate.api
**File:** `venv2/lib/python3.12/site-packages/alembic/autogenerate/api.py`

**Imports:**
- __future__.annotations
- config.Config
- contextlib
- operations.ops
- operations.ops.DowngradeOps
- operations.ops.MigrationScript
- operations.ops.UpgradeOps
- runtime.environment.NameFilterParentNames
- runtime.environment.NameFilterType
- runtime.environment.ProcessRevisionDirectiveFn
- runtime.environment.RenderItemFn
- runtime.migration.MigrationContext
- script.base.Script
- script.base.ScriptDirectory
- script.revision._GetRevArg
- sqlalchemy.engine.Connection
- sqlalchemy.engine.Dialect
- sqlalchemy.engine.Inspector
- sqlalchemy.engine.default.DefaultDialect
- sqlalchemy.inspect
- sqlalchemy.sql.schema.MetaData
- sqlalchemy.sql.schema.SchemaItem
- sqlalchemy.sql.schema.Table
- typing.Any
- typing.Dict
- typing.Iterator
- typing.List
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Union
- util.sqla_compat

**Functions:**

### `def compare_metadata(context: MigrationContext, metadata: MetaData) -> Any`

**Description:**
Compare a database schema to that given in a
:class:`~sqlalchemy.schema.MetaData` instance.

The database connection is presented in the context
of a :class:`.MigrationContext` object, which
provides database connectivity as well as optional
comparison functions to use for datatypes and
server defaults - see the "autogenerate" arguments
at :meth:`.EnvironmentContext.configure`
for details on these.

The return format is a list of "diff" directives,
each representing individual differences::

from alembic.migration import MigrationContext
from alembic.autogenerate import compare_metadata
from sqlalchemy import (
create_engine,
MetaData,
Column,
Integer,
String,
Table,
text,
)
import pprint

engine = create_engine("sqlite://")

with engine.begin() as conn:
conn.execute(
text(
'''
create table foo (
id integer not null primary key,
old_data varchar,
x integer
)
'''
)
)
conn.execute(text("create table bar (data varchar)"))

metadata = MetaData()
Table(
"foo",
metadata,
Column("id", Integer, primary_key=True),
Column("data", Integer),
Column("x", Integer, nullable=False),
)
Table("bat", metadata, Column("info", String))

mc = MigrationContext.configure(engine.connect())

diff = compare_metadata(mc, metadata)
pprint.pprint(diff, indent=2, width=20)

Output::

[
(
"add_table",
Table(
"bat",
MetaData(),
Column("info", String(), table=<bat>),
schema=None,
),
),
(
"remove_table",
Table(
"bar",
MetaData(),
Column("data", VARCHAR(), table=<bar>),
schema=None,
),
),
(
"add_column",
None,
"foo",
Column("data", Integer(), table=<foo>),
),
[
(
"modify_nullable",
None,
"foo",
"x",
{
"existing_comment": None,
"existing_server_default": False,
"existing_type": INTEGER(),
},
True,
False,
)
],
(
"remove_column",
None,
"foo",
Column("old_data", VARCHAR(), table=<foo>),
),
]

:param context: a :class:`.MigrationContext`
instance.
:param metadata: a :class:`~sqlalchemy.schema.MetaData`
instance.

.. seealso::

:func:`.produce_migrations` - produces a :class:`.MigrationScript`
structure based on metadata comparison.

**Line:** 47

---

### `def produce_migrations(context: MigrationContext, metadata: MetaData) -> MigrationScript`

**Description:**
Produce a :class:`.MigrationScript` structure based on schema
comparison.

This function does essentially what :func:`.compare_metadata` does,
but then runs the resulting list of diffs to produce the full
:class:`.MigrationScript` object.   For an example of what this looks like,
see the example in :ref:`customizing_revision`.

.. seealso::

:func:`.compare_metadata` - returns more fundamental "diff"
data from comparing a schema.

**Line:** 173

---

### `def render_python_code(up_or_down_op: Union[(UpgradeOps, DowngradeOps)], sqlalchemy_module_prefix: str = 'sa.', alembic_module_prefix: str = 'op.', render_as_batch: bool = False, imports: Sequence[str] = (), render_item: Optional[RenderItemFn] = None, migration_context: Optional[MigrationContext] = None, user_module_prefix: Optional[str] = None) -> str`

**Description:**
Render Python code given an :class:`.UpgradeOps` or
:class:`.DowngradeOps` object.

This is a convenience function that can be used to test the
autogenerate output of a user-defined :class:`.MigrationScript` structure.

:param up_or_down_op: :class:`.UpgradeOps` or :class:`.DowngradeOps` object
:param sqlalchemy_module_prefix: module prefix for SQLAlchemy objects
:param alembic_module_prefix: module prefix for Alembic constructs
:param render_as_batch: use "batch operations" style for rendering
:param imports: sequence of import symbols to add
:param render_item: callable to render items
:param migration_context: optional :class:`.MigrationContext`
:param user_module_prefix: optional string prefix for user-defined types

.. versionadded:: 1.11.0

**Line:** 204

---

### `def _render_migration_diffs(context: MigrationContext, template_args: Dict[(Any, Any)]) -> None`

**Description:**
legacy, used by test_autogen_composition at the moment

**Line:** 255

---


## Module: venv2.libthon3.12.site-packages.alembic.autogenerate.compare
**File:** `venv2/lib/python3.12/site-packages/alembic/autogenerate/compare.py`

**Imports:**
- __future__.annotations
- alembic.autogenerate.api.AutogenContext
- alembic.ddl.impl.DefaultImpl
- alembic.operations.ops.AlterColumnOp
- alembic.operations.ops.MigrationScript
- alembic.operations.ops.ModifyTableOps
- alembic.operations.ops.UpgradeOps
- contextlib
- ddl._autogen._constraint_sig
- ddl._autogen.is_index_sig
- ddl._autogen.is_uq_sig
- logging
- operations.ops
- re
- sqlalchemy.engine.reflection.Inspector
- sqlalchemy.event
- sqlalchemy.inspect
- sqlalchemy.schema
- sqlalchemy.sql.elements.TextClause
- sqlalchemy.sql.elements.conv
- sqlalchemy.sql.elements.quoted_name
- sqlalchemy.sql.expression
- sqlalchemy.sql.schema.Column
- sqlalchemy.sql.schema.ForeignKeyConstraint
- sqlalchemy.sql.schema.Index
- sqlalchemy.sql.schema.Table
- sqlalchemy.sql.schema.UniqueConstraint
- sqlalchemy.text
- sqlalchemy.types
- sqlalchemy.util.OrderedSet
- typing.Any
- typing.Dict
- typing.Iterator
- typing.Literal
- typing.Mapping
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.cast
- util.sqla_compat

**Functions:**

### `def _populate_migration_script(autogen_context: AutogenContext, migration_script: MigrationScript) -> None`

**Line:** 60

---

### `def _produce_net_changes(autogen_context: AutogenContext, upgrade_ops: UpgradeOps) -> None`

**Line:** 73

---

### `def _autogen_for_tables(autogen_context: AutogenContext, upgrade_ops: UpgradeOps, schemas: Union[(Set[None], Set[Optional[str]])]) -> None`

**Decorators:**
- `@comparators.dispatch_for(...)`

**Line:** 105

---

### `def _compare_tables(conn_table_names: set, metadata_table_names: set, inspector: Inspector, upgrade_ops: UpgradeOps, autogen_context: AutogenContext) -> None`

**Line:** 147

---

### `def _make_index(impl: DefaultImpl, params: Dict[(str, Any)], conn_table: Table) -> Optional[Index]`

**Line:** 298

---

### `def _make_unique_constraint(impl: DefaultImpl, params: Dict[(str, Any)], conn_table: Table) -> UniqueConstraint`

**Line:** 330

---

### `def _make_foreign_key(params: Dict[(str, Any)], conn_table: Table) -> ForeignKeyConstraint`

**Line:** 344

---

### `def _compare_columns(schema: Optional[str], tname: Union[(quoted_name, str)], conn_table: Table, metadata_table: Table, modify_table_ops: ModifyTableOps, autogen_context: AutogenContext, inspector: Inspector) -> Iterator[None]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 368

---

### `def _compare_indexes_and_uniques(autogen_context: AutogenContext, modify_ops: ModifyTableOps, schema: Optional[str], tname: Union[(quoted_name, str)], conn_table: Optional[Table], metadata_table: Optional[Table]) -> None`

**Decorators:**
- `@comparators.dispatch_for(...)`

**Line:** 493

---

### `def _correct_for_uq_duplicates_uix(conn_unique_constraints, conn_indexes, metadata_unique_constraints, metadata_indexes, dialect, impl)`

**Line:** 847

---

### `def _compare_nullable(autogen_context: AutogenContext, alter_column_op: AlterColumnOp, schema: Optional[str], tname: Union[(quoted_name, str)], cname: Union[(quoted_name, str)], conn_col: Column[Any], metadata_col: Column[Any]) -> None`

**Decorators:**
- `@comparators.dispatch_for(...)`

**Line:** 911

---

### `def _setup_autoincrement(autogen_context: AutogenContext, alter_column_op: AlterColumnOp, schema: Optional[str], tname: Union[(quoted_name, str)], cname: quoted_name, conn_col: Column[Any], metadata_col: Column[Any]) -> None`

**Decorators:**
- `@comparators.dispatch_for(...)`

**Line:** 952

---

### `def _compare_type(autogen_context: AutogenContext, alter_column_op: AlterColumnOp, schema: Optional[str], tname: Union[(quoted_name, str)], cname: Union[(quoted_name, str)], conn_col: Column[Any], metadata_col: Column[Any]) -> None`

**Decorators:**
- `@comparators.dispatch_for(...)`

**Line:** 970

---

### `def _render_server_default_for_compare(metadata_default: Optional[Any], autogen_context: AutogenContext) -> Optional[str]`

**Line:** 1012

---

### `def _normalize_computed_default(sqltext: str) -> str`

**Description:**
we want to warn if a computed sql expression has changed.  however
we don't want false positives and the warning is not that critical.
so filter out most forms of variability from the SQL text.

**Line:** 1031

---

### `def _compare_computed_default(autogen_context: AutogenContext, alter_column_op: AlterColumnOp, schema: Optional[str], tname: str, cname: str, conn_col: Column[Any], metadata_col: Column[Any]) -> None`

**Line:** 1041

---

### `def _warn_computed_not_supported(tname: str, cname: str) -> None`

**Line:** 1085

---

### `def _compare_identity_default(autogen_context, alter_column_op, schema, tname, cname, conn_col, metadata_col)`

**Line:** 1089

---

### `def _compare_server_default(autogen_context: AutogenContext, alter_column_op: AlterColumnOp, schema: Optional[str], tname: Union[(quoted_name, str)], cname: Union[(quoted_name, str)], conn_col: Column[Any], metadata_col: Column[Any]) -> Optional[bool]`

**Decorators:**
- `@comparators.dispatch_for(...)`

**Line:** 1107

---

### `def _compare_column_comment(autogen_context: AutogenContext, alter_column_op: AlterColumnOp, schema: Optional[str], tname: Union[(quoted_name, str)], cname: quoted_name, conn_col: Column[Any], metadata_col: Column[Any]) -> Optional[Literal[False]]`

**Decorators:**
- `@comparators.dispatch_for(...)`

**Line:** 1183

---

### `def _compare_foreign_keys(autogen_context: AutogenContext, modify_table_ops: ModifyTableOps, schema: Optional[str], tname: Union[(quoted_name, str)], conn_table: Table, metadata_table: Table) -> None`

**Decorators:**
- `@comparators.dispatch_for(...)`

**Line:** 1211

---

### `def _compare_table_comment(autogen_context: AutogenContext, modify_table_ops: ModifyTableOps, schema: Optional[str], tname: Union[(quoted_name, str)], conn_table: Optional[Table], metadata_table: Optional[Table]) -> None`

**Decorators:**
- `@comparators.dispatch_for(...)`

**Line:** 1336

---


## Module: venv2.libthon3.12.site-packages.alembic.autogenerate.render
**File:** `venv2/lib/python3.12/site-packages/alembic/autogenerate/render.py`

**Imports:**
- __future__.annotations
- alembic.autogenerate.api.AutogenContext
- alembic.config.Config
- alembic.operations.ops.MigrationScript
- alembic.operations.ops.ModifyTableOps
- io.StringIO
- mako.pygen.PythonPrinter
- operations.ops
- re
- sqlalchemy.Computed
- sqlalchemy.Identity
- sqlalchemy.schema
- sqlalchemy.sql
- sqlalchemy.sql.base.DialectKWArgs
- sqlalchemy.sql.elements.ColumnElement
- sqlalchemy.sql.elements.Label
- sqlalchemy.sql.elements.TextClause
- sqlalchemy.sql.elements.conv
- sqlalchemy.sql.elements.quoted_name
- sqlalchemy.sql.schema.CheckConstraint
- sqlalchemy.sql.schema.Column
- sqlalchemy.sql.schema.Constraint
- sqlalchemy.sql.schema.FetchedValue
- sqlalchemy.sql.schema.ForeignKey
- sqlalchemy.sql.schema.ForeignKeyConstraint
- sqlalchemy.sql.schema.Index
- sqlalchemy.sql.schema.MetaData
- sqlalchemy.sql.schema.PrimaryKeyConstraint
- sqlalchemy.sql.schema.UniqueConstraint
- sqlalchemy.sql.sqltypes.ARRAY
- sqlalchemy.sql.type_api.TypeEngine
- sqlalchemy.types
- typing.Any
- typing.Dict
- typing.List
- typing.Literal
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- typing.cast
- util.sqla_compat

**Functions:**

### `def _render_gen_name(autogen_context: AutogenContext, name: sqla_compat._ConstraintName) -> Optional[Union[(quoted_name, str, _f_name)]]`

**Line:** 59

---

### `def _indent(text: str) -> str`

**Line:** 69

---

### `def _render_python_into_templatevars(autogen_context: AutogenContext, migration_script: MigrationScript, template_args: Dict[(str, Union[str, Config])]) -> None`

**Line:** 75

---

### `def _render_cmd_body(op_container: ops.OpContainer, autogen_context: AutogenContext) -> str`

**Line:** 97

---

### `def render_op(autogen_context: AutogenContext, op: ops.MigrateOperation) -> List[str]`

**Line:** 124

---

### `def render_op_text(autogen_context: AutogenContext, op: ops.MigrateOperation) -> str`

**Line:** 132

---

### `def _render_modify_table(autogen_context: AutogenContext, op: ModifyTableOps) -> List[str]`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 139

---

### `def _render_create_table_comment(autogen_context: AutogenContext, op: ops.CreateTableCommentOp) -> str`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 168

---

### `def _render_drop_table_comment(autogen_context: AutogenContext, op: ops.DropTableCommentOp) -> str`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 202

---

### `def _add_table(autogen_context: AutogenContext, op: ops.CreateTableOp) -> str`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 233

---

### `def _drop_table(autogen_context: AutogenContext, op: ops.DropTableOp) -> str`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 291

---

### `def _render_dialect_kwargs_items(autogen_context: AutogenContext, item: DialectKWArgs) -> list[str]`

**Line:** 306

---

### `def _add_index(autogen_context: AutogenContext, op: ops.CreateIndexOp) -> str`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 316

---

### `def _drop_index(autogen_context: AutogenContext, op: ops.DropIndexOp) -> str`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 356

---

### `def _add_unique_constraint(autogen_context: AutogenContext, op: ops.CreateUniqueConstraintOp) -> List[str]`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 382

---

### `def _add_fk_constraint(autogen_context: AutogenContext, op: ops.CreateForeignKeyOp) -> str`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 389

---

### `def _add_pk_constraint(constraint, autogen_context)`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 428

---

### `def _add_check_constraint(constraint, autogen_context)`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 433

---

### `def _drop_constraint(autogen_context: AutogenContext, op: ops.DropConstraintOp) -> str`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 438

---

### `def _add_column(autogen_context: AutogenContext, op: ops.AddColumnOp) -> str`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 461

---

### `def _drop_column(autogen_context: AutogenContext, op: ops.DropColumnOp) -> str`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 488

---

### `def _alter_column(autogen_context: AutogenContext, op: ops.AlterColumnOp) -> str`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 517

---

### `def _ident(name: Optional[Union[(quoted_name, str)]]) -> Optional[str]`

**Description:**
produce a __repr__() object for a string identifier that may
use quoted_name() in SQLAlchemy 0.9 and greater.

The issue worked around here is that quoted_name() doesn't have
very good repr() behavior by itself when unicode is involved.

**Line:** 589

---

### `def _render_potential_expr(value: Any, autogen_context: AutogenContext, wrap_in_element: bool = True, is_server_default: bool = False, is_index: bool = False) -> str`

**Line:** 605

---

### `def _get_index_rendered_expressions(idx: Index, autogen_context: AutogenContext) -> List[str]`

**Line:** 635

---

### `def _uq_constraint(constraint: UniqueConstraint, autogen_context: AutogenContext, alter: bool) -> str`

**Line:** 648

---

### `def _user_autogenerate_prefix(autogen_context, target)`

**Line:** 690

---

### `def _sqlalchemy_autogenerate_prefix(autogen_context: AutogenContext) -> str`

**Line:** 698

---

### `def _alembic_autogenerate_prefix(autogen_context: AutogenContext) -> str`

**Line:** 702

---

### `def _user_defined_render(type_: str, object_: Any, autogen_context: AutogenContext) -> Union[(str, Literal[False])]`

**Line:** 709

---

### `def _render_column(column: Column[Any], autogen_context: AutogenContext) -> str`

**Line:** 721

---

### `def _should_render_server_default_positionally(server_default: Any) -> bool`

**Line:** 778

---

### `def _render_server_default(default: Optional[Union[(FetchedValue, str, TextClause, ColumnElement[Any])]], autogen_context: AutogenContext, repr_: bool = True) -> Optional[str]`

**Line:** 784

---

### `def _render_computed(computed: Computed, autogen_context: AutogenContext) -> str`

**Line:** 813

---

### `def _render_identity(identity: Identity, autogen_context: AutogenContext) -> str`

**Line:** 830

---

### `def _repr_type(type_: TypeEngine, autogen_context: AutogenContext, _skip_variants: bool = False) -> str`

**Line:** 843

---

### `def _render_ARRAY_type(type_: ARRAY, autogen_context: AutogenContext) -> str`

**Line:** 888

---

### `def _render_Variant_type(type_: TypeEngine, autogen_context: AutogenContext) -> str`

**Line:** 897

---

### `def _render_type_w_subtype(type_: TypeEngine, autogen_context: AutogenContext, attrname: str, regexp: str, prefix: Optional[str] = None) -> Union[(Optional[str], Literal[False])]`

**Line:** 912

---

### `def _render_constraint(constraint: Constraint, autogen_context: AutogenContext, namespace_metadata: Optional[MetaData]) -> Optional[str]`

**Line:** 949

---

### `def _render_primary_key(constraint: PrimaryKeyConstraint, autogen_context: AutogenContext, namespace_metadata: Optional[MetaData]) -> Optional[str]`

**Decorators:**
- `@_constraint_renderers.dispatch_for(...)`

**Line:** 964

---

### `def _fk_colspec(fk: ForeignKey, metadata_schema: Optional[str], namespace_metadata: MetaData) -> str`

**Description:**
Implement a 'safe' version of ForeignKey._get_colspec() that
won't fail if the remote table can't be resolved.

**Line:** 990

---

### `def _populate_render_fk_opts(constraint: ForeignKeyConstraint, opts: List[Tuple[(str, str)]]) -> None`

**Line:** 1027

---

### `def _render_foreign_key(constraint: ForeignKeyConstraint, autogen_context: AutogenContext, namespace_metadata: MetaData) -> Optional[str]`

**Decorators:**
- `@_constraint_renderers.dispatch_for(...)`

**Line:** 1045

---

### `def _render_unique_constraint(constraint: UniqueConstraint, autogen_context: AutogenContext, namespace_metadata: Optional[MetaData]) -> str`

**Decorators:**
- `@_constraint_renderers.dispatch_for(...)`

**Line:** 1083

---

### `def _render_check_constraint(constraint: CheckConstraint, autogen_context: AutogenContext, namespace_metadata: Optional[MetaData]) -> Optional[str]`

**Decorators:**
- `@_constraint_renderers.dispatch_for(...)`

**Line:** 1096

---

### `def _execute_sql(autogen_context: AutogenContext, op: ops.ExecuteSQLOp) -> str`

**Decorators:**
- `@renderers.dispatch_for(...)`

**Line:** 1137

---


## Module: venv2.libthon3.12.site-packages.alembic.command
**File:** `venv2/lib/python3.12/site-packages/alembic/command.py`

**Imports:**
- __future__.annotations
- alembic.config.Config
- alembic.script.base.Script
- alembic.script.revision._RevIdType
- os
- pathlib
- runtime.environment.EnvironmentContext
- runtime.environment.ProcessRevisionDirectiveFn
- script.ScriptDirectory
- typing.List
- typing.Optional
- typing.TYPE_CHECKING
- typing.Union
- util.compat

**Functions:**

### `def list_templates(config: Config) -> None`

**Description:**
List available templates.

:param config: a :class:`.Config` object.

**Line:** 25

---

### `def init(config: Config, directory: str, template: str = 'generic', package: bool = False) -> None`

**Description:**
Initialize a new scripts directory.

:param config: a :class:`.Config` object.

:param directory: string path of the target directory.

:param template: string name of the migration environment template to
use.

:param package: when True, write ``__init__.py`` files into the
environment location as well as the versions/ location.

**Line:** 42

---

### `def revision(config: Config, message: Optional[str] = None, autogenerate: bool = False, sql: bool = False, head: str = 'head', splice: bool = False, branch_label: Optional[_RevIdType] = None, version_path: Union[(str, os.PathLike[str], None)] = None, rev_id: Optional[str] = None, depends_on: Optional[str] = None, process_revision_directives: Optional[ProcessRevisionDirectiveFn] = None) -> Union[(Optional[Script], List[Optional[Script]])]`

**Description:**
Create a new revision file.

:param config: a :class:`.Config` object.

:param message: string message to apply to the revision; this is the
``-m`` option to ``alembic revision``.

:param autogenerate: whether or not to autogenerate the script from
the database; this is the ``--autogenerate`` option to
``alembic revision``.

:param sql: whether to dump the script out as a SQL string; when specified,
the script is dumped to stdout.  This is the ``--sql`` option to
``alembic revision``.

:param head: head revision to build the new revision upon as a parent;
this is the ``--head`` option to ``alembic revision``.

:param splice: whether or not the new revision should be made into a
new head of its own; is required when the given ``head`` is not itself
a head.  This is the ``--splice`` option to ``alembic revision``.

:param branch_label: string label to apply to the branch; this is the
``--branch-label`` option to ``alembic revision``.

:param version_path: string symbol identifying a specific version path
from the configuration; this is the ``--version-path`` option to
``alembic revision``.

:param rev_id: optional revision identifier to use instead of having
one generated; this is the ``--rev-id`` option to ``alembic revision``.

:param depends_on: optional list of "depends on" identifiers; this is the
``--depends-on`` option to ``alembic revision``.

:param process_revision_directives: this is a callable that takes the
same form as the callable described at
:paramref:`.EnvironmentContext.configure.process_revision_directives`;
will be applied to the structure generated by the revision process
where it can be altered programmatically.   Note that unlike all
the other parameters, this option is only available via programmatic
use of :func:`.command.revision`.

**Line:** 194

---

### `def check(config: 'Config') -> None`

**Description:**
Check if revision command with autogenerate has pending upgrade ops.

:param config: a :class:`.Config` object.

.. versionadded:: 1.9.0

**Line:** 323

---

### `def merge(config: Config, revisions: _RevIdType, message: Optional[str] = None, branch_label: Optional[_RevIdType] = None, rev_id: Optional[str] = None) -> Optional[Script]`

**Description:**
Merge two revisions together.  Creates a new migration file.

:param config: a :class:`.Config` instance

:param revisions: The revisions to merge.

:param message: string message to apply to the revision.

:param branch_label: string label name to apply to the new revision.

:param rev_id: hardcoded revision identifier instead of generating a new
one.

.. seealso::

:ref:`branches`

**Line:** 382

---

### `def upgrade(config: Config, revision: str, sql: bool = False, tag: Optional[str] = None) -> None`

**Description:**
Upgrade to a later version.

:param config: a :class:`.Config` instance.

:param revision: string revision target or range for --sql mode. May be
``"heads"`` to target the most recent revision(s).

:param sql: if True, use ``--sql`` mode.

:param tag: an arbitrary "tag" that can be intercepted by custom
``env.py`` scripts via the :meth:`.EnvironmentContext.get_tag_argument`
method.

**Line:** 442

---

### `def downgrade(config: Config, revision: str, sql: bool = False, tag: Optional[str] = None) -> None`

**Description:**
Revert to a previous version.

:param config: a :class:`.Config` instance.

:param revision: string revision target or range for --sql mode. May
be ``"base"`` to target the first revision.

:param sql: if True, use ``--sql`` mode.

:param tag: an arbitrary "tag" that can be intercepted by custom
``env.py`` scripts via the :meth:`.EnvironmentContext.get_tag_argument`
method.

**Line:** 486

---

### `def show(config: Config, rev: str) -> None`

**Description:**
Show the revision(s) denoted by the given symbol.

:param config: a :class:`.Config` instance.

:param rev: string revision target. May be ``"current"`` to show the
revision(s) currently applied in the database.

**Line:** 533

---

### `def history(config: Config, rev_range: Optional[str] = None, verbose: bool = False, indicate_current: bool = False) -> None`

**Description:**
List changeset scripts in chronological order.

:param config: a :class:`.Config` instance.

:param rev_range: string revision range.

:param verbose: output in verbose mode.

:param indicate_current: indicate current revision.

**Line:** 559

---

### `def heads(config: Config, verbose: bool = False, resolve_dependencies: bool = False) -> None`

**Description:**
Show current available heads in the script directory.

:param config: a :class:`.Config` instance.

:param verbose: output in verbose mode.

:param resolve_dependencies: treat dependency version as down revisions.

**Line:** 628

---

### `def branches(config: Config, verbose: bool = False) -> None`

**Description:**
Show current branch points.

:param config: a :class:`.Config` instance.

:param verbose: output in verbose mode.

**Line:** 655

---

### `def current(config: Config, verbose: bool = False) -> None`

**Description:**
Display the current revision for a database.

:param config: a :class:`.Config` instance.

:param verbose: output in verbose mode.

**Line:** 684

---

### `def stamp(config: Config, revision: _RevIdType, sql: bool = False, tag: Optional[str] = None, purge: bool = False) -> None`

**Description:**
'stamp' the revision table with the given revision; don't
run any migrations.

:param config: a :class:`.Config` instance.

:param revision: target revision or list of revisions.   May be a list
to indicate stamping of multiple branch heads; may be ``"base"``
to remove all revisions from the table or ``"heads"`` to stamp the
most recent revision(s).

.. note:: this parameter is called "revisions" in the command line
interface.

:param sql: use ``--sql`` mode

:param tag: an arbitrary "tag" that can be intercepted by custom
``env.py`` scripts via the :class:`.EnvironmentContext.get_tag_argument`
method.

:param purge: delete all entries in the version table before stamping.

**Line:** 712

---

### `def edit(config: Config, rev: str) -> None`

**Description:**
Edit revision script(s) using $EDITOR.

:param config: a :class:`.Config` instance.

:param rev: target revision.

**Line:** 779

---

### `def ensure_version(config: Config, sql: bool = False) -> None`

**Description:**
Create the alembic version table if it doesn't exist already .

:param config: a :class:`.Config` instance.

:param sql: use ``--sql`` mode.

.. versionadded:: 1.7.6

**Line:** 812

---


## Module: venv2.libthon3.12.site-packages.alembic.config
**File:** `venv2/lib/python3.12/site-packages/alembic/config.py`

**Imports:**
- __future__.annotations
- alembic
- argparse.ArgumentParser
- argparse.Namespace
- configparser.ConfigParser
- inspect
- os
- pathlib.Path
- re
- sys
- typing.Any
- typing.Dict
- typing.Mapping
- typing.Optional
- typing.Protocol
- typing.Sequence
- typing.TextIO
- typing.Union
- typing.cast
- typing.overload
- typing_extensions.TypedDict
- util.compat
- util.pyfiles._preserving_path_as_str

**Functions:**

### `def main(argv: Optional[Sequence[str]] = None, prog: Optional[str] = None, **kwargs: Any) -> None`

**Description:**
The console runner function for Alembic.

**Line:** 981

---


## Module: venv2.libthon3.12.site-packages.alembic.ddl._autogen
**File:** `venv2/lib/python3.12/site-packages/alembic/ddl/_autogen.py`

**Imports:**
- __future__.annotations
- alembic.autogenerate.api.AutogenContext
- alembic.ddl.impl.DefaultImpl
- sqlalchemy.sql.schema.Constraint
- sqlalchemy.sql.schema.ForeignKeyConstraint
- sqlalchemy.sql.schema.Index
- sqlalchemy.sql.schema.UniqueConstraint
- typing.Any
- typing.ClassVar
- typing.Dict
- typing.Generic
- typing.Literal
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing_extensions.TypeGuard
- util.sqla_compat

**Functions:**

### `def is_index_sig(sig: _constraint_sig) -> TypeGuard[_ix_constraint_sig]`

**Line:** 320

---

### `def is_uq_sig(sig: _constraint_sig) -> TypeGuard[_uq_constraint_sig]`

**Line:** 324

---

### `def is_fk_sig(sig: _constraint_sig) -> TypeGuard[_fk_constraint_sig]`

**Line:** 328

---


## Module: venv2.libthon3.12.site-packages.alembic.ddl.base
**File:** `venv2/lib/python3.12/site-packages/alembic/ddl/base.py`

**Imports:**
- __future__.annotations
- functools
- impl.DefaultImpl
- sqlalchemy.Computed
- sqlalchemy.Identity
- sqlalchemy.Integer
- sqlalchemy.exc
- sqlalchemy.ext.compiler.compiles
- sqlalchemy.schema.Column
- sqlalchemy.schema.DDLElement
- sqlalchemy.sql.compiler.Compiled
- sqlalchemy.sql.compiler.DDLCompiler
- sqlalchemy.sql.elements.TextClause
- sqlalchemy.sql.elements.quoted_name
- sqlalchemy.sql.functions.Function
- sqlalchemy.sql.schema.FetchedValue
- sqlalchemy.sql.type_api.TypeEngine
- sqlalchemy.types
- typing.Any
- typing.Optional
- typing.TYPE_CHECKING
- typing.Union
- util.sqla_compat._columns_for_constraint
- util.sqla_compat._find_columns
- util.sqla_compat._fk_spec
- util.sqla_compat._is_type_bound
- util.sqla_compat._table_for_constraint

**Functions:**

### `def visit_rename_table(element: RenameTable, compiler: DDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 186

---

### `def visit_add_column(element: AddColumn, compiler: DDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 196

---

### `def visit_drop_column(element: DropColumn, compiler: DDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 206

---

### `def visit_column_nullable(element: ColumnNullable, compiler: DDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 216

---

### `def visit_column_type(element: ColumnType, compiler: DDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 227

---

### `def visit_column_name(element: ColumnName, compiler: DDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 236

---

### `def visit_column_default(element: ColumnDefault, compiler: DDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 245

---

### `def visit_computed_column(element: ComputedColumnDefault, compiler: DDLCompiler, **kw)`

**Decorators:**
- `@compiles(...)`

**Line:** 260

---

### `def visit_identity_column(element: IdentityColumnDefault, compiler: DDLCompiler, **kw)`

**Decorators:**
- `@compiles(...)`

**Line:** 270

---

### `def quote_dotted(name: Union[(quoted_name, str)], quote: functools.partial) -> Union[(quoted_name, str)]`

**Description:**
quote the elements of a dotted name

**Line:** 280

---

### `def format_table_name(compiler: Compiled, name: Union[(quoted_name, str)], schema: Optional[Union[(quoted_name, str)]]) -> Union[(quoted_name, str)]`

**Line:** 291

---

### `def format_column_name(compiler: DDLCompiler, name: Optional[Union[(quoted_name, str)]]) -> Union[(quoted_name, str)]`

**Line:** 303

---

### `def format_server_default(compiler: DDLCompiler, default: Optional[_ServerDefault]) -> str`

**Line:** 309

---

### `def format_type(compiler: DDLCompiler, type_: TypeEngine) -> str`

**Line:** 322

---

### `def alter_table(compiler: DDLCompiler, name: str, schema: Optional[str]) -> str`

**Line:** 326

---

### `def drop_column(compiler: DDLCompiler, name: str, if_exists: Optional[bool] = None, **kw) -> str`

**Line:** 334

---

### `def alter_column(compiler: DDLCompiler, name: str) -> str`

**Line:** 343

---

### `def add_column(compiler: DDLCompiler, column: Column[Any], if_not_exists: Optional[bool] = None, **kw) -> str`

**Line:** 347

---


## Module: venv2.libthon3.12.site-packages.alembic.ddl.impl
**File:** `venv2/lib/python3.12/site-packages/alembic/ddl/impl.py`

**Imports:**
- __future__.annotations
- _autogen.ComparisonResult
- _autogen._constraint_sig
- autogenerate.api.AutogenContext
- base._ServerDefault
- logging
- operations.batch.ApplyBatchImpl
- operations.batch.BatchOperationsImpl
- re
- sqlalchemy.Column
- sqlalchemy.MetaData
- sqlalchemy.PrimaryKeyConstraint
- sqlalchemy.String
- sqlalchemy.Table
- sqlalchemy.cast
- sqlalchemy.engine.Connection
- sqlalchemy.engine.Dialect
- sqlalchemy.engine.cursor.CursorResult
- sqlalchemy.engine.reflection.Inspector
- sqlalchemy.schema
- sqlalchemy.sql.ClauseElement
- sqlalchemy.sql.Executable
- sqlalchemy.sql.elements.quoted_name
- sqlalchemy.sql.schema.Constraint
- sqlalchemy.sql.schema.ForeignKeyConstraint
- sqlalchemy.sql.schema.Index
- sqlalchemy.sql.schema.UniqueConstraint
- sqlalchemy.sql.selectable.TableClause
- sqlalchemy.sql.type_api.TypeEngine
- sqlalchemy.text
- typing.Any
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.List
- typing.Literal
- typing.Mapping
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.TextIO
- typing.Tuple
- typing.Type
- typing.Union
- util.sqla_compat

**Functions:**

### `def _compare_identity_options(metadata_io: Union[(schema.Identity, schema.Sequence, None)], inspector_io: Union[(schema.Identity, schema.Sequence, None)], default_io: Union[(schema.Identity, schema.Sequence)], skip: Set[str])`

**Line:** 854

---


## Module: venv2.libthon3.12.site-packages.alembic.ddl.mssql
**File:** `venv2/lib/python3.12/site-packages/alembic/ddl/mssql.py`

**Imports:**
- __future__.annotations
- base.AddColumn
- base.ColumnDefault
- base.ColumnName
- base.ColumnNullable
- base.ColumnType
- base.RenameTable
- base._ServerDefault
- base.alter_column
- base.alter_table
- base.format_column_name
- base.format_server_default
- base.format_table_name
- base.format_type
- impl.DefaultImpl
- re
- sqlalchemy.dialects.mssql.base.MSDDLCompiler
- sqlalchemy.dialects.mssql.base.MSSQLCompiler
- sqlalchemy.engine.cursor.CursorResult
- sqlalchemy.schema.Column
- sqlalchemy.schema.CreateIndex
- sqlalchemy.sql.base.Executable
- sqlalchemy.sql.elements.ClauseElement
- sqlalchemy.sql.schema.Index
- sqlalchemy.sql.schema.Table
- sqlalchemy.sql.selectable.TableClause
- sqlalchemy.sql.type_api.TypeEngine
- sqlalchemy.types
- typing.Any
- typing.Dict
- typing.List
- typing.Literal
- typing.Optional
- typing.TYPE_CHECKING
- typing.Union
- util.sqla_compat
- util.sqla_compat.compiles

**Functions:**

### `def _exec_drop_col_constraint(element: _ExecDropConstraint, compiler: MSSQLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 309

---

### `def _exec_drop_col_fk_constraint(element: _ExecDropFKConstraint, compiler: MSSQLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 334

---

### `def visit_add_column(element: AddColumn, compiler: MSDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 354

---

### `def mssql_add_column(compiler: MSDDLCompiler, column: Column[Any], **kw) -> str`

**Line:** 361

---

### `def visit_column_nullable(element: ColumnNullable, compiler: MSDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 368

---

### `def visit_column_default(element: ColumnDefault, compiler: MSDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 380

---

### `def visit_rename_column(element: ColumnName, compiler: MSDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 393

---

### `def visit_column_type(element: ColumnType, compiler: MSDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 404

---

### `def visit_rename_table(element: RenameTable, compiler: MSDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 415

---


## Module: venv2.libthon3.12.site-packages.alembic.ddl.mysql
**File:** `venv2/lib/python3.12/site-packages/alembic/ddl/mysql.py`

**Imports:**
- __future__.annotations
- base.AlterColumn
- base.ColumnDefault
- base.ColumnName
- base.ColumnNullable
- base.ColumnType
- base._ServerDefault
- base.alter_table
- base.format_column_name
- base.format_server_default
- impl.DefaultImpl
- re
- sqlalchemy.dialects.mysql.base.MySQLDDLCompiler
- sqlalchemy.schema
- sqlalchemy.sql.ddl.DropConstraint
- sqlalchemy.sql.schema.Constraint
- sqlalchemy.sql.type_api.TypeEngine
- sqlalchemy.types
- typing.Any
- typing.Literal
- typing.Optional
- typing.TYPE_CHECKING
- typing.Union
- util.sqla_compat
- util.sqla_compat._is_type_bound
- util.sqla_compat.compiles

**Functions:**

### `def _mysql_doesnt_support_individual(element, compiler, **kw)`

**Decorators:**
- `@compiles(...)`
- `@compiles(...)`
- `@compiles(...)`
- `@compiles(...)`

**Line:** 377

---

### `def _mysql_alter_default(element: MySQLAlterDefault, compiler: MySQLDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 384

---

### `def _mysql_modify_column(element: MySQLModifyColumn, compiler: MySQLDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 399

---

### `def _mysql_change_column(element: MySQLChangeColumn, compiler: MySQLDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 417

---

### `def _mysql_colspec(compiler: MySQLDDLCompiler, nullable: Optional[bool], server_default: Optional[Union[(_ServerDefault, Literal[False])]], type_: TypeEngine, autoincrement: Optional[bool], comment: Optional[Union[(str, Literal[False])]]) -> str`

**Line:** 435

---

### `def _mysql_drop_constraint(element: DropConstraint, compiler: MySQLDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Description:**
Redefine SQLAlchemy's drop constraint to
raise errors for invalid constraint type.

**Line:** 460

---


## Module: venv2.libthon3.12.site-packages.alembic.ddl.oracle
**File:** `venv2/lib/python3.12/site-packages/alembic/ddl/oracle.py`

**Imports:**
- __future__.annotations
- base.AddColumn
- base.ColumnComment
- base.ColumnDefault
- base.ColumnName
- base.ColumnNullable
- base.ColumnType
- base.IdentityColumnDefault
- base.RenameTable
- base.alter_table
- base.format_column_name
- base.format_server_default
- base.format_table_name
- base.format_type
- impl.DefaultImpl
- re
- sqlalchemy.dialects.oracle.base.OracleDDLCompiler
- sqlalchemy.engine.cursor.CursorResult
- sqlalchemy.sql.schema.Column
- sqlalchemy.sql.sqltypes
- typing.Any
- typing.Optional
- typing.TYPE_CHECKING
- util.sqla_compat.compiles

**Functions:**

### `def visit_add_column(element: AddColumn, compiler: OracleDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 95

---

### `def visit_column_nullable(element: ColumnNullable, compiler: OracleDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 105

---

### `def visit_column_type(element: ColumnType, compiler: OracleDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 116

---

### `def visit_column_name(element: ColumnName, compiler: OracleDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 127

---

### `def visit_column_default(element: ColumnDefault, compiler: OracleDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 138

---

### `def visit_column_comment(element: ColumnComment, compiler: OracleDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 153

---

### `def visit_rename_table(element: RenameTable, compiler: OracleDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 171

---

### `def alter_column(compiler: OracleDDLCompiler, name: str) -> str`

**Line:** 180

---

### `def add_column(compiler: OracleDDLCompiler, column: Column[Any], **kw) -> str`

**Line:** 184

---

### `def visit_identity_column(element: IdentityColumnDefault, compiler: OracleDDLCompiler, **kw)`

**Decorators:**
- `@compiles(...)`

**Line:** 189

---


## Module: venv2.libthon3.12.site-packages.alembic.ddl.postgresql
**File:** `venv2/lib/python3.12/site-packages/alembic/ddl/postgresql.py`

**Imports:**
- __future__.annotations
- autogenerate.api.AutogenContext
- autogenerate.render
- autogenerate.render._f_name
- base.AlterColumn
- base.ColumnComment
- base.IdentityColumnDefault
- base.RenameTable
- base._ServerDefault
- base.alter_column
- base.alter_table
- base.format_column_name
- base.format_table_name
- base.format_type
- impl.ComparisonResult
- impl.DefaultImpl
- logging
- operations.base.BatchOperations
- operations.base.Operations
- operations.ops
- operations.schemaobj
- re
- runtime.migration.MigrationContext
- sqlalchemy.Column
- sqlalchemy.Float
- sqlalchemy.Identity
- sqlalchemy.Index
- sqlalchemy.Numeric
- sqlalchemy.UniqueConstraint
- sqlalchemy.dialects.postgresql.BIGINT
- sqlalchemy.dialects.postgresql.ExcludeConstraint
- sqlalchemy.dialects.postgresql.INTEGER
- sqlalchemy.dialects.postgresql.array.ARRAY
- sqlalchemy.dialects.postgresql.base.PGDDLCompiler
- sqlalchemy.dialects.postgresql.hstore.HSTORE
- sqlalchemy.dialects.postgresql.json.JSON
- sqlalchemy.dialects.postgresql.json.JSONB
- sqlalchemy.literal_column
- sqlalchemy.schema.CreateIndex
- sqlalchemy.select
- sqlalchemy.sql.elements.ClauseElement
- sqlalchemy.sql.elements.ColumnClause
- sqlalchemy.sql.elements.ColumnElement
- sqlalchemy.sql.elements.TextClause
- sqlalchemy.sql.elements.quoted_name
- sqlalchemy.sql.functions.FunctionElement
- sqlalchemy.sql.schema.MetaData
- sqlalchemy.sql.schema.Table
- sqlalchemy.sql.type_api.TypeEngine
- sqlalchemy.text
- sqlalchemy.types
- sqlalchemy.types.NULLTYPE
- typing.Any
- typing.Dict
- typing.List
- typing.Literal
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- typing.cast
- util.sqla_compat
- util.sqla_compat.compiles

**Functions:**

### `def visit_rename_table(element: RenameTable, compiler: PGDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 520

---

### `def visit_column_type(element: PostgresqlColumnType, compiler: PGDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 530

---

### `def visit_column_comment(element: ColumnComment, compiler: PGDDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 542

---

### `def visit_identity_column(element: IdentityColumnDefault, compiler: PGDDLCompiler, **kw)`

**Decorators:**
- `@compiles(...)`

**Line:** 564

---

### `def _add_exclude_constraint(autogen_context: AutogenContext, op: CreateExcludeConstraintOp) -> str`

**Decorators:**
- `@render.renderers.dispatch_for(...)`

**Line:** 741

---

### `def _render_inline_exclude_constraint(constraint: ExcludeConstraint, autogen_context: AutogenContext, namespace_metadata: MetaData) -> str`

**Decorators:**
- `@render._constraint_renderers.dispatch_for(...)`

**Line:** 748

---

### `def _postgresql_autogenerate_prefix(autogen_context: AutogenContext) -> str`

**Line:** 762

---

### `def _exclude_constraint(constraint: ExcludeConstraint, autogen_context: AutogenContext, alter: bool) -> str`

**Line:** 769

---

### `def _render_potential_column(value: Union[(ColumnClause[Any], Column[Any], TextClause, FunctionElement[Any])], autogen_context: AutogenContext) -> str`

**Line:** 832

---


## Module: venv2.libthon3.12.site-packages.alembic.ddl.sqlite
**File:** `venv2/lib/python3.12/site-packages/alembic/ddl/sqlite.py`

**Imports:**
- __future__.annotations
- base.ColumnName
- base.RenameTable
- base.alter_table
- base.format_column_name
- base.format_table_name
- impl.DefaultImpl
- operations.batch.BatchOperationsImpl
- re
- sqlalchemy.Computed
- sqlalchemy.JSON
- sqlalchemy.cast
- sqlalchemy.engine.reflection.Inspector
- sqlalchemy.schema
- sqlalchemy.sql
- sqlalchemy.sql.compiler.DDLCompiler
- sqlalchemy.sql.elements.Cast
- sqlalchemy.sql.elements.ClauseElement
- sqlalchemy.sql.schema.Column
- sqlalchemy.sql.schema.Constraint
- sqlalchemy.sql.schema.Table
- sqlalchemy.sql.type_api.TypeEngine
- typing.Any
- typing.Dict
- typing.Optional
- typing.TYPE_CHECKING
- typing.Union
- util.sqla_compat.compiles

**Functions:**

### `def visit_rename_table(element: RenameTable, compiler: DDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 204

---

### `def visit_column_name(element: ColumnName, compiler: DDLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 214

---


## Module: venv2.libthon3.12.site-packages.alembic.operations.toimpl
**File:** `venv2/lib/python3.12/site-packages/alembic/operations/toimpl.py`

**Imports:**
- base.Operations
- sqlalchemy.schema
- sqlalchemy.sql.schema.Table
- typing.TYPE_CHECKING
- util.sqla_compat._copy
- util.sqla_compat.sqla_2

**Functions:**

### `def alter_column(operations: 'Operations', operation: 'ops.AlterColumnOp') -> None`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 18

---

### `def drop_table(operations: 'Operations', operation: 'ops.DropTableOp') -> None`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 81

---

### `def drop_column(operations: 'Operations', operation: 'ops.DropColumnOp') -> None`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 91

---

### `def create_index(operations: 'Operations', operation: 'ops.CreateIndexOp') -> None`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 105

---

### `def drop_index(operations: 'Operations', operation: 'ops.DropIndexOp') -> None`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 116

---

### `def create_table(operations: 'Operations', operation: 'ops.CreateTableOp') -> 'Table'`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 128

---

### `def rename_table(operations: 'Operations', operation: 'ops.RenameTableOp') -> None`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 140

---

### `def create_table_comment(operations: 'Operations', operation: 'ops.CreateTableCommentOp') -> None`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 149

---

### `def drop_table_comment(operations: 'Operations', operation: 'ops.DropTableCommentOp') -> None`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 157

---

### `def add_column(operations: 'Operations', operation: 'ops.AddColumnOp') -> None`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 165

---

### `def create_constraint(operations: 'Operations', operation: 'ops.AddConstraintOp') -> None`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 199

---

### `def drop_constraint(operations: 'Operations', operation: 'ops.DropConstraintOp') -> None`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 208

---

### `def bulk_insert(operations: 'Operations', operation: 'ops.BulkInsertOp') -> None`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 228

---

### `def execute_sql(operations: 'Operations', operation: 'ops.ExecuteSQLOp') -> None`

**Decorators:**
- `@Operations.implementation_for(...)`

**Line:** 237

---


## Module: venv2.libthon3.12.site-packages.alembic.script.revision
**File:** `venv2/lib/python3.12/site-packages/alembic/script/revision.py`

**Imports:**
- __future__.annotations
- collections
- re
- sqlalchemy.util
- typing.Any
- typing.Callable
- typing.Collection
- typing.Deque
- typing.Dict
- typing.FrozenSet
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Literal
- typing.Optional
- typing.Protocol
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.not_none

**Functions:**

### `def tuple_rev_as_scalar(rev: None) -> None`

**Decorators:**
- `@overload`

**Line:** 1706

---

### `def tuple_rev_as_scalar(rev: Union[(Tuple[_T, ...], List[_T])]) -> Union[(_T, Tuple[_T, ...], List[_T])]`

**Decorators:**
- `@overload`

**Line:** 1710

---

### `def tuple_rev_as_scalar(rev: Optional[Sequence[_T]]) -> Union[(_T, Sequence[_T], None)]`

**Line:** 1715

---

### `def is_revision(rev: Any) -> Revision`

**Line:** 1726

---


## Module: venv2.libthon3.12.site-packages.alembic.script.write_hooks
**File:** `venv2/lib/python3.12/site-packages/alembic/script/write_hooks.py`

**Imports:**
- __future__.annotations
- config.PostWriteHookConfig
- os
- shlex
- subprocess
- sys
- typing.Any
- typing.Callable
- typing.Dict
- typing.List
- typing.Optional
- typing.TYPE_CHECKING
- typing.Union
- util.compat
- util.pyfiles._preserving_path_as_str

**Functions:**

### `def register(name: str) -> Callable`

**Description:**
A function decorator that will register that function as a write hook.

See the documentation linked below for an example.

.. seealso::

:ref:`post_write_hooks_custom`

**Line:** 30

---

### `def _invoke(name: str, revision_path: Union[(str, os.PathLike[str])], options: PostWriteHookConfig) -> Any`

**Description:**
Invokes the formatter registered for the given name.

:param name: The name of a formatter in the registry
:param revision: string path to the revision file
:param options: A dict containing kwargs passed to the
specified formatter.
:raises: :class:`alembic.util.CommandError`

**Line:** 49

---

### `def _run_hooks(path: Union[(str, os.PathLike[str])], hooks: list[PostWriteHookConfig]) -> None`

**Description:**
Invoke hooks for a generated revision.

**Line:** 73

---

### `def _parse_cmdline_options(cmdline_options_str: str, path: str) -> List[str]`

**Description:**
Parse options from a string into a list.

Also substitutes the revision script token with the actual filename of
the revision script.

If the revision script token doesn't occur in the options string, it is
automatically prepended.

**Line:** 94

---

### `def console_scripts(path: str, options: dict, ignore_output: bool = False) -> None`

**Decorators:**
- `@register(...)`

**Line:** 116

---

### `def exec_(path: str, options: dict, ignore_output: bool = False) -> None`

**Decorators:**
- `@register(...)`

**Line:** 155

---


## Module: venv2.libthon3.12.site-packages.alembic.templates.async.env
**File:** `venv2/lib/python3.12/site-packages/alembic/templates/async/env.py`

**Imports:**
- alembic.context
- asyncio
- logging.config.fileConfig
- sqlalchemy.engine.Connection
- sqlalchemy.ext.asyncio.async_engine_from_config
- sqlalchemy.pool

**Functions:**

### `def run_migrations_offline() -> None`

**Description:**
Run migrations in 'offline' mode.

This configures the context with just a URL
and not an Engine, though an Engine is acceptable
here as well.  By skipping the Engine creation
we don't even need a DBAPI to be available.

Calls to context.execute() here emit the given string to the
script output.

**Line:** 31

---

### `def do_run_migrations(connection: Connection) -> None`

**Line:** 55

---

### `async def run_async_migrations() -> None`

**Description:**
In this scenario we need to create an Engine
and associate a connection with the context.

**Line:** 62

---

### `def run_migrations_online() -> None`

**Description:**
Run migrations in 'online' mode.

**Line:** 80

---


## Module: venv2.libthon3.12.site-packages.alembic.templates.generic.env
**File:** `venv2/lib/python3.12/site-packages/alembic/templates/generic/env.py`

**Imports:**
- alembic.context
- logging.config.fileConfig
- sqlalchemy.engine_from_config
- sqlalchemy.pool

**Functions:**

### `def run_migrations_offline() -> None`

**Description:**
Run migrations in 'offline' mode.

This configures the context with just a URL
and not an Engine, though an Engine is acceptable
here as well.  By skipping the Engine creation
we don't even need a DBAPI to be available.

Calls to context.execute() here emit the given string to the
script output.

**Line:** 29

---

### `def run_migrations_online() -> None`

**Description:**
Run migrations in 'online' mode.

In this scenario we need to create an Engine
and associate a connection with the context.

**Line:** 53

---


## Module: venv2.libthon3.12.site-packages.alembic.templates.multidb.env
**File:** `venv2/lib/python3.12/site-packages/alembic/templates/multidb/env.py`

**Imports:**
- alembic.context
- logging
- logging.config.fileConfig
- re
- sqlalchemy.engine_from_config
- sqlalchemy.pool

**Functions:**

### `def run_migrations_offline() -> None`

**Description:**
Run migrations in 'offline' mode.

This configures the context with just a URL
and not an Engine, though an Engine is acceptable
here as well.  By skipping the Engine creation
we don't even need a DBAPI to be available.

Calls to context.execute() here emit the given string to the
script output.

**Line:** 46

---

### `def run_migrations_online() -> None`

**Description:**
Run migrations in 'online' mode.

In this scenario we need to create an Engine
and associate a connection with the context.

**Line:** 82

---


## Module: venv2.libthon3.12.site-packages.alembic.templatesproject.env
**File:** `venv2/lib/python3.12/site-packages/alembic/templates/pyproject/env.py`

**Imports:**
- alembic.context
- logging.config.fileConfig
- sqlalchemy.engine_from_config
- sqlalchemy.pool

**Functions:**

### `def run_migrations_offline() -> None`

**Description:**
Run migrations in 'offline' mode.

This configures the context with just a URL
and not an Engine, though an Engine is acceptable
here as well.  By skipping the Engine creation
we don't even need a DBAPI to be available.

Calls to context.execute() here emit the given string to the
script output.

**Line:** 29

---

### `def run_migrations_online() -> None`

**Description:**
Run migrations in 'online' mode.

In this scenario we need to create an Engine
and associate a connection with the context.

**Line:** 53

---


## Module: venv2.libthon3.12.site-packages.alembic.testing.assertions
**File:** `venv2/lib/python3.12/site-packages/alembic/testing/assertions.py`

**Imports:**
- __future__.annotations
- contextlib
- re
- sqlalchemy.engine.URL
- sqlalchemy.engine.default
- sqlalchemy.exc
- sqlalchemy.testing.assertions._expect_warnings
- sqlalchemy.testing.assertions.eq_
- sqlalchemy.testing.assertions.is_
- sqlalchemy.testing.assertions.is_false
- sqlalchemy.testing.assertions.is_not_
- sqlalchemy.testing.assertions.is_true
- sqlalchemy.testing.assertions.ne_
- sqlalchemy.util.decorator
- sys
- typing.Any
- typing.Dict

**Functions:**

### `def _assert_proper_exception_context(exception)`

**Description:**
assert that any exception we're catching does not have a __context__
without a __cause__, and that __suppress_context__ is never set.

Python 3 will report nested as exceptions as "during the handling of
error X, error Y occurred". That's not what we want to do.  we want
these exceptions in a cause chain.

**Line:** 22

---

### `def assert_raises(except_cls, callable_, *args, **kw)`

**Line:** 43

---

### `def assert_raises_context_ok(except_cls, callable_, *args, **kw)`

**Line:** 47

---

### `def assert_raises_message(except_cls, msg, callable_, *args, **kwargs)`

**Line:** 51

---

### `def assert_raises_message_context_ok(except_cls, msg, callable_, *args, **kwargs)`

**Line:** 57

---

### `def _assert_raises(except_cls, callable_, args, kwargs, msg = None, check_context = False)`

**Line:** 63

---

### `def _expect_raises(except_cls, msg = None, check_context = False, text_exact = False)`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 76

---

### `def expect_raises(except_cls, check_context = True)`

**Line:** 101

---

### `def expect_raises_message(except_cls, msg, check_context = True, text_exact = False)`

**Line:** 105

---

### `def eq_ignore_whitespace(a, b, msg = None)`

**Line:** 113

---

### `def _get_dialect(name)`

**Line:** 125

---

### `def expect_warnings(*messages, **kw)`

**Description:**
Context manager which expects one or more warnings.

With no arguments, squelches all SAWarnings emitted via
sqlalchemy.util.warn and sqlalchemy.util.warn_limited.   Otherwise
pass string expressions that will match selected warnings via regex;
all non-matching warnings are sent through.

The expect version **asserts** that the warnings were in fact seen.

Note that the test suite sets SAWarning warnings to raise exceptions.

**Line:** 138

---

### `def emits_python_deprecation_warning(*messages)`

**Description:**
Decorator form of expect_warnings().

Note that emits_warning does **not** assert that the warnings
were in fact seen.

**Line:** 154

---

### `def expect_deprecated(*messages, **kw)`

**Line:** 170

---

### `def expect_sqlalchemy_deprecated(*messages, **kw)`

**Line:** 174

---

### `def expect_sqlalchemy_deprecated_20(*messages, **kw)`

**Line:** 178

---


## Module: venv2.libthon3.12.site-packages.alembic.testing.env
**File:** `venv2/lib/python3.12/site-packages/alembic/testing/env.py`

**Imports:**
- alembic.config.Config
- importlib.machinery
- os
- pathlib.Path
- py_compile
- script.Script
- script.ScriptDirectory
- shutil
- sqlalchemy.testing.config
- sqlalchemy.testing.engines
- sqlalchemy.testing.provision
- textwrap

**Functions:**

### `def _get_staging_directory()`

**Line:** 18

---

### `def staging_env(create = True, template = 'generic', sourceless = False)`

**Line:** 25

---

### `def clear_staging_env()`

**Line:** 59

---

### `def script_file_fixture(txt)`

**Line:** 66

---

### `def env_file_fixture(txt)`

**Line:** 73

---

### `def _sqlite_file_db(tempname = 'foo.db', future = False, scope = None, **options)`

**Line:** 93

---

### `def _sqlite_testing_config(sourceless = False, future = False)`

**Line:** 101

---

### `def _multi_dir_testing_config(sourceless = False, extra_version_location = '')`

**Line:** 147

---

### `def _no_sql_pyproject_config(dialect = 'postgresql', directives = '')`

**Description:**
use a postgresql url with no host so that
connections guaranteed to fail

**Line:** 191

---

### `def _no_sql_testing_config(dialect = 'postgresql', directives = '')`

**Description:**
use a postgresql url with no host so that
connections guaranteed to fail

**Line:** 235

---

### `def _write_toml_config(tomltext, initext)`

**Line:** 274

---

### `def _write_config_file(text)`

**Line:** 281

---

### `def _testing_config()`

**Line:** 288

---

### `def write_script(scriptdir, rev_id, content, encoding = 'ascii', sourceless = False)`

**Line:** 299

---

### `def make_sourceless(path, style)`

**Line:** 325

---

### `def three_rev_fixture(cfg)`

**Line:** 346

---

### `def multi_heads_fixture(cfg, a, b, c)`

**Description:**
Create a multiple head fixture from the three-revs fixture

**Line:** 421

---

### `def _multidb_testing_config(engines)`

**Description:**
alembic.ini fixture to work exactly with the 'multidb' template

**Line:** 507

---

### `def _join_path(base: str, *more: str)`

**Line:** 556

---


## Module: venv2.libthon3.12.site-packages.alembic.testing.fixtures
**File:** `venv2/lib/python3.12/site-packages/alembic/testing/fixtures.py`

**Imports:**
- __future__.annotations
- alembic
- assertions._get_dialect
- configparser
- contextlib.contextmanager
- env._get_staging_directory
- env._sqlite_file_db
- environment.EnvironmentContext
- io
- migration.MigrationContext
- operations.Operations
- os
- re
- shutil
- sqlalchemy.Column
- sqlalchemy.MetaData
- sqlalchemy.String
- sqlalchemy.Table
- sqlalchemy.create_mock_engine
- sqlalchemy.event
- sqlalchemy.inspect
- sqlalchemy.testing
- sqlalchemy.testing.assertions.eq_
- sqlalchemy.testing.config
- sqlalchemy.testing.fixtures.FutureEngineMixin
- sqlalchemy.testing.fixtures.TablesTest
- sqlalchemy.testing.fixtures.TestBase
- sqlalchemy.testing.mock
- sqlalchemy.text
- typing.Any
- typing.Dict
- util.sqla_compat
- util.sqla_compat.sqla_2

**Functions:**

### `def capture_db(dialect = 'postgresql://')`

**Line:** 98

---

### `def capture_context_buffer(**kw)`

**Decorators:**
- `@contextmanager`

**Line:** 112

---

### `def capture_engine_context_buffer(**kw)`

**Decorators:**
- `@contextmanager`

**Line:** 130

---

### `def op_fixture(dialect = 'default', as_sql = False, naming_convention = None, literal_binds = False, native_boolean = None)`

**Line:** 155

---


## Module: venv2.libthon3.12.site-packages.alembic.testing.suite._autogen_fixtures
**File:** `venv2/lib/python3.12/site-packages/alembic/testing/suite/_autogen_fixtures.py`

**Imports:**
- __future__.annotations
- autogenerate.api
- ddl.base._fk_spec
- migration.MigrationContext
- operations.ops
- sqlalchemy.CHAR
- sqlalchemy.CheckConstraint
- sqlalchemy.Column
- sqlalchemy.ForeignKey
- sqlalchemy.Index
- sqlalchemy.Integer
- sqlalchemy.MetaData
- sqlalchemy.Numeric
- sqlalchemy.PrimaryKeyConstraint
- sqlalchemy.String
- sqlalchemy.Table
- sqlalchemy.Text
- sqlalchemy.UniqueConstraint
- sqlalchemy.event
- sqlalchemy.inspect
- sqlalchemy.sql.naming.conv
- sqlalchemy.text
- testing.config
- testing.env.clear_staging_env
- testing.env.staging_env
- testing.eq_
- typing.Any
- typing.Dict
- typing.Set

**Functions:**

### `def new_table(table, parent)`

**Decorators:**
- `@event.listens_for(...)`

**Line:** 39

---

### `def _default_include_object(obj, name, type_, reflected, compare_to)`

**Line:** 43

---


## Module: venv2.libthon3.12.site-packages.alembic.testing.suite.test_op
**File:** `venv2/lib/python3.12/site-packages/alembic/testing/suite/test_op.py`

**Imports:**
- sqlalchemy.Column
- sqlalchemy.Integer
- sqlalchemy.String
- sqlalchemy.Table
- sqlalchemy.event
- sqlalchemy.sql.text
- testing.fixtures.AlterColRoundTripFixture
- testing.fixtures.TestBase

**Functions:**

### `def _add_cols(table, metadata)`

**Decorators:**
- `@event.listens_for(...)`

**Line:** 15

---


## Module: venv2.libthon3.12.site-packages.alembic.testing.util
**File:** `venv2/lib/python3.12/site-packages/alembic/testing/util.py`

**Imports:**
- __future__.annotations
- sqlalchemy.schema
- sqlalchemy.testing.config
- sqlalchemy.testing.engines.testing_engine
- sqlalchemy.util.inspect_getfullargspec
- types
- typing.Union
- util.sqla_2

**Functions:**

### `def flag_combinations(*combinations)`

**Description:**
A facade around @testing.combinations() oriented towards boolean
keyword-based arguments.

Basically generates a nice looking identifier based on the keywords
and also sets up the argument names.

E.g.::

@testing.flag_combinations(
dict(lazy=False, passive=False),
dict(lazy=True, passive=False),
dict(lazy=False, passive=True),
dict(lazy=False, passive=True, raiseload=True),
)


would result in::

@testing.combinations(
('', False, False, False),
('lazy', True, False, False),
('lazy_passive', True, True, False),
('lazy_passive', True, True, True),
id_='iaaa',
argnames='lazy,passive,raiseload'
)

**Line:** 17

---

### `def resolve_lambda(__fn, **kw)`

**Description:**
Given a no-arg lambda and a namespace, return a new lambda that
has all the values filled in.

This is used so that we can have module-level fixtures that
refer to instance-level variables using lambdas.

**Line:** 66

---

### `def metadata_fixture(ddl = 'function')`

**Description:**
Provide MetaData for a pytest fixture.

**Line:** 83

---

### `def _safe_int(value: str) -> Union[(int, str)]`

**Line:** 108

---

### `def testing_engine(url = None, options = None, future = False)`

**Line:** 115

---


## Module: venv2.libthon3.12.site-packages.alembic.testing.warnings
**File:** `venv2/lib/python3.12/site-packages/alembic/testing/warnings.py`

**Imports:**
- pytest
- sqlalchemy.exc
- warnings

**Functions:**

### `def setup_filters()`

**Description:**
Set global warning behavior for the test suite.

**Line:** 14

---


## Module: venv2.libthon3.12.site-packages.alembic.util.compat
**File:** `venv2/lib/python3.12/site-packages/alembic/util/compat.py`

**Imports:**
- __future__.annotations
- configparser.ConfigParser
- importlib.metadata
- importlib.metadata.EntryPoint
- importlib.resources
- importlib_metadata
- importlib_metadata.EntryPoint
- importlib_resources
- io
- os
- pathlib.Path
- sqlalchemy.util.compat.inspect_formatargspec
- sqlalchemy.util.inspect_getfullargspec
- sys
- tomli
- tomllib
- typing
- typing.Any
- typing.Iterator
- typing.List
- typing.Optional
- typing.Sequence
- typing.Union

**Functions:**

### `def path_walk(path: Path, top_down: bool = True) -> Iterator[tuple[(Path, list[str], list[str])]]`

**Line:** 66

---

### `def path_relative_to(path: Path, other: Path, walk_up: bool = False) -> Path`

**Line:** 71

---

### `def path_walk(path: Path, top_down: bool = True) -> Iterator[tuple[(Path, list[str], list[str])]]`

**Line:** 78

---

### `def path_relative_to(path: Path, other: Path, walk_up: bool = False) -> Path`

**Description:**
Calculate the relative path of 'path' with respect to 'other',
optionally allowing 'path' to be outside the subtree of 'other'.

OK I used AI for this, sorry

**Line:** 84

---

### `def importlib_metadata_get(group: str) -> Sequence[EntryPoint]`

**Line:** 111

---

### `def formatannotation_fwdref(annotation: Any, base_module: Optional[Any] = None) -> str`

**Description:**
vendored from python 3.7

**Line:** 119

---

### `def read_config_parser(file_config: ConfigParser, file_argument: Sequence[Union[(str, os.PathLike[str])]]) -> List[str]`

**Line:** 139

---


## Module: venv2.libthon3.12.site-packages.alembic.util.editor
**File:** `venv2/lib/python3.12/site-packages/alembic/util/editor.py`

**Imports:**
- __future__.annotations
- compat.is_posix
- exc.CommandError
- os
- os.path.exists
- os.path.join
- os.path.splitext
- subprocess.check_call
- typing.Dict
- typing.List
- typing.Mapping
- typing.Optional

**Functions:**

### `def open_in_editor(filename: str, environ: Optional[Dict[(str, str)]] = None) -> None`

**Description:**
Opens the given file in a text editor. If the environment variable
``EDITOR`` is set, this is taken as preference.

Otherwise, a list of commonly installed editors is tried.

If no editor matches, an :py:exc:`OSError` is raised.

:param filename: The filename to open. Will be passed  verbatim to the
editor command.
:param environ: An optional drop-in replacement for ``os.environ``. Used
mainly for testing.

**Line:** 17

---

### `def _find_editor(environ: Mapping[(str, str)]) -> str`

**Line:** 41

---

### `def _find_executable(candidate: str, environ: Mapping[(str, str)]) -> Optional[str]`

**Line:** 61

---

### `def _default_editors() -> List[str]`

**Line:** 75

---


## Module: venv2.libthon3.12.site-packages.alembic.util.langhelpers
**File:** `venv2/lib/python3.12/site-packages/alembic/util/langhelpers.py`

**Imports:**
- __future__.annotations
- collections
- collections.abc.Iterable
- compat.inspect_getfullargspec
- sqlalchemy.util.asbool
- sqlalchemy.util.immutabledict
- sqlalchemy.util.memoized_property
- sqlalchemy.util.to_list
- sqlalchemy.util.unique_list
- textwrap
- typing.Any
- typing.Callable
- typing.Dict
- typing.List
- typing.Mapping
- typing.MutableMapping
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- uuid
- warnings

**Functions:**

### `def _with_legacy_names(translations: Any) -> Any`

**Line:** 224

---

### `def rev_id() -> str`

**Line:** 232

---

### `def to_tuple(x: Any, default: Tuple[(Any, ...)]) -> Tuple[(Any, ...)]`

**Decorators:**
- `@overload`

**Line:** 237

---

### `def to_tuple(x: None, default: Optional[_T] = Ellipsis) -> _T`

**Decorators:**
- `@overload`

**Line:** 241

---

### `def to_tuple(x: Any, default: Optional[Tuple[(Any, ...)]] = None) -> Tuple[(Any, ...)]`

**Decorators:**
- `@overload`

**Line:** 245

---

### `def to_tuple(x: Any, default: Optional[Tuple[(Any, ...)]] = None) -> Optional[Tuple[(Any, ...)]]`

**Line:** 250

---

### `def dedupe_tuple(tup: Tuple[(str, ...)]) -> Tuple[(str, ...)]`

**Line:** 263

---

### `def not_none(value: Optional[_T]) -> _T`

**Line:** 330

---


## Module: venv2.libthon3.12.site-packages.alembic.util.messaging
**File:** `venv2/lib/python3.12/site-packages/alembic/util/messaging.py`

**Imports:**
- __future__.annotations
- collections.abc.Iterable
- contextlib.contextmanager
- fcntl
- logging
- sqlalchemy.engine.url
- struct
- sys
- termios
- textwrap
- typing.Iterator
- typing.Optional
- typing.TextIO
- typing.Union
- warnings

**Functions:**

### `def write_outstream(stream: TextIO, quiet: bool = False, *text: Union[(str, bytes)]) -> None`

**Line:** 35

---

### `def status(status_msg: str, newline: bool = False, quiet: bool = False) -> Iterator[None]`

**Decorators:**
- `@contextmanager`

**Line:** 55

---

### `def err(message: str, quiet: bool = False) -> None`

**Line:** 70

---

### `def obfuscate_url_pw(input_url: str) -> str`

**Line:** 76

---

### `def warn(msg: str, stacklevel: int = 2) -> None`

**Line:** 80

---

### `def warn_deprecated(msg: str, stacklevel: int = 2) -> None`

**Line:** 84

---

### `def msg(msg: str, newline: bool = True, flush: bool = False, quiet: bool = False) -> None`

**Line:** 88

---

### `def format_as_comma(value: Optional[Union[(str, Iterable[str])]]) -> str`

**Line:** 114

---


## Module: venv2.libthon3.12.site-packages.alembic.util.sqla_compat
**File:** `venv2/lib/python3.12/site-packages/alembic/util/sqla_compat.py`

**Imports:**
- __future__.annotations
- contextlib
- re
- sqlalchemy.ClauseElement
- sqlalchemy.Identity
- sqlalchemy.Index
- sqlalchemy.Table
- sqlalchemy.__version__
- sqlalchemy.engine.Connection
- sqlalchemy.engine.Dialect
- sqlalchemy.engine.Transaction
- sqlalchemy.ext.compiler.compiles
- sqlalchemy.schema
- sqlalchemy.schema.CheckConstraint
- sqlalchemy.schema.Column
- sqlalchemy.schema.ForeignKeyConstraint
- sqlalchemy.sql
- sqlalchemy.sql.base.ColumnCollection
- sqlalchemy.sql.base.DialectKWArgs
- sqlalchemy.sql.base._NoneName
- sqlalchemy.sql.compiler.SQLCompiler
- sqlalchemy.sql.elements.BindParameter
- sqlalchemy.sql.elements.ColumnClause
- sqlalchemy.sql.elements.ColumnElement
- sqlalchemy.sql.elements.TextClause
- sqlalchemy.sql.elements.UnaryExpression
- sqlalchemy.sql.naming._NONE_NAME
- sqlalchemy.sql.schema
- sqlalchemy.sql.schema.Constraint
- sqlalchemy.sql.schema.SchemaItem
- sqlalchemy.sql.visitors
- sqlalchemy.sql.visitors.traverse
- sqlalchemy.types
- sqlalchemy.util.symbol
- typing.Any
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.Optional
- typing.Protocol
- typing.Set
- typing.TYPE_CHECKING
- typing.Type
- typing.TypeVar
- typing.Union
- typing_extensions.TypeGuard

**Functions:**

### `def _safe_int(value: str) -> Union[(int, str)]`

**Line:** 61

---

### `def compiles(element: Type[ClauseElement], *dialects: str) -> Callable[([_CompilerProtocol], _CompilerProtocol)]`

**Line:** 79

---

### `def _get_identity_options_dict(identity: Union[(Identity, schema.Sequence, None)], dialect_kwargs: bool = False) -> Dict[(str, Any)]`

**Line:** 90

---

### `def constraint_name_defined(name: _ConstraintName) -> TypeGuard[_ConstraintNameDefined]`

**Line:** 141

---

### `def constraint_name_string(name: _ConstraintName) -> TypeGuard[str]`

**Line:** 147

---

### `def constraint_name_or_none(name: _ConstraintName) -> Optional[str]`

**Line:** 151

---

### `def _ensure_scope_for_ddl(connection: Optional[Connection]) -> Iterator[None]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 159

---

### `def _safe_begin_connection_transaction(connection: Connection) -> Transaction`

**Line:** 181

---

### `def _safe_commit_connection_transaction(connection: Connection) -> None`

**Line:** 191

---

### `def _safe_rollback_connection_transaction(connection: Connection) -> None`

**Line:** 199

---

### `def _get_connection_in_transaction(connection: Optional[Connection]) -> bool`

**Line:** 207

---

### `def _idx_table_bound_expressions(idx: Index) -> Iterable[ColumnElement[Any]]`

**Line:** 217

---

### `def _copy(schema_item: _CE, **kw) -> _CE`

**Line:** 221

---

### `def _connectable_has_table(connectable: Connection, tablename: str, schemaname: Union[(str, None)]) -> bool`

**Line:** 228

---

### `def _exec_on_inspector(inspector, statement, **params)`

**Line:** 234

---

### `def _nullability_might_be_unset(metadata_column)`

**Line:** 239

---

### `def _server_default_is_computed(*server_default) -> bool`

**Line:** 245

---

### `def _server_default_is_identity(*server_default) -> bool`

**Line:** 249

---

### `def _table_for_constraint(constraint: Constraint) -> Table`

**Line:** 253

---

### `def _columns_for_constraint(constraint)`

**Line:** 262

---

### `def _resolve_for_variant(type_, dialect)`

**Line:** 271

---

### `def _type_has_variants(type_)`

**Line:** 281

---

### `def _get_variant_mapping(type_)`

**Line:** 284

---

### `def _type_has_variants(type_)`

**Line:** 289

---

### `def _get_variant_mapping(type_)`

**Line:** 292

---

### `def _fk_spec(constraint: ForeignKeyConstraint) -> Any`

**Line:** 296

---

### `def _fk_is_self_referential(constraint: ForeignKeyConstraint) -> bool`

**Line:** 329

---

### `def _is_type_bound(constraint: Constraint) -> bool`

**Line:** 338

---

### `def _find_columns(clause)`

**Description:**
locate Column objects within the given expression.

**Line:** 345

---

### `def _remove_column_from_collection(collection: ColumnCollection, column: Union[(Column[Any], ColumnClause[Any])]) -> None`

**Description:**
remove a column from a ColumnCollection.

**Line:** 353

---

### `def _textual_index_column(table: Table, text_: Union[(str, TextClause, ColumnElement[Any])]) -> Union[(ColumnElement[Any], Column[Any])]`

**Description:**
a workaround for the Index construct's severe lack of flexibility

**Line:** 371

---

### `def _copy_expression(expression: _CE, target_table: Table) -> _CE`

**Line:** 389

---

### `def _render_textual_index_column(element: _textual_index_element, compiler: SQLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 440

---

### `def _render_literal_bindparam(element: _literal_bindparam, compiler: SQLCompiler, **kw) -> str`

**Decorators:**
- `@compiles(...)`

**Line:** 451

---

### `def _get_constraint_final_name(constraint: Union[(Index, Constraint)], dialect: Optional[Dialect]) -> Optional[str]`

**Line:** 457

---

### `def _constraint_is_named(constraint: Union[(Constraint, Index)], dialect: Optional[Dialect]) -> bool`

**Line:** 473

---

### `def is_expression_index(index: Index) -> bool`

**Line:** 485

---

### `def is_expression(expr: Any) -> bool`

**Line:** 492

---


## Module: venv2.libthon3.12.site-packages.alembic.utilfiles
**File:** `venv2/lib/python3.12/site-packages/alembic/util/pyfiles.py`

**Imports:**
- __future__.annotations
- atexit
- contextlib.ExitStack
- exc.CommandError
- importlib
- importlib.machinery
- importlib.util
- mako.exceptions
- mako.template.Template
- os
- pathlib
- re
- tempfile
- types.ModuleType
- typing.Any
- typing.Optional
- typing.Union

**Functions:**

### `def template_to_file(template_file: Union[(str, os.PathLike[str])], dest: Union[(str, os.PathLike[str])], output_encoding: str, append: bool = False, **kw: Any) -> None`

**Line:** 24

---

### `def coerce_resource_to_filename(fname_or_resource: str) -> pathlib.Path`

**Description:**
Interpret a filename as either a filesystem location or as a package
resource.

Names that are non absolute paths and contain a colon
are interpreted as resources and coerced to a file location.

**Line:** 52

---

### `def pyc_file_from_path(path: Union[(str, os.PathLike[str])]) -> Optional[pathlib.Path]`

**Description:**
Given a python source path, locate the .pyc.

**Line:** 78

---

### `def load_python_file(dir_: Union[(str, os.PathLike[str])], filename: Union[(str, os.PathLike[str])]) -> ModuleType`

**Description:**
Load a file from the given path as a Python module.

**Line:** 100

---

### `def load_module_py(module_id: str, path: Union[(str, os.PathLike[str])]) -> ModuleType`

**Line:** 128

---

### `def _preserving_path_as_str(path: Union[(str, os.PathLike[str])]) -> str`

**Description:**
receive str/pathlike and return a string.

Does not convert an incoming string path to a Path first, to help with
unit tests that are doing string path round trips without OS-specific
processing if not necessary.

**Line:** 138

---


## Module: venv2.libthon3.12.site-packages.annotated_types.__init__
**File:** `venv2/lib/python3.12/site-packages/annotated_types/__init__.py`

**Imports:**
- dataclasses.dataclass
- datetime.tzinfo
- math
- sys
- types
- types.EllipsisType
- typing.Annotated
- typing.Any
- typing.Callable
- typing.Iterator
- typing.Literal
- typing.Optional
- typing.Protocol
- typing.SupportsFloat
- typing.SupportsIndex
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.Union
- typing.runtime_checkable
- typing_extensions.Annotated
- typing_extensions.DocInfo
- typing_extensions.Literal
- typing_extensions.Protocol
- typing_extensions.doc
- typing_extensions.runtime_checkable

**Functions:**

### `def doc(documentation: str) -> DocInfo`

**Description:**
Add documentation to a type annotation inside of Annotated.

For example:

>>> def hi(name: Annotated[int, doc("The name of the user")]) -> None: ...

**Line:** 422

---


## Module: venv2.libthon3.12.site-packages.annotated_types.test_cases
**File:** `venv2/lib/python3.12/site-packages/annotated_types/test_cases.py`

**Imports:**
- annotated_types
- datetime.date
- datetime.datetime
- datetime.timedelta
- datetime.timezone
- decimal.Decimal
- math
- sys
- typing.Annotated
- typing.Any
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.NamedTuple
- typing.Set
- typing.Tuple
- typing_extensions.Annotated

**Functions:**

### `def cases() -> Iterable[Case]`

**Line:** 25

---


## Module: venv2.libthon3.12.site-packages.black.__init__
**File:** `venv2/lib/python3.12/site-packages/black/__init__.py`

**Imports:**
- _black_version.version
- black.cache.Cache
- black.comments.normalize_fmt_off
- black.concurrency.reformat_many
- black.const.DEFAULT_EXCLUDES
- black.const.DEFAULT_INCLUDES
- black.const.DEFAULT_LINE_LENGTH
- black.const.STDIN_PLACEHOLDER
- black.files.find_project_root
- black.files.find_pyproject_toml
- black.files.find_user_pyproject_toml
- black.files.gen_python_files
- black.files.get_gitignore
- black.files.normalize_path_maybe_ignore
- black.files.parse_pyproject_toml
- black.files.path_is_excluded
- black.files.wrap_stream_for_windows
- black.handle_ipynb_magics.PYTHON_CELL_MAGICS
- black.handle_ipynb_magics.TRANSFORMED_MAGICS
- black.handle_ipynb_magics.jupyter_dependencies_are_installed
- black.handle_ipynb_magics.mask_cell
- black.handle_ipynb_magics.put_trailing_semicolon_back
- black.handle_ipynb_magics.remove_trailing_semicolon
- black.handle_ipynb_magics.unmask_cell
- black.linegen.LN
- black.linegen.LineGenerator
- black.linegen.transform_line
- black.lines.EmptyLineTracker
- black.lines.LinesBlock
- black.mode.FUTURE_FLAG_TO_FEATURE
- black.mode.Feature
- black.mode.Mode
- black.mode.TargetVersion
- black.mode.VERSION_TO_FEATURES
- black.mode.supports_feature
- black.nodes.STARS
- black.nodes.is_number_token
- black.nodes.is_simple_decorator_expression
- black.nodes.is_string_token
- black.nodes.syms
- black.output.color_diff
- black.output.diff
- black.output.dump_to_file
- black.output.err
- black.output.ipynb_diff
- black.output.out
- black.parsing.InvalidInput
- black.parsing.lib2to3_parse
- black.parsing.parse_ast
- black.parsing.stringify_ast
- black.ranges.adjusted_lines
- black.ranges.convert_unchanged_lines
- black.ranges.parse_line_ranges
- black.report.Changed
- black.report.NothingChanged
- black.report.Report
- black.trans.iter_fexpr_spans
- blib2to3.pgen2.token
- blib2to3.pytree.Leaf
- blib2to3.pytree.Node
- click
- click.core.ParameterSource
- contextlib.contextmanager
- dataclasses.replace
- datetime.datetime
- datetime.timezone
- enum.Enum
- io
- json
- json.decoder.JSONDecodeError
- multiprocessing.freeze_support
- mypy_extensions.mypyc_attr
- pathlib.Path
- pathspec.PathSpec
- pathspec.patterns.gitwildmatch.GitWildMatchPatternError
- platform
- re
- sys
- tokenize
- traceback
- typing.Any
- typing.Collection
- typing.Dict
- typing.Generator
- typing.Iterator
- typing.List
- typing.MutableMapping
- typing.Optional
- typing.Pattern
- typing.Sequence
- typing.Set
- typing.Sized
- typing.Tuple
- typing.Union

**Functions:**

### `def read_pyproject_toml(ctx: click.Context, param: click.Parameter, value: Optional[str]) -> Optional[str]`

**Description:**
Inject Black configuration from "pyproject.toml" into defaults in `ctx`.

Returns the path to a successfully found and read configuration file, None
otherwise.

**Line:** 119

---

### `def target_version_option_callback(c: click.Context, p: Union[(click.Option, click.Parameter)], v: Tuple[(str, ...)]) -> List[TargetVersion]`

**Description:**
Compute the target versions from a --target-version flag.

This is its own function because mypy couldn't infer the type correctly
when it was a lambda, causing mypyc trouble.

**Line:** 183

---

### `def re_compile_maybe_verbose(regex: str) -> Pattern[str]`

**Description:**
Compile a regular expression string in `regex`.

If it contains newlines, use verbose mode.

**Line:** 194

---

### `def validate_regex(ctx: click.Context, param: click.Parameter, value: Optional[str]) -> Optional[Pattern[str]]`

**Line:** 205

---

### `def main(ctx: click.Context, code: Optional[str], line_length: int, target_version: List[TargetVersion], check: bool, diff: bool, line_ranges: Sequence[str], color: bool, fast: bool, pyi: bool, ipynb: bool, python_cell_magics: Sequence[str], skip_source_first_line: bool, skip_string_normalization: bool, skip_magic_trailing_comma: bool, experimental_string_processing: bool, preview: bool, quiet: bool, verbose: bool, required_version: Optional[str], include: Pattern[str], exclude: Optional[Pattern[str]], extend_exclude: Optional[Pattern[str]], force_exclude: Optional[Pattern[str]], stdin_filename: Optional[str], workers: Optional[int], src: Tuple[(str, ...)], config: Optional[str]) -> None`

**Decorators:**
- `@click.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.version_option(...)`
- `@click.argument(...)`
- `@click.option(...)`
- `@click.pass_context`

**Description:**
The uncompromising code formatter.

**Line:** 460

---

### `def get_sources(root: Path, src: Tuple[(str, ...)], quiet: bool, verbose: bool, include: Pattern[str], exclude: Optional[Pattern[str]], extend_exclude: Optional[Pattern[str]], force_exclude: Optional[Pattern[str]], report: 'Report', stdin_filename: Optional[str]) -> Set[Path]`

**Description:**
Compute the set of files to be formatted.

**Line:** 656

---

### `def path_empty(src: Sized, msg: str, quiet: bool, verbose: bool, ctx: click.Context) -> None`

**Description:**
Exit if there is no `src` provided for formatting

**Line:** 751

---

### `def reformat_code(content: str, fast: bool, write_back: WriteBack, mode: Mode, report: Report, lines: Collection[Tuple[(int, int)]] = ()) -> None`

**Description:**
Reformat and print out `content` without spawning child processes.
Similar to `reformat_one`, but for string content.

`fast`, `write_back`, and `mode` options are passed to
:func:`format_file_in_place` or :func:`format_stdin_to_stdout`.

**Line:** 763

---

### `def reformat_one(src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: 'Report', lines: Collection[Tuple[(int, int)]] = ()) -> None`

**Decorators:**
- `@mypyc_attr(...)`

**Description:**
Reformat a single file under `src` without spawning child processes.

`fast`, `write_back`, and `mode` options are passed to
:func:`format_file_in_place` or :func:`format_stdin_to_stdout`.

**Line:** 796

---

### `def format_file_in_place(src: Path, fast: bool, mode: Mode, write_back: WriteBack = WriteBack.NO, lock: Any = None, lines: Collection[Tuple[(int, int)]] = ()) -> bool`

**Description:**
Format file under `src` path. Return True if changed.

If `write_back` is DIFF, write a diff to stdout. If it is YES, write reformatted
code to the file.
`mode` and `fast` options are passed to :func:`format_file_contents`.

**Line:** 852

---

### `def format_stdin_to_stdout(fast: bool, content: Optional[str] = None, write_back: WriteBack = WriteBack.NO, mode: Mode, lines: Collection[Tuple[(int, int)]] = ()) -> bool`

**Description:**
Format file on stdin. Return True if changed.

If content is None, it's read from sys.stdin.

If `write_back` is YES, write reformatted code back to stdout. If it is DIFF,
write a diff to stdout. The `mode` argument is passed to
:func:`format_file_contents`.

**Line:** 920

---

### `def check_stability_and_equivalence(src_contents: str, dst_contents: str, mode: Mode, lines: Collection[Tuple[(int, int)]] = ()) -> None`

**Description:**
Perform stability and equivalence checks.

Raise AssertionError if source and destination contents are not
equivalent, or if a second pass of the formatter would format the
content differently.

**Line:** 972

---

### `def format_file_contents(src_contents: str, fast: bool, mode: Mode, lines: Collection[Tuple[(int, int)]] = ()) -> FileContent`

**Description:**
Reformat contents of a file and return new contents.

If `fast` is False, additionally confirm that the reformatted code is
valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
`mode` is passed to :func:`format_str`.

**Line:** 989

---

### `def validate_cell(src: str, mode: Mode) -> None`

**Description:**
Check that cell does not already contain TransformerManager transformations,
or non-Python cell magics, which might cause tokenizer_rt to break because of
indentations.

If a cell contains ``!ls``, then it'll be transformed to
``get_ipython().system('ls')``. However, if the cell originally contained
``get_ipython().system('ls')``, then it would get transformed in the same way:

>>> TransformerManager().transform_cell("get_ipython().system('ls')")
"get_ipython().system('ls')
"
>>> TransformerManager().transform_cell("!ls")
"get_ipython().system('ls')
"

Due to the impossibility of safely roundtripping in such situations, cells
containing transformed magics will be ignored.

**Line:** 1017

---

### `def format_cell(src: str, fast: bool, mode: Mode) -> str`

**Description:**
Format code in given cell of Jupyter notebook.

General idea is:

- if cell has trailing semicolon, remove it;
- if cell has IPython magics, mask them;
- format cell;
- reinstate IPython magics;
- reinstate trailing semicolon (if originally present);
- strip trailing newlines.

Cells with syntax errors will not be processed, as they
could potentially be automagics or multi-line magics, which
are currently not supported.

**Line:** 1043

---

### `def validate_metadata(nb: MutableMapping[(str, Any)]) -> None`

**Description:**
If notebook is marked as non-Python, don't format it.

All notebook metadata fields are optional, see
https://nbformat.readthedocs.io/en/latest/format_description.html. So
if a notebook has empty metadata, we will try to parse it anyway.

**Line:** 1080

---

### `def format_ipynb_string(src_contents: str, fast: bool, mode: Mode) -> FileContent`

**Description:**
Format Jupyter notebook.

Operate cell-by-cell, only on code cells, only for Python notebooks.
If the ``.ipynb`` originally had a trailing newline, it'll be preserved.

**Line:** 1092

---

### `def format_str(src_contents: str, mode: Mode, lines: Collection[Tuple[(int, int)]] = ()) -> str`

**Description:**
Reformat a string and return new contents.

`mode` determines formatting options, such as how many characters per line are
allowed.  Example:

>>> import black
>>> print(black.format_str("def f(arg:str='')->None:...", mode=black.Mode()))
def f(arg: str = "") -> None:
...

A more complex example:

>>> print(
...   black.format_str(
...     "def f(arg:str='')->None: hey",
...     mode=black.Mode(
...       target_versions={black.TargetVersion.PY36},
...       line_length=10,
...       string_normalization=False,
...       is_pyi=False,
...     ),
...   ),
... )
def f(
arg: str = '',
) -> None:
hey

**Line:** 1124

---

### `def _format_str_once(src_contents: str, mode: Mode, lines: Collection[Tuple[(int, int)]] = ()) -> str`

**Line:** 1167

---

### `def decode_bytes(src: bytes) -> Tuple[(FileContent, Encoding, NewLine)]`

**Description:**
Return a tuple of (decoded_contents, encoding, newline).

`newline` is either CRLF or LF but `decoded_contents` is decoded with
universal newlines (i.e. only contains LF).

**Line:** 1218

---

### `def get_features_used(node: Node, future_imports: Optional[Set[str]] = None) -> Set[Feature]`

**Description:**
Return a set of (relatively) new Python features used in this file.

Currently looking for:
- f-strings;
- self-documenting expressions in f-strings (f"{x=}");
- underscores in numeric literals;
- trailing commas after * or ** in function signatures and calls;
- positional only arguments in function signatures and lambdas;
- assignment expression;
- relaxed decorator syntax;
- usage of __future__ flags (annotations);
- print / exec statements;
- parenthesized context managers;
- match statements;
- except* clause;
- variadic generics;

**Line:** 1235

---

### `def detect_target_versions(node: Node, future_imports: Optional[Set[str]] = None) -> Set[TargetVersion]`

**Description:**
Detect the version to target based on the nodes used.

**Line:** 1371

---

### `def get_future_imports(node: Node) -> Set[str]`

**Description:**
Return a set of __future__ imports in the file.

**Line:** 1381

---

### `def assert_equivalent(src: str, dst: str) -> None`

**Description:**
Raise AssertionError if `src` and `dst` aren't equivalent.

**Line:** 1431

---

### `def assert_stable(src: str, dst: str, mode: Mode, lines: Collection[Tuple[(int, int)]] = ()) -> None`

**Description:**
Raise AssertionError if `dst` reformats differently the second time.

**Line:** 1464

---

### `def nullcontext() -> Iterator[None]`

**Decorators:**
- `@contextmanager`

**Description:**
Return an empty context manager.

To be used like `nullcontext` in Python 3.7.

**Line:** 1488

---

### `def patched_main() -> None`

**Line:** 1496

---


## Module: venv2.libthon3.12.site-packages.black.brackets
**File:** `venv2/lib/python3.12/site-packages/black/brackets.py`

**Imports:**
- black.nodes.BRACKET
- black.nodes.CLOSING_BRACKETS
- black.nodes.COMPARATORS
- black.nodes.LOGIC_OPERATORS
- black.nodes.MATH_OPERATORS
- black.nodes.OPENING_BRACKETS
- black.nodes.UNPACKING_PARENTS
- black.nodes.VARARGS_PARENTS
- black.nodes.is_vararg
- black.nodes.syms
- blib2to3.pgen2.token
- blib2to3.pytree.Leaf
- blib2to3.pytree.Node
- dataclasses.dataclass
- dataclasses.field
- typing.Dict
- typing.Final
- typing.Iterable
- typing.List
- typing.Optional
- typing.Sequence
- typing.Set
- typing.Tuple
- typing.Union

**Functions:**

### `def is_split_after_delimiter(leaf: Leaf, previous: Optional[Leaf] = None) -> Priority`

**Description:**
Return the priority of the `leaf` delimiter, given a line break after it.

The delimiter priorities returned here are from those delimiters that would
cause a line break after themselves.

Higher numbers are higher priority.

**Line:** 218

---

### `def is_split_before_delimiter(leaf: Leaf, previous: Optional[Leaf] = None) -> Priority`

**Description:**
Return the priority of the `leaf` delimiter, given a line break before it.

The delimiter priorities returned here are from those delimiters that would
cause a line break before themselves.

Higher numbers are higher priority.

**Line:** 232

---

### `def max_delimiter_priority_in_atom(node: LN) -> Priority`

**Description:**
Return maximum delimiter priority inside `node`.

This is specific to atoms with contents contained in a pair of parentheses.
If `node` isn't an atom or there are no enclosing parentheses, returns 0.

**Line:** 328

---

### `def get_leaves_inside_matching_brackets(leaves: Sequence[Leaf]) -> Set[LeafID]`

**Description:**
Return leaves that are inside matching brackets.

The input `leaves` can have non-matching brackets at the head or tail parts.
Matching brackets are included.

**Line:** 356

---


## Module: venv2.libthon3.12.site-packages.black.cache
**File:** `venv2/lib/python3.12/site-packages/black/cache.py`

**Imports:**
- _black_version.version
- black.mode.Mode
- dataclasses.dataclass
- dataclasses.field
- hashlib
- os
- pathlib.Path
- pickle
- platformdirs.user_cache_dir
- sys
- tempfile
- typing.Dict
- typing.Iterable
- typing.NamedTuple
- typing.Self
- typing.Set
- typing.Tuple
- typing_extensions.Self

**Functions:**

### `def get_cache_dir() -> Path`

**Description:**
Get the cache directory used by black.

Users can customize this directory on all systems using `BLACK_CACHE_DIR`
environment variable. By default, the cache directory is the user cache directory
under the black application.

This result is immediately set to a constant `black.cache.CACHE_DIR` as to avoid
repeated calls.

**Line:** 29

---

### `def get_cache_file(mode: Mode) -> Path`

**Line:** 49

---


## Module: venv2.libthon3.12.site-packages.black.comments
**File:** `venv2/lib/python3.12/site-packages/black/comments.py`

**Imports:**
- black.mode.Mode
- black.mode.Preview
- black.nodes.CLOSING_BRACKETS
- black.nodes.STANDALONE_COMMENT
- black.nodes.WHITESPACE
- black.nodes.container_of
- black.nodes.first_leaf_of
- black.nodes.preceding_leaf
- black.nodes.syms
- blib2to3.pgen2.token
- blib2to3.pytree.Leaf
- blib2to3.pytree.Node
- dataclasses.dataclass
- functools.lru_cache
- re
- typing.Final
- typing.Iterator
- typing.List
- typing.Optional
- typing.Union

**Functions:**

### `def generate_comments(leaf: LN) -> Iterator[Leaf]`

**Description:**
Clean the prefix of the `leaf` and generate comments from it, if any.

Comments in lib2to3 are shoved into the whitespace prefix.  This happens
in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
move because it does away with modifying the grammar to include all the
possible places in which comments can be placed.

The sad consequence for us though is that comments don't "belong" anywhere.
This is why this function generates simple parentless Leaf objects for
comments.  We simply don't know what the correct parent should be.

No matter though, we can live without this.  We really only need to
differentiate between inline and standalone comments.  The latter don't
share the line with any code.

Inline comments are emitted as regular token.COMMENT leaves.  Standalone
are emitted with a fake STANDALONE_COMMENT token identifier.

**Line:** 49

---

### `def list_comments(prefix: str, is_endmarker: bool) -> List[ProtoComment]`

**Decorators:**
- `@lru_cache(...)`

**Description:**
Return a list of :class:`ProtoComment` objects parsed from the given `prefix`.

**Line:** 73

---

### `def make_comment(content: str) -> str`

**Description:**
Return a consistently formatted comment from the given `content` string.

All comments (except for "##", "#!", "#:", '#'") should have a single
space between the hash sign and the content.

If `content` didn't start with a hash sign, one is provided.

**Line:** 109

---

### `def normalize_fmt_off(node: Node, mode: Mode) -> None`

**Description:**
Convert content between `# fmt: off`/`# fmt: on` into standalone comments.

**Line:** 135

---

### `def convert_one_fmt_off_pair(node: Node, mode: Mode) -> bool`

**Description:**
Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.

Returns True if a pair was converted.

**Line:** 142

---

### `def generate_ignored_nodes(leaf: Leaf, comment: ProtoComment, mode: Mode) -> Iterator[LN]`

**Description:**
Starting from the container of `leaf`, generate all leaves until `# fmt: on`.

If comment is skip, returns leaf only.
Stops at the end of the block.

**Line:** 216

---

### `def _generate_ignored_nodes_from_fmt_skip(leaf: Leaf, comment: ProtoComment) -> Iterator[LN]`

**Description:**
Generate all leaves that should be ignored by the `# fmt: skip` from `leaf`.

**Line:** 263

---

### `def is_fmt_on(container: LN) -> bool`

**Description:**
Determine whether formatting is switched on within a container.
Determined by whether the last `# fmt:` comment is `on` or `off`.

**Line:** 305

---

### `def children_contains_fmt_on(container: LN) -> bool`

**Description:**
Determine if children have formatting switched on.

**Line:** 318

---

### `def contains_pragma_comment(comment_list: List[Leaf]) -> bool`

**Description:**
Returns:
True iff one of the comments in @comment_list is a pragma used by one
of the more common static analysis tools for python (e.g. mypy, flake8,
pylint).

**Line:** 328

---

### `def _contains_fmt_skip_comment(comment_line: str, mode: Mode) -> bool`

**Description:**
Checks if the given comment contains FMT_SKIP alone or paired with other comments.
Matching styles:
# fmt:skip                           <-- single comment
# noqa:XXX # fmt:skip # a nice line  <-- multiple comments (Preview)
# pylint:XXX; fmt:skip               <-- list of comments (; separated, Preview)

**Line:** 342

---


## Module: venv2.libthon3.12.site-packages.black.concurrency
**File:** `venv2/lib/python3.12/site-packages/black/concurrency.py`

**Imports:**
- asyncio
- black.WriteBack
- black.cache.Cache
- black.format_file_in_place
- black.mode.Mode
- black.output.err
- black.report.Changed
- black.report.Report
- concurrent.futures.Executor
- concurrent.futures.ProcessPoolExecutor
- concurrent.futures.ThreadPoolExecutor
- logging
- multiprocessing.Manager
- mypy_extensions.mypyc_attr
- os
- pathlib.Path
- signal
- sys
- traceback
- typing.Any
- typing.Iterable
- typing.Optional
- typing.Set
- uvloop

**Functions:**

### `def maybe_install_uvloop() -> None`

**Description:**
If our environment has uvloop installed we use it.

This is called only from command-line entry points to avoid
interfering with the parent process if Black is used as a library.

**Line:** 27

---

### `def cancel(tasks: Iterable['asyncio.Task[Any]']) -> None`

**Description:**
asyncio signal handler that cancels all `tasks` and reports to stderr.

**Line:** 41

---

### `def shutdown(loop: asyncio.AbstractEventLoop) -> None`

**Description:**
Cancel all pending tasks on `loop`, wait for them, and close the loop.

**Line:** 48

---

### `def reformat_many(sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: Report, workers: Optional[int]) -> None`

**Decorators:**
- `@mypyc_attr(...)`

**Description:**
Reformat multiple files using a ProcessPoolExecutor.

**Line:** 71

---

### `async def schedule_formatting(sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: 'Report', loop: asyncio.AbstractEventLoop, executor: 'Executor') -> None`

**Description:**
Run formatting of `sources` in parallel using the provided `executor`.

(Use ProcessPoolExecutors for actual parallelism.)

`write_back`, `fast`, and `mode` options are passed to
:func:`format_file_in_place`.

**Line:** 121

---


## Module: venv2.libthon3.12.site-packages.black.files
**File:** `venv2/lib/python3.12/site-packages/black/files.py`

**Imports:**
- black.handle_ipynb_magics.jupyter_dependencies_are_installed
- black.mode.TargetVersion
- black.output.err
- black.report.Report
- colorama
- colorama.initialise.wrap_stream
- functools.lru_cache
- io
- mypy_extensions.mypyc_attr
- os
- packaging.specifiers.InvalidSpecifier
- packaging.specifiers.Specifier
- packaging.specifiers.SpecifierSet
- packaging.version.InvalidVersion
- packaging.version.Version
- pathlib.Path
- pathspec.PathSpec
- pathspec.patterns.gitwildmatch.GitWildMatchPatternError
- sys
- tomli
- tomllib
- typing.Any
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Optional
- typing.Pattern
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union

**Functions:**

### `def find_project_root(srcs: Sequence[str], stdin_filename: Optional[str] = None) -> Tuple[(Path, str)]`

**Decorators:**
- `@lru_cache`

**Description:**
Return a directory containing .git, .hg, or pyproject.toml.

That directory will be a common parent of all files and directories
passed in `srcs`.

If no directory in the tree contains a marker that would specify it's the
project root, the root of the file system is returned.

Returns a two-tuple with the first element as the project root path and
the second element as a string describing the method by which the
project root was discovered.

**Line:** 46

---

### `def find_pyproject_toml(path_search_start: Tuple[(str, ...)], stdin_filename: Optional[str] = None) -> Optional[str]`

**Description:**
Find the absolute filepath to a pyproject.toml if it exists

**Line:** 92

---

### `def parse_pyproject_toml(path_config: str) -> Dict[(str, Any)]`

**Decorators:**
- `@mypyc_attr(...)`

**Description:**
Parse a pyproject toml file, pulling out relevant parts for Black.

If parsing fails, will raise a tomllib.TOMLDecodeError.

**Line:** 115

---

### `def infer_target_version(pyproject_toml: Dict[(str, Any)]) -> Optional[List[TargetVersion]]`

**Description:**
Infer Black's target version from the project metadata in pyproject.toml.

Supports the PyPA standard format (PEP 621):
https://packaging.python.org/en/latest/specifications/declaring-project-metadata/#requires-python

If the target version cannot be inferred, returns None.

**Line:** 133

---

### `def parse_req_python_version(requires_python: str) -> Optional[List[TargetVersion]]`

**Description:**
Parse a version string (i.e. ``"3.7"``) to a list of TargetVersion.

If parsing fails, will raise a packaging.version.InvalidVersion error.
If the parsed version cannot be mapped to a valid TargetVersion, returns None.

**Line:** 158

---

### `def parse_req_python_specifier(requires_python: str) -> Optional[List[TargetVersion]]`

**Description:**
Parse a specifier string (i.e. ``">=3.7,<3.10"``) to a list of TargetVersion.

If parsing fails, will raise a packaging.specifiers.InvalidSpecifier error.
If the parsed specifier cannot be mapped to a valid TargetVersion, returns None.

**Line:** 173

---

### `def strip_specifier_set(specifier_set: SpecifierSet) -> SpecifierSet`

**Description:**
Strip minor versions for some specifiers in the specifier set.

For background on version specifiers, see PEP 440:
https://peps.python.org/pep-0440/#version-specifiers

**Line:** 190

---

### `def find_user_pyproject_toml() -> Path`

**Decorators:**
- `@lru_cache`

**Description:**
Return the path to the top-level user configuration for black.

This looks for ~\.black on Windows and ~/.config/black on Linux and other
Unix systems.

May raise:
- RuntimeError: if the current user has no homedir
- PermissionError: if the current process cannot access the user's homedir

**Line:** 216

---

### `def get_gitignore(root: Path) -> PathSpec`

**Decorators:**
- `@lru_cache`

**Description:**
Return a PathSpec matching gitignore content if present.

**Line:** 236

---

### `def normalize_path_maybe_ignore(path: Path, root: Path, report: Optional[Report] = None) -> Optional[str]`

**Description:**
Normalize `path`. May return `None` if `path` was ignored.

`report` is where "path ignored" output goes.

**Line:** 250

---

### `def _path_is_ignored(root_relative_path: str, root: Path, gitignore_dict: Dict[(Path, PathSpec)]) -> bool`

**Line:** 279

---

### `def path_is_excluded(normalized_path: str, pattern: Optional[Pattern[str]]) -> bool`

**Line:** 297

---

### `def gen_python_files(paths: Iterable[Path], root: Path, include: Pattern[str], exclude: Pattern[str], extend_exclude: Optional[Pattern[str]], force_exclude: Optional[Pattern[str]], report: Report, gitignore_dict: Optional[Dict[(Path, PathSpec)]], verbose: bool, quiet: bool) -> Iterator[Path]`

**Description:**
Generate all files under `path` whose paths are not excluded by the
`exclude_regex`, `extend_exclude`, or `force_exclude` regexes,
but are included by the `include` regex.

Symbolic links pointing outside of the `root` directory are ignored.

`report` is where output about exclusions goes.

**Line:** 305

---

### `def wrap_stream_for_windows(f: io.TextIOWrapper) -> Union[(io.TextIOWrapper, 'colorama.AnsiToWin32')]`

**Description:**
Wrap stream with colorama's wrap_stream so colors are shown on Windows.

If `colorama` is unavailable, the original stream is returned unmodified.
Otherwise, the `wrap_stream()` function determines whether the stream needs
to be wrapped for a Windows environment and will accordingly either return
an `AnsiToWin32` wrapper or the original stream.

**Line:** 394

---


## Module: venv2.libthon3.12.site-packages.black.handle_ipynb_magics
**File:** `venv2/lib/python3.12/site-packages/black/handle_ipynb_magics.py`

**Imports:**
- IPython.core.inputtransformer2.TransformerManager
- ast
- black.output.out
- black.report.NothingChanged
- collections
- dataclasses
- functools.lru_cache
- importlib.util.find_spec
- secrets
- sys
- tokenize_rt.reversed_enumerate
- tokenize_rt.src_to_tokens
- tokenize_rt.tokens_to_src
- typing.Dict
- typing.List
- typing.Optional
- typing.Tuple
- typing.TypeGuard
- typing_extensions.TypeGuard

**Functions:**

### `def jupyter_dependencies_are_installed(warn: bool) -> bool`

**Decorators:**
- `@lru_cache`

**Line:** 60

---

### `def remove_trailing_semicolon(src: str) -> Tuple[(str, bool)]`

**Description:**
Remove trailing semicolon from Jupyter notebook cell.

For example,

fig, ax = plt.subplots()
ax.plot(x_data, y_data);  # plot data

would become

fig, ax = plt.subplots()
ax.plot(x_data, y_data)  # plot data

Mirrors the logic in `quiet` from `IPython.core.displayhook`, but uses
``tokenize_rt`` so that round-tripping works fine.

**Line:** 73

---

### `def put_trailing_semicolon_back(src: str, has_trailing_semicolon: bool) -> str`

**Description:**
Put trailing semicolon back if cell originally had it.

Mirrors the logic in `quiet` from `IPython.core.displayhook`, but uses
``tokenize_rt`` so that round-tripping works fine.

**Line:** 105

---

### `def mask_cell(src: str) -> Tuple[(str, List[Replacement])]`

**Description:**
Mask IPython magics so content becomes parseable Python code.

For example,

%matplotlib inline
'foo'

becomes

"25716f358c32750e"
'foo'

The replacements are returned, along with the transformed code.

**Line:** 129

---

### `def get_token(src: str, magic: str) -> str`

**Description:**
Return randomly generated token to mask IPython magic with.

For example, if 'magic' was `%matplotlib inline`, then a possible
token to mask it with would be `"43fdd17f7e5ddc83"`. The token
will be the same length as the magic, and we make sure that it was
not already present anywhere else in the cell.

**Line:** 169

---

### `def replace_cell_magics(src: str) -> Tuple[(str, List[Replacement])]`

**Description:**
Replace cell magic with token.

Note that 'src' will already have been processed by IPython's
TransformerManager().transform_cell.

Example,

get_ipython().run_cell_magic('t', '-n1', 'ls =!ls\n')

becomes

"a794."
ls =!ls

The replacement, along with the transformed code, is returned.

**Line:** 195

---

### `def replace_magics(src: str) -> Tuple[(str, List[Replacement])]`

**Description:**
Replace magics within body of cell.

Note that 'src' will already have been processed by IPython's
TransformerManager().transform_cell.

Example, this

get_ipython().run_line_magic('matplotlib', 'inline')
'foo'

becomes

"5e67db56d490fd39"
'foo'

The replacement, along with the transformed code, are returned.

**Line:** 226

---

### `def unmask_cell(src: str, replacements: List[Replacement]) -> str`

**Description:**
Remove replacements from cell.

For example

"9b20"
foo = bar

becomes

%%time
foo = bar

**Line:** 267

---

### `def _is_ipython_magic(node: ast.expr) -> TypeGuard[ast.Attribute]`

**Description:**
Check if attribute is IPython magic.

Note that the source of the abstract syntax tree
will already have been processed by IPython's
TransformerManager().transform_cell.

**Line:** 285

---

### `def _get_str_args(args: List[ast.expr]) -> List[str]`

**Line:** 300

---


## Module: venv2.libthon3.12.site-packages.black.linegen
**File:** `venv2/lib/python3.12/site-packages/black/linegen.py`

**Imports:**
- black.brackets.COMMA_PRIORITY
- black.brackets.DOT_PRIORITY
- black.brackets.get_leaves_inside_matching_brackets
- black.brackets.max_delimiter_priority_in_atom
- black.comments.FMT_OFF
- black.comments.generate_comments
- black.comments.list_comments
- black.lines.Line
- black.lines.RHSResult
- black.lines.append_leaves
- black.lines.can_be_split
- black.lines.can_omit_invisible_parens
- black.lines.is_line_short_enough
- black.lines.line_to_string
- black.mode.Feature
- black.mode.Mode
- black.mode.Preview
- black.nodes.ASSIGNMENTS
- black.nodes.BRACKETS
- black.nodes.CLOSING_BRACKETS
- black.nodes.OPENING_BRACKETS
- black.nodes.RARROW
- black.nodes.STANDALONE_COMMENT
- black.nodes.STATEMENT
- black.nodes.Visitor
- black.nodes.WHITESPACE
- black.nodes.ensure_visible
- black.nodes.is_arith_like
- black.nodes.is_async_stmt_or_funcdef
- black.nodes.is_atom_with_invisible_parens
- black.nodes.is_docstring
- black.nodes.is_empty_tuple
- black.nodes.is_lpar_token
- black.nodes.is_multiline_string
- black.nodes.is_name_token
- black.nodes.is_one_sequence_between
- black.nodes.is_one_tuple
- black.nodes.is_rpar_token
- black.nodes.is_stub_body
- black.nodes.is_stub_suite
- black.nodes.is_tuple_containing_walrus
- black.nodes.is_type_ignore_comment_string
- black.nodes.is_vararg
- black.nodes.is_walrus_assignment
- black.nodes.is_yield
- black.nodes.syms
- black.nodes.wrap_in_parentheses
- black.numerics.normalize_numeric_literal
- black.strings.fix_docstring
- black.strings.get_string_prefix
- black.strings.normalize_string_prefix
- black.strings.normalize_string_quotes
- black.strings.normalize_unicode_escape_sequences
- black.trans.CannotTransform
- black.trans.StringMerger
- black.trans.StringParenStripper
- black.trans.StringParenWrapper
- black.trans.StringSplitter
- black.trans.Transformer
- black.trans.hug_power_op
- blib2to3.pgen2.token
- blib2to3.pytree.Leaf
- blib2to3.pytree.Node
- dataclasses.replace
- enum.Enum
- enum.auto
- functools.partial
- functools.wraps
- re
- sys
- typing.Collection
- typing.Iterator
- typing.List
- typing.Optional
- typing.Set
- typing.Union
- typing.cast

**Functions:**

### `def _hugging_power_ops_line_to_string(line: Line, features: Collection[Feature], mode: Mode) -> Optional[str]`

**Line:** 540

---

### `def transform_line(line: Line, mode: Mode, features: Collection[Feature] = ()) -> Iterator[Line]`

**Description:**
Transform a `line`, potentially splitting it into many lines.

They should fit in the allotted `line_length` but might not be able to.

`features` are syntactical features that may be used in the output.

**Line:** 551

---

### `def should_split_funcdef_with_rhs(line: Line, mode: Mode) -> bool`

**Description:**
If a funcdef has a magic trailing comma in the return type, then we should first
split the line with rhs to respect the comma.

**Line:** 677

---

### `def left_hand_split(line: Line, _features: Collection[Feature], mode: Mode) -> Iterator[Line]`

**Description:**
Split line into many lines, starting with the first matching bracket pair.

Note: this usually looks weird, only use this for function definitions.
Prefer RHS otherwise.  This is why this function is not symmetrical with
:func:`right_hand_split` which also handles optional parentheses.

**Line:** 717

---

### `def right_hand_split(line: Line, mode: Mode, features: Collection[Feature] = (), omit: Collection[LeafID] = ()) -> Iterator[Line]`

**Description:**
Split line into many lines, starting with the last matching bracket pair.

If the split was by optional parentheses, attempt splitting without them, too.
`omit` is a collection of closing bracket IDs that shouldn't be considered for
this split.

Note: running this function modifies `bracket_depth` on the leaves of `line`.

**Line:** 764

---

### `def _first_right_hand_split(line: Line, omit: Collection[LeafID] = ()) -> RHSResult`

**Description:**
Split the line into head, body, tail starting with the last bracket pair.

Note: this function should not have side effects. It's relied upon by
_maybe_split_omitting_optional_parens to get an opinion whether to prefer
splitting on the right side of an assignment statement.

**Line:** 784

---

### `def _maybe_split_omitting_optional_parens(rhs: RHSResult, line: Line, mode: Mode, features: Collection[Feature] = (), omit: Collection[LeafID] = ()) -> Iterator[Line]`

**Line:** 846

---

### `def _prefer_split_rhs_oop(rhs_oop: RHSResult, mode: Mode) -> bool`

**Description:**
Returns whether we should prefer the result from a split omitting optional parens.

**Line:** 921

---

### `def bracket_split_succeeded_or_raise(head: Line, body: Line, tail: Line) -> None`

**Description:**
Raise :exc:`CannotSplit` if the last left- or right-hand split failed.

Do nothing otherwise.

A left- or right-hand split is based on a pair of brackets. Content before
(and including) the opening bracket is left on one line, content inside the
brackets is put on a separate line, and finally content starting with and
following the closing bracket is put on a separate line.

Those are called `head`, `body`, and `tail`, respectively. If the split
produced the same line (all content in `head`) or ended up with an empty `body`
and the `tail` is just the closing bracket, then it's considered failed.

**Line:** 950

---

### `def bracket_split_build_line(leaves: List[Leaf], original: Line, opening_bracket: Leaf, component: _BracketSplitComponent) -> Line`

**Description:**
Return a new line with given `leaves` and respective comments from `original`.

If it's the head component, brackets will be tracked so trailing commas are
respected.

If it's the body component, the result line is one-indented inside brackets and as
such has its first leaf's prefix normalized and a trailing comma added when
expected.

**Line:** 976

---

### `def dont_increase_indentation(split_func: Transformer) -> Transformer`

**Description:**
Normalize prefix of the first leaf in every line returned by `split_func`.

This is a decorator over relevant split functions.

**Line:** 1057

---

### `def _get_last_non_comment_leaf(line: Line) -> Optional[int]`

**Line:** 1074

---

### `def _safe_add_trailing_comma(safe: bool, delimiter_priority: int, line: Line) -> Line`

**Line:** 1081

---

### `def delimiter_split(line: Line, features: Collection[Feature], mode: Mode) -> Iterator[Line]`

**Decorators:**
- `@dont_increase_indentation`

**Description:**
Split according to delimiters of the highest priority.

If the appropriate Features are given, the split will add trailing commas
also in function signatures and calls that contain `*` and `**`.

**Line:** 1094

---

### `def standalone_comment_split(line: Line, features: Collection[Feature], mode: Mode) -> Iterator[Line]`

**Decorators:**
- `@dont_increase_indentation`

**Description:**
Split standalone comments from the rest of the line.

**Line:** 1178

---

### `def normalize_prefix(leaf: Leaf, inside_brackets: bool) -> None`

**Description:**
Leave existing extra newlines if not `inside_brackets`. Remove everything
else.

Note: don't use backslashes for formatting or you'll lose your voting rights.

**Line:** 1212

---

### `def normalize_invisible_parens(node: Node, parens_after: Set[str], mode: Mode, features: Collection[Feature]) -> None`

**Description:**
Make existing optional parentheses invisible or create new ones.

`parens_after` is a set of string leaf values immediately after which parens
should be put.

Standardizes on visible parentheses for single-element tuples, and keeps
existing visible parentheses for other tuples and generator expressions.

**Line:** 1230

---

### `def _normalize_import_from(parent: Node, child: LN, index: int) -> None`

**Line:** 1338

---

### `def remove_await_parens(node: Node) -> None`

**Line:** 1352

---

### `def _maybe_wrap_cms_in_parens(node: Node, mode: Mode, features: Collection[Feature]) -> None`

**Description:**
When enabled and safe, wrap the multiple context managers in invisible parens.

It is only safe when `features` contain Feature.PARENTHESIZED_CONTEXT_MANAGERS.

**Line:** 1387

---

### `def remove_with_parens(node: Node, parent: Node) -> None`

**Description:**
Recursively hide optional parens in `with` statements.

**Line:** 1430

---

### `def maybe_make_parens_invisible_in_atom(node: LN, parent: LN, remove_brackets_around_comma: bool = False) -> bool`

**Description:**
If it's safe, make the parens in the atom `node` invisible, recursively.
Additionally, remove repeated, adjacent invisible parens from the atom `node`
as they are redundant.

Returns whether the node should itself be wrapped in invisible parentheses.

**Line:** 1472

---

### `def should_split_line(line: Line, opening_bracket: Leaf) -> bool`

**Description:**
Should `line` be immediately split with `delimiter_split()` after RHS?

**Line:** 1544

---

### `def generate_trailers_to_omit(line: Line, line_length: int) -> Iterator[Set[LeafID]]`

**Description:**
Generate sets of closing bracket IDs that should be omitted in a RHS.

Brackets can be omitted if the entire trailer up to and including
a preceding closing bracket fits in one line.

Yielded sets are cumulative (contain results of previous yields, too).  First
set is empty, unless the line should explode, in which case bracket pairs until
the one that needs to explode are omitted.

**Line:** 1571

---

### `def run_transformer(line: Line, transform: Transformer, mode: Mode, features: Collection[Feature], line_str: str = '') -> List[Line]`

**Line:** 1647

---


## Module: venv2.libthon3.12.site-packages.black.lines
**File:** `venv2/lib/python3.12/site-packages/black/lines.py`

**Imports:**
- black.brackets.BracketTracker
- black.brackets.COMMA_PRIORITY
- black.brackets.DOT_PRIORITY
- black.mode.Mode
- black.mode.Preview
- black.nodes.BRACKETS
- black.nodes.CLOSING_BRACKETS
- black.nodes.OPENING_BRACKETS
- black.nodes.STANDALONE_COMMENT
- black.nodes.TEST_DESCENDANTS
- black.nodes.child_towards
- black.nodes.is_docstring
- black.nodes.is_funcdef
- black.nodes.is_import
- black.nodes.is_multiline_string
- black.nodes.is_one_sequence_between
- black.nodes.is_type_comment
- black.nodes.is_type_ignore_comment
- black.nodes.is_with_or_async_with_stmt
- black.nodes.replace_child
- black.nodes.syms
- black.nodes.whitespace
- black.strings.str_width
- blib2to3.pgen2.token
- blib2to3.pytree.Leaf
- blib2to3.pytree.Node
- dataclasses.dataclass
- dataclasses.field
- itertools
- math
- typing.Callable
- typing.Dict
- typing.Iterator
- typing.List
- typing.Optional
- typing.Sequence
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.cast

**Functions:**

### `def enumerate_reversed(sequence: Sequence[T]) -> Iterator[Tuple[(Index, T)]]`

**Description:**
Like `reversed(enumerate(sequence))` if that were possible.

**Line:** 802

---

### `def append_leaves(new_line: Line, old_line: Line, leaves: List[Leaf], preformatted: bool = False) -> None`

**Description:**
Append leaves (taken from @old_line) to @new_line, making sure to fix the
underlying Node structure where appropriate.

All of the leaves in @leaves are duplicated. The duplicates are then
appended to @new_line and used to replace their originals in the underlying
Node structure. Any comments attached to the old leaves are reattached to
the new leaves.

Pre-conditions:
set(@leaves) is a subset of set(@old_line.leaves).

**Line:** 810

---

### `def is_line_short_enough(line: Line, mode: Mode, line_str: str = '') -> bool`

**Description:**
For non-multiline strings, return True if `line` is no longer than `line_length`.
For multiline strings, looks at the context around `line` to determine
if it should be inlined or split up.
Uses the provided `line_str` rendering, if any, otherwise computes a new one.

**Line:** 834

---

### `def can_be_split(line: Line) -> bool`

**Description:**
Return False if the line cannot be split *for sure*.

This is not an exhaustive search but a cheap heuristic that we can use to
avoid some unfortunate formattings (mostly around wrapping unsplittable code
in unnecessary parentheses).

**Line:** 925

---

### `def can_omit_invisible_parens(rhs: RHSResult, line_length: int) -> bool`

**Description:**
Does `rhs.body` have a shape safe to reformat without optional parens around it?

Returns True for only a subset of potentially nice looking formattings but
the point is to not return false positives that end up producing lines that
are too long.

**Line:** 961

---

### `def _can_omit_opening_paren(line: Line, first: Leaf, line_length: int) -> bool`

**Description:**
See `can_omit_invisible_parens`.

**Line:** 1062

---

### `def _can_omit_closing_paren(line: Line, last: Leaf, line_length: int) -> bool`

**Description:**
See `can_omit_invisible_parens`.

**Line:** 1087

---

### `def line_to_string(line: Line) -> str`

**Description:**
Returns the string representation of @line.

WARNING: This is known to be computationally expensive.

**Line:** 1104

---


## Module: venv2.libthon3.12.site-packages.black.mode
**File:** `venv2/lib/python3.12/site-packages/black/mode.py`

**Imports:**
- black.const.DEFAULT_LINE_LENGTH
- dataclasses.dataclass
- dataclasses.field
- enum.Enum
- enum.auto
- hashlib.sha256
- operator.attrgetter
- typing.Dict
- typing.Final
- typing.Set
- warnings.warn

**Functions:**

### `def supports_feature(target_versions: Set[TargetVersion], feature: Feature) -> bool`

**Line:** 164

---


## Module: venv2.libthon3.12.site-packages.black.nodes
**File:** `venv2/lib/python3.12/site-packages/black/nodes.py`

**Imports:**
- black.cache.CACHE_DIR
- black.mode.Mode
- black.mode.Preview
- black.strings.get_string_prefix
- black.strings.has_triple_quotes
- blib2to3.pgen2.token
- blib2to3.pygram
- blib2to3.pytree.Leaf
- blib2to3.pytree.NL
- blib2to3.pytree.Node
- blib2to3.pytree.type_repr
- mypy_extensions.mypyc_attr
- sys
- typing.Final
- typing.Generic
- typing.Iterator
- typing.List
- typing.Optional
- typing.Set
- typing.Tuple
- typing.TypeGuard
- typing.TypeVar
- typing.Union
- typing_extensions.TypeGuard

**Functions:**

### `def whitespace(leaf: Leaf, complex_subscript: bool, mode: Mode) -> str`

**Description:**
Return whitespace prefix if needed for the given `leaf`.

`complex_subscript` signals whether the given leaf is part of a subscription
which has non-trivial arguments, like arithmetic expressions or function calls.

**Line:** 175

---

### `def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]`

**Description:**
Return the first leaf that precedes `node`, if any.

**Line:** 410

---

### `def prev_siblings_are(node: Optional[LN], tokens: List[Optional[NodeType]]) -> bool`

**Description:**
Return if the `node` and its previous siblings match types against the provided
list of tokens; the provided `node`has its type matched against the last element in
the list.  `None` can be used as the first element to declare that the start of the
list is anchored at the start of its parent's children.

**Line:** 428

---

### `def parent_type(node: Optional[LN]) -> Optional[NodeType]`

**Description:**
Returns:
@node.parent.type, if @node is not None and has a parent.
OR
None, otherwise.

**Line:** 444

---

### `def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]`

**Description:**
Return the child of `ancestor` that contains `descendant`.

**Line:** 457

---

### `def replace_child(old_child: LN, new_child: LN) -> None`

**Description:**
Side Effects:
* If @old_child.parent is set, replace @old_child with @new_child in
@old_child's underlying Node structure.
OR
* Otherwise, this function does nothing.

**Line:** 465

---

### `def container_of(leaf: Leaf) -> LN`

**Description:**
Return `leaf` or one of its ancestors that is the topmost container of it.

By "container" we mean a node where `leaf` is the very first child.

**Line:** 482

---

### `def first_leaf_of(node: LN) -> Optional[Leaf]`

**Description:**
Returns the first leaf of the node tree.

**Line:** 507

---

### `def is_arith_like(node: LN) -> bool`

**Description:**
Whether node is an arithmetic or a binary arithmetic expression

**Line:** 517

---

### `def is_docstring(leaf: Leaf) -> bool`

**Line:** 527

---

### `def is_empty_tuple(node: LN) -> bool`

**Description:**
Return True if `node` holds an empty tuple.

**Line:** 549

---

### `def is_one_tuple(node: LN) -> bool`

**Description:**
Return True if `node` holds a tuple with one element, with or without parens.

**Line:** 559

---

### `def is_tuple_containing_walrus(node: LN) -> bool`

**Description:**
Return True if `node` holds a tuple that contains a walrus operator.

**Line:** 575

---

### `def is_one_sequence_between(opening: Leaf, closing: Leaf, leaves: List[Leaf], brackets: Tuple[(int, int)] = ()) -> bool`

**Description:**
Return True if content between `opening` and `closing` is a one-sequence.

**Line:** 586

---

### `def is_walrus_assignment(node: LN) -> bool`

**Description:**
Return True iff `node` is of the shape ( test := test )

**Line:** 623

---

### `def is_simple_decorator_trailer(node: LN, last: bool = False) -> bool`

**Description:**
Return True iff `node` is a trailer valid in a simple decorator

**Line:** 629

---

### `def is_simple_decorator_expression(node: LN) -> bool`

**Description:**
Return True iff `node` could be a 'dotted name' decorator

This function takes the node of the 'namedexpr_test' of the new decorator
grammar and test if it would be valid under the old decorator grammar.

The old grammar was: decorator: @ dotted_name [arguments] NEWLINE
The new grammar is : decorator: @ namedexpr_test NEWLINE

**Line:** 655

---

### `def is_yield(node: LN) -> bool`

**Description:**
Return True if `node` holds a `yield` or `yield from` expression.

**Line:** 679

---

### `def is_vararg(leaf: Leaf, within: Set[NodeType]) -> bool`

**Description:**
Return True if `leaf` is a star or double star in a vararg or kwarg.

If `within` includes VARARGS_PARENTS, this applies to function signatures.
If `within` includes UNPACKING_PARENTS, it applies to right hand-side
extended iterable unpacking (PEP 3132) and additional unpacking
generalizations (PEP 448).

**Line:** 700

---

### `def is_multiline_string(leaf: Leaf) -> bool`

**Description:**
Return True if `leaf` is a multiline string that actually spans many lines.

**Line:** 723

---

### `def is_funcdef(node: Node) -> bool`

**Line:** 728

---

### `def is_stub_suite(node: Node) -> bool`

**Description:**
Return True if `node` is a suite with a stub body.

**Line:** 732

---

### `def is_stub_body(node: LN) -> bool`

**Description:**
Return True if `node` is a simple statement containing an ellipsis.

**Line:** 753

---

### `def is_atom_with_invisible_parens(node: LN) -> bool`

**Description:**
Given a `LN`, determines whether it's an atom `node` with invisible
parens. Useful in dedupe-ing and normalizing parens.

**Line:** 770

---

### `def is_empty_par(leaf: Leaf) -> bool`

**Line:** 788

---

### `def is_empty_lpar(leaf: Leaf) -> bool`

**Line:** 792

---

### `def is_empty_rpar(leaf: Leaf) -> bool`

**Line:** 796

---

### `def is_import(leaf: Leaf) -> bool`

**Description:**
Return True if the given leaf starts an import statement.

**Line:** 800

---

### `def is_with_or_async_with_stmt(leaf: Leaf) -> bool`

**Description:**
Return True if the given leaf starts a with or async with statement.

**Line:** 814

---

### `def is_async_stmt_or_funcdef(leaf: Leaf) -> bool`

**Description:**
Return True if the given leaf starts an async def/for/with statement.

Note that `async def` can be either an `async_stmt` or `async_funcdef`,
the latter is used when it has decorators.

**Line:** 828

---

### `def is_type_comment(leaf: Leaf) -> bool`

**Description:**
Return True if the given leaf is a type comment. This function should only
be used for general type comments (excluding ignore annotations, which should
use `is_type_ignore_comment`). Note that general type comments are no longer
used in modern version of Python, this function may be deprecated in the future.

**Line:** 841

---

### `def is_type_ignore_comment(leaf: Leaf) -> bool`

**Description:**
Return True if the given leaf is a type comment with ignore annotation.

**Line:** 851

---

### `def is_type_ignore_comment_string(value: str) -> bool`

**Description:**
Return True if the given string match with type comment with
ignore annotation.

**Line:** 858

---

### `def wrap_in_parentheses(parent: Node, child: LN, visible: bool = True) -> None`

**Description:**
Wrap `child` in parentheses.

This replaces `child` with an atom holding the parentheses and the old
child.  That requires moving the prefix.

If `visible` is False, the leaves will be valueless (and thus invisible).

**Line:** 864

---

### `def unwrap_singleton_parenthesis(node: LN) -> Optional[LN]`

**Description:**
Returns `wrapped` if `node` is of the shape ( wrapped ).

Parenthesis can be optional. Returns None otherwise

**Line:** 882

---

### `def ensure_visible(leaf: Leaf) -> None`

**Description:**
Make sure parentheses are visible.

They could be invisible as part of some statements (see
:func:`normalize_invisible_parens` and :func:`visit_import_from`).

**Line:** 896

---

### `def is_name_token(nl: NL) -> TypeGuard[Leaf]`

**Line:** 908

---

### `def is_lpar_token(nl: NL) -> TypeGuard[Leaf]`

**Line:** 912

---

### `def is_rpar_token(nl: NL) -> TypeGuard[Leaf]`

**Line:** 916

---

### `def is_string_token(nl: NL) -> TypeGuard[Leaf]`

**Line:** 920

---

### `def is_number_token(nl: NL) -> TypeGuard[Leaf]`

**Line:** 924

---

### `def is_part_of_annotation(leaf: Leaf) -> bool`

**Description:**
Returns whether this leaf is part of type annotations.

**Line:** 928

---

### `def first_leaf(node: LN) -> Optional[Leaf]`

**Description:**
Returns the first leaf of the ancestor node.

**Line:** 940

---

### `def last_leaf(node: LN) -> Optional[Leaf]`

**Description:**
Returns the last leaf of the ancestor node.

**Line:** 950

---

### `def furthest_ancestor_with_last_leaf(leaf: Leaf) -> LN`

**Description:**
Returns the furthest ancestor that has this leaf node as the last leaf.

**Line:** 960

---


## Module: venv2.libthon3.12.site-packages.black.numerics
**File:** `venv2/lib/python3.12/site-packages/black/numerics.py`

**Imports:**
- blib2to3.pytree.Leaf

**Functions:**

### `def format_hex(text: str) -> str`

**Description:**
Formats a hexadecimal string like "0x12B3"

**Line:** 8

---

### `def format_scientific_notation(text: str) -> str`

**Description:**
Formats a numeric string utilizing scentific notation

**Line:** 16

---

### `def format_complex_number(text: str) -> str`

**Description:**
Formats a complex string like `10j`

**Line:** 29

---

### `def format_float_or_int_string(text: str) -> str`

**Description:**
Formats a float string like "1.0".

**Line:** 36

---

### `def normalize_numeric_literal(leaf: Leaf) -> None`

**Description:**
Normalizes numeric (float, int, and complex) literals.

All letters used in the representation are normalized to lowercase.

**Line:** 45

---


## Module: venv2.libthon3.12.site-packages.black.output
**File:** `venv2/lib/python3.12/site-packages/black/output.py`

**Imports:**
- click.echo
- click.style
- difflib
- json
- mypy_extensions.mypyc_attr
- tempfile
- typing.Any
- typing.Optional

**Functions:**

### `def _out(message: Optional[str] = None, nl: bool = True, **styles: Any) -> None`

**Decorators:**
- `@mypyc_attr(...)`

**Line:** 15

---

### `def _err(message: Optional[str] = None, nl: bool = True, **styles: Any) -> None`

**Decorators:**
- `@mypyc_attr(...)`

**Line:** 24

---

### `def out(message: Optional[str] = None, nl: bool = True, **styles: Any) -> None`

**Decorators:**
- `@mypyc_attr(...)`

**Line:** 33

---

### `def err(message: Optional[str] = None, nl: bool = True, **styles: Any) -> None`

**Line:** 37

---

### `def ipynb_diff(a: str, b: str, a_name: str, b_name: str) -> str`

**Description:**
Return a unified diff string between each cell in notebooks `a` and `b`.

**Line:** 41

---

### `def diff(a: str, b: str, a_name: str, b_name: str) -> str`

**Description:**
Return a unified diff string between strings `a` and `b`.

**Line:** 58

---

### `def color_diff(contents: str) -> str`

**Description:**
Inject the ANSI color codes to the diff.

**Line:** 79

---

### `def dump_to_file(ensure_final_newline: bool = True, *output: str) -> str`

**Decorators:**
- `@mypyc_attr(...)`

**Description:**
Dump `output` to a temporary file. Return path to the file.

**Line:** 96

---


## Module: venv2.libthon3.12.site-packages.black.parsing
**File:** `venv2/lib/python3.12/site-packages/black/parsing.py`

**Imports:**
- ast
- black.mode.Feature
- black.mode.TargetVersion
- black.mode.VERSION_TO_FEATURES
- black.mode.supports_feature
- black.nodes.syms
- blib2to3.pgen2.driver
- blib2to3.pgen2.grammar.Grammar
- blib2to3.pgen2.parse.ParseError
- blib2to3.pgen2.tokenize.TokenError
- blib2to3.pygram
- blib2to3.pytree.Leaf
- blib2to3.pytree.Node
- sys
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Set
- typing.Tuple

**Functions:**

### `def get_grammars(target_versions: Set[TargetVersion]) -> List[Grammar]`

**Line:** 23

---

### `def lib2to3_parse(src_txt: str, target_versions: Iterable[TargetVersion] = ()) -> Node`

**Description:**
Given a string with source, return the lib2to3 Node.

**Line:** 54

---

### `def matches_grammar(src_txt: str, grammar: Grammar) -> bool`

**Line:** 96

---

### `def lib2to3_unparse(node: Node) -> str`

**Description:**
Given a lib2to3 node, return its string representation.

**Line:** 106

---

### `def parse_single_version(src: str, version: Tuple[(int, int)], type_comments: bool) -> ast.AST`

**Line:** 112

---

### `def parse_ast(src: str) -> ast.AST`

**Line:** 121

---

### `def _normalize(lineend: str, value: str) -> str`

**Line:** 143

---

### `def stringify_ast(node: ast.AST, depth: int = 0) -> Iterator[str]`

**Description:**
Simple visitor generating strings to compare ASTs by content.

**Line:** 153

---


## Module: venv2.libthon3.12.site-packages.black.ranges
**File:** `venv2/lib/python3.12/site-packages/black/ranges.py`

**Imports:**
- black.nodes.LN
- black.nodes.Leaf
- black.nodes.Node
- black.nodes.STANDALONE_COMMENT
- black.nodes.Visitor
- black.nodes.first_leaf
- black.nodes.furthest_ancestor_with_last_leaf
- black.nodes.last_leaf
- black.nodes.syms
- blib2to3.pgen2.token.ASYNC
- blib2to3.pgen2.token.NEWLINE
- dataclasses.dataclass
- difflib
- typing.Collection
- typing.Iterator
- typing.List
- typing.Sequence
- typing.Set
- typing.Tuple
- typing.Union

**Functions:**

### `def parse_line_ranges(line_ranges: Sequence[str]) -> List[Tuple[(int, int)]]`

**Line:** 21

---

### `def is_valid_line_range(lines: Tuple[(int, int)]) -> bool`

**Description:**
Returns whether the line range is valid.

**Line:** 43

---

### `def adjusted_lines(lines: Collection[Tuple[(int, int)]], original_source: str, modified_source: str) -> List[Tuple[(int, int)]]`

**Description:**
Returns the adjusted line ranges based on edits from the original code.

This computes the new line ranges by diffing original_source and
modified_source, and adjust each range based on how the range overlaps with
the diffs.

Note the diff can contain lines outside of the original line ranges. This can
happen when the formatting has to be done in adjacent to maintain consistent
local results. For example:

1. def my_func(arg1, arg2,
2.             arg3,):
3.   pass

If it restricts to line 2-2, it can't simply reformat line 2, it also has
to reformat line 1:

1. def my_func(
2.     arg1,
3.     arg2,
4.     arg3,
5. ):
6.   pass

In this case, we will expand the line ranges to also include the whole diff
block.

Args:
lines: a collection of line ranges.
original_source: the original source.
modified_source: the modified source.

**Line:** 48

---

### `def convert_unchanged_lines(src_node: Node, lines: Collection[Tuple[(int, int)]]) -> None`

**Description:**
Converts unchanged lines to STANDALONE_COMMENT.

The idea is similar to how `# fmt: on/off` is implemented. It also converts the
nodes between those markers as a single `STANDALONE_COMMENT` leaf node with
the unformatted code as its value. `STANDALONE_COMMENT` is a "fake" token
that will be formatted as-is with its prefix normalized.

Here we perform two passes:

1. Visit the top-level statements, and convert them to a single
`STANDALONE_COMMENT` when unchanged. This speeds up formatting when some
of the top-level statements aren't changed.
2. Convert unchanged "unwrapped lines" to `STANDALONE_COMMENT` nodes line by
line. "unwrapped lines" are divided by the `NEWLINE` token. e.g. a
multi-line statement is *one* "unwrapped line" that ends with `NEWLINE`,
even though this statement itself can span multiple lines, and the
tokenizer only sees the last '
' as the `NEWLINE` token.

NOTE: During pass (2), comment prefixes and indentations are ALWAYS
normalized even when the lines aren't changed. This is fixable by moving
more formatting to pass (1). However, it's hard to get it correct when
incorrect indentations are used. So we defer this to future optimizations.

**Line:** 128

---

### `def _contains_standalone_comment(node: LN) -> bool`

**Line:** 160

---

### `def _convert_unchanged_line_by_line(node: Node, lines_set: Set[int]) -> None`

**Description:**
Converts unchanged to STANDALONE_COMMENT line by line.

**Line:** 224

---

### `def _convert_node_to_standalone_comment(node: LN) -> None`

**Description:**
Convert node to STANDALONE_COMMENT by modifying the tree inline.

**Line:** 278

---

### `def _convert_nodes_to_standalone_comment(nodes: Sequence[LN], newline: Leaf) -> None`

**Description:**
Convert nodes to STANDALONE_COMMENT by modifying the tree inline.

**Line:** 318

---

### `def _leaf_line_end(leaf: Leaf) -> int`

**Description:**
Returns the line number of the leaf node's last line.

**Line:** 348

---

### `def _get_line_range(node_or_nodes: Union[(LN, List[LN])]) -> Set[int]`

**Description:**
Returns the line range of this node or list of nodes.

**Line:** 357

---

### `def _calculate_lines_mappings(original_source: str, modified_source: str) -> Sequence[_LinesMapping]`

**Description:**
Returns a sequence of _LinesMapping by diffing the sources.

For example, given the following diff:
import re
- def func(arg1,
-   arg2, arg3):
+ def func(arg1, arg2, arg3):
pass
It returns the following mappings:
original -> modified
(1, 1)  ->  (1, 1), is_changed_block=False (the "import re" line)
(2, 3)  ->  (2, 2), is_changed_block=True (the diff)
(4, 4)  ->  (3, 3), is_changed_block=False (the "pass" line)

You can think of this visually as if it brings up a side-by-side diff, and tries
to map the line ranges from the left side to the right side:

(1, 1)->(1, 1)    1. import re          1. import re
(2, 3)->(2, 2)    2. def func(arg1,     2. def func(arg1, arg2, arg3):
3.   arg2, arg3):
(4, 4)->(3, 3)    4.   pass             3.   pass

Args:
original_source: the original source.
modified_source: the modified source.

**Line:** 402

---

### `def _find_lines_mapping_index(original_line: int, lines_mappings: Sequence[_LinesMapping], start_index: int) -> int`

**Description:**
Returns the original index of the lines mappings for the original line.

**Line:** 481

---


## Module: venv2.libthon3.12.site-packages.black.strings
**File:** `venv2/lib/python3.12/site-packages/black/strings.py`

**Imports:**
- black._width_table.WIDTH_TABLE
- blib2to3.pytree.Leaf
- functools.lru_cache
- re
- sys
- typing.Final
- typing.List
- typing.Match
- typing.Pattern

**Functions:**

### `def sub_twice(regex: Pattern[str], replacement: str, original: str) -> str`

**Description:**
Replace `regex` with `replacement` twice on `original`.

This is used by string normalization to perform replaces on
overlapping matches.

**Line:** 29

---

### `def has_triple_quotes(string: str) -> bool`

**Description:**
Returns:
True iff @string starts with three quotation characters.

**Line:** 38

---

### `def lines_with_leading_tabs_expanded(s: str) -> List[str]`

**Description:**
Splits string into lines and expands only leading tabs (following the normal
Python rules)

**Line:** 47

---

### `def fix_docstring(docstring: str, prefix: str) -> str`

**Line:** 69

---

### `def get_string_prefix(string: str) -> str`

**Description:**
Pre-conditions:
* assert_is_leaf_string(@string)

Returns:
@string's prefix (e.g. '', 'r', 'f', or 'rf').

**Line:** 93

---

### `def assert_is_leaf_string(string: str) -> None`

**Description:**
Checks the pre-condition that @string has the format that you would expect
of `leaf.value` where `leaf` is some Leaf such that `leaf.type ==
token.STRING`. A more precise description of the pre-conditions that are
checked are listed below.

Pre-conditions:
* @string starts with either ', ", <prefix>', or <prefix>" where
`set(<prefix>)` is some subset of `set(STRING_PREFIX_CHARS)`.
* @string ends with a quote character (' or ").

Raises:
AssertionError(...) if the pre-conditions listed above are not
satisfied.

**Line:** 112

---

### `def normalize_string_prefix(s: str) -> str`

**Description:**
Make all string prefixes lowercase.

**Line:** 147

---

### `def _cached_compile(pattern: str) -> Pattern[str]`

**Decorators:**
- `@lru_cache(...)`

**Line:** 169

---

### `def normalize_string_quotes(s: str) -> str`

**Description:**
Prefer double quotes but only if it doesn't cause more escaping.

Adds or removes backslashes as appropriate. Doesn't parse and fix
strings nested in f-strings.

**Line:** 173

---

### `def normalize_unicode_escape_sequences(leaf: Leaf) -> None`

**Description:**
Replace hex codes in Unicode escape sequences with lowercase representation.

**Line:** 247

---

### `def char_width(char: str) -> int`

**Decorators:**
- `@lru_cache(...)`

**Description:**
Return the width of a single character as it would be displayed in a
terminal or editor (which respects Unicode East Asian Width).

Full width characters are counted as 2, while half width characters are
counted as 1.  Also control characters are counted as 0.

**Line:** 279

---

### `def str_width(line_str: str) -> int`

**Description:**
Return the width of `line_str` as it would be displayed in a terminal
or editor (which respects Unicode East Asian Width).

You could utilize this function to determine, for example, if a string
is too wide to display in a terminal or editor.

**Line:** 305

---

### `def count_chars_in_width(line_str: str, max_width: int) -> int`

**Description:**
Count the number of characters in `line_str` that would fit in a
terminal or editor of `max_width` (which respects Unicode East Asian
Width).

**Line:** 318

---


## Module: venv2.libthon3.12.site-packages.black.trans
**File:** `venv2/lib/python3.12/site-packages/black/trans.py`

**Imports:**
- abc.ABC
- abc.abstractmethod
- black.comments.contains_pragma_comment
- black.lines.Line
- black.lines.append_leaves
- black.mode.Feature
- black.mode.Mode
- black.nodes.CLOSING_BRACKETS
- black.nodes.OPENING_BRACKETS
- black.nodes.STANDALONE_COMMENT
- black.nodes.is_empty_lpar
- black.nodes.is_empty_par
- black.nodes.is_empty_rpar
- black.nodes.is_part_of_annotation
- black.nodes.parent_type
- black.nodes.replace_child
- black.nodes.syms
- black.rusty.Err
- black.rusty.Ok
- black.rusty.Result
- black.strings.assert_is_leaf_string
- black.strings.count_chars_in_width
- black.strings.get_string_prefix
- black.strings.has_triple_quotes
- black.strings.normalize_string_quotes
- black.strings.str_width
- blib2to3.pgen2.token
- blib2to3.pytree.Leaf
- blib2to3.pytree.Node
- collections.defaultdict
- dataclasses.dataclass
- mypy_extensions.trait
- re
- typing.Any
- typing.Callable
- typing.ClassVar
- typing.Collection
- typing.Dict
- typing.Final
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Literal
- typing.Optional
- typing.Sequence
- typing.Set
- typing.Tuple
- typing.TypeVar
- typing.Union

**Functions:**

### `def TErr(err_msg: str) -> Err[CannotTransform]`

**Description:**
(T)ransform Err

Convenience function used when working with the TResult type.

**Line:** 76

---

### `def hug_power_op(line: Line, features: Collection[Feature], mode: Mode) -> Iterator[Line]`

**Description:**
A transformer which normalizes spacing around power operators.

**Line:** 85

---

### `def iter_fexpr_spans(s: str) -> Iterator[Tuple[(int, int)]]`

**Description:**
Yields spans corresponding to expressions in a given f-string.
Spans are half-open ranges (left inclusive, right exclusive).
Assumes the input string is a valid f-string, but will not crash if the input
string is invalid.

**Line:** 1246

---

### `def fstring_contains_expr(s: str) -> bool`

**Line:** 1293

---

### `def _toggle_fexpr_quotes(fstring: str, old_quote: str) -> str`

**Description:**
Toggles quotes used in f-string expressions that are `old_quote`.

f-string expressions can't contain backslashes, so we need to toggle the
quotes if the f-string itself will end up using the same quote. We can
simply toggle without escaping because, quotes can't be reused in f-string
expressions. They will fail to parse.

NOTE: If PEP 701 is accepted, above statement will no longer be true.
Though if quotes can be reused, we can simply reuse them without updates or
escaping, once Black figures out how to parse the new grammar.

**Line:** 1297

---

### `def insert_str_child_factory(string_leaf: Leaf) -> Callable[([LN], None)]`

**Description:**
Factory for a convenience function that is used to orphan @string_leaf
and then insert multiple new leaves into the same part of the node
structure that @string_leaf had originally occupied.

Examples:
Let `string_leaf = Leaf(token.STRING, '"foo"')` and `N =
string_leaf.parent`. Assume the node `N` has the following
original structure:

Node(
expr_stmt, [
Leaf(NAME, 'x'),
Leaf(EQUAL, '='),
Leaf(STRING, '"foo"'),
]
)

We then run the code snippet shown below.
```
insert_str_child = insert_str_child_factory(string_leaf)

lpar = Leaf(token.LPAR, '(')
insert_str_child(lpar)

bar = Leaf(token.STRING, '"bar"')
insert_str_child(bar)

rpar = Leaf(token.RPAR, ')')
insert_str_child(rpar)
```

After which point, it follows that `string_leaf.parent is None` and
the node `N` now has the following structure:

Node(
expr_stmt, [
Leaf(NAME, 'x'),
Leaf(EQUAL, '='),
Leaf(LPAR, '('),
Leaf(STRING, '"bar"'),
Leaf(RPAR, ')'),
]
)

**Line:** 2364

---

### `def is_valid_index_factory(seq: Sequence[Any]) -> Callable[([int], bool)]`

**Description:**
Examples:
```
my_list = [1, 2, 3]

is_valid_index = is_valid_index_factory(my_list)

assert is_valid_index(0)
assert is_valid_index(2)

assert not is_valid_index(3)
assert not is_valid_index(-1)
```

**Line:** 2425

---


## Module: venv2.libthon3.12.site-packages.blackd.__init__
**File:** `venv2/lib/python3.12/site-packages/blackd/__init__.py`

**Imports:**
- _black_version.version
- aiohttp.web
- asyncio
- black
- black.concurrency.maybe_install_uvloop
- click
- concurrent.futures.Executor
- concurrent.futures.ProcessPoolExecutor
- datetime.datetime
- datetime.timezone
- functools.partial
- logging
- middlewares.cors
- multiprocessing.freeze_support
- typing.Set
- typing.Tuple

**Functions:**

### `def main(bind_host: str, bind_port: int) -> None`

**Decorators:**
- `@click.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.version_option(...)`

**Line:** 72

---

### `def make_app() -> web.Application`

**Line:** 82

---

### `async def handle(request: web.Request, executor: Executor) -> web.Response`

**Line:** 91

---

### `def parse_python_variant_header(value: str) -> Tuple[(bool, Set[black.TargetVersion])]`

**Line:** 195

---

### `def patched_main() -> None`

**Line:** 228

---


## Module: venv2.libthon3.12.site-packages.blackd.middlewares
**File:** `venv2/lib/python3.12/site-packages/blackd/middlewares.py`

**Imports:**
- aiohttp.web_middlewares.middleware
- aiohttp.web_request.Request
- aiohttp.web_response.StreamResponse
- typing.Any
- typing.Awaitable
- typing.Callable
- typing.Iterable
- typing.TYPE_CHECKING
- typing.TypeVar

**Functions:**

### `def cors(allow_headers: Iterable[str]) -> Middleware`

**Line:** 21

---


## Module: venv2.libthon3.12.site-packages.blib2to3.pgen2.driver
**File:** `venv2/lib/python3.12/site-packages/blib2to3/pgen2/driver.py`

**Imports:**
- blib2to3.pgen2.grammar.Grammar
- blib2to3.pgen2.tokenize.GoodTokenInfo
- blib2to3.pytree.NL
- contextlib.contextmanager
- dataclasses.dataclass
- dataclasses.field
- io
- logging
- logging.Logger
- os
- pkgutil
- sys
- typing.Any
- typing.IO
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Optional
- typing.Tuple
- typing.Union
- typing.cast

**Functions:**

### `def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> str`

**Line:** 231

---

### `def load_grammar(gt: str = 'Grammar.txt', gp: Optional[str] = None, save: bool = True, force: bool = False, logger: Optional[Logger] = None) -> Grammar`

**Description:**
Load the grammar (maybe from a pickle).

**Line:** 242

---

### `def _newer(a: str, b: str) -> bool`

**Description:**
Inquire whether file a was written since file b.

**Line:** 267

---

### `def load_packaged_grammar(package: str, grammar_source: str, cache_dir: Optional[Path] = None) -> grammar.Grammar`

**Description:**
Normally, loads a pickled grammar by doing
pkgutil.get_data(package, pickled_grammar)
where *pickled_grammar* is computed from *grammar_source* by adding the
Python version and using a ``.pickle`` extension.

However, if *grammar_source* is an extant file, load_grammar(grammar_source)
is called instead. This facilitates using a packaged grammar file when needed
but preserves load_grammar's automatic regeneration behavior when possible.

**Line:** 276

---

### `def main(*args: str) -> bool`

**Description:**
Main program, when run as a script: produce grammar pickle files.

Calls load_grammar for each argument, a path to a grammar text file.

**Line:** 300

---


## Module: venv2.libthon3.12.site-packages.blib2to3.pgen2.literals
**File:** `venv2/lib/python3.12/site-packages/blib2to3/pgen2/literals.py`

**Imports:**
- re
- typing.Dict
- typing.Match

**Functions:**

### `def escape(m: Match[str]) -> str`

**Line:** 23

---

### `def evalString(s: str) -> str`

**Line:** 45

---

### `def test() -> None`

**Line:** 56

---


## Module: venv2.libthon3.12.site-packages.blib2to3.pgen2.parse
**File:** `venv2/lib/python3.12/site-packages/blib2to3/pgen2/parse.py`

**Imports:**
- blib2to3.pgen2.driver.TokenProxy
- blib2to3.pgen2.grammar.Grammar
- blib2to3.pytree.Context
- blib2to3.pytree.Leaf
- blib2to3.pytree.NL
- blib2to3.pytree.Node
- blib2to3.pytree.RawNode
- blib2to3.pytree.convert
- contextlib.contextmanager
- typing.Any
- typing.Callable
- typing.Dict
- typing.Iterator
- typing.List
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- typing.cast

**Functions:**

### `def lam_sub(grammar: Grammar, node: RawNode) -> NL`

**Line:** 43

---

### `def stack_copy(stack: List[Tuple[(DFAS, int, RawNode)]]) -> List[Tuple[(DFAS, int, RawNode)]]`

**Description:**
Nodeless stack copy.

**Line:** 52

---


## Module: venv2.libthon3.12.site-packages.blib2to3.pgen2.pgen
**File:** `venv2/lib/python3.12/site-packages/blib2to3/pgen2/pgen.py`

**Imports:**
- blib2to3.pgen2.grammar
- blib2to3.pgen2.token
- blib2to3.pgen2.tokenize
- blib2to3.pgen2.tokenize.GoodTokenInfo
- os
- typing.Any
- typing.Dict
- typing.IO
- typing.Iterator
- typing.List
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.Tuple
- typing.Union

**Functions:**

### `def generate_grammar(filename: Path = 'Grammar.txt') -> PgenGrammar`

**Line:** 426

---


## Module: venv2.libthon3.12.site-packages.blib2to3.pgen2.token
**File:** `venv2/lib/python3.12/site-packages/blib2to3/pgen2/token.py`

**Imports:**
- typing.Dict
- typing.Final

**Functions:**

### `def ISTERMINAL(x: int) -> bool`

**Line:** 79

---

### `def ISNONTERMINAL(x: int) -> bool`

**Line:** 83

---

### `def ISEOF(x: int) -> bool`

**Line:** 87

---


## Module: venv2.libthon3.12.site-packages.blib2to3.pgen2.tokenize
**File:** `venv2/lib/python3.12/site-packages/blib2to3/pgen2/tokenize.py`

**Imports:**
- blib2to3.pgen2.grammar.Grammar
- blib2to3.pgen2.token.ASYNC
- blib2to3.pgen2.token.AWAIT
- blib2to3.pgen2.token.COMMENT
- blib2to3.pgen2.token.DEDENT
- blib2to3.pgen2.token.ENDMARKER
- blib2to3.pgen2.token.ERRORTOKEN
- blib2to3.pgen2.token.INDENT
- blib2to3.pgen2.token.NAME
- blib2to3.pgen2.token.NEWLINE
- blib2to3.pgen2.token.NL
- blib2to3.pgen2.token.NUMBER
- blib2to3.pgen2.token.OP
- blib2to3.pgen2.token.STRING
- blib2to3.pgen2.token.tok_name
- codecs.BOM_UTF8
- codecs.lookup
- re
- sys
- typing.Callable
- typing.Final
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Optional
- typing.Pattern
- typing.Set
- typing.Tuple
- typing.Union
- typing.cast

**Functions:**

### `def group(*choices: str) -> str`

**Line:** 79

---

### `def any(*choices: str) -> str`

**Line:** 83

---

### `def maybe(*choices: str) -> str`

**Line:** 87

---

### `def _combinations(*l: str) -> Set[str]`

**Line:** 91

---

### `def printtoken(type: int, token: str, srow_col: Coord, erow_col: Coord, line: str) -> None`

**Line:** 203

---

### `def tokenize(readline: Callable[([], str)], tokeneater: TokenEater = printtoken) -> None`

**Description:**
The tokenize() function accepts two parameters: one representing the
input stream, and one providing an output mechanism for tokenize().

The first parameter, readline, must be a callable object which provides
the same interface as the readline() method of built-in file objects.
Each call to the function should return one line of input as a string.

The second parameter, tokeneater, must also be a callable object. It is
called once for each token, with five arguments, corresponding to the
tuples generated by generate_tokens().

**Line:** 216

---

### `def tokenize_loop(readline: Callable[([], str)], tokeneater: TokenEater) -> None`

**Line:** 236

---

### `def _get_normal_name(orig_enc: str) -> str`

**Description:**
Imitates get_normal_name in tokenizer.c.

**Line:** 311

---

### `def detect_encoding(readline: Callable[([], bytes)]) -> Tuple[(str, List[bytes])]`

**Description:**
The detect_encoding() function is used to detect the encoding that should
be used to decode a Python source file. It requires one argument, readline,
in the same way as the tokenize() generator.

It will call readline a maximum of twice, and return the encoding used
(as a string) and a list of any lines (left as bytes) it has read
in.

It detects the encoding from the presence of a utf-8 bom or an encoding
cookie as specified in pep-0263. If both a bom and a cookie are present, but
disagree, a SyntaxError will be raised. If the encoding cookie is an invalid
charset, raise a SyntaxError.  Note that if a utf-8 bom is found,
'utf-8-sig' is returned.

If no encoding is specified, then the default of 'utf-8' will be returned.

**Line:** 324

---

### `def untokenize(iterable: Iterable[TokenInfo]) -> str`

**Description:**
Transform tokens back into Python source code.

Each element returned by the iterable must be a token sequence
with at least two elements, a token number and token value.  If
only two tokens are passed, the resulting output is poor.

Round-trip invariant for full input:
Untokenized source will match input source exactly

Round-trip invariant for limited input:
# Output text will tokenize the back to the input
t1 = [tok[:2] for tok in generate_tokens(f.readline)]
newcode = untokenize(t1)
readline = iter(newcode.splitlines(1)).next
t2 = [tok[:2] for tokin generate_tokens(readline)]
assert t1 == t2

**Line:** 399

---

### `def generate_tokens(readline: Callable[([], str)], grammar: Optional[Grammar] = None) -> Iterator[GoodTokenInfo]`

**Description:**
The generate_tokens() generator requires one argument, readline, which
must be a callable object which provides the same interface as the
readline() method of built-in file objects. Each call to the function
should return one line of input as a string.  Alternately, readline
can be a callable function terminating with StopIteration:
readline = open(myfile).next    # Example of alternate readline

The generator produces 5-tuples with these members: the token type; the
token string; a 2-tuple (srow, scol) of ints specifying the row and
column where the token begins in the source; a 2-tuple (erow, ecol) of
ints specifying the row and column where the token ends in the source;
and the line on which the token was found. The line passed is the
logical line; continuation lines are included.

**Line:** 421

---


## Module: venv2.libthon3.12.site-packages.blib2to3gram
**File:** `venv2/lib/python3.12/site-packages/blib2to3/pygram.py`

**Imports:**
- os
- pgen2.driver
- pgen2.grammar.Grammar
- typing.Union

**Functions:**

### `def initialize(cache_dir: Union[(str, 'os.PathLike[str]', None)] = None) -> None`

**Line:** 161

---


## Module: venv2.libthon3.12.site-packages.blib2to3tree
**File:** `venv2/lib/python3.12/site-packages/blib2to3/pytree.py`

**Imports:**
- blib2to3.pgen2.grammar.Grammar
- io.StringIO
- pgen2.token.tok_name
- pygram.python_symbols
- sys
- typing.Any
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Optional
- typing.Set
- typing.Tuple
- typing.TypeVar
- typing.Union

**Functions:**

### `def type_repr(type_num: int) -> Union[(str, int)]`

**Line:** 40

---

### `def convert(gr: Grammar, raw_node: RawNode) -> NL`

**Description:**
Convert raw node information to a Node or Leaf instance.

This is passed to the parser driver which calls it whenever a reduction of a
grammar rule produces a new complete node, so that the tree is build
strictly bottom-up.

**Line:** 483

---

### `def generate_matches(patterns: List[BasePattern], nodes: List[NL]) -> Iterator[Tuple[(int, _Results)]]`

**Description:**
Generator yielding matches for a sequence of patterns and nodes.

Args:
patterns: a sequence of patterns
nodes: a sequence of nodes

Yields:
(count, results) tuples where:
count: the entire sequence of patterns matches nodes[:count];
results: dict containing named submatches.

**Line:** 956

---


## Module: venv2.libthon3.12.site-packages.blinker._utilities
**File:** `venv2/lib/python3.12/site-packages/blinker/_utilities.py`

**Imports:**
- __future__.annotations
- collections.abc
- inspect
- typing
- weakref.WeakMethod
- weakref.ref

**Functions:**

### `def make_id(obj: object) -> c.Hashable`

**Description:**
Get a stable identifier for a receiver or sender, to be used as a dict
key or in a set.

**Line:** 42

---

### `def make_ref(obj: T, callback: c.Callable[[ref[T]], None] | None = None) -> ref[T]`

**Line:** 60

---


## Module: venv2.libthon3.12.site-packages.click.__init__
**File:** `venv2/lib/python3.12/site-packages/click/__init__.py`

**Imports:**
- __future__.annotations
- core.Argument
- core.Command
- core.CommandCollection
- core.Context
- core.Group
- core.Option
- core.Parameter
- core._BaseCommand
- core._MultiCommand
- decorators.argument
- decorators.command
- decorators.confirmation_option
- decorators.group
- decorators.help_option
- decorators.make_pass_decorator
- decorators.option
- decorators.pass_context
- decorators.pass_obj
- decorators.password_option
- decorators.version_option
- exceptions.Abort
- exceptions.BadArgumentUsage
- exceptions.BadOptionUsage
- exceptions.BadParameter
- exceptions.ClickException
- exceptions.FileError
- exceptions.MissingParameter
- exceptions.NoSuchOption
- exceptions.UsageError
- formatting.HelpFormatter
- formatting.wrap_text
- globals.get_current_context
- importlib.metadata
- parser._OptionParser
- termui.clear
- termui.confirm
- termui.echo_via_pager
- termui.edit
- termui.getchar
- termui.launch
- termui.pause
- termui.progressbar
- termui.prompt
- termui.secho
- termui.style
- termui.unstyle
- types.BOOL
- types.Choice
- types.DateTime
- types.FLOAT
- types.File
- types.FloatRange
- types.INT
- types.IntRange
- types.ParamType
- types.Path
- types.STRING
- types.Tuple
- types.UNPROCESSED
- types.UUID
- utils.echo
- utils.format_filename
- utils.get_app_dir
- utils.get_binary_stream
- utils.get_text_stream
- utils.open_file
- warnings

**Functions:**

### `def __getattr__(name: str) -> object`

**Line:** 74

---


## Module: venv2.libthon3.12.site-packages.click._compat
**File:** `venv2/lib/python3.12/site-packages/click/_compat.py`

**Imports:**
- __future__.annotations
- _winconsole._get_windows_console_stream
- codecs
- collections.abc
- colorama
- errno
- io
- locale
- os
- random
- re
- sys
- types.TracebackType
- typing
- weakref.WeakKeyDictionary

**Functions:**

### `def _make_text_stream(stream: t.BinaryIO, encoding: str | None, errors: str | None, force_readable: bool = False, force_writable: bool = False) -> t.TextIO`

**Line:** 19

---

### `def is_ascii_encoding(encoding: str) -> bool`

**Description:**
Checks if a given encoding is ascii.

**Line:** 40

---

### `def get_best_encoding(stream: t.IO[t.Any]) -> str`

**Description:**
Returns the default stream encoding if not found.

**Line:** 48

---

### `def _is_binary_reader(stream: t.IO[t.Any], default: bool = False) -> bool`

**Line:** 151

---

### `def _is_binary_writer(stream: t.IO[t.Any], default: bool = False) -> bool`

**Line:** 160

---

### `def _find_binary_reader(stream: t.IO[t.Any]) -> t.BinaryIO | None`

**Line:** 173

---

### `def _find_binary_writer(stream: t.IO[t.Any]) -> t.BinaryIO | None`

**Line:** 191

---

### `def _stream_is_misconfigured(stream: t.TextIO) -> bool`

**Description:**
A stream is misconfigured if its encoding is ASCII.

**Line:** 209

---

### `def _is_compat_stream_attr(stream: t.TextIO, attr: str, value: str | None) -> bool`

**Description:**
A stream attribute is compatible if it is equal to the
desired value or the desired value is unset and the attribute
has a value.

**Line:** 218

---

### `def _is_compatible_text_stream(stream: t.TextIO, encoding: str | None, errors: str | None) -> bool`

**Description:**
Check if a stream's encoding and errors attributes are
compatible with the desired values.

**Line:** 227

---

### `def _force_correct_text_stream(text_stream: t.IO[t.Any], encoding: str | None, errors: str | None, is_binary: t.Callable[([t.IO[t.Any], bool], bool)], find_binary: t.Callable[([t.IO[t.Any]], t.BinaryIO | None)], force_readable: bool = False, force_writable: bool = False) -> t.TextIO`

**Line:** 238

---

### `def _force_correct_text_reader(text_reader: t.IO[t.Any], encoding: str | None, errors: str | None, force_readable: bool = False) -> t.TextIO`

**Line:** 284

---

### `def _force_correct_text_writer(text_writer: t.IO[t.Any], encoding: str | None, errors: str | None, force_writable: bool = False) -> t.TextIO`

**Line:** 300

---

### `def get_binary_stdin() -> t.BinaryIO`

**Line:** 316

---

### `def get_binary_stdout() -> t.BinaryIO`

**Line:** 323

---

### `def get_binary_stderr() -> t.BinaryIO`

**Line:** 330

---

### `def get_text_stdin(encoding: str | None = None, errors: str | None = None) -> t.TextIO`

**Line:** 337

---

### `def get_text_stdout(encoding: str | None = None, errors: str | None = None) -> t.TextIO`

**Line:** 344

---

### `def get_text_stderr(encoding: str | None = None, errors: str | None = None) -> t.TextIO`

**Line:** 351

---

### `def _wrap_io_open(file: str | os.PathLike[str] | int, mode: str, encoding: str | None, errors: str | None) -> t.IO[t.Any]`

**Description:**
Handles not passing ``encoding`` and ``errors`` in binary mode.

**Line:** 358

---

### `def open_stream(filename: str | os.PathLike[str], mode: str = 'r', encoding: str | None = None, errors: str | None = 'strict', atomic: bool = False) -> tuple[(t.IO[t.Any], bool)]`

**Line:** 371

---

### `def strip_ansi(value: str) -> str`

**Line:** 488

---

### `def _is_jupyter_kernel_output(stream: t.IO[t.Any]) -> bool`

**Line:** 492

---

### `def should_strip_ansi(stream: t.IO[t.Any] | None = None, color: bool | None = None) -> bool`

**Line:** 499

---

### `def _get_argv_encoding() -> str`

**Line:** 515

---

### `def auto_wrap_for_ansi(stream: t.TextIO, color: bool | None = None) -> t.TextIO`

**Description:**
Support ANSI color and style codes on Windows by wrapping a
stream with colorama.

**Line:** 522

---

### `def _get_argv_encoding() -> str`

**Line:** 559

---

### `def _get_windows_console_stream(f: t.TextIO, encoding: str | None, errors: str | None) -> t.TextIO | None`

**Line:** 562

---

### `def term_len(x: str) -> int`

**Line:** 568

---

### `def isatty(stream: t.IO[t.Any]) -> bool`

**Line:** 572

---

### `def _make_cached_stream_func(src_func: t.Callable[([], t.TextIO | None)], wrapper_func: t.Callable[([], t.TextIO)]) -> t.Callable[([], t.TextIO | None)]`

**Line:** 579

---


## Module: venv2.libthon3.12.site-packages.click._termui_impl
**File:** `venv2/lib/python3.12/site-packages/click/_termui_impl.py`

**Imports:**
- __future__.annotations
- _compat.CYGWIN
- _compat.WIN
- _compat._default_text_stdout
- _compat.get_best_encoding
- _compat.isatty
- _compat.open_stream
- _compat.strip_ansi
- _compat.term_len
- collections.abc
- contextlib
- exceptions.ClickException
- gettext.gettext
- io.StringIO
- math
- msvcrt
- operator.length_hint
- os
- pathlib.Path
- shlex
- shutil
- shutil.which
- subprocess
- sys
- tempfile
- termios
- time
- tty
- types.TracebackType
- typing
- urllib.parse.unquote
- utils.echo
- webbrowser

**Functions:**

### `def pager(generator: cabc.Iterable[str], color: bool | None = None) -> None`

**Description:**
Decide what method to use for paging through text.

**Line:** 370

---

### `def _pipepager(generator: cabc.Iterable[str], cmd_parts: list[str], color: bool | None) -> bool`

**Description:**
Page through text by feeding it to another program. Invoking a
pager through this might support colors.

Returns `True` if the command was found, `False` otherwise and thus another
pager should be attempted.

**Line:** 412

---

### `def _tempfilepager(generator: cabc.Iterable[str], cmd_parts: list[str], color: bool | None) -> bool`

**Description:**
Page through text by invoking a program on a temporary file.

Returns `True` if the command was found, `False` otherwise and thus another
pager should be attempted.

**Line:** 502

---

### `def _nullpager(stream: t.TextIO, generator: cabc.Iterable[str], color: bool | None) -> None`

**Description:**
Simply print unformatted text.  This is the ultimate fallback.

**Line:** 544

---

### `def open_url(url: str, wait: bool = False, locate: bool = False) -> int`

**Line:** 663

---

### `def _translate_ch_to_exc(ch: str) -> None`

**Line:** 734

---

### `def raw_terminal() -> cabc.Iterator[int]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 751

---

### `def getchar(echo: bool) -> str`

**Line:** 754

---

### `def raw_terminal() -> cabc.Iterator[int]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 805

---

### `def getchar(echo: bool) -> str`

**Line:** 831

---


## Module: venv2.libthon3.12.site-packages.click._winconsole
**File:** `venv2/lib/python3.12/site-packages/click/_winconsole.py`

**Imports:**
- __future__.annotations
- _compat._NonClosingTextIOWrapper
- collections.abc
- collections.abc.Buffer
- ctypes.Array
- ctypes.POINTER
- ctypes.Structure
- ctypes.WINFUNCTYPE
- ctypes.byref
- ctypes.c_char
- ctypes.c_char_p
- ctypes.c_int
- ctypes.c_ssize_t
- ctypes.c_ulong
- ctypes.c_void_p
- ctypes.py_object
- ctypes.pythonapi
- ctypes.windll
- ctypes.wintypes.DWORD
- ctypes.wintypes.HANDLE
- ctypes.wintypes.LPCWSTR
- ctypes.wintypes.LPWSTR
- io
- msvcrt
- sys
- time
- typing
- typing_extensions.Buffer

**Functions:**

### `def get_buffer(obj: Buffer, writable: bool = False) -> Array[c_char]`

**Line:** 105

---

### `def _get_text_stdin(buffer_stream: t.BinaryIO) -> t.TextIO`

**Line:** 226

---

### `def _get_text_stdout(buffer_stream: t.BinaryIO) -> t.TextIO`

**Line:** 236

---

### `def _get_text_stderr(buffer_stream: t.BinaryIO) -> t.TextIO`

**Line:** 246

---

### `def _is_console(f: t.TextIO) -> bool`

**Line:** 263

---

### `def _get_windows_console_stream(f: t.TextIO, encoding: str | None, errors: str | None) -> t.TextIO | None`

**Line:** 276

---


## Module: venv2.libthon3.12.site-packages.click.core
**File:** `venv2/lib/python3.12/site-packages/click/core.py`

**Imports:**
- __future__.annotations
- click.shell_completion.CompletionItem
- collections.Counter
- collections.abc
- contextlib.AbstractContextManager
- contextlib.ExitStack
- contextlib.contextmanager
- decorators.command
- decorators.group
- decorators.help_option
- enum
- errno
- exceptions.Abort
- exceptions.BadParameter
- exceptions.ClickException
- exceptions.Exit
- exceptions.MissingParameter
- exceptions.NoArgsIsHelpError
- exceptions.UsageError
- formatting.HelpFormatter
- formatting.join_options
- functools.update_wrapper
- gettext.gettext
- gettext.ngettext
- globals.pop_context
- globals.push_context
- inspect
- itertools.repeat
- os
- parser._OptionParser
- parser._flag_needs_value
- parser._split_opt
- shell_completion.CompletionItem
- shell_completion.shell_complete
- sys
- termui.confirm
- termui.prompt
- termui.style
- types.TracebackType
- typing
- utils.PacifyFlushWrapper
- utils._detect_program_name
- utils._expand_args
- utils.echo
- utils.make_default_short_help
- utils.make_str
- warnings

**Functions:**

### `def _complete_visible_commands(ctx: Context, incomplete: str) -> cabc.Iterator[tuple[(str, Command)]]`

**Description:**
List all the subcommands of a group that start with the
incomplete value and aren't hidden.

:param ctx: Invocation context for the group.
:param incomplete: Value being completed. May be empty.

**Line:** 53

---

### `def _check_nested_chain(base_command: Group, cmd_name: str, cmd: Command, register: bool = False) -> None`

**Line:** 72

---

### `def batch(iterable: cabc.Iterable[V], batch_size: int) -> list[tuple[(V, ...)]]`

**Line:** 92

---

### `def augment_usage_errors(ctx: Context, param: Parameter | None = None) -> cabc.Iterator[None]`

**Decorators:**
- `@contextmanager`

**Description:**
Context manager that attaches extra information to exceptions.

**Line:** 97

---

### `def iter_params_for_processing(invocation_order: cabc.Sequence[Parameter], declaration_order: cabc.Sequence[Parameter]) -> list[Parameter]`

**Description:**
Returns all declared parameters in the order they should be processed.

The declared parameters are re-shuffled depending on the order in which
they were invoked, as well as the eagerness of each parameters.

The invocation order takes precedence over the declaration order. I.e. the
order in which the user provided them to the CLI is respected.

This behavior and its effect on callback evaluation is detailed at:
https://click.palletsprojects.com/en/stable/advanced/#callback-evaluation-order

**Line:** 115

---

### `def _check_iter(value: t.Any) -> cabc.Iterator[t.Any]`

**Description:**
Check if the value is iterable but not a string. Raises a type
error, or return an iterator over the value.

**Line:** 1974

---

### `def __getattr__(name: str) -> object`

**Line:** 3114

---


## Module: venv2.libthon3.12.site-packages.click.decorators
**File:** `venv2/lib/python3.12/site-packages/click/decorators.py`

**Imports:**
- __future__.annotations
- core.Argument
- core.Command
- core.Context
- core.Group
- core.Option
- core.Parameter
- functools.update_wrapper
- gettext.gettext
- globals.get_current_context
- importlib.metadata
- inspect
- typing
- typing_extensions
- utils.echo

**Functions:**

### `def pass_context(f: t.Callable[(te.Concatenate[Context, P], R)]) -> t.Callable[(P, R)]`

**Description:**
Marks a callback as wanting to receive the current context
object as first argument.

**Line:** 28

---

### `def pass_obj(f: t.Callable[(te.Concatenate[T, P], R)]) -> t.Callable[(P, R)]`

**Description:**
Similar to :func:`pass_context`, but only pass the object on the
context onwards (:attr:`Context.obj`).  This is useful if that object
represents the state of a nested system.

**Line:** 39

---

### `def make_pass_decorator(object_type: type[T], ensure: bool = False) -> t.Callable[([t.Callable[te.Concatenate[T, P], R]], t.Callable[P, R])]`

**Description:**
Given an object type this creates a decorator that will work
similar to :func:`pass_obj` but instead of passing the object of the
current context, it will find the innermost context of type
:func:`object_type`.

This generates a decorator that works roughly like this::

from functools import update_wrapper

def decorator(f):
@pass_context
def new_func(ctx, *args, **kwargs):
obj = ctx.find_object(object_type)
return ctx.invoke(f, obj, *args, **kwargs)
return update_wrapper(new_func, f)
return decorator

:param object_type: the type of the object to pass.
:param ensure: if set to `True`, a new object will be created and
remembered on the context if it's not there yet.

**Line:** 51

---

### `def pass_meta_key(key: str, doc_description: str | None = None) -> t.Callable[([t.Callable[te.Concatenate[T, P], R]], t.Callable[P, R])]`

**Description:**
Create a decorator that passes a key from
:attr:`click.Context.meta` as the first argument to the decorated
function.

:param key: Key in ``Context.meta`` to pass.
:param doc_description: Description of the object being passed,
inserted into the decorator's docstring. Defaults to "the 'key'
key from Context.meta".

.. versionadded:: 8.0

**Line:** 100

---

### `def command(name: _AnyCallable) -> Command`

**Decorators:**
- `@t.overload`

**Line:** 138

---

### `def command(name: str | None, cls: type[CmdType], **attrs: t.Any) -> t.Callable[([_AnyCallable], CmdType)]`

**Decorators:**
- `@t.overload`

**Line:** 144

---

### `def command(name: None = None, cls: type[CmdType], **attrs: t.Any) -> t.Callable[([_AnyCallable], CmdType)]`

**Decorators:**
- `@t.overload`

**Line:** 153

---

### `def command(name: str | None = Ellipsis, cls: None = None, **attrs: t.Any) -> t.Callable[([_AnyCallable], Command)]`

**Decorators:**
- `@t.overload`

**Line:** 163

---

### `def command(name: str | _AnyCallable | None = None, cls: type[CmdType] | None = None, **attrs: t.Any) -> Command | t.Callable[[_AnyCallable], Command | CmdType]`

**Description:**
Creates a new :class:`Command` and uses the decorated function as
callback.  This will also automatically attach all decorated
:func:`option`\s and :func:`argument`\s as parameters to the command.

The name of the command defaults to the name of the function, converted to
lowercase, with underscores ``_`` replaced by dashes ``-``, and the suffixes
``_command``, ``_cmd``, ``_group``, and ``_grp`` are removed. For example,
``init_data_command`` becomes ``init-data``.

All keyword arguments are forwarded to the underlying command class.
For the ``params`` argument, any decorated params are appended to
the end of the list.

Once decorated the function turns into a :class:`Command` instance
that can be invoked as a command line utility or be attached to a
command :class:`Group`.

:param name: The name of the command. Defaults to modifying the function's
name as described above.
:param cls: The command class to create. Defaults to :class:`Command`.

.. versionchanged:: 8.2
The suffixes ``_command``, ``_cmd``, ``_group``, and ``_grp`` are
removed when generating the name.

.. versionchanged:: 8.1
This decorator can be applied without parentheses.

.. versionchanged:: 8.1
The ``params`` argument can be used. Decorated params are
appended to the end of the list.

**Line:** 168

---

### `def group(name: _AnyCallable) -> Group`

**Decorators:**
- `@t.overload`

**Line:** 263

---

### `def group(name: str | None, cls: type[GrpType], **attrs: t.Any) -> t.Callable[([_AnyCallable], GrpType)]`

**Decorators:**
- `@t.overload`

**Line:** 269

---

### `def group(name: None = None, cls: type[GrpType], **attrs: t.Any) -> t.Callable[([_AnyCallable], GrpType)]`

**Decorators:**
- `@t.overload`

**Line:** 278

---

### `def group(name: str | None = Ellipsis, cls: None = None, **attrs: t.Any) -> t.Callable[([_AnyCallable], Group)]`

**Decorators:**
- `@t.overload`

**Line:** 288

---

### `def group(name: str | _AnyCallable | None = None, cls: type[GrpType] | None = None, **attrs: t.Any) -> Group | t.Callable[[_AnyCallable], Group | GrpType]`

**Description:**
Creates a new :class:`Group` with a function as callback.  This
works otherwise the same as :func:`command` just that the `cls`
parameter is set to :class:`Group`.

.. versionchanged:: 8.1
This decorator can be applied without parentheses.

**Line:** 293

---

### `def _param_memo(f: t.Callable[(..., t.Any)], param: Parameter) -> None`

**Line:** 314

---

### `def argument(cls: type[Argument] | None = None, *param_decls: str, **attrs: t.Any) -> t.Callable[([FC], FC)]`

**Description:**
Attaches an argument to the command.  All positional arguments are
passed as parameter declarations to :class:`Argument`; all keyword
arguments are forwarded unchanged (except ``cls``).
This is equivalent to creating an :class:`Argument` instance manually
and attaching it to the :attr:`Command.params` list.

For the default argument class, refer to :class:`Argument` and
:class:`Parameter` for descriptions of parameters.

:param cls: the argument class to instantiate.  This defaults to
:class:`Argument`.
:param param_decls: Passed as positional arguments to the constructor of
``cls``.
:param attrs: Passed as keyword arguments to the constructor of ``cls``.

**Line:** 324

---

### `def option(cls: type[Option] | None = None, *param_decls: str, **attrs: t.Any) -> t.Callable[([FC], FC)]`

**Description:**
Attaches an option to the command.  All positional arguments are
passed as parameter declarations to :class:`Option`; all keyword
arguments are forwarded unchanged (except ``cls``).
This is equivalent to creating an :class:`Option` instance manually
and attaching it to the :attr:`Command.params` list.

For the default option class, refer to :class:`Option` and
:class:`Parameter` for descriptions of parameters.

:param cls: the option class to instantiate.  This defaults to
:class:`Option`.
:param param_decls: Passed as positional arguments to the constructor of
``cls``.
:param attrs: Passed as keyword arguments to the constructor of ``cls``.

**Line:** 352

---

### `def confirmation_option(*param_decls: str, **kwargs: t.Any) -> t.Callable[([FC], FC)]`

**Description:**
Add a ``--yes`` option which shows a prompt before continuing if
not passed. If the prompt is declined, the program will exit.

:param param_decls: One or more option names. Defaults to the single
value ``"--yes"``.
:param kwargs: Extra arguments are passed to :func:`option`.

**Line:** 380

---

### `def password_option(*param_decls: str, **kwargs: t.Any) -> t.Callable[([FC], FC)]`

**Description:**
Add a ``--password`` option which prompts for a password, hiding
input and asking to enter the value again for confirmation.

:param param_decls: One or more option names. Defaults to the single
value ``"--password"``.
:param kwargs: Extra arguments are passed to :func:`option`.

**Line:** 404

---

### `def version_option(version: str | None = None, package_name: str | None = None, prog_name: str | None = None, message: str | None = None, *param_decls: str, **kwargs: t.Any) -> t.Callable[([FC], FC)]`

**Description:**
Add a ``--version`` option which immediately prints the version
number and exits the program.

If ``version`` is not provided, Click will try to detect it using
:func:`importlib.metadata.version` to get the version for the
``package_name``.

If ``package_name`` is not provided, Click will try to detect it by
inspecting the stack frames. This will be used to detect the
version, so it must match the name of the installed package.

:param version: The version number to show. If not provided, Click
will try to detect it.
:param param_decls: One or more option names. Defaults to the single
value ``"--version"``.
:param package_name: The package name to detect the version from. If
not provided, Click will try to detect it.
:param prog_name: The name of the CLI to show in the message. If not
provided, it will be detected from the command.
:param message: The message to show. The values ``%(prog)s``,
``%(package)s``, and ``%(version)s`` are available. Defaults to
``"%(prog)s, version %(version)s"``.
:param kwargs: Extra arguments are passed to :func:`option`.
:raise RuntimeError: ``version`` could not be detected.

.. versionchanged:: 8.0
Add the ``package_name`` parameter, and the ``%(package)s``
value for messages.

.. versionchanged:: 8.0
Use :mod:`importlib.metadata` instead of ``pkg_resources``. The
version is detected based on the package name, not the entry
point name. The Python package name must match the installed
package name, or be passed with ``package_name=``.

**Line:** 421

---

### `def help_option(*param_decls: str, **kwargs: t.Any) -> t.Callable[([FC], FC)]`

**Description:**
Pre-configured ``--help`` option which immediately prints the help page
and exits the program.

:param param_decls: One or more option names. Defaults to the single
value ``"--help"``.
:param kwargs: Extra arguments are passed to :func:`option`.

**Line:** 527

---


## Module: venv2.libthon3.12.site-packages.click.exceptions
**File:** `venv2/lib/python3.12/site-packages/click/exceptions.py`

**Imports:**
- __future__.annotations
- _compat.get_text_stderr
- collections.abc
- core.Command
- core.Context
- core.Parameter
- gettext.gettext
- gettext.ngettext
- globals.resolve_color_default
- typing
- utils.echo
- utils.format_filename

**Functions:**

### `def _join_param_hints(param_hint: cabc.Sequence[str] | str | None) -> str | None`

**Line:** 19

---


## Module: venv2.libthon3.12.site-packages.click.formatting
**File:** `venv2/lib/python3.12/site-packages/click/formatting.py`

**Imports:**
- __future__.annotations
- _compat.term_len
- _textwrap.TextWrapper
- collections.abc
- contextlib.contextmanager
- gettext.gettext
- parser._split_opt
- shutil

**Functions:**

### `def measure_table(rows: cabc.Iterable[tuple[(str, str)]]) -> tuple[(int, ...)]`

**Line:** 14

---

### `def iter_rows(rows: cabc.Iterable[tuple[(str, str)]], col_count: int) -> cabc.Iterator[tuple[(str, ...)]]`

**Line:** 24

---

### `def wrap_text(text: str, width: int = 78, initial_indent: str = '', subsequent_indent: str = '', preserve_paragraphs: bool = False) -> str`

**Description:**
A helper function that intelligently wraps text.  By default, it
assumes that it operates on a single paragraph of text but if the
`preserve_paragraphs` parameter is provided it will intelligently
handle paragraphs (defined by two empty lines).

If paragraphs are handled, a paragraph can be prefixed with an empty
line containing the ``\b`` character (``\x08``) to indicate that
no rewrapping should happen in that block.

:param text: the text that should be rewrapped.
:param width: the maximum width for the text.
:param initial_indent: the initial indent that should be placed on the
first line as a string.
:param subsequent_indent: the indent string that should be placed on
each consecutive line.
:param preserve_paragraphs: if this flag is set then the wrapping will
intelligently handle paragraphs.

**Line:** 31

---

### `def join_options(options: cabc.Sequence[str]) -> tuple[(str, bool)]`

**Description:**
Given a list of option strings this joins them in the most appropriate
way and returns them in the form ``(formatted_string,
any_prefix_is_slash)`` where the second item in the tuple is a flag that
indicates if any of the option prefixes was a slash.

**Line:** 283

---


## Module: venv2.libthon3.12.site-packages.click.globals
**File:** `venv2/lib/python3.12/site-packages/click/globals.py`

**Imports:**
- __future__.annotations
- core.Context
- threading.local
- typing

**Functions:**

### `def get_current_context(silent: t.Literal[False] = False) -> Context`

**Decorators:**
- `@t.overload`

**Line:** 13

---

### `def get_current_context(silent: bool = Ellipsis) -> Context | None`

**Decorators:**
- `@t.overload`

**Line:** 17

---

### `def get_current_context(silent: bool = False) -> Context | None`

**Description:**
Returns the current click context.  This can be used as a way to
access the current context object from anywhere.  This is a more implicit
alternative to the :func:`pass_context` decorator.  This function is
primarily useful for helpers such as :func:`echo` which might be
interested in changing its behavior based on the current context.

To push the current context, :meth:`Context.scope` can be used.

.. versionadded:: 5.0

:param silent: if set to `True` the return value is `None` if no context
is available.  The default behavior is to raise a
:exc:`RuntimeError`.

**Line:** 20

---

### `def push_context(ctx: Context) -> None`

**Description:**
Pushes a new context to the current stack.

**Line:** 44

---

### `def pop_context() -> None`

**Description:**
Removes the top level from the stack.

**Line:** 49

---

### `def resolve_color_default(color: bool | None = None) -> bool | None`

**Description:**
Internal helper to get the default value of the color flag.  If a
value is passed it's returned unchanged, otherwise it's looked up from
the current context.

**Line:** 54

---


## Module: venv2.libthon3.12.site-packages.click.parser
**File:** `venv2/lib/python3.12/site-packages/click/parser.py`

**Imports:**
- __future__.annotations
- collections.abc
- collections.deque
- core.Argument
- core.Context
- core.Option
- core.Parameter
- difflib.get_close_matches
- exceptions.BadArgumentUsage
- exceptions.BadOptionUsage
- exceptions.NoSuchOption
- exceptions.UsageError
- gettext.gettext
- gettext.ngettext
- shell_completion.split_arg_string
- typing
- warnings

**Functions:**

### `def _unpack_args(args: cabc.Sequence[str], nargs_spec: cabc.Sequence[int]) -> tuple[(cabc.Sequence[str | cabc.Sequence[str | None] | None], list[str])]`

**Description:**
Given an iterable of arguments and an iterable of nargs specifications,
it returns a tuple with all the unpacked arguments at the first index
and all remaining arguments as the second.

The nargs specification is the number of arguments that should be consumed
or `-1` to indicate that this position should eat up all the remainders.

Missing items are filled with `None`.

**Line:** 52

---

### `def _split_opt(opt: str) -> tuple[(str, str)]`

**Line:** 112

---

### `def _normalize_opt(opt: str, ctx: Context | None) -> str`

**Line:** 121

---

### `def __getattr__(name: str) -> object`

**Line:** 502

---


## Module: venv2.libthon3.12.site-packages.click.shell_completion
**File:** `venv2/lib/python3.12/site-packages/click/shell_completion.py`

**Imports:**
- __future__.annotations
- collections.abc
- core.Argument
- core.Command
- core.Context
- core.Group
- core.Option
- core.Parameter
- core.ParameterSource
- gettext.gettext
- os
- re
- shlex
- shutil
- subprocess
- typing
- utils.echo

**Functions:**

### `def shell_complete(cli: Command, ctx_args: cabc.MutableMapping[(str, t.Any)], prog_name: str, complete_var: str, instruction: str) -> int`

**Description:**
Perform shell completion for the given CLI program.

:param cli: Command being called.
:param ctx_args: Extra arguments to pass to
``cli.make_context``.
:param prog_name: Name of the executable in the shell.
:param complete_var: Name of the environment variable that holds
the completion instruction.
:param instruction: Value of ``complete_var`` with the completion
instruction and shell, in the form ``instruction_shell``.
:return: Status code to exit with.

**Line:** 19

---

### `def add_completion_class(cls: ShellCompleteType, name: str | None = None) -> ShellCompleteType`

**Description:**
Register a :class:`ShellComplete` subclass under the given name.
The name will be provided by the completion instruction environment
variable during completion.

:param cls: The completion class that will handle completion for the
shell.
:param name: Name to register the class under. Defaults to the
class's ``name`` attribute.

**Line:** 414

---

### `def get_completion_class(shell: str) -> type[ShellComplete] | None`

**Description:**
Look up a registered :class:`ShellComplete` subclass by the name
provided by the completion instruction environment variable. If the
name isn't registered, returns ``None``.

:param shell: Name the class is registered under.

**Line:** 434

---

### `def split_arg_string(string: str) -> list[str]`

**Description:**
Split an argument string as with :func:`shlex.split`, but don't
fail if the string is incomplete. Ignores a missing closing quote or
incomplete escape sequence and uses the partial token as-is.

.. code-block:: python

split_arg_string("example 'my file")
["example", "my file"]

split_arg_string("example my\")
["example", "my"]

:param string: String to split.

.. versionchanged:: 8.2
Moved to ``shell_completion`` from ``parser``.

**Line:** 444

---

### `def _is_incomplete_argument(ctx: Context, param: Parameter) -> bool`

**Description:**
Determine if the given parameter is an argument that can still
accept values.

:param ctx: Invocation context for the command represented by the
parsed complete args.
:param param: Argument object being checked.

**Line:** 481

---

### `def _start_of_option(ctx: Context, value: str) -> bool`

**Description:**
Check if the value looks like the start of an option.

**Line:** 506

---

### `def _is_incomplete_option(ctx: Context, args: list[str], param: Parameter) -> bool`

**Description:**
Determine if the given parameter is an option that needs a value.

:param args: List of complete args before the incomplete value.
:param param: Option object being checked.

**Line:** 515

---

### `def _resolve_context(cli: Command, ctx_args: cabc.MutableMapping[(str, t.Any)], prog_name: str, args: list[str]) -> Context`

**Description:**
Produce the context hierarchy starting with the command and
traversing the complete arguments. This only follows the commands,
it doesn't trigger input prompts or callbacks.

:param cli: Command being called.
:param prog_name: Name of the executable in the shell.
:param args: List of complete args before the incomplete value.

**Line:** 539

---

### `def _resolve_incomplete(ctx: Context, args: list[str], incomplete: str) -> tuple[(Command | Parameter, str)]`

**Description:**
Find the Click object that will handle the completion of the
incomplete value. Return the object and the incomplete value.

:param ctx: Invocation context for the command represented by
the parsed complete args.
:param args: List of complete args before the incomplete value.
:param incomplete: Value being completed. May be empty.

**Line:** 600

---


## Module: venv2.libthon3.12.site-packages.click.termui
**File:** `venv2/lib/python3.12/site-packages/click/termui.py`

**Imports:**
- __future__.annotations
- _compat.isatty
- _compat.strip_ansi
- _termui_impl.Editor
- _termui_impl.ProgressBar
- _termui_impl.getchar
- _termui_impl.open_url
- _termui_impl.pager
- _termui_impl.raw_terminal
- collections.abc
- contextlib.AbstractContextManager
- exceptions.Abort
- exceptions.UsageError
- getpass
- gettext.gettext
- globals.resolve_color_default
- inspect
- io
- itertools
- sys
- types.Choice
- types.ParamType
- types.convert_type
- typing
- utils.LazyFile
- utils.echo

**Functions:**

### `def hidden_prompt_func(prompt: str) -> str`

**Line:** 54

---

### `def _build_prompt(text: str, suffix: str, show_default: bool = False, default: t.Any | None = None, show_choices: bool = True, type: ParamType | None = None) -> str`

**Line:** 60

---

### `def _format_default(default: t.Any) -> t.Any`

**Line:** 76

---

### `def prompt(text: str, default: t.Any | None = None, hide_input: bool = False, confirmation_prompt: bool | str = False, type: ParamType | t.Any | None = None, value_proc: t.Callable[[str], t.Any] | None = None, prompt_suffix: str = ': ', show_default: bool = True, err: bool = False, show_choices: bool = True) -> t.Any`

**Description:**
Prompts a user for input.  This is a convenience function that can
be used to prompt a user for input later.

If the user aborts the input by sending an interrupt signal, this
function will catch it and raise a :exc:`Abort` exception.

:param text: the text to show for the prompt.
:param default: the default value to use if no input happens.  If this
is not given it will prompt until it's aborted.
:param hide_input: if this is set to true then the input value will
be hidden.
:param confirmation_prompt: Prompt a second time to confirm the
value. Can be set to a string instead of ``True`` to customize
the message.
:param type: the type to use to check the value against.
:param value_proc: if this parameter is provided it's a function that
is invoked instead of the type conversion to
convert a value.
:param prompt_suffix: a suffix that should be added to the prompt.
:param show_default: shows or hides the default value in the prompt.
:param err: if set to true the file defaults to ``stderr`` instead of
``stdout``, the same as with echo.
:param show_choices: Show or hide choices if the passed type is a Choice.
For example if type is a Choice of either day or week,
show_choices is true and text is "Group by" then the
prompt will be "Group by (day, week): ".

.. versionadded:: 8.0
``confirmation_prompt`` can be a custom string.

.. versionadded:: 7.0
Added the ``show_choices`` parameter.

.. versionadded:: 6.0
Added unicode support for cmd.exe on Windows.

.. versionadded:: 4.0
Added the `err` parameter.

**Line:** 83

---

### `def confirm(text: str, default: bool | None = False, abort: bool = False, prompt_suffix: str = ': ', show_default: bool = True, err: bool = False) -> bool`

**Description:**
Prompts for confirmation (yes/no question).

If the user aborts the input by sending a interrupt signal this
function will catch it and raise a :exc:`Abort` exception.

:param text: the question to ask.
:param default: The default value to use when no input is given. If
``None``, repeat until input is given.
:param abort: if this is set to `True` a negative answer aborts the
exception by raising :exc:`Abort`.
:param prompt_suffix: a suffix that should be added to the prompt.
:param show_default: shows or hides the default value in the prompt.
:param err: if set to true the file defaults to ``stderr`` instead of
``stdout``, the same as with echo.

.. versionchanged:: 8.0
Repeat until input is given if ``default`` is ``None``.

.. versionadded:: 4.0
Added the ``err`` parameter.

**Line:** 194

---

### `def echo_via_pager(text_or_generator: cabc.Iterable[str] | t.Callable[[], cabc.Iterable[str]] | str, color: bool | None = None) -> None`

**Description:**
This function takes a text and shows it via an environment specific
pager on stdout.

.. versionchanged:: 3.0
Added the `color` flag.

:param text_or_generator: the text to page, or alternatively, a
generator emitting the text to page.
:param color: controls if the pager supports ANSI colors or not.  The
default is autodetection.

**Line:** 255

---

### `def progressbar(length: int, label: str | None = None, hidden: bool = False, show_eta: bool = True, show_percent: bool | None = None, show_pos: bool = False, fill_char: str = '#', empty_char: str = '-', bar_template: str = '%(label)s  [%(bar)s]  %(info)s', info_sep: str = '  ', width: int = 36, file: t.TextIO | None = None, color: bool | None = None, update_min_steps: int = 1) -> ProgressBar[int]`

**Decorators:**
- `@t.overload`

**Line:** 288

---

### `def progressbar(iterable: cabc.Iterable[V] | None = None, length: int | None = None, label: str | None = None, hidden: bool = False, show_eta: bool = True, show_percent: bool | None = None, show_pos: bool = False, item_show_func: t.Callable[[V | None], str | None] | None = None, fill_char: str = '#', empty_char: str = '-', bar_template: str = '%(label)s  [%(bar)s]  %(info)s', info_sep: str = '  ', width: int = 36, file: t.TextIO | None = None, color: bool | None = None, update_min_steps: int = 1) -> ProgressBar[V]`

**Decorators:**
- `@t.overload`

**Line:** 308

---

### `def progressbar(iterable: cabc.Iterable[V] | None = None, length: int | None = None, label: str | None = None, hidden: bool = False, show_eta: bool = True, show_percent: bool | None = None, show_pos: bool = False, item_show_func: t.Callable[[V | None], str | None] | None = None, fill_char: str = '#', empty_char: str = '-', bar_template: str = '%(label)s  [%(bar)s]  %(info)s', info_sep: str = '  ', width: int = 36, file: t.TextIO | None = None, color: bool | None = None, update_min_steps: int = 1) -> ProgressBar[V]`

**Description:**
This function creates an iterable context manager that can be used
to iterate over something while showing a progress bar.  It will
either iterate over the `iterable` or `length` items (that are counted
up).  While iteration happens, this function will print a rendered
progress bar to the given `file` (defaults to stdout) and will attempt
to calculate remaining time and more.  By default, this progress bar
will not be rendered if the file is not a terminal.

The context manager creates the progress bar.  When the context
manager is entered the progress bar is already created.  With every
iteration over the progress bar, the iterable passed to the bar is
advanced and the bar is updated.  When the context manager exits,
a newline is printed and the progress bar is finalized on screen.

Note: The progress bar is currently designed for use cases where the
total progress can be expected to take at least several seconds.
Because of this, the ProgressBar class object won't display
progress that is considered too fast, and progress where the time
between steps is less than a second.

No printing must happen or the progress bar will be unintentionally
destroyed.

Example usage::

with progressbar(items) as bar:
for item in bar:
do_something_with(item)

Alternatively, if no iterable is specified, one can manually update the
progress bar through the `update()` method instead of directly
iterating over the progress bar.  The update method accepts the number
of steps to increment the bar with::

with progressbar(length=chunks.total_bytes) as bar:
for chunk in chunks:
process_chunk(chunk)
bar.update(chunks.bytes)

The ``update()`` method also takes an optional value specifying the
``current_item`` at the new position. This is useful when used
together with ``item_show_func`` to customize the output for each
manual step::

with click.progressbar(
length=total_size,
label='Unzipping archive',
item_show_func=lambda a: a.filename
) as bar:
for archive in zip_file:
archive.extract()
bar.update(archive.size, archive)

:param iterable: an iterable to iterate over.  If not provided the length
is required.
:param length: the number of items to iterate over.  By default the
progressbar will attempt to ask the iterator about its
length, which might or might not work.  If an iterable is
also provided this parameter can be used to override the
length.  If an iterable is not provided the progress bar
will iterate over a range of that length.
:param label: the label to show next to the progress bar.
:param hidden: hide the progressbar. Defaults to ``False``. When no tty is
detected, it will only print the progressbar label. Setting this to
``False`` also disables that.
:param show_eta: enables or disables the estimated time display.  This is
automatically disabled if the length cannot be
determined.
:param show_percent: enables or disables the percentage display.  The
default is `True` if the iterable has a length or
`False` if not.
:param show_pos: enables or disables the absolute position display.  The
default is `False`.
:param item_show_func: A function called with the current item which
can return a string to show next to the progress bar. If the
function returns ``None`` nothing is shown. The current item can
be ``None``, such as when entering and exiting the bar.
:param fill_char: the character to use to show the filled part of the
progress bar.
:param empty_char: the character to use to show the non-filled part of
the progress bar.
:param bar_template: the format string to use as template for the bar.
The parameters in it are ``label`` for the label,
``bar`` for the progress bar and ``info`` for the
info section.
:param info_sep: the separator between multiple info items (eta etc.)
:param width: the width of the progress bar in characters, 0 means full
terminal width
:param file: The file to write to. If this is not a terminal then
only the label is printed.
:param color: controls if the terminal supports ANSI colors or not.  The
default is autodetection.  This is only needed if ANSI
codes are included anywhere in the progress bar output
which is not the case by default.
:param update_min_steps: Render only when this many updates have
completed. This allows tuning for very fast iterators.

.. versionadded:: 8.2
The ``hidden`` argument.

.. versionchanged:: 8.0
Output is shown even if execution time is less than 0.5 seconds.

.. versionchanged:: 8.0
``item_show_func`` shows the current item, not the previous one.

.. versionchanged:: 8.0
Labels are echoed if the output is not a TTY. Reverts a change
in 7.0 that removed all output.

.. versionadded:: 8.0
The ``update_min_steps`` parameter.

.. versionadded:: 4.0
The ``color`` parameter and ``update`` method.

.. versionadded:: 2.0

**Line:** 328

---

### `def clear() -> None`

**Description:**
Clears the terminal screen.  This will have the effect of clearing
the whole visible space of the terminal and moving the cursor to the
top left.  This does not do anything if not connected to a terminal.

.. versionadded:: 2.0

**Line:** 487

---

### `def _interpret_color(color: int | tuple[int, int, int] | str, offset: int = 0) -> str`

**Line:** 501

---

### `def style(text: t.Any, fg: int | tuple[int, int, int] | str | None = None, bg: int | tuple[int, int, int] | str | None = None, bold: bool | None = None, dim: bool | None = None, underline: bool | None = None, overline: bool | None = None, italic: bool | None = None, blink: bool | None = None, reverse: bool | None = None, strikethrough: bool | None = None, reset: bool = True) -> str`

**Description:**
Styles a text with ANSI styles and returns the new string.  By
default the styling is self contained which means that at the end
of the string a reset code is issued.  This can be prevented by
passing ``reset=False``.

Examples::

click.echo(click.style('Hello World!', fg='green'))
click.echo(click.style('ATTENTION!', blink=True))
click.echo(click.style('Some things', reverse=True, fg='cyan'))
click.echo(click.style('More colors', fg=(255, 12, 128), bg=117))

Supported color names:

* ``black`` (might be a gray)
* ``red``
* ``green``
* ``yellow`` (might be an orange)
* ``blue``
* ``magenta``
* ``cyan``
* ``white`` (might be light gray)
* ``bright_black``
* ``bright_red``
* ``bright_green``
* ``bright_yellow``
* ``bright_blue``
* ``bright_magenta``
* ``bright_cyan``
* ``bright_white``
* ``reset`` (reset the color code only)

If the terminal supports it, color may also be specified as:

-   An integer in the interval [0, 255]. The terminal must support
8-bit/256-color mode.
-   An RGB tuple of three integers in [0, 255]. The terminal must
support 24-bit/true-color mode.

See https://en.wikipedia.org/wiki/ANSI_color and
https://gist.github.com/XVilka/8346728 for more information.

:param text: the string to style with ansi codes.
:param fg: if provided this will become the foreground color.
:param bg: if provided this will become the background color.
:param bold: if provided this will enable or disable bold mode.
:param dim: if provided this will enable or disable dim mode.  This is
badly supported.
:param underline: if provided this will enable or disable underline.
:param overline: if provided this will enable or disable overline.
:param italic: if provided this will enable or disable italic.
:param blink: if provided this will enable or disable blinking.
:param reverse: if provided this will enable or disable inverse
rendering (foreground becomes background and the
other way round).
:param strikethrough: if provided this will enable or disable
striking through text.
:param reset: by default a reset-all code is added at the end of the
string which means that styles do not carry over.  This
can be disabled to compose styles.

.. versionchanged:: 8.0
A non-string ``message`` is converted to a string.

.. versionchanged:: 8.0
Added support for 256 and RGB color codes.

.. versionchanged:: 8.0
Added the ``strikethrough``, ``italic``, and ``overline``
parameters.

.. versionchanged:: 7.0
Added support for bright colors.

.. versionadded:: 2.0

**Line:** 512

---

### `def unstyle(text: str) -> str`

**Description:**
Removes ANSI styling information from a string.  Usually it's not
necessary to use this function as Click's echo function will
automatically remove styling if necessary.

.. versionadded:: 2.0

:param text: the text to remove style information from.

**Line:** 641

---

### `def secho(message: t.Any | None = None, file: t.IO[t.AnyStr] | None = None, nl: bool = True, err: bool = False, color: bool | None = None, **styles: t.Any) -> None`

**Description:**
This function combines :func:`echo` and :func:`style` into one
call.  As such the following two calls are the same::

click.secho('Hello World!', fg='green')
click.echo(click.style('Hello World!', fg='green'))

All keyword arguments are forwarded to the underlying functions
depending on which one they go with.

Non-string types will be converted to :class:`str`. However,
:class:`bytes` are passed directly to :meth:`echo` without applying
style. If you want to style bytes that represent text, call
:meth:`bytes.decode` first.

.. versionchanged:: 8.0
A non-string ``message`` is converted to a string. Bytes are
passed through without style applied.

.. versionadded:: 2.0

**Line:** 653

---

### `def edit(text: bytes | bytearray, editor: str | None = None, env: cabc.Mapping[str, str] | None = None, require_save: bool = False, extension: str = '.txt') -> bytes | None`

**Decorators:**
- `@t.overload`

**Line:** 688

---

### `def edit(text: str, editor: str | None = None, env: cabc.Mapping[str, str] | None = None, require_save: bool = True, extension: str = '.txt') -> str | None`

**Decorators:**
- `@t.overload`

**Line:** 698

---

### `def edit(text: None = None, editor: str | None = None, env: cabc.Mapping[str, str] | None = None, require_save: bool = True, extension: str = '.txt', filename: str | cabc.Iterable[str] | None = None) -> None`

**Decorators:**
- `@t.overload`

**Line:** 708

---

### `def edit(text: str | bytes | bytearray | None = None, editor: str | None = None, env: cabc.Mapping[str, str] | None = None, require_save: bool = True, extension: str = '.txt', filename: str | cabc.Iterable[str] | None = None) -> str | bytes | bytearray | None`

**Description:**
Edits the given text in the defined editor.  If an editor is given
(should be the full path to the executable but the regular operating
system search path is used for finding the executable) it overrides
the detected editor.  Optionally, some environment variables can be
used.  If the editor is closed without changes, `None` is returned.  In
case a file is edited directly the return value is always `None` and
`require_save` and `extension` are ignored.

If the editor cannot be opened a :exc:`UsageError` is raised.

Note for Windows: to simplify cross-platform usage, the newlines are
automatically converted from POSIX to Windows and vice versa.  As such,
the message here will have ``\n`` as newline markers.

:param text: the text to edit.
:param editor: optionally the editor to use.  Defaults to automatic
detection.
:param env: environment variables to forward to the editor.
:param require_save: if this is true, then not saving in the editor
will make the return value become `None`.
:param extension: the extension to tell the editor about.  This defaults
to `.txt` but changing this might change syntax
highlighting.
:param filename: if provided it will edit this file instead of the
provided text contents.  It will not use a temporary
file as an indirection in that case. If the editor supports
editing multiple files at once, a sequence of files may be
passed as well. Invoke `click.file` once per file instead
if multiple files cannot be managed at once or editing the
files serially is desired.

.. versionchanged:: 8.2.0
``filename`` now accepts any ``Iterable[str]`` in addition to a ``str``
if the ``editor`` supports editing multiple files at once.

**Line:** 718

---

### `def launch(url: str, wait: bool = False, locate: bool = False) -> int`

**Description:**
This function launches the given URL (or filename) in the default
viewer application for this file type.  If this is an executable, it
might launch the executable in a new session.  The return value is
the exit code of the launched application.  Usually, ``0`` indicates
success.

Examples::

click.launch('https://click.palletsprojects.com/')
click.launch('/my/downloaded/file', locate=True)

.. versionadded:: 2.0

:param url: URL or filename of the thing to launch.
:param wait: Wait for the program to exit before returning. This
only works if the launched program blocks. In particular,
``xdg-open`` on Linux does not block.
:param locate: if this is set to `True` then instead of launching the
application associated with the URL it will attempt to
launch a file manager with the file located.  This
might have weird effects if the URL does not point to
the filesystem.

**Line:** 776

---

### `def getchar(echo: bool = False) -> str`

**Description:**
Fetches a single character from the terminal and returns it.  This
will always return a unicode character and under certain rare
circumstances this might return more than one character.  The
situations which more than one character is returned is when for
whatever reason multiple characters end up in the terminal buffer or
standard input was not actually a terminal.

Note that this will always read from the terminal, even if something
is piped into the standard input.

Note for Windows: in rare cases when typing non-ASCII characters, this
function might wait for a second character and then return both at once.
This is because certain Unicode characters look like special-key markers.

.. versionadded:: 2.0

:param echo: if set to `True`, the character read will also show up on
the terminal.  The default is to not show it.

**Line:** 810

---

### `def raw_terminal() -> AbstractContextManager[int]`

**Line:** 840

---

### `def pause(info: str | None = None, err: bool = False) -> None`

**Description:**
This command stops execution and waits for the user to press any
key to continue.  This is similar to the Windows batch "pause"
command.  If the program is not run through a terminal, this command
will instead do nothing.

.. versionadded:: 2.0

.. versionadded:: 4.0
Added the `err` parameter.

:param info: The message to print before pausing. Defaults to
``"Press any key to continue..."``.
:param err: if set to message goes to ``stderr`` instead of
``stdout``, the same as with echo.

**Line:** 846

---


## Module: venv2.libthon3.12.site-packages.click.testing
**File:** `venv2/lib/python3.12/site-packages/click/testing.py`

**Imports:**
- __future__.annotations
- _compat._find_binary_reader
- _typeshed.ReadableBuffer
- collections.abc
- contextlib
- core.Command
- io
- os
- shlex
- shutil
- sys
- tempfile
- types.TracebackType
- typing

**Functions:**

### `def _pause_echo(stream: EchoingStdin | None) -> cabc.Iterator[None]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 61

---

### `def make_input_stream(input: str | bytes | t.IO[t.Any] | None, charset: str) -> t.BinaryIO`

**Line:** 127

---


## Module: venv2.libthon3.12.site-packages.click.types
**File:** `venv2/lib/python3.12/site-packages/click/types.py`

**Imports:**
- __future__.annotations
- _compat._get_argv_encoding
- _compat.open_stream
- click.shell_completion.CompletionItem
- collections.abc
- core.Context
- core.Parameter
- datetime.datetime
- enum
- exceptions.BadParameter
- gettext.gettext
- gettext.ngettext
- operator
- os
- shell_completion.CompletionItem
- stat
- sys
- typing
- typing_extensions
- utils.LazyFile
- utils.format_filename
- utils.safecall
- uuid

**Functions:**

### `def _is_file_like(value: t.Any) -> te.TypeGuard[t.IO[t.Any]]`

**Line:** 831

---

### `def convert_type(ty: t.Any | None, default: t.Any | None = None) -> ParamType`

**Description:**
Find the most appropriate :class:`ParamType` for the given Python
type. If the type isn't provided, it can be inferred from a default
value.

**Line:** 1068

---


## Module: venv2.libthon3.12.site-packages.click.utils
**File:** `venv2/lib/python3.12/site-packages/click/utils.py`

**Imports:**
- __future__.annotations
- _compat.WIN
- _compat._default_text_stderr
- _compat._default_text_stdout
- _compat._find_binary_writer
- _compat.auto_wrap_for_ansi
- _compat.binary_streams
- _compat.open_stream
- _compat.should_strip_ansi
- _compat.strip_ansi
- _compat.text_streams
- collections.abc
- errno
- exceptions.FileError
- functools.update_wrapper
- glob.glob
- globals.resolve_color_default
- os
- re
- sys
- types.ModuleType
- types.TracebackType
- typing
- typing_extensions

**Functions:**

### `def _posixify(name: str) -> str`

**Line:** 32

---

### `def safecall(func: t.Callable[(P, R)]) -> t.Callable[(P, R | None)]`

**Description:**
Wraps a function so that it swallows exceptions.

**Line:** 36

---

### `def make_str(value: t.Any) -> str`

**Description:**
Converts a value into a valid string.

**Line:** 49

---

### `def make_default_short_help(help: str, max_length: int = 45) -> str`

**Description:**
Returns a condensed version of help string.

**Line:** 59

---

### `def echo(message: t.Any | None = None, file: t.IO[t.Any] | None = None, nl: bool = True, err: bool = False, color: bool | None = None) -> None`

**Description:**
Print a message and newline to stdout or a file. This should be
used instead of :func:`print` because it provides better support
for different data, files, and environments.

Compared to :func:`print`, this does the following:

-   Ensures that the output encoding is not misconfigured on Linux.
-   Supports Unicode in the Windows console.
-   Supports writing to binary outputs, and supports writing bytes
to text outputs.
-   Supports colors and styles on Windows.
-   Removes ANSI color and style codes if the output does not look
like an interactive terminal.
-   Always flushes the output.

:param message: The string or bytes to output. Other objects are
converted to strings.
:param file: The file to write to. Defaults to ``stdout``.
:param err: Write to ``stderr`` instead of ``stdout``.
:param nl: Print a newline after the message. Enabled by default.
:param color: Force showing or hiding colors and other styles. By
default Click will remove color if the output does not look like
an interactive terminal.

.. versionchanged:: 6.0
Support Unicode output on the Windows console. Click does not
modify ``sys.stdout``, so ``sys.stdout.write()`` and ``print()``
will still not support Unicode.

.. versionchanged:: 4.0
Added the ``color`` parameter.

.. versionadded:: 3.0
Added the ``err`` parameter.

.. versionchanged:: 2.0
Support colors on Windows if colorama is installed.

**Line:** 222

---

### `def get_binary_stream(name: t.Literal[('stdin', 'stdout', 'stderr')]) -> t.BinaryIO`

**Description:**
Returns a system stream for byte processing.

:param name: the name of the stream to open.  Valid names are ``'stdin'``,
``'stdout'`` and ``'stderr'``

**Line:** 325

---

### `def get_text_stream(name: t.Literal[('stdin', 'stdout', 'stderr')], encoding: str | None = None, errors: str | None = 'strict') -> t.TextIO`

**Description:**
Returns a system stream for text processing.  This usually returns
a wrapped stream around a binary stream returned from
:func:`get_binary_stream` but it also can take shortcuts for already
correctly configured streams.

:param name: the name of the stream to open.  Valid names are ``'stdin'``,
``'stdout'`` and ``'stderr'``
:param encoding: overrides the detected default encoding.
:param errors: overrides the default error mode.

**Line:** 337

---

### `def open_file(filename: str | os.PathLike[str], mode: str = 'r', encoding: str | None = None, errors: str | None = 'strict', lazy: bool = False, atomic: bool = False) -> t.IO[t.Any]`

**Description:**
Open a file, with extra behavior to handle ``'-'`` to indicate
a standard stream, lazy open on write, and atomic write. Similar to
the behavior of the :class:`~click.File` param type.

If ``'-'`` is given to open ``stdout`` or ``stdin``, the stream is
wrapped so that using it in a context manager will not close it.
This makes it possible to use the function without accidentally
closing a standard stream:

.. code-block:: python

with open_file(filename) as f:
...

:param filename: The name or Path of the file to open, or ``'-'`` for
``stdin``/``stdout``.
:param mode: The mode in which to open the file.
:param encoding: The encoding to decode or encode a file opened in
text mode.
:param errors: The error handling mode.
:param lazy: Wait to open the file until it is accessed. For read
mode, the file is temporarily opened to raise access errors
early, then closed until it is read again.
:param atomic: Write to a temporary file and replace the given file
on close.

.. versionadded:: 3.0

**Line:** 358

---

### `def format_filename(filename: str | bytes | os.PathLike[str] | os.PathLike[bytes], shorten: bool = False) -> str`

**Description:**
Format a filename as a string for display. Ensures the filename can be
displayed by replacing any invalid bytes or surrogate escapes in the name
with the replacement character ````.

Invalid bytes or surrogate escapes will raise an error when written to a
stream with ``errors="strict"``. This will typically happen with ``stdout``
when the locale is something like ``en_GB.UTF-8``.

Many scenarios *are* safe to write surrogates though, due to PEP 538 and
PEP 540, including:

-   Writing to ``stderr``, which uses ``errors="backslashreplace"``.
-   The system has ``LANG=C.UTF-8``, ``C``, or ``POSIX``. Python opens
stdout and stderr with ``errors="surrogateescape"``.
-   None of ``LANG/LC_*`` are set. Python assumes ``LANG=C.UTF-8``.
-   Python is started in UTF-8 mode  with  ``PYTHONUTF8=1`` or ``-X utf8``.
Python opens stdout and stderr with ``errors="surrogateescape"``.

:param filename: formats a filename for UI display.  This will also convert
the filename into unicode without failing.
:param shorten: this optionally shortens the filename to strip of the
path that leads up to it.

**Line:** 407

---

### `def get_app_dir(app_name: str, roaming: bool = True, force_posix: bool = False) -> str`

**Description:**
Returns the config folder for the application.  The default behavior
is to return whatever is most appropriate for the operating system.

To give you an idea, for an app called ``"Foo Bar"``, something like
the following folders could be returned:

Mac OS X:
``~/Library/Application Support/Foo Bar``
Mac OS X (POSIX):
``~/.foo-bar``
Unix:
``~/.config/foo-bar``
Unix (POSIX):
``~/.foo-bar``
Windows (roaming):
``C:\Users\<user>\AppData\Roaming\Foo Bar``
Windows (not roaming):
``C:\Users\<user>\AppData\Local\Foo Bar``

.. versionadded:: 2.0

:param app_name: the application name.  This should be properly capitalized
and can contain whitespace.
:param roaming: controls if the folder should be roaming or not on Windows.
Has no effect otherwise.
:param force_posix: if this is set to `True` then on any POSIX system the
folder will be stored in the home folder with a leading
dot instead of the XDG config home or darwin's
application support folder.

**Line:** 449

---

### `def _detect_program_name(path: str | None = None, _main: ModuleType | None = None) -> str`

**Description:**
Determine the command used to run the program, for use in help
text. If a file or entry point was executed, the file name is
returned. If ``python -m`` was used to execute a module or package,
``python -m name`` is returned.

This doesn't try to be too precise, the goal is to give a concise
name for help text. Files are only shown as their name without the
path. ``python`` is only shown for modules, and the full path to
``sys.executable`` is not shown.

:param path: The Python file being executed. Python puts this in
``sys.argv[0]``, which is used by default.
:param _main: The ``__main__`` module. This should only be passed
during internal testing.

.. versionadded:: 8.0
Based on command args detection in the Werkzeug reloader.

:meta private:

**Line:** 523

---

### `def _expand_args(args: cabc.Iterable[str], user: bool = True, env: bool = True, glob_recursive: bool = True) -> list[str]`

**Description:**
Simulate Unix shell expansion with Python functions.

See :func:`glob.glob`, :func:`os.path.expanduser`, and
:func:`os.path.expandvars`.

This is intended for use on Windows, where the shell does not do any
expansion. It may not exactly match what a Unix shell would do.

:param args: List of command line arguments to expand.
:param user: Expand user home directory.
:param env: Expand environment variables.
:param glob_recursive: ``**`` matches directories recursively.

.. versionchanged:: 8.1
Invalid glob patterns are treated as empty expansions rather
than raising an error.

.. versionadded:: 8.0

:meta private:

**Line:** 578

---


## Module: venv2.libthon3.12.site-packages.deprecated.classic
**File:** `venv2/lib/python3.12/site-packages/deprecated/classic.py`

**Imports:**
- functools
- inspect
- platform
- warnings
- wrapt
- wrapt._wrappers

**Functions:**

### `def deprecated(*args, **kwargs)`

**Description:**
This is a decorator which can be used to mark functions
as deprecated. It will result in a warning being emitted
when the function is used.

**Classic usage:**

To use this, decorate your deprecated function with **@deprecated** decorator:

.. code-block:: python

from deprecated import deprecated


@deprecated
def some_old_function(x, y):
return x + y

You can also decorate a class or a method:

.. code-block:: python

from deprecated import deprecated


class SomeClass(object):
@deprecated
def some_old_method(self, x, y):
return x + y


@deprecated
class SomeOldClass(object):
pass

You can give a *reason* message to help the developer to choose another function/class,
and a *version* number to specify the starting version number of the deprecation.

.. code-block:: python

from deprecated import deprecated


@deprecated(reason="use another function", version='1.2.0')
def some_old_function(x, y):
return x + y

The *category* keyword argument allow you to specify the deprecation warning class of your choice.
By default, :exc:`DeprecationWarning` is used, but you can choose :exc:`FutureWarning`,
:exc:`PendingDeprecationWarning` or a custom subclass.

.. code-block:: python

from deprecated import deprecated


@deprecated(category=PendingDeprecationWarning)
def some_old_function(x, y):
return x + y

The *action* keyword argument allow you to locally change the warning filtering.
*action* can be one of "error", "ignore", "always", "default", "module", or "once".
If ``None``, empty or missing, the global filtering mechanism is used.
See: `The Warnings Filter`_ in the Python documentation.

.. code-block:: python

from deprecated import deprecated


@deprecated(action="error")
def some_old_function(x, y):
return x + y

The *extra_stacklevel* keyword argument allows you to specify additional stack levels
to consider instrumentation rather than user code. With the default value of 0, the
warning refers to where the class was instantiated or the function was called.

**Line:** 209

---


## Module: venv2.libthon3.12.site-packages.deprecated.sphinx
**File:** `venv2/lib/python3.12/site-packages/deprecated/sphinx.py`

**Imports:**
- deprecated.classic.ClassicAdapter
- deprecated.classic.deprecated
- re
- textwrap

**Functions:**

### `def versionadded(reason = '', version = '', line_length = 70)`

**Description:**
This decorator can be used to insert a "versionadded" directive
in your function/class docstring in order to document the
version of the project which adds this new functionality in your library.

:param str reason:
Reason message which documents the addition in your library (can be omitted).

:param str version:
Version of your project which adds this feature.
If you follow the `Semantic Versioning <https://semver.org/>`_,
the version number has the format "MAJOR.MINOR.PATCH", and,
in the case of a new functionality, the "PATCH" component should be "0".

:type  line_length: int
:param line_length:
Max line length of the directive text. If non nul, a long text is wrapped in several lines.

:return: the decorated function.

**Line:** 173

---

### `def versionchanged(reason = '', version = '', line_length = 70)`

**Description:**
This decorator can be used to insert a "versionchanged" directive
in your function/class docstring in order to document the
version of the project which modifies this functionality in your library.

:param str reason:
Reason message which documents the modification in your library (can be omitted).

:param str version:
Version of your project which modifies this feature.
If you follow the `Semantic Versioning <https://semver.org/>`_,
the version number has the format "MAJOR.MINOR.PATCH".

:type  line_length: int
:param line_length:
Max line length of the directive text. If non nul, a long text is wrapped in several lines.

:return: the decorated function.

**Line:** 203

---

### `def deprecated(reason = '', version = '', line_length = 70, **kwargs)`

**Description:**
This decorator can be used to insert a "deprecated" directive
in your function/class docstring in order to document the
version of the project which deprecates this functionality in your library.

:param str reason:
Reason message which documents the deprecation in your library (can be omitted).

:param str version:
Version of your project which deprecates this feature.
If you follow the `Semantic Versioning <https://semver.org/>`_,
the version number has the format "MAJOR.MINOR.PATCH".

:type  line_length: int
:param line_length:
Max line length of the directive text. If non nul, a long text is wrapped in several lines.

Keyword arguments can be:

-   "action":
A warning filter used to activate or not the deprecation warning.
Can be one of "error", "ignore", "always", "default", "module", or "once".
If ``None``, empty or missing, the global filtering mechanism is used.

-   "category":
The warning category to use for the deprecation warning.
By default, the category class is :class:`~DeprecationWarning`,
you can inherit this class to define your own deprecation warning category.

-   "extra_stacklevel":
Number of additional stack levels to consider instrumentation rather than user code.
With the default value of 0, the warning refers to where the class was instantiated
or the function was called.


:return: a decorator used to deprecate a function.

.. versionchanged:: 1.2.13
Change the signature of the decorator to reflect the valid use cases.

.. versionchanged:: 1.2.15
Add the *extra_stacklevel* parameter.

**Line:** 232

---


## Module: venv2.libthon3.12.site-packages.dotenv.__init__
**File:** `venv2/lib/python3.12/site-packages/dotenv/__init__.py`

**Imports:**
- ipython.load_ipython_extension
- main.dotenv_values
- main.find_dotenv
- main.get_key
- main.load_dotenv
- main.set_key
- main.unset_key
- typing.Any
- typing.Optional

**Functions:**

### `def load_ipython_extension(ipython: Any) -> None`

**Line:** 7

---

### `def get_cli_string(path: Optional[str] = None, action: Optional[str] = None, key: Optional[str] = None, value: Optional[str] = None, quote: Optional[str] = None)`

**Description:**
Returns a string suitable for running as a shell script.

Useful for converting a arguments passed to a fabric task
to be passed to a `local` or `run` command.

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.dotenv.cli
**File:** `venv2/lib/python3.12/site-packages/dotenv/cli.py`

**Imports:**
- click
- contextlib.contextmanager
- json
- main.dotenv_values
- main.set_key
- main.unset_key
- os
- shlex
- subprocess.Popen
- sys
- typing.Any
- typing.Dict
- typing.IO
- typing.Iterator
- typing.List
- version.__version__

**Functions:**

### `def enumerate_env()`

**Description:**
Return a path for the ${pwd}/.env file.

If pwd does not exist, return None.

**Line:** 20

---

### `def cli(ctx: click.Context, file: Any, quote: Any, export: Any) -> None`

**Decorators:**
- `@click.group(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.version_option(...)`
- `@click.pass_context`

**Description:**
This script is used to set, get or unset values from a .env file.

**Line:** 46

---

### `def stream_file(path: os.PathLike) -> Iterator[IO[str]]`

**Decorators:**
- `@contextmanager`

**Description:**
Open a file and yield the corresponding (decoded) stream.

Exits with error code 2 if the file cannot be opened.

**Line:** 52

---

### `def list(ctx: click.Context, format: bool) -> None`

**Decorators:**
- `@cli.command(...)`
- `@click.pass_context`
- `@click.option(...)`

**Description:**
Display all the stored key/value.

**Line:** 73

---

### `def set(ctx: click.Context, key: Any, value: Any) -> None`

**Decorators:**
- `@cli.command(...)`
- `@click.pass_context`
- `@click.argument(...)`
- `@click.argument(...)`

**Description:**
Store the given key/value.

**Line:** 96

---

### `def get(ctx: click.Context, key: Any) -> None`

**Decorators:**
- `@cli.command(...)`
- `@click.pass_context`
- `@click.argument(...)`

**Description:**
Retrieve the value for the given key.

**Line:** 111

---

### `def unset(ctx: click.Context, key: Any) -> None`

**Decorators:**
- `@cli.command(...)`
- `@click.pass_context`
- `@click.argument(...)`

**Description:**
Removes the given key.

**Line:** 128

---

### `def run(ctx: click.Context, override: bool, commandline: List[str]) -> None`

**Decorators:**
- `@cli.command(...)`
- `@click.pass_context`
- `@click.option(...)`
- `@click.argument(...)`

**Description:**
Run command with environment variables present.

**Line:** 147

---

### `def run_command(command: List[str], env: Dict[(str, str)]) -> int`

**Description:**
Run command in sub process.

Runs the command in a sub process with the variables from `env`
added in the current environment variables.

Parameters
----------
command: List[str]
The command and it's parameters
env: Dict
The additional environment variables

Returns
-------
int
The return code of the command

**Line:** 168

---


## Module: venv2.libthon3.12.site-packages.dotenv.ipython
**File:** `venv2/lib/python3.12/site-packages/dotenv/ipython.py`

**Imports:**
- IPython.core.magic.Magics
- IPython.core.magic.line_magic
- IPython.core.magic.magics_class
- IPython.core.magic_arguments.argument
- IPython.core.magic_arguments.magic_arguments
- IPython.core.magic_arguments.parse_argstring
- main.find_dotenv
- main.load_dotenv

**Functions:**

### `def load_ipython_extension(ipython)`

**Description:**
Register the %dotenv magic.

**Line:** 37

---


## Module: venv2.libthon3.12.site-packages.dotenv.main
**File:** `venv2/lib/python3.12/site-packages/dotenv/main.py`

**Imports:**
- collections.OrderedDict
- contextlib.contextmanager
- io
- logging
- os
- parser.Binding
- parser.parse_stream
- shutil
- sys
- tempfile
- typing.Dict
- typing.IO
- typing.Iterable
- typing.Iterator
- typing.Mapping
- typing.Optional
- typing.Tuple
- typing.Union
- variables.parse_variables

**Functions:**

### `def with_warn_for_invalid_lines(mappings: Iterator[Binding]) -> Iterator[Binding]`

**Line:** 24

---

### `def get_key(dotenv_path: StrPath, key_to_get: str, encoding: Optional[str] = 'utf-8') -> Optional[str]`

**Description:**
Get the value of a given key from the given .env.

Returns `None` if the key isn't found or doesn't have a value.

**Line:** 116

---

### `def rewrite(path: StrPath, encoding: Optional[str]) -> Iterator[Tuple[(IO[str], IO[str])]]`

**Decorators:**
- `@contextmanager`

**Line:** 130

---

### `def set_key(dotenv_path: StrPath, key_to_set: str, value_to_set: str, quote_mode: str = 'always', export: bool = False, encoding: Optional[str] = 'utf-8') -> Tuple[(Optional[bool], str, str)]`

**Description:**
Adds or Updates a key/value to the given .env

If the .env path given doesn't exist, fails instead of risking creating
an orphan .env somewhere in the filesystem

**Line:** 147

---

### `def unset_key(dotenv_path: StrPath, key_to_unset: str, quote_mode: str = 'always', encoding: Optional[str] = 'utf-8') -> Tuple[(Optional[bool], str)]`

**Description:**
Removes a given key from the given `.env` file.

If the .env path given doesn't exist, fails.
If the given key doesn't exist in the .env, fails.

**Line:** 196

---

### `def resolve_variables(values: Iterable[Tuple[(str, Optional[str])]], override: bool) -> Mapping[(str, Optional[str])]`

**Line:** 227

---

### `def _walk_to_root(path: str) -> Iterator[str]`

**Description:**
Yield directories starting from the given directory up to the root

**Line:** 252

---

### `def find_dotenv(filename: str = '.env', raise_error_if_not_found: bool = False, usecwd: bool = False) -> str`

**Description:**
Search in increasingly higher folders for the given file

Returns path to the file if found, or an empty string otherwise

**Line:** 270

---

### `def load_dotenv(dotenv_path: Optional[StrPath] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> bool`

**Description:**
Parse a .env file and then load all the variables found as environment variables.

Parameters:
dotenv_path: Absolute or relative path to .env file.
stream: Text stream (such as `io.StringIO`) with .env content, used if
`dotenv_path` is `None`.
verbose: Whether to output a warning the .env file is missing.
override: Whether to override the system environment variables with the variables
from the `.env` file.
encoding: Encoding to be used to read the file.
Returns:
Bool: True if at least one environment variable is set else False

If both `dotenv_path` and `stream` are `None`, `find_dotenv()` is used to find the
.env file.

**Line:** 311

---

### `def dotenv_values(dotenv_path: Optional[StrPath] = None, stream: Optional[IO[str]] = None, verbose: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> Dict[(str, Optional[str])]`

**Description:**
Parse a .env file and return its content as a dict.

The returned dict will have `None` values for keys without values in the .env file.
For example, `foo=bar` results in `{"foo": "bar"}` whereas `foo` alone results in
`{"foo": None}`

Parameters:
dotenv_path: Absolute or relative path to the .env file.
stream: `StringIO` object with .env content, used if `dotenv_path` is `None`.
verbose: Whether to output a warning if the .env file is missing.
encoding: Encoding to be used to read the file.

If both `dotenv_path` and `stream` are `None`, `find_dotenv()` is used to find the
.env file.

**Line:** 349

---


## Module: venv2.libthon3.12.site-packages.dotenv.parser
**File:** `venv2/lib/python3.12/site-packages/dotenv/parser.py`

**Imports:**
- codecs
- re
- typing.IO
- typing.Iterator
- typing.Match
- typing.NamedTuple
- typing.Optional
- typing.Pattern
- typing.Sequence
- typing.Tuple

**Functions:**

### `def make_regex(string: str, extra_flags: int = 0) -> Pattern[str]`

**Line:** 7

---

### `def decode_escapes(regex: Pattern[str], string: str) -> str`

**Line:** 98

---

### `def parse_key(reader: Reader) -> Optional[str]`

**Line:** 105

---

### `def parse_unquoted_value(reader: Reader) -> str`

**Line:** 116

---

### `def parse_value(reader: Reader) -> str`

**Line:** 121

---

### `def parse_binding(reader: Reader) -> Binding`

**Line:** 135

---

### `def parse_stream(stream: IO[str]) -> Iterator[Binding]`

**Line:** 172

---


## Module: venv2.libthon3.12.site-packages.dotenv.variables
**File:** `venv2/lib/python3.12/site-packages/dotenv/variables.py`

**Imports:**
- abc.ABCMeta
- abc.abstractmethod
- re
- typing.Iterator
- typing.Mapping
- typing.Optional
- typing.Pattern

**Functions:**

### `def parse_variables(value: str) -> Iterator[Atom]`

**Line:** 70

---


## Module: venv2.libthon3.12.site-packages.flask.__init__
**File:** `venv2/lib/python3.12/site-packages/flask/__init__.py`

**Imports:**
- app.Flask
- app.Request
- app.Response
- blueprints.Blueprint
- config.Config
- ctx.after_this_request
- ctx.copy_current_request_context
- ctx.has_app_context
- ctx.has_request_context
- globals.__app_ctx_stack
- globals.__request_ctx_stack
- globals.current_app
- globals.g
- globals.request
- globals.session
- helpers.abort
- helpers.flash
- helpers.get_flashed_messages
- helpers.get_template_attribute
- helpers.make_response
- helpers.redirect
- helpers.send_file
- helpers.send_from_directory
- helpers.stream_with_context
- helpers.url_for
- json.jsonify
- markupsafe.Markup
- markupsafe.escape
- signals.appcontext_popped
- signals.appcontext_pushed
- signals.appcontext_tearing_down
- signals.before_render_template
- signals.got_request_exception
- signals.message_flashed
- signals.request_finished
- signals.request_started
- signals.request_tearing_down
- signals.template_rendered
- templating.render_template
- templating.render_template_string
- templating.stream_template
- templating.stream_template_string
- warnings

**Functions:**

### `def __getattr__(name)`

**Line:** 44

---


## Module: venv2.libthon3.12.site-packages.flask.app
**File:** `venv2/lib/python3.12/site-packages/flask/app.py`

**Imports:**
- __future__.annotations
- asgiref.sync.async_to_sync
- blueprints.Blueprint
- click
- collections.abc.Iterator
- config.Config
- config.ConfigAttribute
- ctx.AppContext
- ctx.RequestContext
- ctx._AppCtxGlobals
- datetime.timedelta
- debughelpers.FormDataRoutingRedirect
- globals._cv_app
- globals._cv_request
- globals.g
- globals.request
- globals.request_ctx
- globals.session
- helpers._split_blueprint_path
- helpers.get_debug_flag
- helpers.get_flashed_messages
- helpers.get_load_dotenv
- inspect.iscoroutinefunction
- itertools.chain
- json.provider.DefaultJSONProvider
- json.provider.JSONProvider
- logging
- logging.create_logger
- os
- scaffold.Scaffold
- scaffold._endpoint_from_view_func
- scaffold._sentinel
- scaffold.find_package
- scaffold.setupmethod
- sessions.SecureCookieSessionInterface
- sessions.SessionInterface
- signals.appcontext_tearing_down
- signals.got_request_exception
- signals.request_finished
- signals.request_started
- signals.request_tearing_down
- sys
- templating.DispatchingJinjaLoader
- templating.Environment
- testing.EnvironBuilder
- testing.FlaskCliRunner
- testing.FlaskClient
- types.TracebackType
- typing
- urllib.parse.quote
- warnings
- weakref
- werkzeug.datastructures.Headers
- werkzeug.datastructures.ImmutableDict
- werkzeug.exceptions.Aborter
- werkzeug.exceptions.BadRequest
- werkzeug.exceptions.BadRequestKeyError
- werkzeug.exceptions.HTTPException
- werkzeug.exceptions.InternalServerError
- werkzeug.routing.BuildError
- werkzeug.routing.Map
- werkzeug.routing.MapAdapter
- werkzeug.routing.RequestRedirect
- werkzeug.routing.RoutingException
- werkzeug.routing.Rule
- werkzeug.serving.is_running_from_reloader
- werkzeug.serving.run_simple
- werkzeug.utils.cached_property
- werkzeug.utils.redirect
- werkzeug.wrappers.Response
- wrappers.Request
- wrappers.Response

**Functions:**

### `def _make_timedelta(value: timedelta | int | None) -> timedelta | None`

**Line:** 85

---


## Module: venv2.libthon3.12.site-packages.flask.cli
**File:** `venv2/lib/python3.12/site-packages/flask/cli.py`

**Imports:**
- __future__.annotations
- app.Flask
- ast
- click
- click.core.ParameterSource
- code
- cryptography
- dotenv
- functools.update_wrapper
- globals.current_app
- helpers.get_debug_flag
- helpers.get_load_dotenv
- importlib
- importlib.metadata
- importlib_metadata
- inspect
- operator.itemgetter
- os
- platform
- re
- readline
- rlcompleter.Completer
- ssl
- sys
- traceback
- typing
- werkzeug.run_simple
- werkzeug.serving.is_running_from_reloader
- werkzeug.utils.import_string

**Functions:**

### `def find_best_app(module)`

**Description:**
Given a module instance this tries to find the best possible
application in the module or raises an exception.

**Line:** 33

---

### `def _called_with_wrong_args(f)`

**Description:**
Check whether calling a function raised a ``TypeError`` because
the call failed or because something in the factory raised the
error.

:param f: The function that was called.
:return: ``True`` if the call failed.

**Line:** 86

---

### `def find_app_by_string(module, app_name)`

**Description:**
Check if the given string is a variable name or a function. Call
a function to get the app instance, or return the variable directly.

**Line:** 112

---

### `def prepare_import(path)`

**Description:**
Given a filename this will try to calculate the python path, add it
to the search path and return the actual module name that is expected.

**Line:** 188

---

### `def locate_app(module_name, app_name, raise_if_not_found = True)`

**Line:** 217

---

### `def get_version(ctx, param, value)`

**Line:** 241

---

### `def with_appcontext(f)`

**Description:**
Wraps a callback so that it's guaranteed to be executed with the
script's application context.

Custom commands (and their options) registered under ``app.cli`` or
``blueprint.cli`` will always have an app context available, this
decorator is not required in that case.

.. versionchanged:: 2.2
The app context is active for subcommands as well as the
decorated callback. The app context is always available to
``app.cli`` command and parameter callbacks.

**Line:** 338

---

### `def _set_app(ctx: click.Context, param: click.Option, value: str | None) -> str | None`

**Line:** 394

---

### `def _set_debug(ctx: click.Context, param: click.Option, value: bool) -> bool | None`

**Line:** 422

---

### `def _env_file_callback(ctx: click.Context, param: click.Option, value: str | None) -> str | None`

**Line:** 447

---

### `def _path_is_ancestor(path, other)`

**Description:**
Take ``other`` and remove the length of ``path`` from it. Then join it
to ``path``. If it is the original value, ``path`` is an ancestor of
``other``.

**Line:** 648

---

### `def load_dotenv(path: str | os.PathLike | None = None) -> bool`

**Description:**
Load "dotenv" files in order of precedence to set environment variables.

If an env var is already set it is not overwritten, so earlier files in the
list are preferred over later files.

This is a no-op if `python-dotenv`_ is not installed.

.. _python-dotenv: https://github.com/theskumar/python-dotenv#readme

:param path: Load the file at this location instead of searching.
:return: ``True`` if a file was loaded.

.. versionchanged:: 2.0
The current directory is not changed to the location of the
loaded file.

.. versionchanged:: 2.0
When loading the env files, set the default encoding to UTF-8.

.. versionchanged:: 1.1.0
Returns ``False`` when python-dotenv is not installed, or when
the given path isn't a file.

.. versionadded:: 1.0

**Line:** 655

---

### `def show_server_banner(debug, app_import_path)`

**Description:**
Show extra startup messages the first time the server is run,
ignoring the reloader.

**Line:** 716

---

### `def _validate_key(ctx, param, value)`

**Description:**
The ``--key`` option must be specified when ``--cert`` is a file.
Modifies the ``cert`` param to be a ``(cert, key)`` pair if needed.

**Line:** 776

---

### `def run_command(info, host, port, reload, debugger, with_threads, cert, extra_files, exclude_patterns)`

**Decorators:**
- `@click.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@pass_script_info`

**Description:**
Run a local development server.

This server is for development purposes only. It does not provide
the stability, security, or performance of production WSGI servers.

The reloader and debugger are enabled by default with the '--debug'
option.

**Line:** 878

---

### `def shell_command() -> None`

**Decorators:**
- `@click.command(...)`
- `@with_appcontext`

**Description:**
Run an interactive Python shell in the context of a given
Flask application.  The application will populate the default
namespace of this shell according to its configuration.

This is useful for executing small snippets of management code
without having to manually configure the application.

**Line:** 942

---

### `def routes_command(sort: str, all_methods: bool) -> None`

**Decorators:**
- `@click.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@with_appcontext`

**Description:**
Show all registered routes with endpoints and methods.

**Line:** 1002

---

### `def main() -> None`

**Line:** 1063

---


## Module: venv2.libthon3.12.site-packages.flask.ctx
**File:** `venv2/lib/python3.12/site-packages/flask/ctx.py`

**Imports:**
- __future__.annotations
- app.Flask
- contextvars
- functools.update_wrapper
- globals._cv_app
- globals._cv_request
- sessions.SessionMixin
- signals.appcontext_popped
- signals.appcontext_pushed
- sys
- types.TracebackType
- typing
- werkzeug.exceptions.HTTPException
- wrappers.Request

**Functions:**

### `def after_this_request(f: ft.AfterRequestCallable) -> ft.AfterRequestCallable`

**Description:**
Executes a function after this request.  This is useful to modify
response objects.  The function is passed the response object and has
to return the same or a new one.

Example::

@app.route('/')
def index():
@after_this_request
def add_header(response):
response.headers['X-Foo'] = 'Parachute'
return response
return 'Hello World!'

This is more useful if a function other than the view function wants to
modify a response.  For instance think of a decorator that wants to add
some headers without converting the return value into a response object.

.. versionadded:: 0.9

**Line:** 115

---

### `def copy_current_request_context(f: t.Callable) -> t.Callable`

**Description:**
A helper function that decorates a function to retain the current
request context.  This is useful when working with greenlets.  The moment
the function is decorated a copy of the request context is created and
then pushed when the function is called.  The current session is also
included in the copied request context.

Example::

import gevent
from flask import copy_current_request_context

@app.route('/')
def index():
@copy_current_request_context
def do_some_work():
# do some work here, it can access flask.request or
# flask.session like you would otherwise in the view function.
...
gevent.spawn(do_some_work)
return 'Regular response'

.. versionadded:: 0.10

**Line:** 148

---

### `def has_request_context() -> bool`

**Description:**
If you have code that wants to test if a request context is there or
not this function can be used.  For instance, you may want to take advantage
of request information if the request object is available, but fail
silently if it is unavailable.

::

class User(db.Model):

def __init__(self, username, remote_addr=None):
self.username = username
if remote_addr is None and has_request_context():
remote_addr = request.remote_addr
self.remote_addr = remote_addr

Alternatively you can also just test any of the context bound objects
(such as :class:`request` or :class:`g`) for truthness::

class User(db.Model):

def __init__(self, username, remote_addr=None):
self.username = username
if remote_addr is None and request:
remote_addr = request.remote_addr
self.remote_addr = remote_addr

.. versionadded:: 0.7

**Line:** 189

---

### `def has_app_context() -> bool`

**Description:**
Works like :func:`has_request_context` but for the application
context.  You can also just do a boolean check on the
:data:`current_app` object instead.

.. versionadded:: 0.9

**Line:** 221

---


## Module: venv2.libthon3.12.site-packages.flask.debughelpers
**File:** `venv2/lib/python3.12/site-packages/flask/debughelpers.py`

**Imports:**
- __future__.annotations
- app.Flask
- blueprints.Blueprint
- globals.request_ctx
- typing

**Functions:**

### `def attach_enctype_error_multidict(request)`

**Description:**
Patch ``request.files.__getitem__`` to raise a descriptive error
about ``enctype=multipart/form-data``.

:param request: The request to patch.
:meta private:

**Line:** 73

---

### `def _dump_loader_info(loader) -> t.Generator`

**Line:** 99

---

### `def explain_template_loading_attempts(app: Flask, template, attempts) -> None`

**Description:**
This should help developers understand what failed

**Line:** 116

---


## Module: venv2.libthon3.12.site-packages.flask.globals
**File:** `venv2/lib/python3.12/site-packages/flask/globals.py`

**Imports:**
- __future__.annotations
- app.Flask
- contextvars.ContextVar
- ctx.AppContext
- ctx.RequestContext
- ctx._AppCtxGlobals
- sessions.SessionMixin
- typing
- warnings
- werkzeug.local.LocalProxy
- wrappers.Request

**Functions:**

### `def __getattr__(name: str) -> t.Any`

**Line:** 75

---


## Module: venv2.libthon3.12.site-packages.flask.helpers
**File:** `venv2/lib/python3.12/site-packages/flask/helpers.py`

**Imports:**
- __future__.annotations
- datetime.datetime
- functools.lru_cache
- functools.update_wrapper
- globals._cv_request
- globals.current_app
- globals.request
- globals.request_ctx
- globals.session
- importlib.util
- os
- signals.message_flashed
- socket
- sys
- threading.RLock
- typing
- warnings
- werkzeug.exceptions.abort
- werkzeug.utils
- werkzeug.utils.redirect
- werkzeug.wrappers.Response
- wrappers.Response

**Functions:**

### `def get_debug_flag() -> bool`

**Description:**
Get whether debug mode should be enabled for the app, indicated by the
:envvar:`FLASK_DEBUG` environment variable. The default is ``False``.

**Line:** 30

---

### `def get_load_dotenv(default: bool = True) -> bool`

**Description:**
Get whether the user has disabled loading default dotenv files by
setting :envvar:`FLASK_SKIP_DOTENV`. The default is ``True``, load
the files.

:param default: What to return if the env var isn't set.

**Line:** 38

---

### `def stream_with_context(generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]]) -> t.Iterator[t.AnyStr]`

**Description:**
Request contexts disappear when the response is started on the server.
This is done for efficiency reasons and to make it less likely to encounter
memory leaks with badly written WSGI middlewares.  The downside is that if
you are using streamed responses, the generator cannot access request bound
information any more.

This function however can help you keep the context around for longer::

from flask import stream_with_context, request, Response

@app.route('/stream')
def streamed_response():
@stream_with_context
def generate():
yield 'Hello '
yield request.args['name']
yield '!'
return Response(generate())

Alternatively it can also be used around a specific generator::

from flask import stream_with_context, request, Response

@app.route('/stream')
def streamed_response():
def generate():
yield 'Hello '
yield request.args['name']
yield '!'
return Response(stream_with_context(generate()))

.. versionadded:: 0.9

**Line:** 53

---

### `def make_response(*args: t.Any) -> Response`

**Description:**
Sometimes it is necessary to set additional headers in a view.  Because
views do not have to return response objects but can return a value that
is converted into a response object by Flask itself, it becomes tricky to
add headers to it.  This function can be called instead of using a return
and you will get a response object which you can use to attach headers.

If view looked like this and you want to add a new header::

def index():
return render_template('index.html', foo=42)

You can now do something like this::

def index():
response = make_response(render_template('index.html', foo=42))
response.headers['X-Parachutes'] = 'parachutes are cool'
return response

This function accepts the very same arguments you can return from a
view function.  This for example creates a response with a 404 error
code::

response = make_response(render_template('not_found.html'), 404)

The other use case of this function is to force the return value of a
view function into a response which is helpful with view
decorators::

response = make_response(view_function())
response.headers['X-Parachutes'] = 'parachutes are cool'

Internally this function does the following things:

-   if no arguments are passed, it creates a new response argument
-   if one argument is passed, :meth:`flask.Flask.make_response`
is invoked with it.
-   if more than one argument is passed, the arguments are passed
to the :meth:`flask.Flask.make_response` function as tuple.

.. versionadded:: 0.6

**Line:** 132

---

### `def url_for(endpoint: str, _anchor: str | None = None, _method: str | None = None, _scheme: str | None = None, _external: bool | None = None, **values: t.Any) -> str`

**Description:**
Generate a URL to the given endpoint with the given values.

This requires an active request or application context, and calls
:meth:`current_app.url_for() <flask.Flask.url_for>`. See that method
for full documentation.

:param endpoint: The endpoint name associated with the URL to
generate. If this starts with a ``.``, the current blueprint
name (if any) will be used.
:param _anchor: If given, append this as ``#anchor`` to the URL.
:param _method: If given, generate the URL associated with this
method for the endpoint.
:param _scheme: If given, the URL will have this scheme if it is
external.
:param _external: If given, prefer the URL to be internal (False) or
require it to be external (True). External URLs include the
scheme and domain. When not in an active request, URLs are
external by default.
:param values: Values to use for the variable parts of the URL rule.
Unknown keys are appended as query string arguments, like
``?a=b&c=d``.

.. versionchanged:: 2.2
Calls ``current_app.url_for``, allowing an app to override the
behavior.

.. versionchanged:: 0.10
The ``_scheme`` parameter was added.

.. versionchanged:: 0.9
The ``_anchor`` and ``_method`` parameters were added.

.. versionchanged:: 0.9
Calls ``app.handle_url_build_error`` on build errors.

**Line:** 181

---

### `def redirect(location: str, code: int = 302, Response: type[BaseResponse] | None = None) -> BaseResponse`

**Description:**
Create a redirect response object.

If :data:`~flask.current_app` is available, it will use its
:meth:`~flask.Flask.redirect` method, otherwise it will use
:func:`werkzeug.utils.redirect`.

:param location: The URL to redirect to.
:param code: The status code for the redirect.
:param Response: The response class to use. Not used when
``current_app`` is active, which uses ``app.response_class``.

.. versionadded:: 2.2
Calls ``current_app.redirect`` if available instead of always
using Werkzeug's default ``redirect``.

**Line:** 235

---

### `def abort(code: int | BaseResponse, *args: t.Any, **kwargs: t.Any) -> t.NoReturn`

**Description:**
Raise an :exc:`~werkzeug.exceptions.HTTPException` for the given
status code.

If :data:`~flask.current_app` is available, it will call its
:attr:`~flask.Flask.aborter` object, otherwise it will use
:func:`werkzeug.exceptions.abort`.

:param code: The status code for the exception, which must be
registered in ``app.aborter``.
:param args: Passed to the exception.
:param kwargs: Passed to the exception.

.. versionadded:: 2.2
Calls ``current_app.aborter`` if available instead of always
using Werkzeug's default ``abort``.

**Line:** 259

---

### `def get_template_attribute(template_name: str, attribute: str) -> t.Any`

**Description:**
Loads a macro (or variable) a template exports.  This can be used to
invoke a macro from within Python code.  If you for example have a
template named :file:`_cider.html` with the following contents:

.. sourcecode:: html+jinja

{% macro hello(name) %}Hello {{ name }}!{% endmacro %}

You can access this from Python code like this::

hello = get_template_attribute('_cider.html', 'hello')
return hello('World')

.. versionadded:: 0.2

:param template_name: the name of the template
:param attribute: the name of the variable of macro to access

**Line:** 282

---

### `def flash(message: str, category: str = 'message') -> None`

**Description:**
Flashes a message to the next request.  In order to remove the
flashed message from the session and to display it to the user,
the template has to call :func:`get_flashed_messages`.

.. versionchanged:: 0.3
`category` parameter added.

:param message: the message to be flashed.
:param category: the category for the message.  The following values
are recommended: ``'message'`` for any kind of message,
``'error'`` for errors, ``'info'`` for information
messages and ``'warning'`` for warnings.  However any
kind of string can be used as category.

**Line:** 304

---

### `def get_flashed_messages(with_categories: bool = False, category_filter: t.Iterable[str] = ()) -> list[str] | list[tuple[str, str]]`

**Description:**
Pulls all flashed messages from the session and returns them.
Further calls in the same request to the function will return
the same messages.  By default just the messages are returned,
but when `with_categories` is set to ``True``, the return value will
be a list of tuples in the form ``(category, message)`` instead.

Filter the flashed messages to one or more categories by providing those
categories in `category_filter`.  This allows rendering categories in
separate html blocks.  The `with_categories` and `category_filter`
arguments are distinct:

* `with_categories` controls whether categories are returned with message
text (``True`` gives a tuple, where ``False`` gives just the message text).
* `category_filter` filters the messages down to only those matching the
provided categories.

See :doc:`/patterns/flashing` for examples.

.. versionchanged:: 0.3
`with_categories` parameter added.

.. versionchanged:: 0.9
`category_filter` parameter added.

:param with_categories: set to ``True`` to also receive categories.
:param category_filter: filter of categories to limit return values.  Only
categories in the list will be returned.

**Line:** 338

---

### `def _prepare_send_file_kwargs(**kwargs: t.Any) -> dict[(str, t.Any)]`

**Line:** 380

---

### `def send_file(path_or_file: os.PathLike | str | t.BinaryIO, mimetype: str | None = None, as_attachment: bool = False, download_name: str | None = None, conditional: bool = True, etag: bool | str = True, last_modified: datetime | int | float | None = None, max_age: None | (int | t.Callable[[str | None], int | None]) = None) -> Response`

**Description:**
Send the contents of a file to the client.

The first argument can be a file path or a file-like object. Paths
are preferred in most cases because Werkzeug can manage the file and
get extra information from the path. Passing a file-like object
requires that the file is opened in binary mode, and is mostly
useful when building a file in memory with :class:`io.BytesIO`.

Never pass file paths provided by a user. The path is assumed to be
trusted, so a user could craft a path to access a file you didn't
intend. Use :func:`send_from_directory` to safely serve
user-requested paths from within a directory.

If the WSGI server sets a ``file_wrapper`` in ``environ``, it is
used, otherwise Werkzeug's built-in wrapper is used. Alternatively,
if the HTTP server supports ``X-Sendfile``, configuring Flask with
``USE_X_SENDFILE = True`` will tell the server to send the given
path, which is much more efficient than reading it in Python.

:param path_or_file: The path to the file to send, relative to the
current working directory if a relative path is given.
Alternatively, a file-like object opened in binary mode. Make
sure the file pointer is seeked to the start of the data.
:param mimetype: The MIME type to send for the file. If not
provided, it will try to detect it from the file name.
:param as_attachment: Indicate to a browser that it should offer to
save the file instead of displaying it.
:param download_name: The default name browsers will use when saving
the file. Defaults to the passed file name.
:param conditional: Enable conditional and range responses based on
request headers. Requires passing a file path and ``environ``.
:param etag: Calculate an ETag for the file, which requires passing
a file path. Can also be a string to use instead.
:param last_modified: The last modified time to send for the file,
in seconds. If not provided, it will try to detect it from the
file path.
:param max_age: How long the client should cache the file, in
seconds. If set, ``Cache-Control`` will be ``public``, otherwise
it will be ``no-cache`` to prefer conditional caching.

.. versionchanged:: 2.0
``download_name`` replaces the ``attachment_filename``
parameter. If ``as_attachment=False``, it is passed with
``Content-Disposition: inline`` instead.

.. versionchanged:: 2.0
``max_age`` replaces the ``cache_timeout`` parameter.
``conditional`` is enabled and ``max_age`` is not set by
default.

.. versionchanged:: 2.0
``etag`` replaces the ``add_etags`` parameter. It can be a
string to use instead of generating one.

.. versionchanged:: 2.0
Passing a file-like object that inherits from
:class:`~io.TextIOBase` will raise a :exc:`ValueError` rather
than sending an empty file.

.. versionadded:: 2.0
Moved the implementation to Werkzeug. This is now a wrapper to
pass some Flask-specific arguments.

.. versionchanged:: 1.1
``filename`` may be a :class:`~os.PathLike` object.

.. versionchanged:: 1.1
Passing a :class:`~io.BytesIO` object supports range requests.

.. versionchanged:: 1.0.3
Filenames are encoded with ASCII instead of Latin-1 for broader
compatibility with WSGI servers.

.. versionchanged:: 1.0
UTF-8 filenames as specified in :rfc:`2231` are supported.

.. versionchanged:: 0.12
The filename is no longer automatically inferred from file
objects. If you want to use automatic MIME and etag support,
pass a filename via ``filename_or_fp`` or
``attachment_filename``.

.. versionchanged:: 0.12
``attachment_filename`` is preferred over ``filename`` for MIME
detection.

.. versionchanged:: 0.9
``cache_timeout`` defaults to
:meth:`Flask.get_send_file_max_age`.

.. versionchanged:: 0.7
MIME guessing and etag support for file-like objects was
deprecated because it was unreliable. Pass a filename if you are
able to, otherwise attach an etag yourself.

.. versionchanged:: 0.5
The ``add_etags``, ``cache_timeout`` and ``conditional``
parameters were added. The default behavior is to add etags.

.. versionadded:: 0.2

**Line:** 393

---

### `def send_from_directory(directory: os.PathLike | str, path: os.PathLike | str, **kwargs: t.Any) -> Response`

**Description:**
Send a file from within a directory using :func:`send_file`.

.. code-block:: python

@app.route("/uploads/<path:name>")
def download_file(name):
return send_from_directory(
app.config['UPLOAD_FOLDER'], name, as_attachment=True
)

This is a secure way to serve files from a folder, such as static
files or uploads. Uses :func:`~werkzeug.security.safe_join` to
ensure the path coming from the client is not maliciously crafted to
point outside the specified directory.

If the final path does not point to an existing regular file,
raises a 404 :exc:`~werkzeug.exceptions.NotFound` error.

:param directory: The directory that ``path`` must be located under,
relative to the current application's root path.
:param path: The path to the file to send, relative to
``directory``.
:param kwargs: Arguments to pass to :func:`send_file`.

.. versionchanged:: 2.0
``path`` replaces the ``filename`` parameter.

.. versionadded:: 2.0
Moved the implementation to Werkzeug. This is now a wrapper to
pass some Flask-specific arguments.

.. versionadded:: 0.5

**Line:** 519

---

### `def get_root_path(import_name: str) -> str`

**Description:**
Find the root path of a package, or the path that contains a
module. If it cannot be found, returns the current working
directory.

Not to be confused with the value returned by :func:`find_package`.

:meta private:

**Line:** 562

---

### `def is_ip(value: str) -> bool`

**Description:**
Determine if the given string is an IP address.

:param value: value to check
:type value: str

:return: True if string is an IP address
:rtype: bool

.. deprecated:: 2.3
Will be removed in Flask 2.4.

**Line:** 665

---

### `def _split_blueprint_path(name: str) -> list[str]`

**Decorators:**
- `@lru_cache(...)`

**Line:** 695

---


## Module: venv2.libthon3.12.site-packages.flask.json.__init__
**File:** `venv2/lib/python3.12/site-packages/flask/json/__init__.py`

**Imports:**
- __future__.annotations
- globals.current_app
- json
- provider._default
- typing
- wrappers.Response

**Functions:**

### `def dumps(obj: t.Any, **kwargs: t.Any) -> str`

**Description:**
Serialize data as JSON.

If :data:`~flask.current_app` is available, it will use its
:meth:`app.json.dumps() <flask.json.provider.JSONProvider.dumps>`
method, otherwise it will use :func:`json.dumps`.

:param obj: The data to serialize.
:param kwargs: Arguments passed to the ``dumps`` implementation.

.. versionchanged:: 2.3
The ``app`` parameter was removed.

.. versionchanged:: 2.2
Calls ``current_app.json.dumps``, allowing an app to override
the behavior.

.. versionchanged:: 2.0.2
:class:`decimal.Decimal` is supported by converting to a string.

.. versionchanged:: 2.0
``encoding`` will be removed in Flask 2.1.

.. versionchanged:: 1.0.3
``app`` can be passed directly, rather than requiring an app
context for configuration.

**Line:** 13

---

### `def dump(obj: t.Any, fp: t.IO[str], **kwargs: t.Any) -> None`

**Description:**
Serialize data as JSON and write to a file.

If :data:`~flask.current_app` is available, it will use its
:meth:`app.json.dump() <flask.json.provider.JSONProvider.dump>`
method, otherwise it will use :func:`json.dump`.

:param obj: The data to serialize.
:param fp: A file opened for writing text. Should use the UTF-8
encoding to be valid JSON.
:param kwargs: Arguments passed to the ``dump`` implementation.

.. versionchanged:: 2.3
The ``app`` parameter was removed.

.. versionchanged:: 2.2
Calls ``current_app.json.dump``, allowing an app to override
the behavior.

.. versionchanged:: 2.0
Writing to a binary file, and the ``encoding`` argument, will be
removed in Flask 2.1.

**Line:** 47

---

### `def loads(s: str | bytes, **kwargs: t.Any) -> t.Any`

**Description:**
Deserialize data as JSON.

If :data:`~flask.current_app` is available, it will use its
:meth:`app.json.loads() <flask.json.provider.JSONProvider.loads>`
method, otherwise it will use :func:`json.loads`.

:param s: Text or UTF-8 bytes.
:param kwargs: Arguments passed to the ``loads`` implementation.

.. versionchanged:: 2.3
The ``app`` parameter was removed.

.. versionchanged:: 2.2
Calls ``current_app.json.loads``, allowing an app to override
the behavior.

.. versionchanged:: 2.0
``encoding`` will be removed in Flask 2.1. The data must be a
string or UTF-8 bytes.

.. versionchanged:: 1.0.3
``app`` can be passed directly, rather than requiring an app
context for configuration.

**Line:** 77

---

### `def load(fp: t.IO[t.AnyStr], **kwargs: t.Any) -> t.Any`

**Description:**
Deserialize data as JSON read from a file.

If :data:`~flask.current_app` is available, it will use its
:meth:`app.json.load() <flask.json.provider.JSONProvider.load>`
method, otherwise it will use :func:`json.load`.

:param fp: A file opened for reading text or UTF-8 bytes.
:param kwargs: Arguments passed to the ``load`` implementation.

.. versionchanged:: 2.3
The ``app`` parameter was removed.

.. versionchanged:: 2.2
Calls ``current_app.json.load``, allowing an app to override
the behavior.

.. versionchanged:: 2.2
The ``app`` parameter will be removed in Flask 2.3.

.. versionchanged:: 2.0
``encoding`` will be removed in Flask 2.1. The file must be text
mode, or binary mode with UTF-8 bytes.

**Line:** 108

---

### `def jsonify(*args: t.Any, **kwargs: t.Any) -> Response`

**Description:**
Serialize the given arguments as JSON, and return a
:class:`~flask.Response` object with the ``application/json``
mimetype. A dict or list returned from a view will be converted to a
JSON response automatically without needing to call this.

This requires an active request or application context, and calls
:meth:`app.json.response() <flask.json.provider.JSONProvider.response>`.

In debug mode, the output is formatted with indentation to make it
easier to read. This may also be controlled by the provider.

Either positional or keyword arguments can be given, not both.
If no arguments are given, ``None`` is serialized.

:param args: A single value to serialize, or multiple values to
treat as a list to serialize.
:param kwargs: Treat as a dict to serialize.

.. versionchanged:: 2.2
Calls ``current_app.json.response``, allowing an app to override
the behavior.

.. versionchanged:: 2.0.2
:class:`decimal.Decimal` is supported by converting to a string.

.. versionchanged:: 0.11
Added support for serializing top-level arrays. This was a
security risk in ancient browsers. See :ref:`security-json`.

.. versionadded:: 0.2

**Line:** 138

---


## Module: venv2.libthon3.12.site-packages.flask.json.provider
**File:** `venv2/lib/python3.12/site-packages/flask/json/provider.py`

**Imports:**
- __future__.annotations
- app.Flask
- dataclasses
- datetime.date
- decimal
- json
- typing
- uuid
- weakref
- werkzeug.http.http_date
- wrappers.Response

**Functions:**

### `def _default(o: t.Any) -> t.Any`

**Line:** 107

---


## Module: venv2.libthon3.12.site-packages.flask.logging
**File:** `venv2/lib/python3.12/site-packages/flask/logging.py`

**Imports:**
- __future__.annotations
- app.Flask
- globals.request
- logging
- sys
- typing
- werkzeug.local.LocalProxy

**Functions:**

### `def wsgi_errors_stream() -> t.TextIO`

**Decorators:**
- `@LocalProxy`

**Description:**
Find the most appropriate error stream for the application. If a request
is active, log to ``wsgi.errors``, otherwise use ``sys.stderr``.

If you configure your own :class:`logging.StreamHandler`, you may want to
use this for the stream. If you are using file or dict configuration and
can't import this directly, you can refer to it as
``ext://flask.logging.wsgi_errors_stream``.

**Line:** 16

---

### `def has_level_handler(logger: logging.Logger) -> bool`

**Description:**
Check if there is a handler in the logging chain that will handle the
given logger's :meth:`effective level <~logging.Logger.getEffectiveLevel>`.

**Line:** 28

---

### `def create_logger(app: Flask) -> logging.Logger`

**Description:**
Get the Flask app's logger and configure it if needed.

The logger name will be the same as
:attr:`app.import_name <flask.Flask.name>`.

When :attr:`~flask.Flask.debug` is enabled, set the logger level to
:data:`logging.DEBUG` if it is not set.

If there is no handler for the logger's effective level, add a
:class:`~logging.StreamHandler` for
:func:`~flask.logging.wsgi_errors_stream` with a basic format.

**Line:** 55

---


## Module: venv2.libthon3.12.site-packages.flask.scaffold
**File:** `venv2/lib/python3.12/site-packages/flask/scaffold.py`

**Imports:**
- __future__.annotations
- cli.AppGroup
- collections.defaultdict
- datetime.timedelta
- functools.update_wrapper
- globals.current_app
- helpers.get_root_path
- helpers.send_from_directory
- importlib.util
- jinja2.FileSystemLoader
- os
- pathlib
- sys
- templating._default_template_ctx_processor
- typing
- werkzeug.exceptions.HTTPException
- werkzeug.exceptions.default_exceptions
- werkzeug.utils.cached_property
- wrappers.Response

**Functions:**

### `def setupmethod(f: F) -> F`

**Line:** 45

---

### `def _endpoint_from_view_func(view_func: t.Callable) -> str`

**Description:**
Internal helper that returns the default endpoint for a given
function.  This always is the function name.

**Line:** 774

---

### `def _path_is_relative_to(path: pathlib.PurePath, base: str) -> bool`

**Line:** 782

---

### `def _find_package_path(import_name)`

**Description:**
Find the path that contains the package or module.

**Line:** 791

---

### `def find_package(import_name: str)`

**Description:**
Find the prefix that a package is installed under, and the path
that it would be imported from.

The prefix is the directory containing the standard directory
hierarchy (lib, bin, etc.). If the package is not installed to the
system (:attr:`sys.prefix`) or a virtualenv (``site-packages``),
``None`` is returned.

The path is the entry in :attr:`sys.path` that contains the package
for import. If the package is not installed, it's assumed that the
package was imported from the current working directory.

**Line:** 835

---


## Module: venv2.libthon3.12.site-packages.flask.signals
**File:** `venv2/lib/python3.12/site-packages/flask/signals.py`

**Imports:**
- __future__.annotations
- blinker.Namespace
- typing
- warnings

**Functions:**

### `def __getattr__(name: str) -> t.Any`

**Line:** 23

---


## Module: venv2.libthon3.12.site-packages.flask.templating
**File:** `venv2/lib/python3.12/site-packages/flask/templating.py`

**Imports:**
- __future__.annotations
- app.Flask
- debughelpers.explain_template_loading_attempts
- globals._cv_app
- globals._cv_request
- globals.current_app
- globals.request
- helpers.stream_with_context
- jinja2.BaseLoader
- jinja2.Environment
- jinja2.Template
- jinja2.TemplateNotFound
- scaffold.Scaffold
- signals.before_render_template
- signals.template_rendered
- typing

**Functions:**

### `def _default_template_ctx_processor() -> dict[(str, t.Any)]`

**Description:**
Default template context processor.  Injects `request`,
`session` and `g`.

**Line:** 23

---

### `def _render(app: Flask, template: Template, context: dict[(str, t.Any)]) -> str`

**Line:** 127

---

### `def render_template(template_name_or_list: str | Template | list[str | Template], **context: t.Any) -> str`

**Description:**
Render a template by name with the given context.

:param template_name_or_list: The name of the template to render. If
a list is given, the first name to exist will be rendered.
:param context: The variables to make available in the template.

**Line:** 139

---

### `def render_template_string(source: str, **context: t.Any) -> str`

**Description:**
Render a template from the given source string with the given
context.

:param source: The source code of the template to render.
:param context: The variables to make available in the template.

**Line:** 154

---

### `def _stream(app: Flask, template: Template, context: dict[(str, t.Any)]) -> t.Iterator[str]`

**Line:** 166

---

### `def stream_template(template_name_or_list: str | Template | list[str | Template], **context: t.Any) -> t.Iterator[str]`

**Description:**
Render a template by name with the given context as a stream.
This returns an iterator of strings, which can be used as a
streaming response from a view.

:param template_name_or_list: The name of the template to render. If
a list is given, the first name to exist will be rendered.
:param context: The variables to make available in the template.

.. versionadded:: 2.2

**Line:** 189

---

### `def stream_template_string(source: str, **context: t.Any) -> t.Iterator[str]`

**Description:**
Render a template from the given source string with the given
context as a stream. This returns an iterator of strings, which can
be used as a streaming response from a view.

:param source: The source code of the template to render.
:param context: The variables to make available in the template.

.. versionadded:: 2.2

**Line:** 208

---


## Module: venv2.libthon3.12.site-packages.flask.testing
**File:** `venv2/lib/python3.12/site-packages/flask/testing.py`

**Imports:**
- __future__.annotations
- app.Flask
- cli.ScriptInfo
- click.testing.CliRunner
- contextlib.ExitStack
- contextlib.contextmanager
- copy.copy
- importlib.metadata
- sessions.SessionMixin
- types.TracebackType
- typing
- urllib.parse.urlsplit
- werkzeug.test
- werkzeug.test.Client
- werkzeug.test.TestResponse
- werkzeug.wrappers.Request

**Functions:**

### `def _get_werkzeug_version() -> str`

**Line:** 99

---


## Module: venv2.libthon3.12.site-packages.flask_cors.core
**File:** `venv2/lib/python3.12/site-packages/flask_cors/core.py`

**Imports:**
- collections.abc.Iterable
- datetime.timedelta
- flask.current_app
- flask.request
- logging
- re
- werkzeug.datastructures.Headers
- werkzeug.datastructures.MultiDict

**Functions:**

### `def parse_resources(resources)`

**Line:** 62

---

### `def get_regexp_pattern(regexp)`

**Description:**
Helper that returns regexp pattern from given value.

:param regexp: regular expression to stringify
:type regexp: _sre.SRE_Pattern or str
:returns: string representation of given regexp pattern
:rtype: str

**Line:** 94

---

### `def get_cors_origins(options, request_origin)`

**Line:** 109

---

### `def get_allow_headers(options, acl_request_headers)`

**Line:** 157

---

### `def get_cors_headers(options, request_headers, request_method)`

**Line:** 172

---

### `def set_cors_headers(resp, options)`

**Description:**
Performs the actual evaluation of Flask-CORS options and actually
modifies the response object.

This function is used both in the decorator and the after_request
callback

**Line:** 224

---

### `def probably_regex(maybe_regex)`

**Line:** 254

---

### `def re_fix(reg)`

**Description:**
Replace the invalid regex r'*' with the valid, wildcard regex r'/.*' to
enable the CORS app extension to have a more user friendly api.

**Line:** 263

---

### `def try_match_any(inst, patterns)`

**Line:** 271

---

### `def try_match(request_origin, maybe_regex)`

**Description:**
Safely attempts to match a pattern or string to a request origin.

**Line:** 275

---

### `def get_cors_options(appInstance, *dicts)`

**Description:**
Compute CORS options for an application by combining the DEFAULT_OPTIONS,
the app's configuration-specified options and any dictionaries passed. The
last specified option wins.

**Line:** 288

---

### `def get_app_kwarg_dict(appInstance = None)`

**Description:**
Returns the dictionary of CORS specific app configurations.

**Line:** 303

---

### `def flexible_str(obj)`

**Description:**
A more flexible str function which intelligently handles stringifying
strings, lists and other iterables. The results are lexographically sorted
to ensure generated responses are consistent when iterables such as Set
are used.

**Line:** 317

---

### `def serialize_option(options_dict, key, upper = False)`

**Line:** 332

---

### `def ensure_iterable(inst)`

**Description:**
Wraps scalars or string types as a list, or returns the iterable instance.

**Line:** 338

---

### `def sanitize_regex_param(param)`

**Line:** 349

---

### `def serialize_options(opts)`

**Description:**
A helper method to serialize and processes the options dictionary.

**Line:** 353

---


## Module: venv2.libthon3.12.site-packages.flask_cors.decorator
**File:** `venv2/lib/python3.12/site-packages/flask_cors/decorator.py`

**Imports:**
- core.FLASK_CORS_EVALUATED
- core.get_cors_options
- core.set_cors_headers
- flask.current_app
- flask.make_response
- flask.request
- functools.update_wrapper
- logging

**Functions:**

### `def cross_origin(*args, **kwargs)`

**Description:**
This function is the decorator which is used to wrap a Flask route with.
In the simplest case, simply use the default parameters to allow all
origins in what is the most permissive configuration. If this method
modifies state or performs authentication which may be brute-forced, you
should add some degree of protection, such as Cross Site Request Forgery
protection.

:param origins:
The origin, or list of origins to allow requests from.
The origin(s) may be regular expressions, case-sensitive strings,
or else an asterisk

Default : '*'
:type origins: list, string or regex

:param methods:
The method or list of methods which the allowed origins are allowed to
access for non-simple requests.

Default : [GET, HEAD, POST, OPTIONS, PUT, PATCH, DELETE]
:type methods: list or string

:param expose_headers:
The header or list which are safe to expose to the API of a CORS API
specification.

Default : None
:type expose_headers: list or string

:param allow_headers:
The header or list of header field names which can be used when this
resource is accessed by allowed origins. The header(s) may be regular
expressions, case-sensitive strings, or else an asterisk.

Default : '*', allow all headers
:type allow_headers: list, string or regex

:param supports_credentials:
Allows users to make authenticated requests. If true, injects the
`Access-Control-Allow-Credentials` header in responses. This allows
cookies and credentials to be submitted across domains.

:note: This option cannot be used in conjunction with a '*' origin

Default : False
:type supports_credentials: bool

:param max_age:
The maximum time for which this CORS request maybe cached. This value
is set as the `Access-Control-Max-Age` header.

Default : None
:type max_age: timedelta, integer, string or None

:param send_wildcard: If True, and the origins parameter is `*`, a wildcard
`Access-Control-Allow-Origin` header is sent, rather than the
request's `Origin` header.

Default : False
:type send_wildcard: bool

:param vary_header:
If True, the header Vary: Origin will be returned as per the W3
implementation guidelines.

Setting this header when the `Access-Control-Allow-Origin` is
dynamically generated (e.g. when there is more than one allowed
origin, and an Origin than '*' is returned) informs CDNs and other
caches that the CORS headers are dynamic, and cannot be cached.

If False, the Vary header will never be injected or altered.

Default : True
:type vary_header: bool

:param automatic_options:
Only applies to the `cross_origin` decorator. If True, Flask-CORS will
override Flask's default OPTIONS handling to return CORS headers for
OPTIONS requests.

Default : True
:type automatic_options: bool

**Line:** 20

---


## Module: venv2.libthon3.12.site-packages.flask_cors.extension
**File:** `venv2/lib/python3.12/site-packages/flask_cors/extension.py`

**Imports:**
- core.ACL_ORIGIN
- core.get_cors_options
- core.get_regexp_pattern
- core.parse_resources
- core.set_cors_headers
- core.try_match
- flask.request
- logging
- urllib.parse.unquote_plus

**Functions:**

### `def make_after_request_function(resources)`

**Line:** 185

---


## Module: venv2.libthon3.12.site-packages.flask_jwt_extended.default_callbacks
**File:** `venv2/lib/python3.12/site-packages/flask_jwt_extended/default_callbacks.py`

**Imports:**
- flask.jsonify
- flask.typing.ResponseReturnValue
- flask_jwt_extended.config.config
- http.HTTPStatus
- typing.Any

**Functions:**

### `def default_additional_claims_callback(userdata: Any) -> dict`

**Description:**
By default, we add no additional claims to the access tokens.

:param userdata: data passed in as the ```identity``` argument to the
```create_access_token``` and ```create_refresh_token```
functions

**Line:** 18

---

### `def default_blocklist_callback(jwt_headers: dict, jwt_data: dict) -> bool`

**Line:** 29

---

### `def default_jwt_headers_callback(default_headers) -> dict`

**Description:**
By default header typically consists of two parts: the type of the token,
which is JWT, and the signing algorithm being used, such as HMAC SHA256
or RSA. But we don't set the default header here we set it as empty which
further by default set while encoding the token
:return: default we set None here

**Line:** 33

---

### `def default_user_identity_callback(userdata: Any) -> Any`

**Description:**
By default, we use the passed in object directly as the jwt identity.
See this for additional info:

:param userdata: data passed in as the ```identity``` argument to the
```create_access_token``` and ```create_refresh_token```
functions

**Line:** 44

---

### `def default_expired_token_callback(_expired_jwt_header: dict, _expired_jwt_data: dict) -> ResponseReturnValue`

**Description:**
By default, if an expired token attempts to access a protected endpoint,
we return a generic error message with a 401 status

**Line:** 56

---

### `def default_invalid_token_callback(error_string: str) -> ResponseReturnValue`

**Description:**
By default, if an invalid token attempts to access a protected endpoint, we
return the error string for why it is not valid with a 422 status code

:param error_string: String indicating why the token is invalid

**Line:** 66

---

### `def default_unauthorized_callback(error_string: str) -> ResponseReturnValue`

**Description:**
By default, if a protected endpoint is accessed without a JWT, we return
the error string indicating why this is unauthorized, with a 401 status code

:param error_string: String indicating why this request is unauthorized

**Line:** 79

---

### `def default_needs_fresh_token_callback(jwt_header: dict, jwt_data: dict) -> ResponseReturnValue`

**Description:**
By default, if a non-fresh jwt is used to access a ```fresh_jwt_required```
endpoint, we return a general error message with a 401 status code

**Line:** 89

---

### `def default_revoked_token_callback(jwt_header: dict, jwt_data: dict) -> ResponseReturnValue`

**Description:**
By default, if a revoked token is used to access a protected endpoint, we
return a general error message with a 401 status code

**Line:** 102

---

### `def default_user_lookup_error_callback(_jwt_header: dict, jwt_data: dict) -> ResponseReturnValue`

**Description:**
By default, if a user_lookup callback is defined and the callback
function returns None, we return a general error message with a 401
status code

**Line:** 115

---

### `def default_token_verification_callback(_jwt_header: dict, _jwt_data: dict) -> bool`

**Description:**
By default, we do not do any verification of the user claims.

**Line:** 128

---

### `def default_token_verification_failed_callback(_jwt_header: dict, _jwt_data: dict) -> ResponseReturnValue`

**Description:**
By default, if the user claims verification failed, we return a generic
error message with a 400 status code

**Line:** 135

---

### `def default_decode_key_callback(jwt_header: dict, jwt_data: dict) -> str`

**Description:**
By default, the decode key specified via the JWT_SECRET_KEY or
JWT_PUBLIC_KEY settings will be used to decode all tokens

**Line:** 148

---

### `def default_encode_key_callback(identity: Any) -> str`

**Description:**
By default, the encode key specified via the JWT_SECRET_KEY or
JWT_PRIVATE_KEY settings will be used to encode all tokens

**Line:** 156

---


## Module: venv2.libthon3.12.site-packages.flask_jwt_extended.internal_utils
**File:** `venv2/lib/python3.12/site-packages/flask_jwt_extended/internal_utils.py`

**Imports:**
- flask.Flask
- flask.current_app
- flask.json.provider.DefaultJSONProvider
- flask_jwt_extended.JWTManager
- flask_jwt_extended.exceptions.RevokedTokenError
- flask_jwt_extended.exceptions.UserClaimsVerificationError
- flask_jwt_extended.exceptions.WrongTokenError
- json
- typing.Any
- typing.TYPE_CHECKING
- typing.Type

**Functions:**

### `def get_jwt_manager() -> 'JWTManager'`

**Line:** 27

---

### `def has_user_lookup() -> bool`

**Line:** 37

---

### `def user_lookup(*args, **kwargs) -> Any`

**Line:** 42

---

### `def verify_token_type(decoded_token: dict, refresh: bool) -> None`

**Line:** 49

---

### `def verify_token_not_blocklisted(jwt_header: dict, jwt_data: dict) -> None`

**Line:** 56

---

### `def custom_verification_for_token(jwt_header: dict, jwt_data: dict) -> None`

**Line:** 62

---

### `def get_json_encoder(app: Flask) -> Type[json.JSONEncoder]`

**Description:**
Get the JSON Encoder for the provided flask app

Starting with flask version 2.2 the flask application provides a
interface to register a custom JSON Encoder/Decoder under the json_provider_class.
As this interface is not compatible with the standard JSONEncoder, the `default`
method of the class is wrapped.

Lookup Order:
- app.json_encoder - For Flask < 2.2
- app.json_provider_class.default
- flask.json.provider.DefaultJSONProvider.default

**Line:** 81

---


## Module: venv2.libthon3.12.site-packages.flask_jwt_extended.tokens
**File:** `venv2/lib/python3.12/site-packages/flask_jwt_extended/tokens.py`

**Imports:**
- datetime.datetime
- datetime.timedelta
- datetime.timezone
- flask_jwt_extended.exceptions.CSRFError
- flask_jwt_extended.exceptions.JWTDecodeError
- flask_jwt_extended.typing.ExpiresDelta
- flask_jwt_extended.typing.Fresh
- hmac.compare_digest
- json.JSONEncoder
- jwt
- typing.Any
- typing.Iterable
- typing.List
- typing.Type
- typing.Union
- uuid

**Functions:**

### `def _encode_jwt(algorithm: str, audience: Union[(str, Iterable[str])], claim_overrides: dict, csrf: bool, expires_delta: ExpiresDelta, fresh: Fresh, header_overrides: dict, identity: Any, identity_claim_key: str, issuer: str, json_encoder: Type[JSONEncoder], secret: str, token_type: str, nbf: bool) -> str`

**Line:** 21

---

### `def _decode_jwt(algorithms: List, allow_expired: bool, audience: Union[(str, Iterable[str])], csrf_value: str, encoded_token: str, identity_claim_key: str, issuer: str, leeway: int, secret: str, verify_aud: bool) -> dict`

**Line:** 77

---


## Module: venv2.libthon3.12.site-packages.flask_jwt_extended.utils
**File:** `venv2/lib/python3.12/site-packages/flask_jwt_extended/utils.py`

**Imports:**
- flask.Response
- flask.g
- flask_jwt_extended.config.config
- flask_jwt_extended.internal_utils.get_jwt_manager
- flask_jwt_extended.typing.ExpiresDelta
- flask_jwt_extended.typing.Fresh
- jwt
- typing.Any
- typing.Optional
- werkzeug.local.LocalProxy

**Functions:**

### `def get_jwt() -> dict`

**Description:**
In a protected endpoint, this will return the python dictionary which has
the payload of the JWT that is accessing the endpoint. If no JWT is present
due to ``jwt_required(optional=True)``, an empty dictionary is returned.

:return:
The payload (claims) of the JWT in the current request

**Line:** 18

---

### `def get_jwt_header() -> dict`

**Description:**
In a protected endpoint, this will return the python dictionary which has
the header of the JWT that is accessing the endpoint. If no JWT is present
due to ``jwt_required(optional=True)``, an empty dictionary is returned.

:return:
The headers of the JWT in the current request

**Line:** 36

---

### `def get_jwt_identity() -> Any`

**Description:**
In a protected endpoint, this will return the identity of the JWT that is
accessing the endpoint. If no JWT is present due to
``jwt_required(optional=True)``, ``None`` is returned.

:return:
The identity of the JWT in the current request

**Line:** 54

---

### `def get_jwt_request_location() -> Optional[str]`

**Description:**
In a protected endpoint, this will return the "location" at which the JWT
that is accessing the endpoint was found--e.g., "cookies", "query-string",
"headers", or "json". If no JWT is present due to ``jwt_required(optional=True)``,
None is returned.

:return:
The location of the JWT in the current request; e.g., "cookies",
"query-string", "headers", or "json"

**Line:** 66

---

### `def get_current_user() -> Any`

**Description:**
In a protected endpoint, this will return the user object for the JWT that
is accessing the endpoint.

This is only usable if :meth:`~flask_jwt_extended.JWTManager.user_lookup_loader`
is configured. If the user loader callback is not being used, this will
raise an error.

If no JWT is present due to ``jwt_required(optional=True)``, ``None`` is returned.

:return:
The current user object for the JWT in the current request

**Line:** 80

---

### `def decode_token(encoded_token: str, csrf_value: Optional[str] = None, allow_expired: bool = False) -> dict`

**Description:**
Returns the decoded token (python dict) from an encoded JWT. This does all
the checks to ensure that the decoded token is valid before returning it.

This will not fire the user loader callbacks, save the token for access
in protected endpoints, checked if a token is revoked, etc. This is puerly
used to ensure that a JWT is valid.

:param encoded_token:
The encoded JWT to decode.

:param csrf_value:
Expected CSRF double submit value (optional).

:param allow_expired:
If ``True``, do not raise an error if the JWT is expired.  Defaults to ``False``

:return:
Dictionary containing the payload of the JWT decoded JWT.

**Line:** 104

---

### `def create_access_token(identity: Any, fresh: Fresh = False, expires_delta: Optional[ExpiresDelta] = None, additional_claims = None, additional_headers = None)`

**Description:**
Create a new access token.

:param identity:
The identity of this token. It can be any data that is json serializable.
You can use :meth:`~flask_jwt_extended.JWTManager.user_identity_loader`
to define a callback function to convert any object passed in into a json
serializable format.

:param fresh:
If this token should be marked as fresh, and can thus access endpoints
protected with ``@jwt_required(fresh=True)``. Defaults to ``False``.

This value can also be a ``datetime.timedelta``, which indicate
how long this token will be considered fresh.

:param expires_delta:
A ``datetime.timedelta`` for how long this token should last before it
expires. Set to False to disable expiration. If this is None, it will use
the ``JWT_ACCESS_TOKEN_EXPIRES`` config value (see :ref:`Configuration Options`)

:param additional_claims:
Optional. A hash of claims to include in the access token.  These claims are
merged into the default claims (exp, iat, etc) and claims returned from the
:meth:`~flask_jwt_extended.JWTManager.additional_claims_loader` callback.
On conflict, these claims take precedence.

:param headers:
Optional. A hash of headers to include in the access token. These headers
are merged into the default headers (alg, typ) and headers returned from
the :meth:`~flask_jwt_extended.JWTManager.additional_headers_loader`
callback. On conflict, these headers take precedence.

:return:
An encoded access token

**Line:** 131

---

### `def create_refresh_token(identity: Any, expires_delta: Optional[ExpiresDelta] = None, additional_claims = None, additional_headers = None)`

**Description:**
Create a new refresh token.

:param identity:
The identity of this token. It can be any data that is json serializable.
You can use :meth:`~flask_jwt_extended.JWTManager.user_identity_loader`
to define a callback function to convert any object passed in into a json
serializable format.

:param expires_delta:
A ``datetime.timedelta`` for how long this token should last before it expires.
Set to False to disable expiration. If this is None, it will use the
``JWT_REFRESH_TOKEN_EXPIRES`` config value (see :ref:`Configuration Options`)

:param additional_claims:
Optional. A hash of claims to include in the refresh token. These claims are
merged into the default claims (exp, iat, etc) and claims returned from the
:meth:`~flask_jwt_extended.JWTManager.additional_claims_loader` callback.
On conflict, these claims take precedence.

:param headers:
Optional. A hash of headers to include in the refresh token. These headers
are merged into the default headers (alg, typ) and headers returned from the
:meth:`~flask_jwt_extended.JWTManager.additional_headers_loader` callback.
On conflict, these headers take precedence.

:return:
An encoded refresh token

**Line:** 185

---

### `def get_unverified_jwt_headers(encoded_token: str) -> dict`

**Description:**
Returns the Headers of an encoded JWT without verifying the signature of the JWT.

:param encoded_token:
The encoded JWT to get the Header from.

:return:
JWT header parameters as python dict()

**Line:** 231

---

### `def get_jti(encoded_token: str) -> Optional[str]`

**Description:**
Returns the JTI (unique identifier) of an encoded JWT

:param encoded_token:
The encoded JWT to get the JTI from.

:return:
The JTI (unique identifier) of a JWT, if it is present.

**Line:** 244

---

### `def get_csrf_token(encoded_token: str) -> str`

**Description:**
Returns the CSRF double submit token from an encoded JWT.

:param encoded_token:
The encoded JWT

:return:
The CSRF double submit token (string)

**Line:** 257

---

### `def set_access_cookies(response: Response, encoded_access_token: str, max_age = None, domain = None) -> None`

**Description:**
Modifiy a Flask Response to set a cookie containing the access JWT.
Also sets the corresponding CSRF cookies if ``JWT_CSRF_IN_COOKIES`` is ``True``
(see :ref:`Configuration Options`)

:param response:
A Flask Response object.

:param encoded_access_token:
The encoded access token to set in the cookies.

:param max_age:
The max age of the cookie. If this is None, it will use the
``JWT_SESSION_COOKIE`` option (see :ref:`Configuration Options`). Otherwise,
it will use this as the cookies ``max-age`` and the JWT_SESSION_COOKIE option
will be ignored. Values should be the number of seconds (as an integer).

:param domain:
The domain of the cookie. If this is None, it will use the
``JWT_COOKIE_DOMAIN`` option (see :ref:`Configuration Options`). Otherwise,
it will use this as the cookies ``domain`` and the JWT_COOKIE_DOMAIN option
will be ignored.

**Line:** 271

---

### `def set_refresh_cookies(response: Response, encoded_refresh_token: str, max_age: Optional[int] = None, domain: Optional[str] = None) -> None`

**Description:**
Modifiy a Flask Response to set a cookie containing the refresh JWT.
Also sets the corresponding CSRF cookies if ``JWT_CSRF_IN_COOKIES`` is ``True``
(see :ref:`Configuration Options`)

:param response:
A Flask Response object.

:param encoded_refresh_token:
The encoded refresh token to set in the cookies.

:param max_age:
The max age of the cookie. If this is None, it will use the
``JWT_SESSION_COOKIE`` option (see :ref:`Configuration Options`). Otherwise,
it will use this as the cookies ``max-age`` and the JWT_SESSION_COOKIE option
will be ignored. Values should be the number of seconds (as an integer).

:param domain:
The domain of the cookie. If this is None, it will use the
``JWT_COOKIE_DOMAIN`` option (see :ref:`Configuration Options`). Otherwise,
it will use this as the cookies ``domain`` and the JWT_COOKIE_DOMAIN option
will be ignored.

**Line:** 321

---

### `def unset_jwt_cookies(response: Response, domain: Optional[str] = None) -> None`

**Description:**
Modifiy a Flask Response to delete the cookies containing access or refresh
JWTs.  Also deletes the corresponding CSRF cookies if applicable.

:param response:
A Flask Response object

**Line:** 374

---

### `def unset_access_cookies(response: Response, domain: Optional[str] = None) -> None`

**Description:**
Modifiy a Flask Response to delete the cookie containing an access JWT.
Also deletes the corresponding CSRF cookie if applicable.

:param response:
A Flask Response object

:param domain:
The domain of the cookie. If this is None, it will use the
``JWT_COOKIE_DOMAIN`` option (see :ref:`Configuration Options`). Otherwise,
it will use this as the cookies ``domain`` and the JWT_COOKIE_DOMAIN option
will be ignored.

**Line:** 386

---

### `def unset_refresh_cookies(response: Response, domain: Optional[str] = None) -> None`

**Description:**
Modifiy a Flask Response to delete the cookie containing a refresh JWT.
Also deletes the corresponding CSRF cookie if applicable.

:param response:
A Flask Response object

:param domain:
The domain of the cookie. If this is None, it will use the
``JWT_COOKIE_DOMAIN`` option (see :ref:`Configuration Options`). Otherwise,
it will use this as the cookies ``domain`` and the JWT_COOKIE_DOMAIN option
will be ignored.

**Line:** 424

---

### `def current_user_context_processor() -> Any`

**Line:** 462

---


## Module: venv2.libthon3.12.site-packages.flask_jwt_extended.view_decorators
**File:** `venv2/lib/python3.12/site-packages/flask_jwt_extended/view_decorators.py`

**Imports:**
- datetime.datetime
- datetime.timezone
- flask.current_app
- flask.g
- flask.request
- flask_jwt_extended.config.config
- flask_jwt_extended.exceptions.CSRFError
- flask_jwt_extended.exceptions.FreshTokenRequired
- flask_jwt_extended.exceptions.InvalidHeaderError
- flask_jwt_extended.exceptions.InvalidQueryParamError
- flask_jwt_extended.exceptions.NoAuthorizationError
- flask_jwt_extended.exceptions.UserLookupError
- flask_jwt_extended.internal_utils.custom_verification_for_token
- flask_jwt_extended.internal_utils.has_user_lookup
- flask_jwt_extended.internal_utils.user_lookup
- flask_jwt_extended.internal_utils.verify_token_not_blocklisted
- flask_jwt_extended.internal_utils.verify_token_type
- flask_jwt_extended.utils.decode_token
- flask_jwt_extended.utils.get_unverified_jwt_headers
- functools.wraps
- re.split
- typing.Any
- typing.Optional
- typing.Sequence
- typing.Tuple
- typing.Union
- werkzeug.exceptions.BadRequest

**Functions:**

### `def _verify_token_is_fresh(jwt_header: dict, jwt_data: dict) -> None`

**Line:** 34

---

### `def verify_jwt_in_request(optional: bool = False, fresh: bool = False, refresh: bool = False, locations: Optional[LocationType] = None, verify_type: bool = True, skip_revocation_check: bool = False) -> Optional[Tuple[(dict, dict)]]`

**Description:**
Verify that a valid JWT is present in the request, unless ``optional=True`` in
which case no JWT is also considered valid.

:param optional:
If ``True``, do not raise an error if no JWT is present in the request.
Defaults to ``False``.

:param fresh:
If ``True``, require a JWT marked as ``fresh`` in order to be verified.
Defaults to ``False``.

:param refresh:
If ``True``, requires a refresh JWT to access this endpoint. If ``False``,
requires an access JWT to access this endpoint. Defaults to ``False``

:param locations:
A location or list of locations to look for the JWT in this request, for
example ``'headers'`` or ``['headers', 'cookies']``. Defaults to ``None``
which indicates that JWTs will be looked for in the locations defined by the
``JWT_TOKEN_LOCATION`` configuration option.

:param verify_type:
If ``True``, the token type (access or refresh) will be checked according
to the ``refresh`` argument. If ``False``, type will not be checked and both
access and refresh tokens will be accepted.

:param skip_revocation_check:
If ``True``, revocation status of the token will be *not* checked. If ``False``,
revocation status of the token will be checked.

:return:
A tuple containing the jwt_header and the jwt_data if a valid JWT is
present in the request. If ``optional=True`` and no JWT is in the request,
``None`` will be returned instead. Raise an exception if an invalid JWT
is in the request.

**Line:** 45

---

### `def jwt_required(optional: bool = False, fresh: bool = False, refresh: bool = False, locations: Optional[LocationType] = None, verify_type: bool = True, skip_revocation_check: bool = False) -> Any`

**Description:**
A decorator to protect a Flask endpoint with JSON Web Tokens.

Any route decorated with this will require a valid JWT to be present in the
request (unless optional=True, in which case no JWT is also valid) before the
endpoint can be called.

:param optional:
If ``True``, allow the decorated endpoint to be accessed if no JWT is present in
the request. Defaults to ``False``.

:param fresh:
If ``True``, require a JWT marked with ``fresh`` to be able to access this
endpoint. Defaults to ``False``.

:param refresh:
If ``True``, requires a refresh JWT to access this endpoint. If ``False``,
requires an access JWT to access this endpoint. Defaults to ``False``.

:param locations:
A location or list of locations to look for the JWT in this request, for
example ``'headers'`` or ``['headers', 'cookies']``. Defaults to ``None``
which indicates that JWTs will be looked for in the locations defined by the
``JWT_TOKEN_LOCATION`` configuration option.

:param verify_type:
If ``True``, the token type (access or refresh) will be checked according
to the ``refresh`` argument. If ``False``, type will not be checked and both
access and refresh tokens will be accepted.

:param skip_revocation_check:
If ``True``, revocation status of the token will be *not* checked. If ``False``,
revocation status of the token will be checked.

**Line:** 121

---

### `def _load_user(jwt_header: dict, jwt_data: dict) -> Optional[dict]`

**Line:** 177

---

### `def _decode_jwt_from_headers() -> Tuple[(str, None)]`

**Line:** 189

---

### `def _decode_jwt_from_cookies(refresh: bool) -> Tuple[(str, Optional[str])]`

**Line:** 233

---

### `def _decode_jwt_from_query_string() -> Tuple[(str, None)]`

**Line:** 259

---

### `def _decode_jwt_from_json(refresh: bool) -> Tuple[(str, None)]`

**Line:** 277

---

### `def _decode_jwt_from_request(locations: LocationType, fresh: bool, refresh: bool = False, verify_type: bool = True, skip_revocation_check: bool = False) -> Tuple[(dict, dict, str)]`

**Line:** 298

---


## Module: venv2.libthon3.12.site-packages.flask_limiter._compat
**File:** `venv2/lib/python3.12/site-packages/flask_limiter/_compat.py`

**Imports:**
- __future__.annotations
- flask
- flask.ctx.RequestContext
- flask.globals.request_ctx

**Functions:**

### `def request_context() -> RequestContext`

**Line:** 13

---


## Module: venv2.libthon3.12.site-packages.flask_limiter._version
**File:** `venv2/lib/python3.12/site-packages/flask_limiter/_version.py`

**Imports:**
- json

**Functions:**

### `def get_versions()`

**Line:** 20

---


## Module: venv2.libthon3.12.site-packages.flask_limiter.commands
**File:** `venv2/lib/python3.12/site-packages/flask_limiter/commands.py`

**Imports:**
- click
- flask.Flask
- flask.cli.with_appcontext
- flask.current_app
- flask_limiter.Limiter
- flask_limiter.constants.ConfigVars
- flask_limiter.constants.ExemptionScope
- flask_limiter.constants.HeaderNames
- flask_limiter.util.get_qualified_name
- flask_limiter.wrappers.Limit
- functools.partial
- itertools
- limits.strategies.RateLimiter
- rich.console.Console
- rich.console.group
- rich.live.Live
- rich.pretty.Pretty
- rich.prompt.Confirm
- rich.table.Table
- rich.theme.Theme
- rich.tree.Tree
- time
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generator
- typing.List
- typing.Optional
- typing.Set
- typing.Tuple
- typing.Union
- typing_extensions.TypedDict
- urllib.parse.urlparse
- werkzeug.exceptions.MethodNotAllowed
- werkzeug.exceptions.NotFound
- werkzeug.routing.Rule

**Functions:**

### `def render_func(func: Any) -> Union[(str, Pretty)]`

**Line:** 44

---

### `def render_storage(ext: Limiter) -> Tree`

**Line:** 52

---

### `def render_strategy(strategy: RateLimiter) -> str`

**Line:** 66

---

### `def render_limit_state(limiter: Limiter, endpoint: str, limit: Limit, key: str, method: str) -> str`

**Line:** 70

---

### `def render_limit(limit: Limit, simple: bool = True) -> str`

**Line:** 86

---

### `def render_limits(app: Flask, limiter: Limiter, limits: Tuple[(List[Limit], ...)], endpoint: Optional[str] = None, blueprint: Optional[str] = None, rule: Optional[Rule] = None, exemption_scope: ExemptionScope = ExemptionScope.NONE, test: Optional[str] = None, method: str = 'GET', label: Optional[str] = '') -> Tree`

**Line:** 100

---

### `def get_filtered_endpoint(app: Flask, console: Console, endpoint: Optional[str], path: Optional[str], method: Optional[str] = None) -> Optional[str]`

**Line:** 160

---

### `def cli() -> None`

**Decorators:**
- `@click.group(...)`

**Line:** 196

---

### `def config() -> None`

**Decorators:**
- `@cli.command(...)`
- `@with_appcontext`

**Line:** 202

---

### `def limits(endpoint: Optional[str] = None, path: Optional[str] = None, method: str = 'GET', key: Optional[str] = None, watch: bool = False) -> None`

**Decorators:**
- `@cli.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@with_appcontext`

**Line:** 368

---

### `def clear(key: str, endpoint: Optional[str] = None, path: Optional[str] = None, method: str = 'GET', y: bool = False) -> None`

**Decorators:**
- `@cli.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@with_appcontext`

**Line:** 490

---


## Module: venv2.libthon3.12.site-packages.flask_limiter.contrib.util
**File:** `venv2/lib/python3.12/site-packages/flask_limiter/contrib/util.py`

**Imports:**
- flask.request

**Functions:**

### `def get_remote_address_cloudflare() -> str`

**Description:**
:return: the ip address for the current request from the CF-Connecting-IP header
(or 127.0.0.1 if none found)

**Line:** 4

---


## Module: venv2.libthon3.12.site-packages.flask_limiter.util
**File:** `venv2/lib/python3.12/site-packages/flask_limiter/util.py`

**Imports:**
- __future__.annotations
- flask.request
- typing.Any
- typing.Callable

**Functions:**

### `def get_remote_address() -> str`

**Description:**
:return: the ip address for the current request
(or 127.0.0.1 if none found)

**Line:** 8

---

### `def get_qualified_name(callable: Callable[(..., Any)]) -> str`

**Description:**
Generate the fully qualified name of a callable for use in storing
mappings of decorated functions to rate limits

The __qualname__ of the callable is appended in case there is a name
clash in a module due to locally scoped functions that are decorated.

TODO: Ideally __qualname__ should be enough, however view functions
generated by class based views do not update that and therefore
would not be uniquely identifiable unless __module__ & __name__
are inspected.

:meta private:

**Line:** 17

---


## Module: venv2.libthon3.12.site-packages.flask_migrate.__init__
**File:** `venv2/lib/python3.12/site-packages/flask_migrate/__init__.py`

**Imports:**
- alembic.__version__
- alembic.command
- alembic.config.Config
- alembic.util.CommandError
- argparse
- flask.current_app
- flask_migrate.cli.db
- functools.wraps
- logging
- os
- sys

**Functions:**

### `def catch_errors(f)`

**Line:** 107

---

### `def list_templates()`

**Decorators:**
- `@catch_errors`

**Description:**
List available templates.

**Line:** 119

---

### `def init(directory = None, multidb = False, template = None, package = False)`

**Decorators:**
- `@catch_errors`

**Description:**
Creates a new migration repository

**Line:** 132

---

### `def revision(directory = None, message = None, autogenerate = False, sql = False, head = 'head', splice = False, branch_label = None, version_path = None, rev_id = None)`

**Decorators:**
- `@catch_errors`

**Description:**
Create a new revision file.

**Line:** 152

---

### `def migrate(directory = None, message = None, sql = False, head = 'head', splice = False, branch_label = None, version_path = None, rev_id = None, x_arg = None)`

**Decorators:**
- `@catch_errors`

**Description:**
Alias for 'revision --autogenerate'

**Line:** 165

---

### `def edit(directory = None, revision = 'current')`

**Decorators:**
- `@catch_errors`

**Description:**
Edit current revision.

**Line:** 176

---

### `def merge(directory = None, revisions = '', message = None, branch_label = None, rev_id = None)`

**Decorators:**
- `@catch_errors`

**Description:**
Merge two revisions together.  Creates a new migration file

**Line:** 187

---

### `def upgrade(directory = None, revision = 'head', sql = False, tag = None, x_arg = None)`

**Decorators:**
- `@catch_errors`

**Description:**
Upgrade to a later version

**Line:** 196

---

### `def downgrade(directory = None, revision = '-1', sql = False, tag = None, x_arg = None)`

**Decorators:**
- `@catch_errors`

**Description:**
Revert to a previous version

**Line:** 204

---

### `def show(directory = None, revision = 'head')`

**Decorators:**
- `@catch_errors`

**Description:**
Show the revision denoted by the given symbol.

**Line:** 214

---

### `def history(directory = None, rev_range = None, verbose = False, indicate_current = False)`

**Decorators:**
- `@catch_errors`

**Description:**
List changeset scripts in chronological order.

**Line:** 221

---

### `def heads(directory = None, verbose = False, resolve_dependencies = False)`

**Decorators:**
- `@catch_errors`

**Description:**
Show current available heads in the script directory

**Line:** 233

---

### `def branches(directory = None, verbose = False)`

**Decorators:**
- `@catch_errors`

**Description:**
Show current branch points

**Line:** 241

---

### `def current(directory = None, verbose = False)`

**Decorators:**
- `@catch_errors`

**Description:**
Display the current revision for each database.

**Line:** 248

---

### `def stamp(directory = None, revision = 'head', sql = False, tag = None)`

**Decorators:**
- `@catch_errors`

**Description:**
'stamp' the revision table with the given revision; don't run any
migrations

**Line:** 255

---

### `def check(directory = None)`

**Decorators:**
- `@catch_errors`

**Description:**
Check if there are any new operations to migrate

**Line:** 263

---


## Module: venv2.libthon3.12.site-packages.flask_migrate.cli
**File:** `venv2/lib/python3.12/site-packages/flask_migrate/cli.py`

**Imports:**
- click
- flask.cli.with_appcontext
- flask_migrate.branches
- flask_migrate.check
- flask_migrate.current
- flask_migrate.downgrade
- flask_migrate.edit
- flask_migrate.heads
- flask_migrate.history
- flask_migrate.init
- flask_migrate.list_templates
- flask_migrate.merge
- flask_migrate.migrate
- flask_migrate.revision
- flask_migrate.show
- flask_migrate.stamp
- flask_migrate.upgrade

**Functions:**

### `def db()`

**Decorators:**
- `@click.group(...)`

**Description:**
Perform database migrations.

**Line:** 21

---

### `def list_templates()`

**Decorators:**
- `@db.command(...)`
- `@with_appcontext`

**Description:**
List available templates.

**Line:** 28

---

### `def init(directory, multidb, template, package)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@with_appcontext`

**Description:**
Creates a new migration repository.

**Line:** 44

---

### `def revision(directory, message, autogenerate, sql, head, splice, branch_label, version_path, rev_id)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@with_appcontext`

**Description:**
Create a new revision file.

**Line:** 72

---

### `def migrate(directory, message, sql, head, splice, branch_label, version_path, rev_id, x_arg)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@with_appcontext`

**Description:**
Autogenerate a new revision file (Alias for
'revision --autogenerate')

**Line:** 101

---

### `def edit(directory, revision)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@click.argument(...)`
- `@with_appcontext`

**Description:**
Edit a revision file

**Line:** 114

---

### `def merge(directory, message, branch_label, rev_id, revisions)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.argument(...)`
- `@with_appcontext`

**Description:**
Merge two revisions together, creating a new revision file

**Line:** 130

---

### `def upgrade(directory, sql, tag, x_arg, revision)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.argument(...)`
- `@with_appcontext`

**Description:**
Upgrade to a later version

**Line:** 148

---

### `def downgrade(directory, sql, tag, x_arg, revision)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.argument(...)`
- `@with_appcontext`

**Description:**
Revert to a previous version

**Line:** 166

---

### `def show(directory, revision)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@click.argument(...)`
- `@with_appcontext`

**Description:**
Show the revision denoted by the given symbol.

**Line:** 176

---

### `def history(directory, rev_range, verbose, indicate_current)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@with_appcontext`

**Description:**
List changeset scripts in chronological order.

**Line:** 191

---

### `def heads(directory, verbose, resolve_dependencies)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@with_appcontext`

**Description:**
Show current available heads in the script directory

**Line:** 203

---

### `def branches(directory, verbose)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@with_appcontext`

**Description:**
Show current branch points

**Line:** 213

---

### `def current(directory, verbose)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@with_appcontext`

**Description:**
Display the current revision for each database.

**Line:** 223

---

### `def stamp(directory, sql, tag, revision)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.option(...)`
- `@click.argument(...)`
- `@with_appcontext`

**Description:**
'stamp' the revision table with the given revision; don't run any
migrations

**Line:** 239

---

### `def check(directory)`

**Decorators:**
- `@db.command(...)`
- `@click.option(...)`
- `@with_appcontext`

**Description:**
Check if there are any new operations to migrate

**Line:** 249

---


## Module: venv2.libthon3.12.site-packages.flask_migrate.templates.aioflask-multidb.env
**File:** `venv2/lib/python3.12/site-packages/flask_migrate/templates/aioflask-multidb/env.py`

**Imports:**
- alembic.context
- asyncio
- flask.current_app
- logging
- logging.config.fileConfig
- sqlalchemy.MetaData

**Functions:**

### `def get_engine(bind_key = None)`

**Line:** 22

---

### `def get_engine_url(bind_key = None)`

**Line:** 31

---

### `def get_metadata(bind)`

**Description:**
Return the metadata for a bind.

**Line:** 64

---

### `def run_migrations_offline()`

**Description:**
Run migrations in 'offline' mode.

This configures the context with just a URL
and not an Engine, though an Engine is acceptable
here as well.  By skipping the Engine creation
we don't even need a DBAPI to be available.

Calls to context.execute() here emit the given string to the
script output.

**Line:** 79

---

### `def do_run_migrations(_, engines)`

**Line:** 118

---

### `async def run_migrations_online()`

**Description:**
Run migrations in 'online' mode.

In this scenario we need to create an Engine
and associate a connection with the context.

**Line:** 172

---


## Module: venv2.libthon3.12.site-packages.flask_migrate.templates.aioflask.env
**File:** `venv2/lib/python3.12/site-packages/flask_migrate/templates/aioflask/env.py`

**Imports:**
- alembic.context
- asyncio
- flask.current_app
- logging
- logging.config.fileConfig

**Functions:**

### `def get_engine()`

**Line:** 19

---

### `def get_engine_url()`

**Line:** 28

---

### `def get_metadata()`

**Line:** 49

---

### `def run_migrations_offline()`

**Description:**
Run migrations in 'offline' mode.

This configures the context with just a URL
and not an Engine, though an Engine is acceptable
here as well.  By skipping the Engine creation
we don't even need a DBAPI to be available.

Calls to context.execute() here emit the given string to the
script output.

**Line:** 55

---

### `def do_run_migrations(connection)`

**Line:** 76

---

### `async def run_migrations_online()`

**Description:**
Run migrations in 'online' mode.

In this scenario we need to create an Engine
and associate a connection with the context.

**Line:** 101

---


## Module: venv2.libthon3.12.site-packages.flask_migrate.templates.flask-multidb.env
**File:** `venv2/lib/python3.12/site-packages/flask_migrate/templates/flask-multidb/env.py`

**Imports:**
- alembic.context
- flask.current_app
- logging
- logging.config.fileConfig
- sqlalchemy.MetaData

**Functions:**

### `def get_engine(bind_key = None)`

**Line:** 21

---

### `def get_engine_url(bind_key = None)`

**Line:** 30

---

### `def get_metadata(bind)`

**Description:**
Return the metadata for a bind.

**Line:** 62

---

### `def run_migrations_offline()`

**Description:**
Run migrations in 'offline' mode.

This configures the context with just a URL
and not an Engine, though an Engine is acceptable
here as well.  By skipping the Engine creation
we don't even need a DBAPI to be available.

Calls to context.execute() here emit the given string to the
script output.

**Line:** 77

---

### `def run_migrations_online()`

**Description:**
Run migrations in 'online' mode.

In this scenario we need to create an Engine
and associate a connection with the context.

**Line:** 116

---


## Module: venv2.libthon3.12.site-packages.flask_migrate.templates.flask.env
**File:** `venv2/lib/python3.12/site-packages/flask_migrate/templates/flask/env.py`

**Imports:**
- alembic.context
- flask.current_app
- logging
- logging.config.fileConfig

**Functions:**

### `def get_engine()`

**Line:** 18

---

### `def get_engine_url()`

**Line:** 27

---

### `def get_metadata()`

**Line:** 48

---

### `def run_migrations_offline()`

**Description:**
Run migrations in 'offline' mode.

This configures the context with just a URL
and not an Engine, though an Engine is acceptable
here as well.  By skipping the Engine creation
we don't even need a DBAPI to be available.

Calls to context.execute() here emit the given string to the
script output.

**Line:** 54

---

### `def run_migrations_online()`

**Description:**
Run migrations in 'online' mode.

In this scenario we need to create an Engine
and associate a connection with the context.

**Line:** 75

---


## Module: venv2.libthon3.12.site-packages.flask_sqlalchemy.__init__
**File:** `venv2/lib/python3.12/site-packages/flask_sqlalchemy/__init__.py`

**Imports:**
- __future__.annotations
- extension.SQLAlchemy
- importlib.metadata
- typing
- warnings

**Functions:**

### `def __getattr__(name: str) -> t.Any`

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.flask_sqlalchemy.cli
**File:** `venv2/lib/python3.12/site-packages/flask_sqlalchemy/cli.py`

**Imports:**
- __future__.annotations
- flask.current_app
- typing

**Functions:**

### `def add_models_to_shell() -> dict[(str, t.Any)]`

**Description:**
Registered with :meth:`~flask.Flask.shell_context_processor` if
``add_models_to_shell`` is enabled. Adds the ``db`` instance and all model classes
to ``flask shell``.

**Line:** 8

---


## Module: venv2.libthon3.12.site-packages.flask_sqlalchemy.extension
**File:** `venv2/lib/python3.12/site-packages/flask_sqlalchemy/extension.py`

**Imports:**
- __future__.annotations
- cli.add_models_to_shell
- flask.Flask
- flask.abort
- flask.current_app
- flask.has_app_context
- model.BindMixin
- model.DefaultMeta
- model.DefaultMetaNoName
- model.Model
- model.NameMixin
- model._QueryProperty
- os
- pagination.Pagination
- pagination.SelectPagination
- query.Query
- session.Session
- session._app_ctx_id
- sqlalchemy
- sqlalchemy.event
- sqlalchemy.exc
- sqlalchemy.orm
- table._Table
- types
- typing
- warnings
- weakref.WeakKeyDictionary

**Functions:**

### `def _get_2x_declarative_bases(model_class: _FSA_MCT) -> list[t.Type[t.Union[(sa_orm.DeclarativeBase, sa_orm.DeclarativeBaseNoMeta)]]]`

**Line:** 51

---


## Module: venv2.libthon3.12.site-packages.flask_sqlalchemy.model
**File:** `venv2/lib/python3.12/site-packages/flask_sqlalchemy/model.py`

**Imports:**
- __future__.annotations
- extension.SQLAlchemy
- query.Query
- re
- sqlalchemy
- sqlalchemy.orm
- typing

**Functions:**

### `def should_set_tablename(cls: type) -> bool`

**Description:**
Determine whether ``__tablename__`` should be generated for a model.

-   If no class in the MRO sets a name, one should be generated.
-   If a declared attr is found, it should be used instead.
-   If a name is found, it should be used if the class is a mixin, otherwise one
should be generated.
-   Abstract models should not have one generated.

Later, ``__table_cls__`` will determine if the model looks like single or
joined-table inheritance. If no primary key is found, the name will be unset.

**Line:** 267

---

### `def camel_to_snake_case(name: str) -> str`

**Description:**
Convert a ``CamelCase`` name to ``snake_case``.

**Line:** 315

---


## Module: venv2.libthon3.12.site-packages.flask_sqlalchemy.record_queries
**File:** `venv2/lib/python3.12/site-packages/flask_sqlalchemy/record_queries.py`

**Imports:**
- __future__.annotations
- dataclasses
- flask.current_app
- flask.g
- flask.has_app_context
- inspect
- sqlalchemy
- sqlalchemy.event
- time.perf_counter
- typing

**Functions:**

### `def get_recorded_queries() -> list[_QueryInfo]`

**Description:**
Get the list of recorded query information for the current session. Queries are
recorded if the config :data:`.SQLALCHEMY_RECORD_QUERIES` is enabled.

Each query info object has the following attributes:

``statement``
The string of SQL generated by SQLAlchemy with parameter placeholders.
``parameters``
The parameters sent with the SQL statement.
``start_time`` / ``end_time``
Timing info about when the query started execution and when the results where
returned. Accuracy and value depends on the operating system.
``duration``
The time the query took in seconds.
``location``
A string description of where in your application code the query was executed.
This may not be possible to calculate, and the format is not stable.

.. versionchanged:: 3.0
Renamed from ``get_debug_queries``.

.. versionchanged:: 3.0
The info object is a dataclass instead of a tuple.

.. versionchanged:: 3.0
The info object attribute ``context`` is renamed to ``location``.

.. versionchanged:: 3.0
Not enabled automatically in debug or testing mode.

**Line:** 15

---

### `def _listen(engine: sa.engine.Engine) -> None`

**Line:** 74

---

### `def _record_start(context: sa.engine.ExecutionContext, **kwargs: t.Any) -> None`

**Line:** 79

---

### `def _record_end(context: sa.engine.ExecutionContext, **kwargs: t.Any) -> None`

**Line:** 86

---


## Module: venv2.libthon3.12.site-packages.flask_sqlalchemy.session
**File:** `venv2/lib/python3.12/site-packages/flask_sqlalchemy/session.py`

**Imports:**
- __future__.annotations
- extension.SQLAlchemy
- flask.globals.app_ctx
- sqlalchemy
- sqlalchemy.exc
- sqlalchemy.orm
- typing

**Functions:**

### `def _clause_to_engine(clause: sa.ClauseElement | None, engines: t.Mapping[(str | None, sa.engine.Engine)]) -> sa.engine.Engine | None`

**Description:**
If the clause is a table, return the engine associated with the table's
metadata's bind key.

**Line:** 81

---

### `def _app_ctx_id() -> int`

**Description:**
Get the id of the current Flask application context for the session scope.

**Line:** 109

---


## Module: venv2.libthon3.12.site-packages.flask_sqlalchemy.track_modifications
**File:** `venv2/lib/python3.12/site-packages/flask_sqlalchemy/track_modifications.py`

**Imports:**
- __future__.annotations
- flask.current_app
- flask.has_app_context
- flask.signals.Namespace
- session.Session
- sqlalchemy
- sqlalchemy.event
- sqlalchemy.orm
- typing

**Functions:**

### `def _listen(session: sa_orm.scoped_session[Session]) -> None`

**Line:** 32

---

### `def _record_ops(session: Session, **kwargs: t.Any) -> None`

**Line:** 40

---

### `def _before_commit(session: Session) -> None`

**Line:** 58

---

### `def _after_commit(session: Session) -> None`

**Line:** 72

---

### `def _after_rollback(session: Session) -> None`

**Line:** 87

---


## Module: venv2.libthon3.12.site-packages.gunicorn.app.pasterapp
**File:** `venv2/lib/python3.12/site-packages/gunicorn/app/pasterapp.py`

**Imports:**
- configparser
- gunicorn.app.wsgiapp.WSGIApplication
- gunicorn.config.get_default_config_file
- os
- paste.deploy.loadapp

**Functions:**

### `def get_wsgi_app(config_uri, name = None, defaults = None)`

**Line:** 15

---

### `def has_logging_config(config_file)`

**Line:** 27

---

### `def serve(app, global_conf, **local_conf)`

**Description:**
A Paste Deployment server runner.

Example configuration:

[server:main]
use = egg:gunicorn#main
host = 127.0.0.1
port = 5000

**Line:** 33

---


## Module: venv2.libthon3.12.site-packages.gunicorn.app.wsgiapp
**File:** `venv2/lib/python3.12/site-packages/gunicorn/app/wsgiapp.py`

**Imports:**
- gunicorn.app.base.Application
- gunicorn.app.wsgiapp.WSGIApplication
- gunicorn.errors.ConfigError
- gunicorn.util
- os
- pasterapp.get_wsgi_app
- pasterapp.has_logging_config

**Functions:**

### `def run()`

**Description:**
The ``gunicorn`` command line runner for launching Gunicorn with
generic WSGI applications.

**Line:** 61

---


## Module: venv2.libthon3.12.site-packages.gunicorn.config
**File:** `venv2/lib/python3.12/site-packages/gunicorn/config.py`

**Imports:**
- argparse
- copy
- grp
- gunicorn.__version__
- gunicorn.errors.ConfigError
- gunicorn.reloader.reloader_engines
- gunicorn.util
- inspect
- os
- pwd
- re
- shlex
- ssl
- sys
- textwrap

**Functions:**

### `def make_settings(ignore = None)`

**Line:** 28

---

### `def auto_int(_, x)`

**Line:** 39

---

### `def validate_bool(val)`

**Line:** 333

---

### `def validate_dict(val)`

**Line:** 349

---

### `def validate_pos_int(val)`

**Line:** 355

---

### `def validate_ssl_version(val)`

**Line:** 366

---

### `def validate_string(val)`

**Line:** 372

---

### `def validate_file_exists(val)`

**Line:** 380

---

### `def validate_list_string(val)`

**Line:** 388

---

### `def validate_list_of_existing_files(val)`

**Line:** 399

---

### `def validate_string_to_list(val)`

**Line:** 403

---

### `def validate_class(val)`

**Line:** 412

---

### `def validate_callable(arity)`

**Line:** 420

---

### `def validate_user(val)`

**Line:** 444

---

### `def validate_group(val)`

**Line:** 458

---

### `def validate_post_request(val)`

**Line:** 473

---

### `def validate_chdir(val)`

**Line:** 487

---

### `def validate_statsd_address(val)`

**Line:** 501

---

### `def validate_reload_engine(val)`

**Line:** 522

---

### `def get_default_config_file()`

**Line:** 529

---


## Module: venv2.libthon3.12.site-packages.gunicorn.debug
**File:** `venv2/lib/python3.12/site-packages/gunicorn/debug.py`

**Imports:**
- inspect
- linecache
- re
- sys

**Functions:**

### `def spew(trace_names = None, show_values = False)`

**Description:**
Install a trace hook which writes incredibly detailed logs
about what code is being executed to stdout.

**Line:** 59

---

### `def unspew()`

**Description:**
Remove the trace hook installed by spew.

**Line:** 66

---


## Module: venv2.libthon3.12.site-packages.gunicorn.glogging
**File:** `venv2/lib/python3.12/site-packages/gunicorn/glogging.py`

**Imports:**
- base64
- binascii
- gunicorn.util
- json
- logging
- logging.config.dictConfig
- logging.config.fileConfig
- os
- socket
- sys
- threading
- time
- traceback

**Functions:**

### `def loggers()`

**Description:**
get list of all loggers

**Line:** 89

---

### `def parse_syslog_address(addr)`

**Line:** 119

---


## Module: venv2.libthon3.12.site-packages.gunicorn.http.wsgi
**File:** `venv2/lib/python3.12/site-packages/gunicorn/http/wsgi.py`

**Imports:**
- gunicorn.SERVER
- gunicorn.SERVER_SOFTWARE
- gunicorn.http.errors.InvalidHeader
- gunicorn.http.errors.InvalidHeaderName
- gunicorn.http.message.HEADER_RE
- gunicorn.util
- io
- logging
- os
- re
- sys

**Functions:**

### `def base_environ(cfg)`

**Line:** 68

---

### `def default_environ(req, sock, cfg)`

**Line:** 81

---

### `def proxy_environ(req)`

**Line:** 94

---

### `def create(req, sock, client, server, cfg)`

**Line:** 109

---


## Module: venv2.libthon3.12.site-packages.gunicorn.sock
**File:** `venv2/lib/python3.12/site-packages/gunicorn/sock.py`

**Imports:**
- errno
- gunicorn.util
- os
- socket
- ssl
- stat
- sys
- time

**Functions:**

### `def _sock_type(addr)`

**Line:** 130

---

### `def create_sockets(conf, log, fds = None)`

**Description:**
Create a new socket for the configured addresses or file descriptors.

If a configured address is a tuple then a TCP socket is created.
If it is a string, a Unix socket is created. Otherwise, a TypeError is
raised.

**Line:** 143

---

### `def close_sockets(listeners, unlink = True)`

**Line:** 208

---

### `def ssl_context(conf)`

**Line:** 216

---

### `def ssl_wrap_socket(sock, conf)`

**Line:** 228

---


## Module: venv2.libthon3.12.site-packages.gunicorn.systemd
**File:** `venv2/lib/python3.12/site-packages/gunicorn/systemd.py`

**Imports:**
- os
- socket

**Functions:**

### `def listen_fds(unset_environment = True)`

**Description:**
Get the number of sockets inherited from systemd socket activation.

:param unset_environment: clear systemd environment variables unless False
:type unset_environment: bool
:return: the number of sockets to inherit from systemd socket activation
:rtype: int

Returns zero immediately if $LISTEN_PID is not set to the current pid.
Otherwise, returns the number of systemd activation sockets specified by
$LISTEN_FDS.

When $LISTEN_PID matches the current pid, unsets the environment variables
unless the ``unset_environment`` flag is ``False``.

.. note::
Unlike the sd_listen_fds C function, this implementation does not set
the FD_CLOEXEC flag because the gunicorn arbiter never needs to do this.

.. seealso::
`<https://www.freedesktop.org/software/systemd/man/sd_listen_fds.html>`_

**Line:** 12

---

### `def sd_notify(state, logger, unset_environment = False)`

**Description:**
Send a notification to systemd. state is a string; see
the man page of sd_notify (http://www.freedesktop.org/software/systemd/man/sd_notify.html)
for a description of the allowable values.

If the unset_environment parameter is True, sd_notify() will unset
the $NOTIFY_SOCKET environment variable before returning (regardless of
whether the function call itself succeeded or not). Further calls to
sd_notify() will then fail, but the variable is no longer inherited by
child processes.

**Line:** 49

---


## Module: venv2.libthon3.12.site-packages.gunicorn.util
**File:** `venv2/lib/python3.12/site-packages/gunicorn/util.py`

**Imports:**
- ast
- email.utils
- errno
- fcntl
- gunicorn.errors.AppImportError
- gunicorn.workers.SUPPORTED_WORKERS
- html
- importlib
- importlib.metadata
- importlib_metadata
- inspect
- io
- logging
- os
- os.closerange
- pwd
- random
- re
- setproctitle.setproctitle
- socket
- sys
- textwrap
- time
- traceback
- urllib.parse
- warnings

**Functions:**

### `def _setproctitle(title)`

**Line:** 53

---

### `def _setproctitle(title)`

**Line:** 56

---

### `def load_entry_point(distribution, group, name)`

**Line:** 60

---

### `def load_class(uri, default = 'gunicorn.workers.sync.SyncWorker', section = 'gunicorn.workers')`

**Line:** 69

---

### `def get_arity(f)`

**Line:** 125

---

### `def get_username(uid)`

**Description:**
get the username for a user id

**Line:** 136

---

### `def set_owner_process(uid, gid, initgroups = False)`

**Description:**
set user and group of workers processes

**Line:** 141

---

### `def chown(path, uid, gid)`

**Line:** 164

---

### `def _waitfor(func, pathname, waitall = False)`

**Line:** 169

---

### `def _unlink(filename)`

**Line:** 202

---

### `def unlink(filename)`

**Line:** 208

---

### `def is_ipv6(addr)`

**Line:** 217

---

### `def parse_address(netloc, default_port = '8000')`

**Line:** 227

---

### `def close_on_exec(fd)`

**Line:** 258

---

### `def set_non_blocking(fd)`

**Line:** 264

---

### `def close(sock)`

**Line:** 269

---

### `def closerange(fd_low, fd_high)`

**Line:** 279

---

### `def write_chunk(sock, data)`

**Line:** 288

---

### `def write(sock, data, chunked = False)`

**Line:** 296

---

### `def write_nonblock(sock, data, chunked = False)`

**Line:** 302

---

### `def write_error(sock, status_int, reason, mesg)`

**Line:** 314

---

### `def _called_with_wrong_args(f)`

**Description:**
Check whether calling a function raised a ``TypeError`` because
the call failed or because something in the function raised the
error.

:param f: The function that was called.
:return: ``True`` if the call failed.

**Line:** 337

---

### `def import_app(module)`

**Line:** 363

---

### `def getcwd()`

**Line:** 446

---

### `def http_date(timestamp = None)`

**Description:**
Return the current date and time formatted for a message header.

**Line:** 460

---

### `def is_hoppish(header)`

**Line:** 468

---

### `def daemonize(enable_stdio_inheritance = False)`

**Description:**
Standard daemonization of a process.
http://www.faqs.org/faqs/unix-faq/programmer/faq/ section 1.7

**Line:** 472

---

### `def seed()`

**Line:** 558

---

### `def check_is_writable(path)`

**Line:** 565

---

### `def to_bytestring(value, encoding = 'utf8')`

**Description:**
Converts a string argument to a byte string

**Line:** 573

---

### `def has_fileno(obj)`

**Line:** 583

---

### `def warn(msg)`

**Line:** 596

---

### `def make_fail_app(msg)`

**Line:** 609

---

### `def split_request_uri(uri)`

**Line:** 622

---

### `def reraise(tp, value, tb = None)`

**Line:** 635

---

### `def bytes_to_str(b)`

**Line:** 647

---

### `def unquote_to_wsgi_str(string)`

**Line:** 653

---


## Module: venv2.libthon3.12.site-packages.gunicorn.workers.geventlet
**File:** `venv2/lib/python3.12/site-packages/gunicorn/workers/geventlet.py`

**Imports:**
- eventlet
- eventlet.greenio.GreenSocket
- eventlet.greenthread
- eventlet.hubs
- eventlet.wsgi
- functools.partial
- greenlet
- gunicorn.sock.ssl_wrap_socket
- gunicorn.workers.base_async.AsyncWorker
- packaging.version.parse
- sys

**Functions:**

### `def _eventlet_socket_sendfile(self, file, offset = 0, count = None)`

**Line:** 32

---

### `def _eventlet_serve(sock, handle, concurrency)`

**Description:**
Serve requests forever.

This code is nearly identical to ``eventlet.convenience.serve`` except
that it attempts to join the pool at the end, which allows for gunicorn
graceful shutdowns.

**Line:** 70

---

### `def _eventlet_stop(client, server, conn)`

**Description:**
Stop a greenlet handling a request and close its connection.

This code is lifted from eventlet so as not to depend on undocumented
functions in the library.

**Line:** 93

---

### `def patch_sendfile()`

**Line:** 111

---


## Module: venv2.libthon3.12.site-packages.iniconfig._parse
**File:** `venv2/lib/python3.12/site-packages/iniconfig/_parse.py`

**Imports:**
- __future__.annotations
- exceptions.ParseError
- typing.NamedTuple

**Functions:**

### `def parse_lines(path: str, line_iter: list[str]) -> list[_ParsedLine]`

**Line:** 17

---

### `def _parseline(path: str, line: str, lineno: int) -> tuple[(str | None, str | None)]`

**Line:** 47

---

### `def iscommentline(line: str) -> bool`

**Line:** 80

---


## Module: venv2.libthon3.12.site-packages.itsdangerous.__init__
**File:** `venv2/lib/python3.12/site-packages/itsdangerous/__init__.py`

**Imports:**
- __future__.annotations
- encoding.base64_decode
- encoding.base64_encode
- encoding.want_bytes
- exc.BadData
- exc.BadHeader
- exc.BadPayload
- exc.BadSignature
- exc.BadTimeSignature
- exc.SignatureExpired
- importlib.metadata
- serializer.Serializer
- signer.HMACAlgorithm
- signer.NoneAlgorithm
- signer.Signer
- timed.TimedSerializer
- timed.TimestampSigner
- typing
- url_safe.URLSafeSerializer
- url_safe.URLSafeTimedSerializer
- warnings

**Functions:**

### `def __getattr__(name: str) -> t.Any`

**Line:** 24

---


## Module: venv2.libthon3.12.site-packages.itsdangerous.encoding
**File:** `venv2/lib/python3.12/site-packages/itsdangerous/encoding.py`

**Imports:**
- __future__.annotations
- base64
- exc.BadData
- string
- struct
- typing

**Functions:**

### `def want_bytes(s: str | bytes, encoding: str = 'utf-8', errors: str = 'strict') -> bytes`

**Line:** 11

---

### `def base64_encode(string: str | bytes) -> bytes`

**Description:**
Base64 encode a string of bytes or text. The resulting bytes are
safe to use in URLs.

**Line:** 20

---

### `def base64_decode(string: str | bytes) -> bytes`

**Description:**
Base64 decode a URL-safe string of bytes or text. The result is
bytes.

**Line:** 28

---

### `def int_to_bytes(num: int) -> bytes`

**Line:** 49

---

### `def bytes_to_int(bytestr: bytes) -> int`

**Line:** 53

---


## Module: venv2.libthon3.12.site-packages.itsdangerous.serializer
**File:** `venv2/lib/python3.12/site-packages/itsdangerous/serializer.py`

**Imports:**
- __future__.annotations
- collections.abc
- encoding.want_bytes
- exc.BadPayload
- exc.BadSignature
- json
- signer.Signer
- signer._make_keys_list
- typing
- typing_extensions

**Functions:**

### `def is_text_serializer(serializer: _PDataSerializer[t.Any]) -> te.TypeGuard[_PDataSerializer[str]]`

**Description:**
Checks whether a serializer generates text or binary.

**Line:** 35

---


## Module: venv2.libthon3.12.site-packages.itsdangerous.signer
**File:** `venv2/lib/python3.12/site-packages/itsdangerous/signer.py`

**Imports:**
- __future__.annotations
- collections.abc
- encoding._base64_alphabet
- encoding.base64_decode
- encoding.base64_encode
- encoding.want_bytes
- exc.BadSignature
- hashlib
- hmac
- typing

**Functions:**

### `def _lazy_sha1(string: bytes = b'') -> t.Any`

**Description:**
Don't access ``hashlib.sha1`` until runtime. FIPS builds may not include
SHA-1, in which case the import and use as a default would fail before the
developer can configure something else.

**Line:** 40

---

### `def _make_keys_list(secret_key: str | bytes | cabc.Iterable[str] | cabc.Iterable[bytes]) -> list[bytes]`

**Line:** 67

---


## Module: venv2.libthon3.12.site-packages.jinja2.async_utils
**File:** `venv2/lib/python3.12/site-packages/jinja2/async_utils.py`

**Imports:**
- functools.WRAPPER_ASSIGNMENTS
- functools.wraps
- inspect
- typing
- typing_extensions
- utils._PassArg
- utils.pass_eval_context

**Functions:**

### `def async_variant(normal_func)`

**Line:** 15

---

### `async def auto_await(value: t.Union[(t.Awaitable['V'], 'V')]) -> 'V'`

**Line:** 62

---

### `def auto_aiter(iterable: 't.Union[t.AsyncIterable[V], t.Iterable[V]]') -> 't.AsyncIterator[V]'`

**Line:** 87

---

### `async def auto_to_list(value: 't.Union[t.AsyncIterable[V], t.Iterable[V]]') -> t.List['V']`

**Line:** 96

---


## Module: venv2.libthon3.12.site-packages.jinja2.compiler
**File:** `venv2/lib/python3.12/site-packages/jinja2/compiler.py`

**Imports:**
- contextlib.contextmanager
- environment.Environment
- exceptions.TemplateAssertionError
- functools.update_wrapper
- idtracking.Symbols
- idtracking.VAR_LOAD_ALIAS
- idtracking.VAR_LOAD_PARAMETER
- idtracking.VAR_LOAD_RESOLVE
- idtracking.VAR_LOAD_UNDEFINED
- io.StringIO
- itertools.chain
- keyword.iskeyword
- markupsafe.Markup
- markupsafe.escape
- nodes.EvalContext
- optimizer.Optimizer
- runtime.async_exported
- runtime.exported
- typing
- typing_extensions
- utils._PassArg
- utils.concat
- visitor.NodeVisitor

**Functions:**

### `def optimizeconst(f: F) -> F`

**Line:** 45

---

### `def _make_binop(op: str) -> t.Callable[(['CodeGenerator', nodes.BinExpr, 'Frame'], None)]`

**Line:** 61

---

### `def _make_unop(op: str) -> t.Callable[(['CodeGenerator', nodes.UnaryExpr, 'Frame'], None)]`

**Line:** 82

---

### `def generate(node: nodes.Template, environment: 'Environment', name: t.Optional[str], filename: t.Optional[str], stream: t.Optional[t.TextIO] = None, defer_init: bool = False, optimized: bool = True) -> t.Optional[str]`

**Description:**
Generate the python source for a node tree.

**Line:** 101

---

### `def has_safe_repr(value: t.Any) -> bool`

**Description:**
Does the node have a safe representation?

**Line:** 125

---

### `def find_undeclared(nodes: t.Iterable[nodes.Node], names: t.Iterable[str]) -> t.Set[str]`

**Description:**
Check if the names passed are accessed undeclared.  The return value
is a set of all the undeclared names from the sequence of names found.

**Line:** 142

---


## Module: venv2.libthon3.12.site-packages.jinja2.debug
**File:** `venv2/lib/python3.12/site-packages/jinja2/debug.py`

**Imports:**
- exceptions.TemplateSyntaxError
- runtime.Context
- sys
- types.CodeType
- types.TracebackType
- typing
- utils.internal_code
- utils.missing

**Functions:**

### `def rewrite_traceback_stack(source: t.Optional[str] = None) -> BaseException`

**Description:**
Rewrite the current exception to replace any tracebacks from
within compiled template code with tracebacks that look like they
came from the template source.

This must be called within an ``except`` block.

:param source: For ``TemplateSyntaxError``, the original source if
known.
:return: The original exception with the rewritten traceback.

**Line:** 14

---

### `def fake_traceback(exc_value: BaseException, tb: t.Optional[TracebackType], filename: str, lineno: int) -> TracebackType`

**Description:**
Produce a new traceback object that looks like it came from the
template source instead of the compiled code. The filename, line
number, and location name will point to the template, and the local
variables will be the current template context.

:param exc_value: The original exception to be re-raised to create
the new traceback.
:param tb: The original traceback to get the local variables and
code info from.
:param filename: The template filename.
:param lineno: The line number in the template source.

**Line:** 76

---

### `def get_template_locals(real_locals: t.Mapping[(str, t.Any)]) -> t.Dict[(str, t.Any)]`

**Description:**
Based on the runtime locals, get the context that would be
available at that point in the template.

**Line:** 150

---


## Module: venv2.libthon3.12.site-packages.jinja2.environment
**File:** `venv2/lib/python3.12/site-packages/jinja2/environment.py`

**Imports:**
- asyncio
- bccache.BytecodeCache
- collections.ChainMap
- compiler.CodeGenerator
- compiler.generate
- debug.rewrite_traceback_stack
- defaults.BLOCK_END_STRING
- defaults.BLOCK_START_STRING
- defaults.COMMENT_END_STRING
- defaults.COMMENT_START_STRING
- defaults.DEFAULT_FILTERS
- defaults.DEFAULT_NAMESPACE
- defaults.DEFAULT_POLICIES
- defaults.DEFAULT_TESTS
- defaults.KEEP_TRAILING_NEWLINE
- defaults.LINE_COMMENT_PREFIX
- defaults.LINE_STATEMENT_PREFIX
- defaults.LSTRIP_BLOCKS
- defaults.NEWLINE_SEQUENCE
- defaults.TRIM_BLOCKS
- defaults.VARIABLE_END_STRING
- defaults.VARIABLE_START_STRING
- exceptions.TemplateNotFound
- exceptions.TemplateRuntimeError
- exceptions.TemplateSyntaxError
- exceptions.TemplatesNotFound
- exceptions.UndefinedError
- ext.Extension
- functools.lru_cache
- functools.partial
- functools.reduce
- lexer.Lexer
- lexer.TokenStream
- lexer.get_lexer
- loaders.BaseLoader
- loaders.ModuleLoader
- markupsafe.Markup
- nodes.EvalContext
- os
- parser.Parser
- runtime.Context
- runtime.Undefined
- runtime.new_context
- types.CodeType
- typing
- typing_extensions
- utils.LRUCache
- utils._PassArg
- utils.concat
- utils.consume
- utils.import_string
- utils.internalcode
- utils.missing
- weakref
- zipfile.ZIP_DEFLATED
- zipfile.ZIP_STORED
- zipfile.ZipFile
- zipfile.ZipInfo

**Functions:**

### `def get_spontaneous_environment(cls: t.Type[_env_bound], *args: t.Any) -> _env_bound`

**Decorators:**
- `@lru_cache(...)`

**Description:**
Return a new spontaneous environment. A spontaneous environment
is used for templates created directly rather than through an
existing environment.

:param cls: Environment class to create.
:param args: Positional arguments passed to environment.

**Line:** 69

---

### `def create_cache(size: int) -> t.Optional[t.MutableMapping[(t.Tuple['weakref.ref[t.Any]', str], 'Template')]]`

**Description:**
Return the cache class for the given size.

**Line:** 82

---

### `def copy_cache(cache: t.Optional[t.MutableMapping[(t.Any, t.Any)]]) -> t.Optional[t.MutableMapping[(t.Tuple['weakref.ref[t.Any]', str], 'Template')]]`

**Description:**
Create an empty copy of the given cache.

**Line:** 95

---

### `def load_extensions(environment: 'Environment', extensions: t.Sequence[t.Union[(str, t.Type['Extension'])]]) -> t.Dict[(str, 'Extension')]`

**Description:**
Load the extensions from the list and bind it to the environment.
Returns a dict of instantiated extensions.

**Line:** 108

---

### `def _environment_config_check(environment: _env_bound) -> _env_bound`

**Description:**
Perform a sanity check on the environment.

**Line:** 126

---


## Module: venv2.libthon3.12.site-packages.jinja2.ext
**File:** `venv2/lib/python3.12/site-packages/jinja2/ext.py`

**Imports:**
- environment.Environment
- exceptions.TemplateAssertionError
- exceptions.TemplateSyntaxError
- gettext
- lexer.Token
- lexer.TokenStream
- markupsafe.Markup
- parser.Parser
- pprint
- re
- runtime.Context
- runtime.Undefined
- runtime.concat
- typing
- typing_extensions
- utils.import_string
- utils.pass_context

**Functions:**

### `def _gettext_alias(__context: Context, *args: t.Any, **kwargs: t.Any) -> t.Union[(t.Any, Undefined)]`

**Decorators:**
- `@pass_context`

**Line:** 165

---

### `def _make_new_gettext(func: t.Callable[([str], str)]) -> t.Callable[(..., str)]`

**Line:** 171

---

### `def _make_new_ngettext(func: t.Callable[([str, str, int], str)]) -> t.Callable[(..., str)]`

**Line:** 185

---

### `def _make_new_pgettext(func: t.Callable[([str, str], str)]) -> t.Callable[(..., str)]`

**Line:** 204

---

### `def _make_new_npgettext(func: t.Callable[([str, str, str, int], str)]) -> t.Callable[(..., str)]`

**Line:** 221

---

### `def extract_from_ast(ast: nodes.Template, gettext_functions: t.Sequence[str] = GETTEXT_FUNCTIONS, babel_style: bool = True) -> t.Iterator[t.Tuple[(int, str, t.Union[t.Optional[str], t.Tuple[t.Optional[str], ...]])]]`

**Description:**
Extract localizable strings from the given template node.  Per
default this function returns matches in babel style that means non string
parameters as well as keyword arguments are returned as `None`.  This
allows Babel to figure out what you really meant if you are using
gettext functions that allow keyword arguments for placeholder expansion.
If you don't want that behavior set the `babel_style` parameter to `False`
which causes only strings to be returned and parameters are always stored
in tuples.  As a consequence invalid gettext calls (calls without a single
string parameter or string parameters after non-string parameters) are
skipped.

This example explains the behavior:

>>> from jinja2 import Environment
>>> env = Environment()
>>> node = env.parse('{{ (_("foo"), _(), ngettext("foo", "bar", 42)) }}')
>>> list(extract_from_ast(node))
[(1, '_', 'foo'), (1, '_', ()), (1, 'ngettext', ('foo', 'bar', None))]
>>> list(extract_from_ast(node, babel_style=False))
[(1, '_', ('foo',)), (1, 'ngettext', ('foo', 'bar'))]

For every string found this function yields a ``(lineno, function,
message)`` tuple, where:

* ``lineno`` is the number of the line on which the string was found,
* ``function`` is the name of the ``gettext`` function used (if the
string was extracted from embedded Python code), and
*   ``message`` is the string, or a tuple of strings for functions
with multiple string arguments.

This extraction function operates on the AST and is because of that unable
to extract any comments.  For comment support you have to use the babel
extraction interface or extract comments yourself.

**Line:** 655

---

### `def babel_extract(fileobj: t.BinaryIO, keywords: t.Sequence[str], comment_tags: t.Sequence[str], options: t.Dict[(str, t.Any)]) -> t.Iterator[t.Tuple[(int, str, t.Union[t.Optional[str], t.Tuple[t.Optional[str], ...]], t.List[str])]]`

**Description:**
Babel extraction method for Jinja templates.

.. versionchanged:: 2.3
Basic support for translation comments was added.  If `comment_tags`
is now set to a list of keywords for extraction, the extractor will
try to find the best preceding comment that begins with one of the
keywords.  For best results, make sure to not have more than one
gettext call in one line of code and the matching comment in the
same line or the line before.

.. versionchanged:: 2.5.1
The `newstyle_gettext` flag can be set to `True` to enable newstyle
gettext calls.

.. versionchanged:: 2.7
A `silent` option can now be provided.  If set to `False` template
syntax errors are propagated instead of being ignored.

:param fileobj: the file-like object the messages should be extracted from
:param keywords: a list of keywords (i.e. function names) that should be
recognized as translation functions
:param comment_tags: a list of translator tags to search for and include
in the results.
:param options: a dictionary of additional options (optional)
:return: an iterator over ``(lineno, funcname, message, comments)`` tuples.
(comments will be empty currently)

**Line:** 774

---


## Module: venv2.libthon3.12.site-packages.jinja2.filters
**File:** `venv2/lib/python3.12/site-packages/jinja2/filters.py`

**Imports:**
- async_utils.async_variant
- async_utils.auto_aiter
- async_utils.auto_await
- async_utils.auto_to_list
- collections.abc
- environment.Environment
- exceptions.FilterArgumentError
- inspect.getattr_static
- itertools.chain
- itertools.groupby
- markupsafe.Markup
- markupsafe.escape
- markupsafe.soft_str
- math
- nodes.EvalContext
- random
- re
- runtime.Context
- runtime.Undefined
- sandbox.SandboxedEnvironment
- textwrap
- typing
- typing_extensions
- utils.htmlsafe_json_dumps
- utils.pass_context
- utils.pass_environment
- utils.pass_eval_context
- utils.pformat
- utils.url_quote
- utils.urlize

**Functions:**

### `def ignore_case(value: V) -> V`

**Description:**
For use as a postprocessor for :func:`make_attrgetter`. Converts strings
to lowercase and returns other types as-is.

**Line:** 49

---

### `def make_attrgetter(environment: 'Environment', attribute: t.Optional[t.Union[(str, int)]], postprocess: t.Optional[t.Callable[([t.Any], t.Any)]] = None, default: t.Optional[t.Any] = None) -> t.Callable[([t.Any], t.Any)]`

**Description:**
Returns a callable that looks up the given attribute from a
passed object with the rules of the environment.  Dots are allowed
to access attributes of attributes.  Integer parts in paths are
looked up as integers.

**Line:** 58

---

### `def make_multi_attrgetter(environment: 'Environment', attribute: t.Optional[t.Union[(str, int)]], postprocess: t.Optional[t.Callable[([t.Any], t.Any)]] = None) -> t.Callable[([t.Any], t.List[t.Any])]`

**Description:**
Returns a callable that looks up the given comma separated
attributes from a passed object with the rules of the environment.
Dots are allowed to access attributes of each attribute.  Integer
parts in paths are looked up as integers.

The value returned by the returned callable is a list of extracted
attribute values.

Examples of attribute: "attr1,attr2", "attr1.inner1.0,attr2.inner2.0", etc.

**Line:** 86

---

### `def _prepare_attribute_parts(attr: t.Optional[t.Union[(str, int)]]) -> t.List[t.Union[(str, int)]]`

**Line:** 127

---

### `def do_forceescape(value: 't.Union[str, HasHTML]') -> Markup`

**Description:**
Enforce HTML escaping.  This will probably double escape variables.

**Line:** 139

---

### `def do_urlencode(value: t.Union[(str, t.Mapping[str, t.Any], t.Iterable[t.Tuple[str, t.Any]])]) -> str`

**Description:**
Quote data for use in a URL path or query using UTF-8.

Basic wrapper around :func:`urllib.parse.quote` when given a
string, or :func:`urllib.parse.urlencode` for a dict or iterable.

:param value: Data to quote. A string will be quoted directly. A
dict or iterable of ``(key, value)`` pairs will be joined as a
query string.

When given a string, "/" is not quoted. HTTP servers treat "/" and
"%2F" equivalently in paths. If you need quoted slashes, use the
``|replace("/", "%2F")`` filter.

.. versionadded:: 2.7

**Line:** 147

---

### `def do_replace(eval_ctx: 'EvalContext', s: str, old: str, new: str, count: t.Optional[int] = None) -> str`

**Decorators:**
- `@pass_eval_context`

**Description:**
Return a copy of the value with all occurrences of a substring
replaced with a new one. The first argument is the substring
that should be replaced, the second is the replacement string.
If the optional third argument ``count`` is given, only the first
``count`` occurrences are replaced:

.. sourcecode:: jinja

{{ "Hello World"|replace("Hello", "Goodbye") }}
-> Goodbye World

{{ "aaaaargh"|replace("a", "d'oh, ", 2) }}
-> d'oh, d'oh, aaargh

**Line:** 179

---

### `def do_upper(s: str) -> str`

**Description:**
Convert a value to uppercase.

**Line:** 214

---

### `def do_lower(s: str) -> str`

**Description:**
Convert a value to lowercase.

**Line:** 219

---

### `def do_items(value: t.Union[(t.Mapping[K, V], Undefined)]) -> t.Iterator[t.Tuple[(K, V)]]`

**Description:**
Return an iterator over the ``(key, value)`` items of a mapping.

``x|items`` is the same as ``x.items()``, except if ``x`` is
undefined an empty iterator is returned.

This filter is useful if you expect the template to be rendered with
an implementation of Jinja in another programming language that does
not have a ``.items()`` method on its mapping type.

.. code-block:: html+jinja

<dl>
{% for key, value in my_dict|items %}
<dt>{{ key }}
<dd>{{ value }}
{% endfor %}
</dl>

.. versionadded:: 3.1

**Line:** 224

---

### `def do_xmlattr(eval_ctx: 'EvalContext', d: t.Mapping[(str, t.Any)], autospace: bool = True) -> str`

**Decorators:**
- `@pass_eval_context`

**Description:**
Create an SGML/XML attribute string based on the items in a dict.

**Values** that are neither ``none`` nor ``undefined`` are automatically
escaped, safely allowing untrusted user input.

User input should not be used as **keys** to this filter. If any key
contains a space, ``/`` solidus, ``>`` greater-than sign, or ``=`` equals
sign, this fails with a ``ValueError``. Regardless of this, user input
should never be used as keys to this filter, or must be separately validated
first.

.. sourcecode:: html+jinja

<ul{{ {'class': 'my_list', 'missing': none,
'id': 'list-%d'|format(variable)}|xmlattr }}>
...
</ul>

Results in something like this:

.. sourcecode:: html

<ul class="my_list" id="list-42">
...
</ul>

As you can see it automatically prepends a space in front of the item
if the filter returned something unless the second parameter is false.

.. versionchanged:: 3.1.4
Keys with ``/`` solidus, ``>`` greater-than sign, or ``=`` equals sign
are not allowed.

.. versionchanged:: 3.1.3
Keys with spaces are not allowed.

**Line:** 260

---

### `def do_capitalize(s: str) -> str`

**Description:**
Capitalize a value. The first character will be uppercase, all others
lowercase.

**Line:** 321

---

### `def do_title(s: str) -> str`

**Description:**
Return a titlecased version of the value. I.e. words will start with
uppercase letters, all remaining characters are lowercase.

**Line:** 331

---

### `def do_dictsort(value: t.Mapping[(K, V)], case_sensitive: bool = False, by: 'te.Literal["key", "value"]' = 'key', reverse: bool = False) -> t.List[t.Tuple[(K, V)]]`

**Description:**
Sort a dict and yield (key, value) pairs. Python dicts may not
be in the order you want to display them in, so sort them first.

.. sourcecode:: jinja

{% for key, value in mydict|dictsort %}
sort the dict by key, case insensitive

{% for key, value in mydict|dictsort(reverse=true) %}
sort the dict by key, case insensitive, reverse order

{% for key, value in mydict|dictsort(true) %}
sort the dict by key, case sensitive

{% for key, value in mydict|dictsort(false, 'value') %}
sort the dict by value, case insensitive

**Line:** 344

---

### `def do_sort(environment: 'Environment', value: 't.Iterable[V]', reverse: bool = False, case_sensitive: bool = False, attribute: t.Optional[t.Union[(str, int)]] = None) -> 't.List[V]'`

**Decorators:**
- `@pass_environment`

**Description:**
Sort an iterable using Python's :func:`sorted`.

.. sourcecode:: jinja

{% for city in cities|sort %}
...
{% endfor %}

:param reverse: Sort descending instead of ascending.
:param case_sensitive: When sorting strings, sort upper and lower
case separately.
:param attribute: When sorting objects or dicts, an attribute or
key to sort by. Can use dot notation like ``"address.city"``.
Can be a list of attributes like ``"age,name"``.

The sort is stable, it does not change the relative order of
elements that compare equal. This makes it is possible to chain
sorts on different attributes and ordering.

.. sourcecode:: jinja

{% for user in users|sort(attribute="name")
|sort(reverse=true, attribute="age") %}
...
{% endfor %}

As a shortcut to chaining when the direction is the same for all
attributes, pass a comma separate list of attributes.

.. sourcecode:: jinja

{% for user in users|sort(attribute="age,name") %}
...
{% endfor %}

.. versionchanged:: 2.11.0
The ``attribute`` parameter can be a comma separated list of
attributes, e.g. ``"age,name"``.

.. versionchanged:: 2.6
The ``attribute`` parameter was added.

**Line:** 386

---

### `def sync_do_unique(environment: 'Environment', value: 't.Iterable[V]', case_sensitive: bool = False, attribute: t.Optional[t.Union[(str, int)]] = None) -> 't.Iterator[V]'`

**Decorators:**
- `@pass_environment`

**Description:**
Returns a list of unique items from the given iterable.

.. sourcecode:: jinja

{{ ['foo', 'bar', 'foobar', 'FooBar']|unique|list }}
-> ['foo', 'bar', 'foobar']

The unique items are yielded in the same order as their first occurrence in
the iterable passed to the filter.

:param case_sensitive: Treat upper and lower case strings as distinct.
:param attribute: Filter objects with unique values for this attribute.

**Line:** 442

---

### `async def do_unique(environment: 'Environment', value: 't.Union[t.AsyncIterable[V], t.Iterable[V]]', case_sensitive: bool = False, attribute: t.Optional[t.Union[(str, int)]] = None) -> 't.Iterator[V]'`

**Decorators:**
- `@async_variant(...)`

**Line:** 475

---

### `def _min_or_max(environment: 'Environment', value: 't.Iterable[V]', func: 't.Callable[..., V]', case_sensitive: bool, attribute: t.Optional[t.Union[(str, int)]]) -> 't.Union[V, Undefined]'`

**Line:** 486

---

### `def do_min(environment: 'Environment', value: 't.Iterable[V]', case_sensitive: bool = False, attribute: t.Optional[t.Union[(str, int)]] = None) -> 't.Union[V, Undefined]'`

**Decorators:**
- `@pass_environment`

**Description:**
Return the smallest item from the sequence.

.. sourcecode:: jinja

{{ [1, 2, 3]|min }}
-> 1

:param case_sensitive: Treat upper and lower case strings as distinct.
:param attribute: Get the object with the min value of this attribute.

**Line:** 507

---

### `def do_max(environment: 'Environment', value: 't.Iterable[V]', case_sensitive: bool = False, attribute: t.Optional[t.Union[(str, int)]] = None) -> 't.Union[V, Undefined]'`

**Decorators:**
- `@pass_environment`

**Description:**
Return the largest item from the sequence.

.. sourcecode:: jinja

{{ [1, 2, 3]|max }}
-> 3

:param case_sensitive: Treat upper and lower case strings as distinct.
:param attribute: Get the object with the max value of this attribute.

**Line:** 527

---

### `def do_default(value: V, default_value: V = '', boolean: bool = False) -> V`

**Description:**
If the value is undefined it will return the passed default value,
otherwise the value of the variable:

.. sourcecode:: jinja

{{ my_variable|default('my_variable is not defined') }}

This will output the value of ``my_variable`` if the variable was
defined, otherwise ``'my_variable is not defined'``. If you want
to use default with variables that evaluate to false you have to
set the second parameter to `true`:

.. sourcecode:: jinja

{{ ''|default('the string was empty', true) }}

.. versionchanged:: 2.11
It's now possible to configure the :class:`~jinja2.Environment` with
:class:`~jinja2.ChainableUndefined` to make the `default` filter work
on nested elements and attributes that may contain undefined values
in the chain without getting an :exc:`~jinja2.UndefinedError`.

**Line:** 546

---

### `def sync_do_join(eval_ctx: 'EvalContext', value: t.Iterable[t.Any], d: str = '', attribute: t.Optional[t.Union[(str, int)]] = None) -> str`

**Decorators:**
- `@pass_eval_context`

**Description:**
Return a string which is the concatenation of the strings in the
sequence. The separator between elements is an empty string per
default, you can define it with the optional parameter:

.. sourcecode:: jinja

{{ [1, 2, 3]|join('|') }}
-> 1|2|3

{{ [1, 2, 3]|join }}
-> 123

It is also possible to join certain attributes of an object:

.. sourcecode:: jinja

{{ users|join(', ', attribute='username') }}

.. versionadded:: 2.6
The `attribute` parameter was added.

**Line:** 580

---

### `async def do_join(eval_ctx: 'EvalContext', value: t.Union[(t.AsyncIterable[t.Any], t.Iterable[t.Any])], d: str = '', attribute: t.Optional[t.Union[(str, int)]] = None) -> str`

**Decorators:**
- `@async_variant(...)`

**Line:** 638

---

### `def do_center(value: str, width: int = 80) -> str`

**Description:**
Centers the value in a field of a given width.

**Line:** 647

---

### `def sync_do_first(environment: 'Environment', seq: 't.Iterable[V]') -> 't.Union[V, Undefined]'`

**Decorators:**
- `@pass_environment`

**Description:**
Return the first item of a sequence.

**Line:** 653

---

### `async def do_first(environment: 'Environment', seq: 't.Union[t.AsyncIterable[V], t.Iterable[V]]') -> 't.Union[V, Undefined]'`

**Decorators:**
- `@async_variant(...)`

**Line:** 664

---

### `def do_last(environment: 'Environment', seq: 't.Reversible[V]') -> 't.Union[V, Undefined]'`

**Decorators:**
- `@pass_environment`

**Description:**
Return the last item of a sequence.

Note: Does not work with generators. You may want to explicitly
convert it to a list:

.. sourcecode:: jinja

{{ data | selectattr('name', '==', 'Jinja') | list | last }}

**Line:** 674

---

### `def do_random(context: 'Context', seq: 't.Sequence[V]') -> 't.Union[V, Undefined]'`

**Decorators:**
- `@pass_context`

**Description:**
Return a random item from the sequence.

**Line:** 696

---

### `def do_filesizeformat(value: t.Union[(str, float, int)], binary: bool = False) -> str`

**Description:**
Format the value like a 'human-readable' file size (i.e. 13 kB,
4.1 MB, 102 Bytes, etc).  Per default decimal prefixes are used (Mega,
Giga, etc.), if the second parameter is set to `True` the binary
prefixes are used (Mebi, Gibi).

**Line:** 704

---

### `def do_pprint(value: t.Any) -> str`

**Description:**
Pretty print a variable. Useful for debugging.

**Line:** 737

---

### `def do_urlize(eval_ctx: 'EvalContext', value: str, trim_url_limit: t.Optional[int] = None, nofollow: bool = False, target: t.Optional[str] = None, rel: t.Optional[str] = None, extra_schemes: t.Optional[t.Iterable[str]] = None) -> str`

**Decorators:**
- `@pass_eval_context`

**Description:**
Convert URLs in text into clickable links.

This may not recognize links in some situations. Usually, a more
comprehensive formatter, such as a Markdown library, is a better
choice.

Works on ``http://``, ``https://``, ``www.``, ``mailto:``, and email
addresses. Links with trailing punctuation (periods, commas, closing
parentheses) and leading punctuation (opening parentheses) are
recognized excluding the punctuation. Email addresses that include
header fields are not recognized (for example,
``mailto:address@example.com?cc=copy@example.com``).

:param value: Original text containing URLs to link.
:param trim_url_limit: Shorten displayed URL values to this length.
:param nofollow: Add the ``rel=nofollow`` attribute to links.
:param target: Add the ``target`` attribute to links.
:param rel: Add the ``rel`` attribute to links.
:param extra_schemes: Recognize URLs that start with these schemes
in addition to the default behavior. Defaults to
``env.policies["urlize.extra_schemes"]``, which defaults to no
extra schemes.

.. versionchanged:: 3.0
The ``extra_schemes`` parameter was added.

.. versionchanged:: 3.0
Generate ``https://`` links for URLs without a scheme.

.. versionchanged:: 3.0
The parsing rules were updated. Recognize email addresses with
or without the ``mailto:`` scheme. Validate IP addresses. Ignore
parentheses and brackets in more cases.

.. versionchanged:: 2.8
The ``target`` parameter was added.

**Line:** 746

---

### `def do_indent(s: str, width: t.Union[(int, str)] = 4, first: bool = False, blank: bool = False) -> str`

**Description:**
Return a copy of the string with each line indented by 4 spaces. The
first line and blank lines are not indented by default.

:param width: Number of spaces, or a string, to indent by.
:param first: Don't skip indenting the first line.
:param blank: Don't skip indenting empty lines.

.. versionchanged:: 3.0
``width`` can be a string.

.. versionchanged:: 2.10
Blank lines are not indented by default.

Rename the ``indentfirst`` argument to ``first``.

**Line:** 825

---

### `def do_truncate(env: 'Environment', s: str, length: int = 255, killwords: bool = False, end: str = '...', leeway: t.Optional[int] = None) -> str`

**Decorators:**
- `@pass_environment`

**Description:**
Return a truncated copy of the string. The length is specified
with the first parameter which defaults to ``255``. If the second
parameter is ``true`` the filter will cut the text at length. Otherwise
it will discard the last word. If the text was in fact
truncated it will append an ellipsis sign (``"..."``). If you want a
different ellipsis sign than ``"..."`` you can specify it using the
third parameter. Strings that only exceed the length by the tolerance
margin given in the fourth parameter will not be truncated.

.. sourcecode:: jinja

{{ "foo bar baz qux"|truncate(9) }}
-> "foo..."
{{ "foo bar baz qux"|truncate(9, True) }}
-> "foo ba..."
{{ "foo bar baz qux"|truncate(11) }}
-> "foo bar baz qux"
{{ "foo bar baz qux"|truncate(11, False, '...', 0) }}
-> "foo bar..."

The default leeway on newer Jinja versions is 5 and was 0 before but
can be reconfigured globally.

**Line:** 874

---

### `def do_wordwrap(environment: 'Environment', s: str, width: int = 79, break_long_words: bool = True, wrapstring: t.Optional[str] = None, break_on_hyphens: bool = True) -> str`

**Decorators:**
- `@pass_environment`

**Description:**
Wrap a string to the given width. Existing newlines are treated
as paragraphs to be wrapped separately.

:param s: Original text to wrap.
:param width: Maximum length of wrapped lines.
:param break_long_words: If a word is longer than ``width``, break
it across lines.
:param break_on_hyphens: If a word contains hyphens, it may be split
across lines.
:param wrapstring: String to join each wrapped line. Defaults to
:attr:`Environment.newline_sequence`.

.. versionchanged:: 2.11
Existing newlines are treated as paragraphs wrapped separately.

.. versionchanged:: 2.11
Added the ``break_on_hyphens`` parameter.

.. versionchanged:: 2.7
Added the ``wrapstring`` parameter.

**Line:** 922

---

### `def do_wordcount(s: str) -> int`

**Description:**
Count the words in that string.

**Line:** 980

---

### `def do_int(value: t.Any, default: int = 0, base: int = 10) -> int`

**Description:**
Convert the value into an integer. If the
conversion doesn't work it will return ``0``. You can
override this default using the first parameter. You
can also override the default base (10) in the second
parameter, which handles input with prefixes such as
0b, 0o and 0x for bases 2, 8 and 16 respectively.
The base is ignored for decimal numbers and non-string values.

**Line:** 985

---

### `def do_float(value: t.Any, default: float = 0.0) -> float`

**Description:**
Convert the value into a floating point number. If the
conversion doesn't work it will return ``0.0``. You can
override this default using the first parameter.

**Line:** 1007

---

### `def do_format(value: str, *args: t.Any, **kwargs: t.Any) -> str`

**Description:**
Apply the given values to a `printf-style`_ format string, like
``string % values``.

.. sourcecode:: jinja

{{ "%s, %s!"|format(greeting, name) }}
Hello, World!

In most cases it should be more convenient and efficient to use the
``%`` operator or :meth:`str.format`.

.. code-block:: text

{{ "%s, %s!" % (greeting, name) }}
{{ "{}, {}!".format(greeting, name) }}

.. _printf-style: https://docs.python.org/library/stdtypes.html
#printf-style-string-formatting

**Line:** 1018

---

### `def do_trim(value: str, chars: t.Optional[str] = None) -> str`

**Description:**
Strip leading and trailing characters, by default whitespace.

**Line:** 1046

---

### `def do_striptags(value: 't.Union[str, HasHTML]') -> str`

**Description:**
Strip SGML/XML tags and replace adjacent whitespace by one space.

**Line:** 1051

---

### `def sync_do_slice(value: 't.Collection[V]', slices: int, fill_with: 't.Optional[V]' = None) -> 't.Iterator[t.List[V]]'`

**Description:**
Slice an iterator and return a list of lists containing
those items. Useful if you want to create a div containing
three ul tags that represent columns:

.. sourcecode:: html+jinja

<div class="columnwrapper">
{%- for column in items|slice(3) %}
<ul class="column-{{ loop.index }}">
{%- for item in column %}
<li>{{ item }}</li>
{%- endfor %}
</ul>
{%- endfor %}
</div>

If you pass it a second argument it's used to fill missing
values on the last iteration.

**Line:** 1059

---

### `async def do_slice(value: 't.Union[t.AsyncIterable[V], t.Iterable[V]]', slices: int, fill_with: t.Optional[t.Any] = None) -> 't.Iterator[t.List[V]]'`

**Decorators:**
- `@async_variant(...)`

**Line:** 1103

---

### `def do_batch(value: 't.Iterable[V]', linecount: int, fill_with: 't.Optional[V]' = None) -> 't.Iterator[t.List[V]]'`

**Description:**
A filter that batches items. It works pretty much like `slice`
just the other way round. It returns a list of lists with the
given number of items. If you provide a second parameter this
is used to fill up missing items. See this example:

.. sourcecode:: html+jinja

<table>
{%- for row in items|batch(3, '&nbsp;') %}
<tr>
{%- for column in row %}
<td>{{ column }}</td>
{%- endfor %}
</tr>
{%- endfor %}
</table>

**Line:** 1111

---

### `def do_round(value: float, precision: int = 0, method: 'te.Literal["common", "ceil", "floor"]' = 'common') -> float`

**Description:**
Round the number to a given precision. The first
parameter specifies the precision (default is ``0``), the
second the rounding method:

- ``'common'`` rounds either up or down
- ``'ceil'`` always rounds up
- ``'floor'`` always rounds down

If you don't specify a method ``'common'`` is used.

.. sourcecode:: jinja

{{ 42.55|round }}
-> 43.0
{{ 42.55|round(1, 'floor') }}
-> 42.5

Note that even if rounded to 0 precision, a float is returned.  If
you need a real integer, pipe it through `int`:

.. sourcecode:: jinja

{{ 42.55|round|int }}
-> 43

**Line:** 1148

---

### `def sync_do_groupby(environment: 'Environment', value: 't.Iterable[V]', attribute: t.Union[(str, int)], default: t.Optional[t.Any] = None, case_sensitive: bool = False) -> 't.List[_GroupTuple]'`

**Decorators:**
- `@pass_environment`

**Description:**
Group a sequence of objects by an attribute using Python's
:func:`itertools.groupby`. The attribute can use dot notation for
nested access, like ``"address.city"``. Unlike Python's ``groupby``,
the values are sorted first so only one group is returned for each
unique value.

For example, a list of ``User`` objects with a ``city`` attribute
can be rendered in groups. In this example, ``grouper`` refers to
the ``city`` value of the group.

.. sourcecode:: html+jinja

<ul>{% for city, items in users|groupby("city") %}
<li>{{ city }}
<ul>{% for user in items %}
<li>{{ user.name }}
{% endfor %}</ul>
</li>
{% endfor %}</ul>

``groupby`` yields namedtuples of ``(grouper, list)``, which
can be used instead of the tuple unpacking above. ``grouper`` is the
value of the attribute, and ``list`` is the items with that value.

.. sourcecode:: html+jinja

<ul>{% for group in users|groupby("city") %}
<li>{{ group.grouper }}: {{ group.list|join(", ") }}
{% endfor %}</ul>

You can specify a ``default`` value to use if an object in the list
does not have the given attribute.

.. sourcecode:: jinja

<ul>{% for city, items in users|groupby("city", default="NY") %}
<li>{{ city }}: {{ items|map(attribute="name")|join(", ") }}</li>
{% endfor %}</ul>

Like the :func:`~jinja-filters.sort` filter, sorting and grouping is
case-insensitive by default. The ``key`` for each group will have
the case of the first item in that group of values. For example, if
a list of users has cities ``["CA", "NY", "ca"]``, the "CA" group
will have two values. This can be disabled by passing
``case_sensitive=True``.

.. versionchanged:: 3.1
Added the ``case_sensitive`` parameter. Sorting and grouping is
case-insensitive by default, matching other filters that do
comparisons.

.. versionchanged:: 3.0
Added the ``default`` parameter.

.. versionchanged:: 2.6
The attribute supports dot notation for nested access.

**Line:** 1202

---

### `async def do_groupby(environment: 'Environment', value: 't.Union[t.AsyncIterable[V], t.Iterable[V]]', attribute: t.Union[(str, int)], default: t.Optional[t.Any] = None, case_sensitive: bool = False) -> 't.List[_GroupTuple]'`

**Decorators:**
- `@async_variant(...)`

**Line:** 1286

---

### `def sync_do_sum(environment: 'Environment', iterable: 't.Iterable[V]', attribute: t.Optional[t.Union[(str, int)]] = None, start: V = 0) -> V`

**Decorators:**
- `@pass_environment`

**Description:**
Returns the sum of a sequence of numbers plus the value of parameter
'start' (which defaults to 0).  When the sequence is empty it returns
start.

It is also possible to sum up only certain attributes:

.. sourcecode:: jinja

Total: {{ items|sum(attribute='price') }}

.. versionchanged:: 2.6
The ``attribute`` parameter was added to allow summing up over
attributes.  Also the ``start`` parameter was moved on to the right.

**Line:** 1313

---

### `async def do_sum(environment: 'Environment', iterable: 't.Union[t.AsyncIterable[V], t.Iterable[V]]', attribute: t.Optional[t.Union[(str, int)]] = None, start: V = 0) -> V`

**Decorators:**
- `@async_variant(...)`

**Line:** 1340

---

### `def sync_do_list(value: 't.Iterable[V]') -> 't.List[V]'`

**Description:**
Convert the value into a list.  If it was a string the returned list
will be a list of characters.

**Line:** 1361

---

### `async def do_list(value: 't.Union[t.AsyncIterable[V], t.Iterable[V]]') -> 't.List[V]'`

**Decorators:**
- `@async_variant(...)`

**Line:** 1369

---

### `def do_mark_safe(value: str) -> Markup`

**Description:**
Mark the value as safe which means that in an environment with automatic
escaping enabled this variable will not be escaped.

**Line:** 1373

---

### `def do_mark_unsafe(value: str) -> str`

**Description:**
Mark a value as unsafe.  This is the reverse operation for :func:`safe`.

**Line:** 1380

---

### `def do_reverse(value: str) -> str`

**Decorators:**
- `@typing.overload`

**Line:** 1386

---

### `def do_reverse(value: 't.Iterable[V]') -> 't.Iterable[V]'`

**Decorators:**
- `@typing.overload`

**Line:** 1390

---

### `def do_reverse(value: t.Union[(str, t.Iterable[V])]) -> t.Union[(str, t.Iterable[V])]`

**Description:**
Reverse the object or return an iterator that iterates over it the other
way round.

**Line:** 1393

---

### `def do_attr(environment: 'Environment', obj: t.Any, name: str) -> t.Union[(Undefined, t.Any)]`

**Decorators:**
- `@pass_environment`

**Description:**
Get an attribute of an object. ``foo|attr("bar")`` works like
``foo.bar``, but returns undefined instead of falling back to ``foo["bar"]``
if the attribute doesn't exist.

See :ref:`Notes on subscriptions <notes-on-subscriptions>` for more details.

**Line:** 1412

---

### `def sync_do_map(context: 'Context', value: t.Iterable[t.Any], name: str, *args: t.Any, **kwargs: t.Any) -> t.Iterable[t.Any]`

**Decorators:**
- `@typing.overload`

**Line:** 1437

---

### `def sync_do_map(context: 'Context', value: t.Iterable[t.Any], attribute: str = Ellipsis, default: t.Optional[t.Any] = None) -> t.Iterable[t.Any]`

**Decorators:**
- `@typing.overload`

**Line:** 1447

---

### `def sync_do_map(context: 'Context', value: t.Iterable[t.Any], *args: t.Any, **kwargs: t.Any) -> t.Iterable[t.Any]`

**Decorators:**
- `@pass_context`

**Description:**
Applies a filter on a sequence of objects or looks up an attribute.
This is useful when dealing with lists of objects but you are really
only interested in a certain value of it.

The basic usage is mapping on an attribute.  Imagine you have a list
of users but you are only interested in a list of usernames:

.. sourcecode:: jinja

Users on this page: {{ users|map(attribute='username')|join(', ') }}

You can specify a ``default`` value to use if an object in the list
does not have the given attribute.

.. sourcecode:: jinja

{{ users|map(attribute="username", default="Anonymous")|join(", ") }}

Alternatively you can let it invoke a filter by passing the name of the
filter and the arguments afterwards.  A good example would be applying a
text conversion filter on a sequence:

.. sourcecode:: jinja

Users on this page: {{ titles|map('lower')|join(', ') }}

Similar to a generator comprehension such as:

.. code-block:: python

(u.username for u in users)
(getattr(u, "username", "Anonymous") for u in users)
(do_lower(x) for x in titles)

.. versionchanged:: 2.11.0
Added the ``default`` parameter.

.. versionadded:: 2.7

**Line:** 1457

---

### `def do_map(context: 'Context', value: t.Union[(t.AsyncIterable[t.Any], t.Iterable[t.Any])], name: str, *args: t.Any, **kwargs: t.Any) -> t.Iterable[t.Any]`

**Decorators:**
- `@typing.overload`

**Line:** 1507

---

### `def do_map(context: 'Context', value: t.Union[(t.AsyncIterable[t.Any], t.Iterable[t.Any])], attribute: str = Ellipsis, default: t.Optional[t.Any] = None) -> t.Iterable[t.Any]`

**Decorators:**
- `@typing.overload`

**Line:** 1517

---

### `async def do_map(context: 'Context', value: t.Union[(t.AsyncIterable[t.Any], t.Iterable[t.Any])], *args: t.Any, **kwargs: t.Any) -> t.AsyncIterable[t.Any]`

**Decorators:**
- `@async_variant(...)`

**Line:** 1527

---

### `def sync_do_select(context: 'Context', value: 't.Iterable[V]', *args: t.Any, **kwargs: t.Any) -> 't.Iterator[V]'`

**Decorators:**
- `@pass_context`

**Description:**
Filters a sequence of objects by applying a test to each object,
and only selecting the objects with the test succeeding.

If no test is specified, each object will be evaluated as a boolean.

Example usage:

.. sourcecode:: jinja

{{ numbers|select("odd") }}
{{ numbers|select("odd") }}
{{ numbers|select("divisibleby", 3) }}
{{ numbers|select("lessthan", 42) }}
{{ strings|select("equalto", "mystring") }}

Similar to a generator comprehension such as:

.. code-block:: python

(n for n in numbers if test_odd(n))
(n for n in numbers if test_divisibleby(n, 3))

.. versionadded:: 2.7

**Line:** 1541

---

### `async def do_select(context: 'Context', value: 't.Union[t.AsyncIterable[V], t.Iterable[V]]', *args: t.Any, **kwargs: t.Any) -> 't.AsyncIterator[V]'`

**Decorators:**
- `@async_variant(...)`

**Line:** 1572

---

### `def sync_do_reject(context: 'Context', value: 't.Iterable[V]', *args: t.Any, **kwargs: t.Any) -> 't.Iterator[V]'`

**Decorators:**
- `@pass_context`

**Description:**
Filters a sequence of objects by applying a test to each object,
and rejecting the objects with the test succeeding.

If no test is specified, each object will be evaluated as a boolean.

Example usage:

.. sourcecode:: jinja

{{ numbers|reject("odd") }}

Similar to a generator comprehension such as:

.. code-block:: python

(n for n in numbers if not test_odd(n))

.. versionadded:: 2.7

**Line:** 1582

---

### `async def do_reject(context: 'Context', value: 't.Union[t.AsyncIterable[V], t.Iterable[V]]', *args: t.Any, **kwargs: t.Any) -> 't.AsyncIterator[V]'`

**Decorators:**
- `@async_variant(...)`

**Line:** 1608

---

### `def sync_do_selectattr(context: 'Context', value: 't.Iterable[V]', *args: t.Any, **kwargs: t.Any) -> 't.Iterator[V]'`

**Decorators:**
- `@pass_context`

**Description:**
Filters a sequence of objects by applying a test to the specified
attribute of each object, and only selecting the objects with the
test succeeding.

If no test is specified, the attribute's value will be evaluated as
a boolean.

Example usage:

.. sourcecode:: jinja

{{ users|selectattr("is_active") }}
{{ users|selectattr("email", "none") }}

Similar to a generator comprehension such as:

.. code-block:: python

(user for user in users if user.is_active)
(user for user in users if test_none(user.email))

.. versionadded:: 2.7

**Line:** 1618

---

### `async def do_selectattr(context: 'Context', value: 't.Union[t.AsyncIterable[V], t.Iterable[V]]', *args: t.Any, **kwargs: t.Any) -> 't.AsyncIterator[V]'`

**Decorators:**
- `@async_variant(...)`

**Line:** 1648

---

### `def sync_do_rejectattr(context: 'Context', value: 't.Iterable[V]', *args: t.Any, **kwargs: t.Any) -> 't.Iterator[V]'`

**Decorators:**
- `@pass_context`

**Description:**
Filters a sequence of objects by applying a test to the specified
attribute of each object, and rejecting the objects with the test
succeeding.

If no test is specified, the attribute's value will be evaluated as
a boolean.

.. sourcecode:: jinja

{{ users|rejectattr("is_active") }}
{{ users|rejectattr("email", "none") }}

Similar to a generator comprehension such as:

.. code-block:: python

(user for user in users if not user.is_active)
(user for user in users if not test_none(user.email))

.. versionadded:: 2.7

**Line:** 1658

---

### `async def do_rejectattr(context: 'Context', value: 't.Union[t.AsyncIterable[V], t.Iterable[V]]', *args: t.Any, **kwargs: t.Any) -> 't.AsyncIterator[V]'`

**Decorators:**
- `@async_variant(...)`

**Line:** 1686

---

### `def do_tojson(eval_ctx: 'EvalContext', value: t.Any, indent: t.Optional[int] = None) -> Markup`

**Decorators:**
- `@pass_eval_context`

**Description:**
Serialize an object to a string of JSON, and mark it safe to
render in HTML. This filter is only for use in HTML documents.

The returned string is safe to render in HTML documents and
``<script>`` tags. The exception is in HTML attributes that are
double quoted; either use single quotes or the ``|forceescape``
filter.

:param value: The object to serialize to JSON.
:param indent: The ``indent`` parameter passed to ``dumps``, for
pretty-printing the value.

.. versionadded:: 2.9

**Line:** 1696

---

### `def prepare_map(context: 'Context', args: t.Tuple[(t.Any, ...)], kwargs: t.Dict[(str, t.Any)]) -> t.Callable[([t.Any], t.Any)]`

**Line:** 1724

---

### `def prepare_select_or_reject(context: 'Context', args: t.Tuple[(t.Any, ...)], kwargs: t.Dict[(str, t.Any)], modfunc: t.Callable[([t.Any], t.Any)], lookup_attr: bool) -> t.Callable[([t.Any], t.Any)]`

**Line:** 1752

---

### `def select_or_reject(context: 'Context', value: 't.Iterable[V]', args: t.Tuple[(t.Any, ...)], kwargs: t.Dict[(str, t.Any)], modfunc: t.Callable[([t.Any], t.Any)], lookup_attr: bool) -> 't.Iterator[V]'`

**Line:** 1786

---

### `async def async_select_or_reject(context: 'Context', value: 't.Union[t.AsyncIterable[V], t.Iterable[V]]', args: t.Tuple[(t.Any, ...)], kwargs: t.Dict[(str, t.Any)], modfunc: t.Callable[([t.Any], t.Any)], lookup_attr: bool) -> 't.AsyncIterator[V]'`

**Line:** 1802

---


## Module: venv2.libthon3.12.site-packages.jinja2.idtracking
**File:** `venv2/lib/python3.12/site-packages/jinja2/idtracking.py`

**Imports:**
- typing
- typing_extensions
- visitor.NodeVisitor

**Functions:**

### `def find_symbols(nodes: t.Iterable[nodes.Node], parent_symbols: t.Optional['Symbols'] = None) -> 'Symbols'`

**Line:** 15

---

### `def symbols_for_node(node: nodes.Node, parent_symbols: t.Optional['Symbols'] = None) -> 'Symbols'`

**Line:** 25

---


## Module: venv2.libthon3.12.site-packages.jinja2.lexer
**File:** `venv2/lib/python3.12/site-packages/jinja2/lexer.py`

**Imports:**
- _identifier.pattern
- ast.literal_eval
- collections.deque
- environment.Environment
- exceptions.TemplateSyntaxError
- re
- sys.intern
- typing
- typing_extensions
- utils.LRUCache

**Functions:**

### `def _describe_token_type(token_type: str) -> str`

**Line:** 165

---

### `def describe_token(token: 'Token') -> str`

**Description:**
Returns a description of the token.

**Line:** 185

---

### `def describe_token_expr(expr: str) -> str`

**Description:**
Like `describe_token` but for token expressions.

**Line:** 193

---

### `def count_newlines(value: str) -> int`

**Description:**
Count the number of newline characters in the string.  This is
useful for extensions that filter a stream.

**Line:** 206

---

### `def compile_rules(environment: 'Environment') -> t.List[t.Tuple[(str, str)]]`

**Description:**
Compiles all the rules from the environment into a list of rules.

**Line:** 213

---

### `def get_lexer(environment: 'Environment') -> 'Lexer'`

**Description:**
Return a lexer which is probably cached.

**Line:** 428

---


## Module: venv2.libthon3.12.site-packages.jinja2.loaders
**File:** `venv2/lib/python3.12/site-packages/jinja2/loaders.py`

**Imports:**
- collections.abc
- environment.Environment
- environment.Template
- exceptions.TemplateNotFound
- hashlib.sha1
- importlib.import_module
- importlib.util
- os
- posixpath
- sys
- types.ModuleType
- typing
- utils.internalcode
- weakref
- zipimport

**Functions:**

### `def split_template_path(template: str) -> t.List[str]`

**Description:**
Split a path into segments and perform a sanity check.  If it detects
'..' in the path it will raise a `TemplateNotFound` error.

**Line:** 25

---

### `def _get_zipimporter_files(z: t.Any) -> t.Dict[(str, object)]`

**Line:** 248

---

### `def _get_zipimporter_files(z: t.Any) -> t.Dict[(str, object)]`

**Line:** 259

---


## Module: venv2.libthon3.12.site-packages.jinja2.meta
**File:** `venv2/lib/python3.12/site-packages/jinja2/meta.py`

**Imports:**
- compiler.CodeGenerator
- compiler.Frame
- environment.Environment
- typing

**Functions:**

### `def find_undeclared_variables(ast: nodes.Template) -> t.Set[str]`

**Description:**
Returns a set of all variables in the AST that will be looked up from
the context at runtime.  Because at compile time it's not known which
variables will be used depending on the path the execution takes at
runtime, all variables are returned.

>>> from jinja2 import Environment, meta
>>> env = Environment()
>>> ast = env.parse('{% set foo = 42 %}{{ bar + foo }}')
>>> meta.find_undeclared_variables(ast) == {'bar'}
True

.. admonition:: Implementation

Internally the code generator is used for finding undeclared variables.
This is good to know because the code generator might raise a
:exc:`TemplateAssertionError` during compilation and as a matter of
fact this function can currently raise that exception as well.

**Line:** 34

---

### `def find_referenced_templates(ast: nodes.Template) -> t.Iterator[t.Optional[str]]`

**Description:**
Finds all the referenced templates from the AST.  This will return an
iterator over all the hardcoded template extensions, inclusions and
imports.  If dynamic inheritance or inclusion is used, `None` will be
yielded.

>>> from jinja2 import Environment, meta
>>> env = Environment()
>>> ast = env.parse('{% extends "layout.html" %}{% include helper %}')
>>> list(meta.find_referenced_templates(ast))
['layout.html', None]

This function is useful for dependency tracking.  For example if you want
to rebuild parts of the website after a layout template has changed.

**Line:** 62

---


## Module: venv2.libthon3.12.site-packages.jinja2.nativetypes
**File:** `venv2/lib/python3.12/site-packages/jinja2/nativetypes.py`

**Imports:**
- ast.literal_eval
- ast.parse
- compiler.CodeGenerator
- compiler.Frame
- compiler.has_safe_repr
- environment.Environment
- environment.Template
- itertools.chain
- itertools.islice
- types.GeneratorType
- typing

**Functions:**

### `def native_concat(values: t.Iterable[t.Any]) -> t.Optional[t.Any]`

**Description:**
Return a native Python type from the list of compiled nodes. If
the result is a single node, its value is returned. Otherwise, the
nodes are concatenated as strings. If the result can be parsed with
:func:`ast.literal_eval`, the parsed value is returned. Otherwise,
the string is returned.

:param values: Iterable of outputs to concatenate.

**Line:** 16

---


## Module: venv2.libthon3.12.site-packages.jinja2.nodes
**File:** `venv2/lib/python3.12/site-packages/jinja2/nodes.py`

**Imports:**
- collections.deque
- compiler.has_safe_repr
- environment.Environment
- inspect
- markupsafe.Markup
- operator
- typing
- typing_extensions
- utils._PassArg

**Functions:**

### `def get_eval_context(node: 'Node', ctx: t.Optional[EvalContext]) -> EvalContext`

**Line:** 94

---

### `def args_as_const(node: t.Union[('_FilterTestCommon', 'Call')], eval_ctx: t.Optional[EvalContext]) -> t.Tuple[(t.List[t.Any], t.Dict[t.Any, t.Any])]`

**Line:** 718

---

### `def _failing_new(*args: t.Any, **kwargs: t.Any) -> 'te.NoReturn'`

**Line:** 1201

---


## Module: venv2.libthon3.12.site-packages.jinja2.optimizer
**File:** `venv2/lib/python3.12/site-packages/jinja2/optimizer.py`

**Imports:**
- environment.Environment
- typing
- visitor.NodeTransformer

**Functions:**

### `def optimize(node: nodes.Node, environment: 'Environment') -> nodes.Node`

**Description:**
The context hint can be used to perform an static optimization
based on the context given.

**Line:** 20

---


## Module: venv2.libthon3.12.site-packages.jinja2.runtime
**File:** `venv2/lib/python3.12/site-packages/jinja2/runtime.py`

**Imports:**
- async_utils.auto_aiter
- async_utils.auto_await
- collections.abc
- environment.Environment
- exceptions.TemplateNotFound
- exceptions.TemplateRuntimeError
- exceptions.UndefinedError
- functools
- itertools.chain
- logging
- markupsafe.Markup
- markupsafe.escape
- markupsafe.soft_str
- nodes.EvalContext
- sys
- typing
- typing_extensions
- utils.Namespace
- utils._PassArg
- utils.concat
- utils.internalcode
- utils.missing
- utils.object_type_repr
- utils.pass_eval_context

**Functions:**

### `def identity(x: V) -> V`

**Description:**
Returns its argument. Useful for certain things in the
environment.

**Line:** 70

---

### `def markup_join(seq: t.Iterable[t.Any]) -> str`

**Description:**
Concatenation that escapes if necessary and converts to string.

**Line:** 77

---

### `def str_join(seq: t.Iterable[t.Any]) -> str`

**Description:**
Simple args to string conversion and concatenation.

**Line:** 88

---

### `def new_context(environment: 'Environment', template_name: t.Optional[str], blocks: t.Dict[(str, t.Callable[['Context'], t.Iterator[str]])], vars: t.Optional[t.Dict[(str, t.Any)]] = None, shared: bool = False, globals: t.Optional[t.MutableMapping[(str, t.Any)]] = None, locals: t.Optional[t.Mapping[(str, t.Any)]] = None) -> 'Context'`

**Description:**
Internal helper for context creation.

**Line:** 93

---

### `def _dict_method_all(dict_method: F) -> F`

**Line:** 136

---

### `def make_logging_undefined(logger: t.Optional['logging.Logger'] = None, base: t.Type[Undefined] = Undefined) -> t.Type[Undefined]`

**Description:**
Given a logger object this returns a new undefined class that will
log certain failures.  It will log iterations and printing.  If no
logger is given a default logger is created.

Example::

logger = logging.getLogger(__name__)
LoggingUndefined = make_logging_undefined(
logger=logger,
base=Undefined
)

.. versionadded:: 2.8

:param logger: the logger to use.  If not provided, a default logger
is created.
:param base: the base class to add logging functionality to.  This
defaults to :class:`Undefined`.

**Line:** 912

---


## Module: venv2.libthon3.12.site-packages.jinja2.sandbox
**File:** `venv2/lib/python3.12/site-packages/jinja2/sandbox.py`

**Imports:**
- _string.formatter_field_name_split
- collections.abc
- collections.deque
- environment.Environment
- exceptions.SecurityError
- functools.update_wrapper
- markupsafe.EscapeFormatter
- markupsafe.Markup
- operator
- runtime.Context
- runtime.Undefined
- string.Formatter
- types
- typing

**Functions:**

### `def safe_range(*args: int) -> range`

**Description:**
A range that can't generate ranges with a length of more than
MAX_RANGE items.

**Line:** 87

---

### `def unsafe(f: F) -> F`

**Description:**
Marks a function or method as unsafe.

.. code-block: python

@unsafe
def delete(self):
pass

**Line:** 102

---

### `def is_internal_attribute(obj: t.Any, attr: str) -> bool`

**Description:**
Test if the attribute given is an internal python attribute.  For
example this function returns `True` for the `func_code` attribute of
python objects.  This is useful if the environment method
:meth:`~SandboxedEnvironment.is_safe_attribute` is overridden.

>>> from jinja2.sandbox import is_internal_attribute
>>> is_internal_attribute(str, "mro")
True
>>> is_internal_attribute(str, "upper")
False

**Line:** 115

---

### `def modifies_known_mutable(obj: t.Any, attr: str) -> bool`

**Description:**
This function checks if an attribute on a builtin mutable object
(list, dict, set or deque) or the corresponding ABCs would modify it
if called.

>>> modifies_known_mutable({}, "clear")
True
>>> modifies_known_mutable({}, "keys")
False
>>> modifies_known_mutable([], "append")
True
>>> modifies_known_mutable([], "index")
False

If called with an unsupported object, ``False`` is returned.

>>> modifies_known_mutable("foo", "upper")
False

**Line:** 152

---


## Module: venv2.libthon3.12.site-packages.jinja2.tests
**File:** `venv2/lib/python3.12/site-packages/jinja2/tests.py`

**Imports:**
- collections.abc
- environment.Environment
- numbers.Number
- operator
- runtime.Undefined
- typing
- utils.pass_environment

**Functions:**

### `def test_odd(value: int) -> bool`

**Description:**
Return true if the variable is odd.

**Line:** 15

---

### `def test_even(value: int) -> bool`

**Description:**
Return true if the variable is even.

**Line:** 20

---

### `def test_divisibleby(value: int, num: int) -> bool`

**Description:**
Check if a variable is divisible by a number.

**Line:** 25

---

### `def test_defined(value: t.Any) -> bool`

**Description:**
Return true if the variable is defined:

.. sourcecode:: jinja

{% if variable is defined %}
value of variable: {{ variable }}
{% else %}
variable is not defined
{% endif %}

See the :func:`default` filter for a simple way to set undefined
variables.

**Line:** 30

---

### `def test_undefined(value: t.Any) -> bool`

**Description:**
Like :func:`defined` but the other way round.

**Line:** 47

---

### `def test_filter(env: 'Environment', value: str) -> bool`

**Decorators:**
- `@pass_environment`

**Description:**
Check if a filter exists by name. Useful if a filter may be
optionally available.

.. code-block:: jinja

{% if 'markdown' is filter %}
{{ value | markdown }}
{% else %}
{{ value }}
{% endif %}

.. versionadded:: 3.0

**Line:** 53

---

### `def test_test(env: 'Environment', value: str) -> bool`

**Decorators:**
- `@pass_environment`

**Description:**
Check if a test exists by name. Useful if a test may be
optionally available.

.. code-block:: jinja

{% if 'loud' is test %}
{% if value is loud %}
{{ value|upper }}
{% else %}
{{ value|lower }}
{% endif %}
{% else %}
{{ value }}
{% endif %}

.. versionadded:: 3.0

**Line:** 71

---

### `def test_none(value: t.Any) -> bool`

**Description:**
Return true if the variable is none.

**Line:** 92

---

### `def test_boolean(value: t.Any) -> bool`

**Description:**
Return true if the object is a boolean value.

.. versionadded:: 2.11

**Line:** 97

---

### `def test_false(value: t.Any) -> bool`

**Description:**
Return true if the object is False.

.. versionadded:: 2.11

**Line:** 105

---

### `def test_true(value: t.Any) -> bool`

**Description:**
Return true if the object is True.

.. versionadded:: 2.11

**Line:** 113

---

### `def test_integer(value: t.Any) -> bool`

**Description:**
Return true if the object is an integer.

.. versionadded:: 2.11

**Line:** 122

---

### `def test_float(value: t.Any) -> bool`

**Description:**
Return true if the object is a float.

.. versionadded:: 2.11

**Line:** 131

---

### `def test_lower(value: str) -> bool`

**Description:**
Return true if the variable is lowercased.

**Line:** 139

---

### `def test_upper(value: str) -> bool`

**Description:**
Return true if the variable is uppercased.

**Line:** 144

---

### `def test_string(value: t.Any) -> bool`

**Description:**
Return true if the object is a string.

**Line:** 149

---

### `def test_mapping(value: t.Any) -> bool`

**Description:**
Return true if the object is a mapping (dict etc.).

.. versionadded:: 2.6

**Line:** 154

---

### `def test_number(value: t.Any) -> bool`

**Description:**
Return true if the variable is a number.

**Line:** 162

---

### `def test_sequence(value: t.Any) -> bool`

**Description:**
Return true if the variable is a sequence. Sequences are variables
that are iterable.

**Line:** 167

---

### `def test_sameas(value: t.Any, other: t.Any) -> bool`

**Description:**
Check if an object points to the same memory address than another
object:

.. sourcecode:: jinja

{% if foo.attribute is sameas false %}
the foo attribute really is the `False` singleton
{% endif %}

**Line:** 180

---

### `def test_iterable(value: t.Any) -> bool`

**Description:**
Check if it's possible to iterate over an object.

**Line:** 193

---

### `def test_escaped(value: t.Any) -> bool`

**Description:**
Check if the value is escaped.

**Line:** 203

---

### `def test_in(value: t.Any, seq: t.Container[t.Any]) -> bool`

**Description:**
Check if value is in seq.

.. versionadded:: 2.10

**Line:** 208

---


## Module: venv2.libthon3.12.site-packages.jinja2.utils
**File:** `venv2/lib/python3.12/site-packages/jinja2/utils.py`

**Imports:**
- collections.abc
- collections.deque
- constants.LOREM_IPSUM_WORDS
- enum
- environment.get_spontaneous_environment
- json
- lexer._lexer_cache
- markupsafe
- os
- pprint.pformat
- random.choice
- random.randrange
- re
- runtime.Undefined
- threading.Lock
- types.CodeType
- typing
- typing_extensions
- urllib.parse.quote_from_bytes

**Functions:**

### `def pass_context(f: F) -> F`

**Description:**
Pass the :class:`~jinja2.runtime.Context` as the first argument
to the decorated function when called while rendering a template.

Can be used on functions, filters, and tests.

If only ``Context.eval_context`` is needed, use
:func:`pass_eval_context`. If only ``Context.environment`` is
needed, use :func:`pass_environment`.

.. versionadded:: 3.0.0
Replaces ``contextfunction`` and ``contextfilter``.

**Line:** 38

---

### `def pass_eval_context(f: F) -> F`

**Description:**
Pass the :class:`~jinja2.nodes.EvalContext` as the first argument
to the decorated function when called while rendering a template.
See :ref:`eval-context`.

Can be used on functions, filters, and tests.

If only ``EvalContext.environment`` is needed, use
:func:`pass_environment`.

.. versionadded:: 3.0.0
Replaces ``evalcontextfunction`` and ``evalcontextfilter``.

**Line:** 55

---

### `def pass_environment(f: F) -> F`

**Description:**
Pass the :class:`~jinja2.Environment` as the first argument to
the decorated function when called while rendering a template.

Can be used on functions, filters, and tests.

.. versionadded:: 3.0.0
Replaces ``environmentfunction`` and ``environmentfilter``.

**Line:** 72

---

### `def internalcode(f: F) -> F`

**Description:**
Marks the function as internally used

**Line:** 98

---

### `def is_undefined(obj: t.Any) -> bool`

**Description:**
Check if the object passed is undefined.  This does nothing more than
performing an instance check against :class:`Undefined` but looks nicer.
This can be used for custom filters or tests that want to react to
undefined variables.  For example a custom default filter can look like
this::

def default(var, default=''):
if is_undefined(var):
return default
return var

**Line:** 104

---

### `def consume(iterable: t.Iterable[t.Any]) -> None`

**Description:**
Consumes an iterable without doing anything with it.

**Line:** 121

---

### `def clear_caches() -> None`

**Description:**
Jinja keeps internal caches for environments and lexers.  These are
used so that Jinja doesn't have to recreate environments and lexers all
the time.  Normally you don't have to care about that but if you are
measuring memory consumption you may want to clean the caches.

**Line:** 127

---

### `def import_string(import_name: str, silent: bool = False) -> t.Any`

**Description:**
Imports an object based on a string.  This is useful if you want to
use import paths as endpoints or something similar.  An import path can
be specified either in dotted notation (``xml.sax.saxutils.escape``)
or with a colon as object delimiter (``xml.sax.saxutils:escape``).

If the `silent` is True the return value will be `None` if the import
fails.

:return: imported object

**Line:** 140

---

### `def open_if_exists(filename: str, mode: str = 'rb') -> t.Optional[t.IO[t.Any]]`

**Description:**
Returns a file descriptor for the filename if that file exists,
otherwise ``None``.

**Line:** 164

---

### `def object_type_repr(obj: t.Any) -> str`

**Description:**
Returns the name of the object's type.  For some recognized
singletons the name of the object is returned instead. (For
example for `None` and `Ellipsis`).

**Line:** 174

---

### `def pformat(obj: t.Any) -> str`

**Description:**
Format an object using :func:`pprint.pformat`.

**Line:** 192

---

### `def urlize(text: str, trim_url_limit: t.Optional[int] = None, rel: t.Optional[str] = None, target: t.Optional[str] = None, extra_schemes: t.Optional[t.Iterable[str]] = None) -> str`

**Description:**
Convert URLs in text into clickable links.

This may not recognize links in some situations. Usually, a more
comprehensive formatter, such as a Markdown library, is a better
choice.

Works on ``http://``, ``https://``, ``www.``, ``mailto:``, and email
addresses. Links with trailing punctuation (periods, commas, closing
parentheses) and leading punctuation (opening parentheses) are
recognized excluding the punctuation. Email addresses that include
header fields are not recognized (for example,
``mailto:address@example.com?cc=copy@example.com``).

:param text: Original text containing URLs to link.
:param trim_url_limit: Shorten displayed URL values to this length.
:param target: Add the ``target`` attribute to links.
:param rel: Add the ``rel`` attribute to links.
:param extra_schemes: Recognize URLs that start with these schemes
in addition to the default behavior.

.. versionchanged:: 3.0
The ``extra_schemes`` parameter was added.

.. versionchanged:: 3.0
Generate ``https://`` links for URLs without a scheme.

.. versionchanged:: 3.0
The parsing rules were updated. Recognize email addresses with
or without the ``mailto:`` scheme. Validate IP addresses. Ignore
parentheses and brackets in more cases.

**Line:** 230

---

### `def generate_lorem_ipsum(n: int = 5, html: bool = True, min: int = 20, max: int = 100) -> str`

**Description:**
Generate some lorem ipsum for the template.

**Line:** 353

---

### `def url_quote(obj: t.Any, charset: str = 'utf-8', for_qs: bool = False) -> str`

**Description:**
Quote a string for use in a URL using the given charset.

:param obj: String or bytes to quote. Other types are converted to
string then encoded to bytes using the given charset.
:param charset: Encode text to bytes using this charset.
:param for_qs: Quote "/" and use "+" for spaces.

**Line:** 408

---

### `def select_autoescape(enabled_extensions: t.Collection[str] = (), disabled_extensions: t.Collection[str] = (), default_for_string: bool = True, default: bool = False) -> t.Callable[([t.Optional[str]], bool)]`

**Description:**
Intelligently sets the initial value of autoescaping based on the
filename of the template.  This is the recommended way to configure
autoescaping if you do not want to write a custom function yourself.

If you want to enable it for all templates created from strings or
for all templates with `.html` and `.xml` extensions::

from jinja2 import Environment, select_autoescape
env = Environment(autoescape=select_autoescape(
enabled_extensions=('html', 'xml'),
default_for_string=True,
))

Example configuration to turn it on at all times except if the template
ends with `.txt`::

from jinja2 import Environment, select_autoescape
env = Environment(autoescape=select_autoescape(
disabled_extensions=('txt',),
default_for_string=True,
default=True,
))

The `enabled_extensions` is an iterable of all the extensions that
autoescaping should be enabled for.  Likewise `disabled_extensions` is
a list of all templates it should be disabled for.  If a template is
loaded from a string then the default from `default_for_string` is used.
If nothing matches then the initial value of autoescaping is set to the
value of `default`.

For security reasons this function operates case insensitive.

.. versionadded:: 2.9

**Line:** 581

---

### `def htmlsafe_json_dumps(obj: t.Any, dumps: t.Optional[t.Callable[(..., str)]] = None, **kwargs: t.Any) -> markupsafe.Markup`

**Description:**
Serialize an object to a string of JSON with :func:`json.dumps`,
then replace HTML-unsafe characters with Unicode escapes and mark
the result safe with :class:`~markupsafe.Markup`.

This is available in templates as the ``|tojson`` filter.

The following characters are escaped: ``<``, ``>``, ``&``, ``'``.

The returned string is safe to render in HTML documents and
``<script>`` tags. The exception is in HTML attributes that are
double quoted; either use single quotes or the ``|forceescape``
filter.

:param obj: The object to serialize to JSON.
:param dumps: The ``dumps`` function to use. Defaults to
``env.policies["json.dumps_function"]``, which defaults to
:func:`json.dumps`.
:param kwargs: Extra arguments to pass to ``dumps``. Merged onto
``env.policies["json.dumps_kwargs"]``.

.. versionchanged:: 3.0
The ``dumper`` parameter is renamed to ``dumps``.

.. versionadded:: 2.9

**Line:** 637

---


## Module: venv2.libthon3.12.site-packages.jwt.algorithms
**File:** `venv2/lib/python3.12/site-packages/jwt/algorithms.py`

**Imports:**
- __future__.annotations
- abc.ABC
- abc.abstractmethod
- cryptography.exceptions.InvalidSignature
- cryptography.exceptions.UnsupportedAlgorithm
- cryptography.hazmat.backends.default_backend
- cryptography.hazmat.primitives.asymmetric.ec.ECDSA
- cryptography.hazmat.primitives.asymmetric.ec.EllipticCurve
- cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePrivateKey
- cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePrivateNumbers
- cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicKey
- cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicNumbers
- cryptography.hazmat.primitives.asymmetric.ec.SECP256K1
- cryptography.hazmat.primitives.asymmetric.ec.SECP256R1
- cryptography.hazmat.primitives.asymmetric.ec.SECP384R1
- cryptography.hazmat.primitives.asymmetric.ec.SECP521R1
- cryptography.hazmat.primitives.asymmetric.ed25519.Ed25519PrivateKey
- cryptography.hazmat.primitives.asymmetric.ed25519.Ed25519PublicKey
- cryptography.hazmat.primitives.asymmetric.ed448.Ed448PrivateKey
- cryptography.hazmat.primitives.asymmetric.ed448.Ed448PublicKey
- cryptography.hazmat.primitives.asymmetric.padding
- cryptography.hazmat.primitives.asymmetric.rsa.RSAPrivateKey
- cryptography.hazmat.primitives.asymmetric.rsa.RSAPrivateNumbers
- cryptography.hazmat.primitives.asymmetric.rsa.RSAPublicKey
- cryptography.hazmat.primitives.asymmetric.rsa.RSAPublicNumbers
- cryptography.hazmat.primitives.asymmetric.rsa.rsa_crt_dmp1
- cryptography.hazmat.primitives.asymmetric.rsa.rsa_crt_dmq1
- cryptography.hazmat.primitives.asymmetric.rsa.rsa_crt_iqmp
- cryptography.hazmat.primitives.asymmetric.rsa.rsa_recover_prime_factors
- cryptography.hazmat.primitives.hashes
- cryptography.hazmat.primitives.serialization.Encoding
- cryptography.hazmat.primitives.serialization.NoEncryption
- cryptography.hazmat.primitives.serialization.PrivateFormat
- cryptography.hazmat.primitives.serialization.PublicFormat
- cryptography.hazmat.primitives.serialization.load_pem_private_key
- cryptography.hazmat.primitives.serialization.load_pem_public_key
- cryptography.hazmat.primitives.serialization.load_ssh_public_key
- exceptions.InvalidKeyError
- hashlib
- hmac
- json
- types.HashlibHash
- types.JWKDict
- typing.Any
- typing.ClassVar
- typing.Literal
- typing.NoReturn
- typing.TYPE_CHECKING
- typing.cast
- typing.overload
- utils.base64url_decode
- utils.base64url_encode
- utils.der_to_raw_signature
- utils.force_bytes
- utils.from_base64url_uint
- utils.is_pem_format
- utils.is_ssh_key
- utils.raw_to_der_signature
- utils.to_base64url_uint

**Functions:**

### `def get_default_algorithms() -> dict[(str, Algorithm)]`

**Description:**
Returns the algorithms that are implemented by the library.

**Line:** 105

---


## Module: venv2.libthon3.12.site-packages.jwt.help
**File:** `venv2/lib/python3.12/site-packages/jwt/help.py`

**Imports:**
- cryptography
- json
- platform
- sys
- typing.Dict

**Functions:**

### `def info() -> Dict[(str, Dict[str, str])]`

**Description:**
Generate information for a bug report.
Based on the requests package help utility module.

**Line:** 16

---

### `def main() -> None`

**Description:**
Pretty-print the bug information as JSON.

**Line:** 61

---


## Module: venv2.libthon3.12.site-packages.jwt.utils
**File:** `venv2/lib/python3.12/site-packages/jwt/utils.py`

**Imports:**
- base64
- binascii
- cryptography.hazmat.primitives.asymmetric.ec.EllipticCurve
- cryptography.hazmat.primitives.asymmetric.utils.decode_dss_signature
- cryptography.hazmat.primitives.asymmetric.utils.encode_dss_signature
- re
- typing.Optional
- typing.Union

**Functions:**

### `def force_bytes(value: Union[(bytes, str)]) -> bytes`

**Line:** 16

---

### `def base64url_decode(input: Union[(bytes, str)]) -> bytes`

**Line:** 25

---

### `def base64url_encode(input: bytes) -> bytes`

**Line:** 36

---

### `def to_base64url_uint(val: int, bit_length: Optional[int] = None) -> bytes`

**Line:** 40

---

### `def from_base64url_uint(val: Union[(bytes, str)]) -> int`

**Line:** 52

---

### `def number_to_bytes(num: int, num_bytes: int) -> bytes`

**Line:** 57

---

### `def bytes_to_number(string: bytes) -> int`

**Line:** 62

---

### `def bytes_from_int(val: int, bit_length: Optional[int] = None) -> bytes`

**Line:** 66

---

### `def der_to_raw_signature(der_sig: bytes, curve: 'EllipticCurve') -> bytes`

**Line:** 74

---

### `def raw_to_der_signature(raw_sig: bytes, curve: 'EllipticCurve') -> bytes`

**Line:** 83

---

### `def is_pem_format(key: bytes) -> bool`

**Line:** 126

---

### `def is_ssh_key(key: bytes) -> bool`

**Line:** 141

---


## Module: venv2.libthon3.12.site-packages.limits._version
**File:** `venv2/lib/python3.12/site-packages/limits/_version.py`

**Imports:**
- json

**Functions:**

### `def get_versions()`

**Line:** 20

---


## Module: venv2.libthon3.12.site-packages.limits.aio.storage.base
**File:** `venv2/lib/python3.12/site-packages/limits/aio/storage/base.py`

**Imports:**
- __future__.annotations
- abc.ABC
- abc.abstractmethod
- deprecated.sphinx.versionadded
- functools
- limits.errors
- limits.storage.registry.StorageRegistry
- limits.typing.Any
- limits.typing.Awaitable
- limits.typing.Callable
- limits.typing.P
- limits.typing.R
- limits.typing.cast
- limits.util.LazyDependency

**Functions:**

### `def _wrap_errors(fn: Callable[(P, Awaitable[R])]) -> Callable[(P, Awaitable[R])]`

**Line:** 21

---


## Module: venv2.libthon3.12.site-packages.limits.limits
**File:** `venv2/lib/python3.12/site-packages/limits/limits.py`

**Imports:**
- __future__.annotations
- functools.total_ordering
- limits.typing.ClassVar
- limits.typing.NamedTuple
- limits.typing.cast

**Functions:**

### `def safe_string(value: bytes | str | int | float) -> str`

**Description:**
normalize a byte/str/int or float to a str

**Line:** 10

---


## Module: venv2.libthon3.12.site-packages.limits.storage.__init__
**File:** `venv2/lib/python3.12/site-packages/limits/storage/__init__.py`

**Imports:**
- __future__.annotations
- base.MovingWindowSupport
- base.SlidingWindowCounterSupport
- base.Storage
- errors.ConfigurationError
- limits
- memcached.MemcachedStorage
- memory.MemoryStorage
- mongodb.MongoDBStorage
- mongodb.MongoDBStorageBase
- redis.RedisStorage
- redis_cluster.RedisClusterStorage
- redis_sentinel.RedisSentinelStorage
- registry.SCHEMES
- typing.TypeAlias
- typing.cast
- urllib

**Functions:**

### `def storage_from_string(storage_string: str, **options: float | str | bool) -> StorageTypes`

**Description:**
Factory function to get an instance of the storage class based
on the uri of the storage. In most cases using it should be sufficient
instead of directly instantiating the storage classes. for example::

from limits.storage import storage_from_string

memory = storage_from_string("memory://")
memcached = storage_from_string("memcached://localhost:11211")
redis = storage_from_string("redis://localhost:6379")

The same function can be used to construct the :ref:`storage:async storage`
variants, for example::

from limits.storage import storage_from_string

memory = storage_from_string("async+memory://")
memcached = storage_from_string("async+memcached://localhost:11211")
redis = storage_from_string("async+redis://localhost:6379")

:param storage_string: a string of the form ``scheme://host:port``.
More details about supported storage schemes can be found at
:ref:`storage:storage scheme`
:param options: all remaining keyword arguments are passed to the
constructor matched by :paramref:`storage_string`.
:raises ConfigurationError: when the :attr:`storage_string` cannot be
mapped to a registered :class:`limits.storage.Storage`
or :class:`limits.aio.storage.Storage` instance.

**Line:** 26

---


## Module: venv2.libthon3.12.site-packages.limits.storage.base
**File:** `venv2/lib/python3.12/site-packages/limits/storage/base.py`

**Imports:**
- __future__.annotations
- abc.ABC
- abc.abstractmethod
- functools
- limits.errors
- limits.storage.registry.StorageRegistry
- limits.typing.Any
- limits.typing.Callable
- limits.typing.P
- limits.typing.R
- limits.typing.cast
- limits.util.LazyDependency

**Functions:**

### `def _wrap_errors(fn: Callable[(P, R)]) -> Callable[(P, R)]`

**Line:** 18

---


## Module: venv2.libthon3.12.site-packages.limits.util
**File:** `venv2/lib/python3.12/site-packages/limits/util.py`

**Imports:**
- __future__.annotations
- collections.UserDict
- dataclasses
- errors.ConfigurationError
- importlib.resources
- limits.GRANULARITIES
- limits.RateLimitItem
- limits.typing.NamedTuple
- packaging.version.Version
- re
- sys
- types.ModuleType
- typing.TYPE_CHECKING

**Functions:**

### `def get_dependency(module_path: str) -> tuple[(ModuleType, Version | None)]`

**Description:**
safe function to import a module at runtime

**Line:** 138

---

### `def get_package_data(path: str) -> bytes`

**Line:** 153

---

### `def parse_many(limit_string: str) -> list[RateLimitItem]`

**Description:**
parses rate limits in string notation containing multiple rate limits
(e.g. ``1/second; 5/minute``)

:param limit_string: rate limit string using :ref:`ratelimit-string`
:raise ValueError: if the string notation is invalid.

**Line:** 157

---

### `def parse(limit_string: str) -> RateLimitItem`

**Description:**
parses a single rate limit in string notation
(e.g. ``1/second`` or ``1 per second``)

:param limit_string: rate limit string using :ref:`ratelimit-string`
:raise ValueError: if the string notation is invalid.

**Line:** 184

---

### `def granularity_from_string(granularity_string: str) -> type[RateLimitItem]`

**Description:**
:param granularity_string:
:raise ValueError:

**Line:** 197

---


## Module: venv2.libthon3.12.site-packages.mako._ast_util
**File:** `venv2/lib/python3.12/site-packages/mako/_ast_util.py`

**Imports:**
- _ast.AST
- _ast.Add
- _ast.And
- _ast.BitAnd
- _ast.BitOr
- _ast.BitXor
- _ast.Div
- _ast.Eq
- _ast.FloorDiv
- _ast.Gt
- _ast.GtE
- _ast.If
- _ast.In
- _ast.Invert
- _ast.Is
- _ast.IsNot
- _ast.LShift
- _ast.Lt
- _ast.LtE
- _ast.Mod
- _ast.Mult
- _ast.Name
- _ast.Not
- _ast.NotEq
- _ast.NotIn
- _ast.Or
- _ast.PyCF_ONLY_AST
- _ast.RShift
- _ast.Sub
- _ast.UAdd
- _ast.USub

**Functions:**

### `def parse(expr, filename = '<unknown>', mode = 'exec')`

**Description:**
Parse an expression into an AST node.

**Line:** 89

---

### `def iter_fields(node)`

**Description:**
Iterate over all fields of a node, only yielding existing fields.

**Line:** 94

---


## Module: venv2.libthon3.12.site-packages.mako.cmd
**File:** `venv2/lib/python3.12/site-packages/mako/cmd.py`

**Imports:**
- argparse.ArgumentParser
- mako.exceptions
- mako.lookup.TemplateLookup
- mako.template.Template
- os.path.dirname
- os.path.isfile
- sys

**Functions:**

### `def varsplit(var)`

**Line:** 16

---

### `def _exit()`

**Line:** 22

---

### `def cmdline(argv = None)`

**Line:** 27

---


## Module: venv2.libthon3.12.site-packages.mako.codegen
**File:** `venv2/lib/python3.12/site-packages/mako/codegen.py`

**Imports:**
- json
- mako.ast
- mako.exceptions
- mako.filters
- mako.parsetree
- mako.pygen.PythonPrinter
- mako.util
- re
- time

**Functions:**

### `def compile(node, uri, filename = None, default_filters = None, buffer_filters = None, imports = None, future_imports = None, source_encoding = None, generate_magic_comment = True, strict_undefined = False, enable_loop = True, reserved_names = frozenset())`

**Description:**
Generate module source code given a parsetree node,
uri, and optional source filename

**Line:** 31

---

### `def mangle_mako_loop(node, printer)`

**Description:**
converts a for loop into a context manager wrapped around a for loop
when access to the `loop` variable has been detected in the for loop body

**Line:** 1274

---


## Module: venv2.libthon3.12.site-packages.mako.compat
**File:** `venv2/lib/python3.12/site-packages/mako/compat.py`

**Imports:**
- collections
- importlib.metadata
- importlib.util
- inspect
- sys

**Functions:**

### `def inspect_getargspec(func)`

**Description:**
getargspec based on fully vendored getfullargspec from Python 3.3.

**Line:** 21

---

### `def load_module(module_id, path)`

**Line:** 50

---

### `def exception_as()`

**Line:** 57

---

### `def exception_name(exc)`

**Line:** 61

---

### `def importlib_metadata_get(group)`

**Line:** 65

---


## Module: venv2.libthon3.12.site-packages.mako.exceptions
**File:** `venv2/lib/python3.12/site-packages/mako/exceptions.py`

**Imports:**
- mako.compat
- mako.ext.pygmentplugin.pygments_html_formatter
- mako.ext.pygmentplugin.syntax_highlight
- mako.filters.html_escape
- mako.template
- mako.util
- sys
- traceback

**Functions:**

### `def _format_filepos(lineno, pos, filename)`

**Line:** 24

---

### `def text_error_template(lookup = None)`

**Description:**
Provides a template that renders a stack trace in a similar format to
the Python interpreter, substituting source template filenames, line
numbers and code for that of the originating source template, as
applicable.

**Line:** 241

---

### `def _install_pygments()`

**Line:** 269

---

### `def _install_fallback()`

**Line:** 275

---

### `def _install_highlighting()`

**Line:** 285

---

### `def html_error_template()`

**Description:**
Provides a template that renders a stack trace in an HTML format,
providing an excerpt of code as well as substituting source template
filenames, line numbers and code for that of the originating source
template, as applicable.

The template's default ``encoding_errors`` value is
``'htmlentityreplace'``. The template has two options. With the
``full`` option disabled, only a section of an HTML document is
returned. With the ``css`` option disabled, the default stylesheet
won't be included.

**Line:** 295

---


## Module: venv2.libthon3.12.site-packages.mako.ext.autohandler
**File:** `venv2/lib/python3.12/site-packages/mako/ext/autohandler.py`

**Imports:**
- os
- posixpath
- re

**Functions:**

### `def autohandler(template, context, name = 'autohandler')`

**Line:** 33

---

### `def _file_exists(lookup, path)`

**Line:** 64

---


## Module: venv2.libthon3.12.site-packages.mako.ext.babelplugin
**File:** `venv2/lib/python3.12/site-packages/mako/ext/babelplugin.py`

**Imports:**
- babel.messages.extract.extract_python
- mako.ext.extract.MessageExtractor

**Functions:**

### `def extract(fileobj, keywords, comment_tags, options)`

**Description:**
Extract messages from Mako templates.

:param fileobj: the file-like object the messages should be extracted from
:param keywords: a list of keywords (i.e. function names) that should be
recognized as translation functions
:param comment_tags: a list of translator tags to search for and include
in the results
:param options: a dictionary of additional options (optional)
:return: an iterator over ``(lineno, funcname, message, comments)`` tuples
:rtype: ``iterator``

**Line:** 44

---


## Module: venv2.libthon3.12.site-packages.mako.ext.preprocessors
**File:** `venv2/lib/python3.12/site-packages/mako/ext/preprocessors.py`

**Imports:**
- re

**Functions:**

### `def convert_comments(text)`

**Description:**
preprocess old style comments.

example:

from mako.ext.preprocessors import convert_comments
t = Template(..., preprocessor=convert_comments)

**Line:** 13

---


## Module: venv2.libthon3.12.site-packages.mako.extgmentplugin
**File:** `venv2/lib/python3.12/site-packages/mako/ext/pygmentplugin.py`

**Imports:**
- pygments.formatters.html.HtmlFormatter
- pygments.highlight
- pygments.lexer.DelegatingLexer
- pygments.lexer.RegexLexer
- pygments.lexer.bygroups
- pygments.lexer.include
- pygments.lexer.using
- pygments.lexers.agile.Python3Lexer
- pygments.lexers.agile.PythonLexer
- pygments.lexers.web.CssLexer
- pygments.lexers.web.HtmlLexer
- pygments.lexers.web.JavascriptLexer
- pygments.lexers.web.XmlLexer
- pygments.token.Comment
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Operator
- pygments.token.Other
- pygments.token.String
- pygments.token.Text

**Functions:**

### `def syntax_highlight(filename = '', language = None)`

**Line:** 141

---


## Module: venv2.libthon3.12.site-packages.mako.filters
**File:** `venv2/lib/python3.12/site-packages/mako/filters.py`

**Imports:**
- codecs
- html.entities.codepoint2name
- html.entities.name2codepoint
- markupsafe
- re
- urllib.parse.quote_plus

**Functions:**

### `def xml_escape(string)`

**Line:** 27

---

### `def url_escape(string)`

**Line:** 31

---

### `def trim(string)`

**Line:** 37

---

### `def htmlentityreplace_errors(ex)`

**Description:**
An encoding error handler.

This python codecs error handler replaces unencodable
characters with HTML entities, or, if no HTML entity exists for
the character, XML character references::

>>> 'The cost was 12.'.encode('latin1', 'htmlentityreplace')
'The cost was &euro;12.'

**Line:** 132

---


## Module: venv2.libthon3.12.site-packages.mako.runtime
**File:** `venv2/lib/python3.12/site-packages/mako/runtime.py`

**Imports:**
- builtins
- functools
- mako.compat
- mako.exceptions
- mako.template
- mako.util
- sys

**Functions:**

### `def supports_caller(func)`

**Description:**
Apply a caller_stack compatibility decorator to a plain
Python function.

See the example in :ref:`namespaces_python_modules`.

**Line:** 707

---

### `def capture(context, callable_, *args, **kwargs)`

**Description:**
Execute the given template def, capturing the output into
a buffer.

See the example in :ref:`namespaces_python_modules`.

**Line:** 725

---

### `def _decorate_toplevel(fn)`

**Line:** 746

---

### `def _decorate_inline(context, fn)`

**Line:** 764

---

### `def _include_file(context, uri, calling_uri, **kwargs)`

**Description:**
locate the template from the given uri and include it in
the current output.

**Line:** 776

---

### `def _inherit_from(context, uri, calling_uri)`

**Description:**
called by the _inherit method in template modules to set
up the inheritance chain at the start of a template's
execution.

**Line:** 796

---

### `def _lookup_template(context, uri, relativeto)`

**Line:** 828

---

### `def _populate_self_namespace(context, template, self_ns = None)`

**Line:** 844

---

### `def _render(template, callable_, args, data, as_unicode = False)`

**Description:**
create a Context and return the string
output of the given template and template callable.

**Line:** 860

---

### `def _kwargs_for_callable(callable_, data)`

**Line:** 884

---

### `def _kwargs_for_include(callable_, data, **kwargs)`

**Line:** 899

---

### `def _render_context(tmpl, callable_, context, *args, **kwargs)`

**Line:** 908

---

### `def _exec_template(callable_, context, args = None, kwargs = None)`

**Description:**
execute a rendering callable given the callable, a
Context, and optional explicit arguments

the contextual Template will be located if it exists, and
the error handling options specified on that Template will
be interpreted here.

**Line:** 923

---

### `def _render_error(template, context, error)`

**Line:** 946

---


## Module: venv2.libthon3.12.site-packages.mako.template
**File:** `venv2/lib/python3.12/site-packages/mako/template.py`

**Imports:**
- json
- mako.cache
- mako.codegen
- mako.compat
- mako.exceptions
- mako.lexer.Lexer
- mako.runtime
- mako.util
- os
- re
- shutil
- stat
- tempfile
- types
- weakref

**Functions:**

### `def _compile(template, text, filename, generate_magic_comment)`

**Line:** 645

---

### `def _compile_text(template, text, filename)`

**Line:** 670

---

### `def _compile_module_file(template, text, filename, outputpath, module_writer)`

**Line:** 685

---

### `def _get_module_info_from_callable(callable_)`

**Line:** 706

---

### `def _get_module_info(filename)`

**Line:** 710

---


## Module: venv2.libthon3.12.site-packages.mako.testing._config
**File:** `venv2/lib/python3.12/site-packages/mako/testing/_config.py`

**Imports:**
- configparser
- dataclasses
- dataclasses.dataclass
- helpers.make_path
- pathlib.Path
- typing.Callable
- typing.ClassVar
- typing.Optional
- typing.Union

**Functions:**

### `def _parse_cfg_file(filespec: Union[(Path, str)])`

**Line:** 46

---

### `def _build_getter(cfg_obj, cfg_section, method, converter = None)`

**Line:** 58

---

### `def _build_getter_dispatch(cfg_obj, cfg_section, converters = None)`

**Line:** 87

---


## Module: venv2.libthon3.12.site-packages.mako.testing.assertions
**File:** `venv2/lib/python3.12/site-packages/mako/testing/assertions.py`

**Imports:**
- contextlib
- re
- sys

**Functions:**

### `def eq_(a, b, msg = None)`

**Description:**
Assert a == b, with repr messaging on failure.

**Line:** 6

---

### `def ne_(a, b, msg = None)`

**Description:**
Assert a != b, with repr messaging on failure.

**Line:** 11

---

### `def in_(a, b, msg = None)`

**Description:**
Assert a in b, with repr messaging on failure.

**Line:** 16

---

### `def not_in(a, b, msg = None)`

**Description:**
Assert a in not b, with repr messaging on failure.

**Line:** 21

---

### `def _assert_proper_exception_context(exception)`

**Description:**
assert that any exception we're catching does not have a __context__
without a __cause__, and that __suppress_context__ is never set.

Python 3 will report nested as exceptions as "during the handling of
error X, error Y occurred". That's not what we want to do. We want
these exceptions in a cause chain.

**Line:** 26

---

### `def _assert_proper_cause_cls(exception, cause_cls)`

**Description:**
assert that any exception we're catching does not have a __context__
without a __cause__, and that __suppress_context__ is never set.

Python 3 will report nested as exceptions as "during the handling of
error X, error Y occurred". That's not what we want to do. We want
these exceptions in a cause chain.

**Line:** 47

---

### `def assert_raises(except_cls, callable_, *args, **kw)`

**Line:** 63

---

### `def assert_raises_with_proper_context(except_cls, callable_, *args, **kw)`

**Line:** 67

---

### `def assert_raises_with_given_cause(except_cls, cause_cls, callable_, *args, **kw)`

**Line:** 71

---

### `def assert_raises_message(except_cls, msg, callable_, *args, **kwargs)`

**Line:** 77

---

### `def assert_raises_message_with_proper_context(except_cls, msg, callable_, *args, **kwargs)`

**Line:** 81

---

### `def assert_raises_message_with_given_cause(except_cls, msg, cause_cls, callable_, *args, **kwargs)`

**Line:** 89

---

### `def _assert_raises(except_cls, callable_, args, kwargs, msg = None, check_context = False, cause_cls = None)`

**Line:** 97

---

### `def _expect_raises(except_cls, msg = None, check_context = False, cause_cls = None)`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 116

---

### `def expect_raises(except_cls, check_context = False)`

**Line:** 151

---

### `def expect_raises_message(except_cls, msg, check_context = False)`

**Line:** 155

---

### `def expect_raises_with_proper_context(except_cls, check_context = True)`

**Line:** 159

---

### `def expect_raises_message_with_proper_context(except_cls, msg, check_context = True)`

**Line:** 163

---


## Module: venv2.libthon3.12.site-packages.mako.testing.exclusions
**File:** `venv2/lib/python3.12/site-packages/mako/testing/exclusions.py`

**Imports:**
- babel.messages.extract
- dogpile.cache
- lingua
- mako.exceptions
- mako.ext.beaker_cache.has_beaker
- mako.util.update_wrapper
- pygments
- pytest

**Functions:**

### `def _pygments_version()`

**Line:** 48

---

### `def requires_no_pygments_exceptions(fn)`

**Line:** 70

---


## Module: venv2.libthon3.12.site-packages.mako.testing.helpers
**File:** `venv2/lib/python3.12/site-packages/mako/testing/helpers.py`

**Imports:**
- contextlib
- pathlib
- pathlib.Path
- re
- time
- typing.Union
- unittest.mock

**Functions:**

### `def flatten_result(result)`

**Line:** 10

---

### `def result_lines(result)`

**Line:** 14

---

### `def result_raw_lines(result)`

**Line:** 22

---

### `def make_path(filespec: Union[(Path, str)], make_absolute: bool = True, check_exists: bool = False) -> Path`

**Line:** 26

---

### `def _unlink_path(path, missing_ok = False)`

**Line:** 39

---

### `def replace_file_with_dir(pathspec)`

**Line:** 49

---

### `def file_with_template_code(filespec)`

**Line:** 56

---

### `def rewind_compile_time(hours = 1)`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 67

---


## Module: venv2.libthon3.12.site-packages.mako.util
**File:** `venv2/lib/python3.12/site-packages/mako/util.py`

**Imports:**
- ast.parse
- codecs
- collections
- compat.importlib_metadata_get
- mako.exceptions
- operator
- os
- re
- timeit

**Functions:**

### `def update_wrapper(decorated, fn)`

**Line:** 17

---

### `def verify_directory(dir_)`

**Description:**
create and/or verify a filesystem directory.

**Line:** 53

---

### `def to_list(x, default = None)`

**Line:** 67

---

### `def parse_encoding(fp)`

**Description:**
Deduce the encoding of a Python source file (binary mode) from magic
comment.

It does this in the same way as the `Python interpreter`__

.. __: http://docs.python.org/ref/encodings.html

The ``fp`` argument should be a seekable file object in binary mode.

**Line:** 233

---

### `def sorted_dict_repr(d)`

**Description:**
repr() a dictionary with the keys in order.

Used by the lexer unit test to compare parse trees based on strings.

**Line:** 282

---

### `def restore__ast(_ast)`

**Description:**
Attempt to restore the required classes to the _ast module if it
appears to be missing them

**Line:** 293

---

### `def read_file(path, mode = 'rb')`

**Line:** 374

---

### `def read_python_file(path)`

**Line:** 379

---


## Module: venv2.libthon3.12.site-packages.makogen
**File:** `venv2/lib/python3.12/site-packages/mako/pygen.py`

**Imports:**
- mako.exceptions
- re

**Functions:**

### `def adjust_whitespace(text)`

**Description:**
remove the left-whitespace margin of a block of Python code.

**Line:** 253

---


## Module: venv2.libthon3.12.site-packages.makoparser
**File:** `venv2/lib/python3.12/site-packages/mako/pyparser.py`

**Imports:**
- _ast
- mako._ast_util
- mako.compat
- mako.exceptions
- mako.util
- operator

**Functions:**

### `def parse(code, mode = 'exec', **exception_kwargs)`

**Description:**
Parse an expression into AST

**Line:** 32

---


## Module: venv2.libthon3.12.site-packages.markdown_it._punycode
**File:** `venv2/lib/python3.12/site-packages/markdown_it/_punycode.py`

**Imports:**
- codecs
- re
- typing.Callable

**Functions:**

### `def encode(uni: str) -> str`

**Line:** 31

---

### `def decode(ascii: str) -> str`

**Line:** 35

---

### `def map_domain(string: str, fn: Callable[([str], str)]) -> str`

**Line:** 39

---

### `def to_unicode(obj: str) -> str`

**Line:** 52

---

### `def to_ascii(obj: str) -> str`

**Line:** 61

---


## Module: venv2.libthon3.12.site-packages.markdown_it.cli.parse
**File:** `venv2/lib/python3.12/site-packages/markdown_it/cli/parse.py`

**Imports:**
- __future__.annotations
- argparse
- collections.abc.Iterable
- collections.abc.Sequence
- markdown_it.__version__
- markdown_it.main.MarkdownIt
- sys

**Functions:**

### `def main(args: Sequence[str] | None = None) -> int`

**Line:** 19

---

### `def convert(filenames: Iterable[str]) -> None`

**Line:** 28

---

### `def convert_file(filename: str) -> None`

**Description:**
Parse a Markdown file and dump the output to stdout.

**Line:** 33

---

### `def interactive() -> None`

**Description:**
Parse user input, dump to stdout, rinse and repeat.
Python REPL style.

**Line:** 46

---

### `def parse_args(args: Sequence[str] | None) -> argparse.Namespace`

**Description:**
Parse input CLI arguments.

**Line:** 67

---

### `def print_heading() -> None`

**Line:** 102

---


## Module: venv2.libthon3.12.site-packages.markdown_it.common.normalize_url
**File:** `venv2/lib/python3.12/site-packages/markdown_it/common/normalize_url.py`

**Imports:**
- __future__.annotations
- collections.abc.Callable
- contextlib.suppress
- mdurl
- re
- urllib.parse.quote
- urllib.parse.unquote
- urllib.parse.urlparse
- urllib.parse.urlunparse

**Functions:**

### `def normalizeLink(url: str) -> str`

**Description:**
Normalize destination URLs in links

::

[label]:   destination   'title'
^^^^^^^^^^^

**Line:** 15

---

### `def normalizeLinkText(url: str) -> str`

**Description:**
Normalize autolink content

::

<destination>
~~~~~~~~~~~

**Line:** 40

---

### `def validateLink(url: str, validator: Callable[[str], bool] | None = None) -> bool`

**Description:**
Validate URL link is allowed in output.

This validator can prohibit more than really needed to prevent XSS.
It's a tradeoff to keep code simple and to be secure by default.

Note: url should be normalized at this point, and existing entities decoded.

**Line:** 70

---


## Module: venv2.libthon3.12.site-packages.markdown_it.common.utils
**File:** `venv2/lib/python3.12/site-packages/markdown_it/common/utils.py`

**Imports:**
- __future__.annotations
- entities.entities
- re
- typing.Match
- typing.TypeVar

**Functions:**

### `def charCodeAt(src: str, pos: int) -> int | None`

**Description:**
Returns the Unicode value of the character at the specified location.

@param - index The zero-based index of the desired character.
If there is no character at the specified index, NaN is returned.

This was added for compatibility with python

**Line:** 11

---

### `def charStrAt(src: str, pos: int) -> str | None`

**Description:**
Returns the Unicode value of the character at the specified location.

@param - index The zero-based index of the desired character.
If there is no character at the specified index, NaN is returned.

This was added for compatibility with python

**Line:** 26

---

### `def arrayReplaceAt(src: list[_ItemTV], pos: int, newElements: list[_ItemTV]) -> list[_ItemTV]`

**Description:**
Remove element from array and put another array at those position.
Useful for some operations with tokens

**Line:** 44

---

### `def isValidEntityCode(c: int) -> bool`

**Line:** 54

---

### `def fromCodePoint(c: int) -> str`

**Description:**
Convert ordinal to unicode.

Note, in the original Javascript two string characters were required,
for codepoints larger than `0xFFFF`.
But Python 3 can represent any unicode codepoint in one character.

**Line:** 78

---

### `def replaceEntityPattern(match: str, name: str) -> str`

**Description:**
Convert HTML entity patterns,
see https://spec.commonmark.org/0.30/#entity-references

**Line:** 98

---

### `def unescapeAll(string: str) -> str`

**Line:** 117

---

### `def stripEscape(string: str) -> str`

**Description:**
Strip escape \ characters

**Line:** 134

---

### `def escapeHtml(raw: str) -> str`

**Description:**
Replace special characters "&", "<", ">" and '"' to HTML-safe sequences.

**Line:** 139

---

### `def escapeRE(string: str) -> str`

**Line:** 154

---

### `def isSpace(code: int | None) -> bool`

**Description:**
Check if character code is a whitespace.

**Line:** 162

---

### `def isStrSpace(ch: str | None) -> bool`

**Description:**
Check if character is a whitespace.

**Line:** 167

---

### `def isWhiteSpace(code: int) -> bool`

**Description:**
Zs (unicode class) || [\t\f\v\r\n]

**Line:** 187

---

### `def isPunctChar(ch: str) -> bool`

**Description:**
Check if character is a punctuation character.

**Line:** 202

---

### `def isMdAsciiPunct(ch: int) -> bool`

**Description:**
Markdown ASCII punctuation characters.

::

!, ", #, $, %, &, ', (, ), *, +, ,, -, ., /, :, ;, <, =, >, ?, @, [, \, ], ^, _, `, {, |, }, or ~

See http://spec.commonmark.org/0.15/#ascii-punctuation-character

Don't confuse with unicode punctuation !!! It lacks some chars in ascii range.

**Line:** 243

---

### `def normalizeReference(string: str) -> str`

**Description:**
Helper to unify [reference labels].

**Line:** 258

---

### `def isLinkOpen(string: str) -> bool`

**Line:** 313

---

### `def isLinkClose(string: str) -> bool`

**Line:** 317

---


## Module: venv2.libthon3.12.site-packages.markdown_it.helpers.parse_link_destination
**File:** `venv2/lib/python3.12/site-packages/markdown_it/helpers/parse_link_destination.py`

**Imports:**
- common.utils.charCodeAt
- common.utils.unescapeAll

**Functions:**

### `def parseLinkDestination(string: str, pos: int, maximum: int) -> _Result`

**Line:** 18

---


## Module: venv2.libthon3.12.site-packages.markdown_it.helpers.parse_link_label
**File:** `venv2/lib/python3.12/site-packages/markdown_it/helpers/parse_link_label.py`

**Imports:**
- markdown_it.rules_inline.StateInline

**Functions:**

### `def parseLinkLabel(state: StateInline, start: int, disableNested: bool = False) -> int`

**Line:** 11

---


## Module: venv2.libthon3.12.site-packages.markdown_it.helpers.parse_link_title
**File:** `venv2/lib/python3.12/site-packages/markdown_it/helpers/parse_link_title.py`

**Imports:**
- common.utils.charCodeAt
- common.utils.unescapeAll

**Functions:**

### `def parseLinkTitle(string: str, pos: int, maximum: int) -> _Result`

**Line:** 19

---


## Module: venv2.libthon3.12.site-packages.markdown_it.presets.commonmark
**File:** `venv2/lib/python3.12/site-packages/markdown_it/presets/commonmark.py`

**Imports:**
- utils.PresetType

**Functions:**

### `def make() -> PresetType`

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.markdown_it.presets.default
**File:** `venv2/lib/python3.12/site-packages/markdown_it/presets/default.py`

**Imports:**
- utils.PresetType

**Functions:**

### `def make() -> PresetType`

**Line:** 5

---


## Module: venv2.libthon3.12.site-packages.markdown_it.presets.zero
**File:** `venv2/lib/python3.12/site-packages/markdown_it/presets/zero.py`

**Imports:**
- utils.PresetType

**Functions:**

### `def make() -> PresetType`

**Line:** 8

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_block.blockquote
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_block/blockquote.py`

**Imports:**
- __future__.annotations
- common.utils.isStrSpace
- logging
- state_block.StateBlock

**Functions:**

### `def blockquote(state: StateBlock, startLine: int, endLine: int, silent: bool) -> bool`

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_block.code
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_block/code.py`

**Imports:**
- logging
- state_block.StateBlock

**Functions:**

### `def code(state: StateBlock, startLine: int, endLine: int, silent: bool) -> bool`

**Line:** 9

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_block.fence
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_block/fence.py`

**Imports:**
- logging
- state_block.StateBlock

**Functions:**

### `def fence(state: StateBlock, startLine: int, endLine: int, silent: bool) -> bool`

**Line:** 9

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_block.heading
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_block/heading.py`

**Imports:**
- __future__.annotations
- common.utils.isStrSpace
- logging
- state_block.StateBlock

**Functions:**

### `def heading(state: StateBlock, startLine: int, endLine: int, silent: bool) -> bool`

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_block.hr
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_block/hr.py`

**Imports:**
- common.utils.isStrSpace
- logging
- state_block.StateBlock

**Functions:**

### `def hr(state: StateBlock, startLine: int, endLine: int, silent: bool) -> bool`

**Line:** 13

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_block.html_block
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_block/html_block.py`

**Imports:**
- __future__.annotations
- common.html_blocks.block_names
- common.html_re.HTML_OPEN_CLOSE_TAG_STR
- logging
- re
- state_block.StateBlock

**Functions:**

### `def html_block(state: StateBlock, startLine: int, endLine: int, silent: bool) -> bool`

**Line:** 34

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_block.lheading
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_block/lheading.py`

**Imports:**
- logging
- state_block.StateBlock

**Functions:**

### `def lheading(state: StateBlock, startLine: int, endLine: int, silent: bool) -> bool`

**Line:** 9

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_block.list
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_block/list.py`

**Imports:**
- common.utils.isStrSpace
- logging
- state_block.StateBlock

**Functions:**

### `def skipBulletListMarker(state: StateBlock, startLine: int) -> int`

**Line:** 12

---

### `def skipOrderedListMarker(state: StateBlock, startLine: int) -> int`

**Line:** 37

---

### `def markTightParagraphs(state: StateBlock, idx: int) -> None`

**Line:** 88

---

### `def list_block(state: StateBlock, startLine: int, endLine: int, silent: bool) -> bool`

**Line:** 101

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_block.paragraph
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_block/paragraph.py`

**Imports:**
- logging
- state_block.StateBlock

**Functions:**

### `def paragraph(state: StateBlock, startLine: int, endLine: int, silent: bool) -> bool`

**Line:** 9

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_block.reference
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_block/reference.py`

**Imports:**
- common.utils.charCodeAt
- common.utils.isSpace
- common.utils.normalizeReference
- logging
- state_block.StateBlock

**Functions:**

### `def reference(state: StateBlock, startLine: int, _endLine: int, silent: bool) -> bool`

**Line:** 9

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_block.table
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_block/table.py`

**Imports:**
- __future__.annotations
- common.utils.charStrAt
- common.utils.isStrSpace
- re
- state_block.StateBlock

**Functions:**

### `def getLine(state: StateBlock, line: int) -> str`

**Line:** 13

---

### `def escapedSplit(string: str) -> list[str]`

**Line:** 21

---

### `def table(state: StateBlock, startLine: int, endLine: int, silent: bool) -> bool`

**Line:** 52

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_core.block
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_core/block.py`

**Imports:**
- state_core.StateCore
- token.Token

**Functions:**

### `def block(state: StateCore) -> None`

**Line:** 5

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_core.inline
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_core/inline.py`

**Imports:**
- state_core.StateCore

**Functions:**

### `def inline(state: StateCore) -> None`

**Description:**
Parse inlines

**Line:** 4

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_core.linkify
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_core/linkify.py`

**Imports:**
- __future__.annotations
- common.utils.arrayReplaceAt
- common.utils.isLinkClose
- common.utils.isLinkOpen
- re
- state_core.StateCore
- token.Token
- typing.Protocol

**Functions:**

### `def linkify(state: StateCore) -> None`

**Description:**
Rule for identifying plain-text links.

**Line:** 15

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_core.normalize
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_core/normalize.py`

**Imports:**
- re
- state_core.StateCore

**Functions:**

### `def normalize(state: StateCore) -> None`

**Line:** 11

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_core.replacements
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_core/replacements.py`

**Imports:**
- __future__.annotations
- logging
- re
- state_core.StateCore
- token.Token

**Functions:**

### `def replaceFn(match: re.Match[str]) -> str`

**Line:** 58

---

### `def replace_scoped(inlineTokens: list[Token]) -> None`

**Line:** 62

---

### `def replace_rare(inlineTokens: list[Token]) -> None`

**Line:** 76

---

### `def replace(state: StateCore) -> None`

**Line:** 112

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_core.smartquotes
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_core/smartquotes.py`

**Imports:**
- __future__.annotations
- common.utils.charCodeAt
- common.utils.isMdAsciiPunct
- common.utils.isPunctChar
- common.utils.isWhiteSpace
- re
- state_core.StateCore
- token.Token
- typing.Any

**Functions:**

### `def replaceAt(string: str, index: int, ch: str) -> str`

**Line:** 17

---

### `def process_inlines(tokens: list[Token], state: StateCore) -> None`

**Line:** 24

---

### `def smartquotes(state: StateCore) -> None`

**Line:** 194

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_core.text_join
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_core/text_join.py`

**Imports:**
- __future__.annotations
- state_core.StateCore
- token.Token

**Functions:**

### `def text_join(state: StateCore) -> None`

**Description:**
Join raw text for escape sequences (`text_special`) tokens with the rest of the text

**Line:** 14

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.autolink
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/autolink.py`

**Imports:**
- re
- state_inline.StateInline

**Functions:**

### `def autolink(state: StateInline, silent: bool) -> bool`

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.backticks
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/backticks.py`

**Imports:**
- re
- state_inline.StateInline

**Functions:**

### `def backtick(state: StateInline, silent: bool) -> bool`

**Line:** 9

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.balance_pairs
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/balance_pairs.py`

**Imports:**
- __future__.annotations
- state_inline.Delimiter
- state_inline.StateInline

**Functions:**

### `def processDelimiters(state: StateInline, delimiters: list[Delimiter]) -> None`

**Description:**
For each opening emphasis-like marker find a matching closing one.

**Line:** 7

---

### `def link_pairs(state: StateInline) -> None`

**Line:** 126

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.emphasis
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/emphasis.py`

**Imports:**
- __future__.annotations
- state_inline.Delimiter
- state_inline.StateInline

**Functions:**

### `def tokenize(state: StateInline, silent: bool) -> bool`

**Description:**
Insert each marker as a separate text token, and add it to delimiter list

**Line:** 8

---

### `def _postProcess(state: StateInline, delimiters: list[Delimiter]) -> None`

**Line:** 40

---

### `def postProcess(state: StateInline) -> None`

**Description:**
Walk through delimiter list and replace text tokens with tags.

**Line:** 96

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.entity
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/entity.py`

**Imports:**
- common.entities.entities
- common.utils.fromCodePoint
- common.utils.isValidEntityCode
- re
- state_inline.StateInline

**Functions:**

### `def entity(state: StateInline, silent: bool) -> bool`

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.escape
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/escape.py`

**Imports:**
- common.utils.isStrSpace
- state_inline.StateInline

**Functions:**

### `def escape(state: StateInline, silent: bool) -> bool`

**Description:**
Process escaped chars and hardbreaks.

**Line:** 8

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.fragments_join
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/fragments_join.py`

**Imports:**
- state_inline.StateInline

**Functions:**

### `def fragments_join(state: StateInline) -> None`

**Description:**
Clean up tokens after emphasis and strikethrough postprocessing:
merge adjacent text nodes into one and re-calculate all token levels

This is necessary because initially emphasis delimiter markers (``*, _, ~``)
are treated as their own separate text tokens. Then emphasis rule either
leaves them as text (needed to merge with adjacent text) or turns them
into opening/closing tags (which messes up levels inside).

**Line:** 4

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.html_inline
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/html_inline.py`

**Imports:**
- common.html_re.HTML_TAG_RE
- common.utils.isLinkClose
- common.utils.isLinkOpen
- state_inline.StateInline

**Functions:**

### `def isLetter(ch: int) -> bool`

**Line:** 7

---

### `def html_inline(state: StateInline, silent: bool) -> bool`

**Line:** 13

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.image
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/image.py`

**Imports:**
- __future__.annotations
- common.utils.isStrSpace
- common.utils.normalizeReference
- state_inline.StateInline
- token.Token

**Functions:**

### `def image(state: StateInline, silent: bool) -> bool`

**Line:** 9

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.link
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/link.py`

**Imports:**
- common.utils.isStrSpace
- common.utils.normalizeReference
- state_inline.StateInline

**Functions:**

### `def link(state: StateInline, silent: bool) -> bool`

**Line:** 7

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.linkify
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/linkify.py`

**Imports:**
- re
- state_inline.StateInline

**Functions:**

### `def linkify(state: StateInline, silent: bool) -> bool`

**Description:**
Rule for identifying plain-text links.

**Line:** 10

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.newline
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/newline.py`

**Imports:**
- common.utils.charStrAt
- common.utils.isStrSpace
- state_inline.StateInline

**Functions:**

### `def newline(state: StateInline, silent: bool) -> bool`

**Line:** 6

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.strikethrough
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/strikethrough.py`

**Imports:**
- __future__.annotations
- state_inline.Delimiter
- state_inline.StateInline

**Functions:**

### `def tokenize(state: StateInline, silent: bool) -> bool`

**Description:**
Insert each marker as a separate text token, and add it to delimiter list

**Line:** 7

---

### `def _postProcess(state: StateInline, delimiters: list[Delimiter]) -> None`

**Line:** 51

---

### `def postProcess(state: StateInline) -> None`

**Description:**
Walk through delimiter list and replace text tokens with tags.

**Line:** 112

---


## Module: venv2.libthon3.12.site-packages.markdown_it.rules_inline.text
**File:** `venv2/lib/python3.12/site-packages/markdown_it/rules_inline/text.py`

**Imports:**
- state_inline.StateInline

**Functions:**

### `def text(state: StateInline, silent: bool) -> bool`

**Line:** 39

---


## Module: venv2.libthon3.12.site-packages.markdown_it.token
**File:** `venv2/lib/python3.12/site-packages/markdown_it/token.py`

**Imports:**
- __future__.annotations
- collections.abc.Callable
- collections.abc.MutableMapping
- dataclasses
- markdown_it._compat.DATACLASS_KWARGS
- typing.Any
- typing.Literal
- warnings

**Functions:**

### `def convert_attrs(value: Any) -> Any`

**Description:**
Convert Token.attrs set as ``None`` or ``[[key, value], ...]`` to a dict.

This improves compatibility with upstream markdown-it.

**Line:** 11

---


## Module: venv2.libthon3.12.site-packages.markdown_it.tree
**File:** `venv2/lib/python3.12/site-packages/markdown_it/tree.py`

**Imports:**
- __future__.annotations
- collections.abc.Generator
- collections.abc.Sequence
- textwrap
- token.Token
- typing.Any
- typing.NamedTuple
- typing.TypeVar
- typing.overload

**Functions:**

### `def _removesuffix(string: str, suffix: str) -> str`

**Description:**
Remove a suffix from a string.

Replace this with str.removesuffix() from stdlib when minimum Python
version is 3.9.

**Line:** 337

---


## Module: venv2.libthon3.12.site-packages.markdown_it.utils
**File:** `venv2/lib/python3.12/site-packages/markdown_it/utils.py`

**Imports:**
- __future__.annotations
- collections.abc.MutableMapping
- pathlib.Path
- typing.Any
- typing.Callable
- typing.Iterable
- typing.MutableMapping
- typing.TypedDict
- typing.cast

**Functions:**

### `def read_fixture_file(path: str | Path) -> list[list[Any]]`

**Line:** 157

---


## Module: venv2.libthon3.12.site-packages.markupsafe.__init__
**File:** `venv2/lib/python3.12/site-packages/markupsafe/__init__.py`

**Imports:**
- __future__.annotations
- _native._escape_inner
- _speedups._escape_inner
- collections.abc
- html.unescape
- importlib.metadata
- string
- typing
- typing_extensions
- warnings

**Functions:**

### `def escape(s: t.Any) -> Markup`

**Description:**
Replace the characters ``&``, ``<``, ``>``, ``'``, and ``"`` in
the string with HTML-safe sequences. Use this if you need to display
text that might contain such characters in HTML.

If the object has an ``__html__`` method, it is called and the
return value is assumed to already be safe for HTML.

:param s: An object to be converted to a string and escaped.
:return: A :class:`Markup` string with the escaped text.

**Line:** 24

---

### `def escape_silent(s: t.Any | None) -> Markup`

**Description:**
Like :func:`escape` but treats ``None`` as the empty string.
Useful with optional values, as otherwise you get the string
``'None'`` when the value is ``None``.

>>> escape(None)
Markup('None')
>>> escape_silent(None)
Markup('')

**Line:** 48

---

### `def soft_str(s: t.Any) -> str`

**Description:**
Convert an object to a string if it isn't already. This preserves
a :class:`Markup` string rather than converting it back to a basic
string, so it will still be marked as safe and won't be escaped
again.

>>> value = escape("<User 1>")
>>> value
Markup('&lt;User 1&gt;')
>>> escape(str(value))
Markup('&amp;lt;User 1&amp;gt;')
>>> escape(soft_str(value))
Markup('&lt;User 1&gt;')

**Line:** 64

---

### `def __getattr__(name: str) -> t.Any`

**Line:** 382

---


## Module: venv2.libthon3.12.site-packages.markupsafe._native
**File:** `venv2/lib/python3.12/site-packages/markupsafe/_native.py`

**Functions:**

### `def _escape_inner(s: str) -> str`

**Line:** 1

---


## Module: venv2.libthon3.12.site-packages.mdurl._decode
**File:** `venv2/lib/python3.12/site-packages/mdurl/_decode.py`

**Imports:**
- __future__.annotations
- collections.abc.Sequence
- functools
- re

**Functions:**

### `def get_decode_cache(exclude: str) -> Sequence[str]`

**Line:** 13

---

### `def decode(string: str, exclude: str = DECODE_DEFAULT_CHARS) -> str`

**Line:** 33

---

### `def repl_func_with_cache(match: re.Match, cache: Sequence[str]) -> str`

**Line:** 39

---


## Module: venv2.libthon3.12.site-packages.mdurl._encode
**File:** `venv2/lib/python3.12/site-packages/mdurl/_encode.py`

**Imports:**
- __future__.annotations
- collections.abc.Sequence
- string.ascii_letters
- string.digits
- string.hexdigits
- urllib.parse.quote

**Functions:**

### `def get_encode_cache(exclude: str) -> Sequence[str]`

**Line:** 17

---

### `def encode(string: str, exclude: str = ENCODE_DEFAULT_CHARS, keep_escaped: bool = True) -> str`

**Line:** 45

---


## Module: venv2.libthon3.12.site-packages.mdurl._format
**File:** `venv2/lib/python3.12/site-packages/mdurl/_format.py`

**Imports:**
- __future__.annotations
- mdurl._url.URL
- typing.TYPE_CHECKING

**Functions:**

### `def format(url: URL) -> str`

**Line:** 9

---


## Module: venv2.libthon3.12.site-packages.mdurl._parse
**File:** `venv2/lib/python3.12/site-packages/mdurl/_parse.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- mdurl._url.URL
- re

**Functions:**

### `def url_parse(url: URL | str, slashes_denote_host: bool = False) -> URL`

**Line:** 297

---


## Module: venv2.libthon3.12.site-packages.mypy.__main__
**File:** `venv2/lib/python3.12/site-packages/mypy/__main__.py`

**Imports:**
- __future__.annotations
- mypy.main.main
- mypy.main.process_options
- mypy.util.FancyFormatter
- os
- sys
- traceback

**Functions:**

### `def console_entry() -> None`

**Line:** 13

---


## Module: venv2.libthon3.12.site-packages.mypy.api
**File:** `venv2/lib/python3.12/site-packages/mypy/api.py`

**Imports:**
- __future__.annotations
- io.StringIO
- mypy.dmypy.client.main
- mypy.main.main
- sys
- typing.Callable
- typing.TextIO

**Functions:**

### `def _run(main_wrapper: Callable[([TextIO, TextIO], None)]) -> tuple[(str, str, int)]`

**Line:** 53

---

### `def run(args: list[str]) -> tuple[(str, str, int)]`

**Line:** 67

---

### `def run_dmypy(args: list[str]) -> tuple[(str, str, int)]`

**Line:** 76

---


## Module: venv2.libthon3.12.site-packages.mypy.applytype
**File:** `venv2/lib/python3.12/site-packages/mypy/applytype.py`

**Imports:**
- __future__.annotations
- mypy.erasetype.erase_typevars
- mypy.expandtype.expand_type
- mypy.nodes.Context
- mypy.subtypes
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.ParamSpecType
- mypy.types.PartialType
- mypy.types.Type
- mypy.types.TypeVarId
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.UninhabitedType
- mypy.types.UnpackType
- mypy.types.get_proper_type
- typing.Callable
- typing.Sequence

**Functions:**

### `def get_target_type(tvar: TypeVarLikeType, type: Type, callable: CallableType, report_incompatible_typevar_value: Callable[([CallableType, Type, str, Context], None)], context: Context, skip_unsatisfied: bool) -> Type | None`

**Line:** 25

---

### `def apply_generic_arguments(callable: CallableType, orig_types: Sequence[Type | None], report_incompatible_typevar_value: Callable[([CallableType, Type, str, Context], None)], context: Context, skip_unsatisfied: bool = False) -> CallableType`

**Description:**
Apply generic type arguments to a callable type.

For example, applying [int] to 'def [T] (T) -> T' results in
'def (int) -> int'.

Note that each type can be None; in this case, it will not be applied.

If `skip_unsatisfied` is True, then just skip the types that don't satisfy type variable
bound or constraints, instead of giving an error.

**Line:** 78

---


## Module: venv2.libthon3.12.site-packages.mypy.argmap
**File:** `venv2/lib/python3.12/site-packages/mypy/argmap.py`

**Imports:**
- __future__.annotations
- mypy.infer.ArgumentInferContext
- mypy.maptype.map_instance_to_supertype
- mypy.nodes
- mypy.subtypes.is_subtype
- mypy.types.AnyType
- mypy.types.Instance
- mypy.types.ParamSpecType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeVarTupleType
- mypy.types.TypedDictType
- mypy.types.UnpackType
- mypy.types.get_proper_type
- typing.Callable
- typing.Sequence
- typing.TYPE_CHECKING

**Functions:**

### `def map_actuals_to_formals(actual_kinds: list[nodes.ArgKind], actual_names: Sequence[str | None] | None, formal_kinds: list[nodes.ArgKind], formal_names: Sequence[str | None], actual_arg_type: Callable[([int], Type)]) -> list[list[int]]`

**Description:**
Calculate mapping between actual (caller) args and formals.

The result contains a list of caller argument indexes mapping to each
callee argument index, indexed by callee index.

The caller_arg_type argument should evaluate to the type of the actual
argument type with the given index.

**Line:** 26

---

### `def map_formals_to_actuals(actual_kinds: list[nodes.ArgKind], actual_names: Sequence[str | None] | None, formal_kinds: list[nodes.ArgKind], formal_names: list[str | None], actual_arg_type: Callable[([int], Type)]) -> list[list[int]]`

**Description:**
Calculate the reverse mapping of map_actuals_to_formals.

**Line:** 124

---


## Module: venv2.libthon3.12.site-packages.mypy.binder
**File:** `venv2/lib/python3.12/site-packages/mypy/binder.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- contextlib.contextmanager
- mypy.erasetype.remove_instance_last_known_values
- mypy.join.join_simple
- mypy.literals.Key
- mypy.literals.literal
- mypy.literals.literal_hash
- mypy.literals.subkeys
- mypy.nodes.Expression
- mypy.nodes.IndexExpr
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.RefExpr
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.subtypes.is_same_type
- mypy.subtypes.is_subtype
- mypy.types.AnyType
- mypy.types.Instance
- mypy.types.NoneType
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.find_unpack_in_list
- mypy.types.get_proper_type
- mypy.typevars.fill_typevars_with_any
- typing.DefaultDict
- typing.Iterator
- typing.List
- typing.Optional
- typing.Tuple
- typing.Union
- typing.cast
- typing_extensions.TypeAlias

**Functions:**

### `def get_declaration(expr: BindableExpression) -> Type | None`

**Line:** 470

---

### `def collapse_variadic_union(typ: UnionType) -> Type`

**Description:**
Simplify a union involving variadic tuple if possible.

This will collapse a type like e.g.
tuple[X, Z] | tuple[X, Y, Z] | tuple[X, Y, Y, *tuple[Y, ...], Z]
back to
tuple[X, *tuple[Y, ...], Z]
which is equivalent, but much simpler form of the same type.

**Line:** 481

---


## Module: venv2.libthon3.12.site-packages.mypy.build
**File:** `venv2/lib/python3.12/site-packages/mypy/build.py`

**Imports:**
- __future__.annotations
- collections
- contextlib
- errno
- gc
- importlib
- json
- mypy.build
- mypy.checker.TypeChecker
- mypy.config_parser.parse_mypy_comments
- mypy.errorcodes
- mypy.errors.CompileError
- mypy.errors.ErrorInfo
- mypy.errors.Errors
- mypy.errors.report_internal_error
- mypy.fixup.fixup_module
- mypy.freetree.free_tree
- mypy.fscache.FileSystemCache
- mypy.graph_utils.prepare_sccs
- mypy.graph_utils.strongly_connected_components
- mypy.graph_utils.topsort
- mypy.indirection.TypeIndirectionVisitor
- mypy.messages.MessageBuilder
- mypy.metastore.FilesystemMetadataStore
- mypy.metastore.MetadataStore
- mypy.metastore.SqliteMetadataStore
- mypy.modulefinder.BuildSource
- mypy.modulefinder.BuildSourceSet
- mypy.modulefinder.FindModuleCache
- mypy.modulefinder.ModuleNotFoundReason
- mypy.modulefinder.ModuleSearchResult
- mypy.modulefinder.SearchPaths
- mypy.modulefinder.compute_search_paths
- mypy.nodes.Expression
- mypy.nodes.Import
- mypy.nodes.ImportAll
- mypy.nodes.ImportBase
- mypy.nodes.ImportFrom
- mypy.nodes.MypyFile
- mypy.nodes.SymbolTable
- mypy.nodes.TypeInfo
- mypy.options.Options
- mypy.parse.parse
- mypy.partially_defined.PossiblyUndefinedVariableVisitor
- mypy.plugin.ChainedPlugin
- mypy.plugin.Plugin
- mypy.plugin.ReportConfigContext
- mypy.plugins.default.DefaultPlugin
- mypy.refinfo.get_undocumented_ref_info_json
- mypy.renaming.LimitedVariableRenameVisitor
- mypy.renaming.VariableRenameVisitor
- mypy.report.Reports
- mypy.semanal.SemanticAnalyzer
- mypy.semanal_main
- mypy.semanal_pass1.SemanticAnalyzerPreAnalysis
- mypy.server.deps.dump_all_dependencies
- mypy.server.deps.get_dependencies
- mypy.server.deps.merge_dependencies
- mypy.server.target.trigger_to_target
- mypy.stats.dump_type_stats
- mypy.stubinfo.legacy_bundled_packages
- mypy.stubinfo.non_bundled_packages
- mypy.stubinfo.stub_distribution_name
- mypy.types.Type
- mypy.typestate.reset_global_state
- mypy.typestate.type_state
- mypy.util.DecodeError
- mypy.util.decode_python_encoding
- mypy.util.get_mypy_comments
- mypy.util.hash_digest
- mypy.util.is_stub_package_file
- mypy.util.is_sub_path
- mypy.util.is_typeshed_file
- mypy.util.module_prefix
- mypy.util.read_py_file
- mypy.util.time_ref
- mypy.util.time_spent_us
- mypy.version.__version__
- os
- platform
- re
- stat
- sys
- time
- types
- typing.AbstractSet
- typing.Any
- typing.Callable
- typing.ClassVar
- typing.Dict
- typing.Final
- typing.Iterator
- typing.Mapping
- typing.NamedTuple
- typing.NoReturn
- typing.Sequence
- typing.TYPE_CHECKING
- typing.TextIO
- typing_extensions.TypeAlias
- typing_extensions.TypedDict

**Functions:**

### `def build(sources: list[BuildSource], options: Options, alt_lib_path: str | None = None, flush_errors: Callable[[list[str], bool], None] | None = None, fscache: FileSystemCache | None = None, stdout: TextIO | None = None, stderr: TextIO | None = None, extra_plugins: Sequence[Plugin] | None = None) -> BuildResult`

**Description:**
Analyze a program.

A single call to build performs parsing, semantic analysis and optionally
type checking for the program *and* all imported modules, recursively.

Return BuildResult if successful or only non-blocking errors were found;
otherwise raise CompileError.

If a flush_errors callback is provided, all error messages will be
passed to it and the errors and messages fields of BuildResult and
CompileError (respectively) will be empty. Otherwise those fields will
report any error messages.

Args:
sources: list of sources to build
options: build options
alt_lib_path: an additional directory for looking up library modules
(takes precedence over other directories)
flush_errors: optional function to flush errors after a file is processed
fscache: optionally a file-system cacher

**Line:** 144

---

### `def _build(sources: list[BuildSource], options: Options, alt_lib_path: str | None, flush_errors: Callable[([list[str], bool], None)], fscache: FileSystemCache | None, stdout: TextIO, stderr: TextIO, extra_plugins: Sequence[Plugin]) -> BuildResult`

**Line:** 205

---

### `def default_data_dir() -> str`

**Description:**
Returns directory containing typeshed directory.

**Line:** 294

---

### `def normpath(path: str, options: Options) -> str`

**Description:**
Convert path to absolute; but to relative in bazel mode.

(Bazel's distributed cache doesn't like filesystem metadata to
end up in output files.)

**Line:** 299

---

### `def cache_meta_from_dict(meta: dict[(str, Any)], data_json: str) -> CacheMeta`

**Description:**
Build a CacheMeta object from a json metadata dictionary

Args:
meta: JSON metadata read from the metadata cache file
data_json: Path to the .data.json file containing the AST trees

**Line:** 345

---

### `def import_priority(imp: ImportBase, toplevel_priority: int) -> int`

**Description:**
Compute import priority from an import node.

**Line:** 384

---

### `def load_plugins_from_config(options: Options, errors: Errors, stdout: TextIO) -> tuple[(list[Plugin], dict[str, str])]`

**Description:**
Load all configured plugins.

Return a list of all the loaded plugins from the config file.
The second return value is a snapshot of versions/hashes of loaded user
plugins (for cache validation).

**Line:** 396

---

### `def load_plugins(options: Options, errors: Errors, stdout: TextIO, extra_plugins: Sequence[Plugin]) -> tuple[(Plugin, dict[str, str])]`

**Description:**
Load all configured plugins.

Return a plugin that encapsulates all plugins chained together. Always
at least include the default plugin (it's last in the chain).
The second return value is a snapshot of versions/hashes of loaded user
plugins (for cache validation).

**Line:** 488

---

### `def take_module_snapshot(module: types.ModuleType) -> str`

**Description:**
Take plugin module snapshot by recording its version and hash.

We record _both_ hash and the version to detect more possible changes
(e.g. if there is a change in modules imported by a plugin).

**Line:** 510

---

### `def find_config_file_line_number(path: str, section: str, setting_name: str) -> int`

**Description:**
Return the approximate location of setting_name within mypy config file.

Return -1 if can't determine the line unambiguously.

**Line:** 526

---

### `def deps_to_json(x: dict[(str, set[str])]) -> str`

**Line:** 909

---

### `def write_deps_cache(rdeps: dict[(str, dict[str, set[str]])], manager: BuildManager, graph: Graph) -> None`

**Description:**
Write cache files for fine-grained dependencies.

Serialize fine-grained dependencies map for fine grained mode.

Dependencies on some module 'm' is stored in the dependency cache
file m.deps.json.  This entails some spooky action at a distance:
if module 'n' depends on 'm', that produces entries in m.deps.json.
When there is a dependency on a module that does not exist in the
build, it is stored with its first existing parent module. If no
such module exists, it is stored with the fake module FAKE_ROOT_MODULE.

This means that the validity of the fine-grained dependency caches
are a global property, so we store validity checking information for
fine-grained dependencies in a global cache file:
* We take a snapshot of current sources to later check consistency
between the fine-grained dependency cache and module cache metadata
* We store the mtime of all of the dependency files to verify they
haven't changed

**Line:** 923

---

### `def invert_deps(deps: dict[(str, set[str])], graph: Graph) -> dict[(str, dict[str, set[str]])]`

**Description:**
Splits fine-grained dependencies based on the module of the trigger.

Returns a dictionary from module ids to all dependencies on that
module. Dependencies not associated with a module in the build will be
associated with the nearest parent module that is in the build, or the
fake module FAKE_ROOT_MODULE if none are.

**Line:** 987

---

### `def generate_deps_for_cache(manager: BuildManager, graph: Graph) -> dict[(str, dict[str, set[str]])]`

**Description:**
Generate fine-grained dependencies into a form suitable for serializing.

This does a couple things:
1. Splits fine-grained deps based on the module of the trigger
2. For each module we generated fine-grained deps for, load any previous
deps and merge them in.

Returns a dictionary from module ids to all dependencies on that
module. Dependencies not associated with a module in the build will be
associated with the nearest parent module that is in the build, or the
fake module FAKE_ROOT_MODULE if none are.

**Line:** 1013

---

### `def write_plugins_snapshot(manager: BuildManager) -> None`

**Description:**
Write snapshot of versions and hashes of currently active plugins.

**Line:** 1044

---

### `def read_plugins_snapshot(manager: BuildManager) -> dict[str, str] | None`

**Description:**
Read cached snapshot of versions and hashes of plugins from previous run.

**Line:** 1052

---

### `def read_quickstart_file(options: Options, stdout: TextIO) -> dict[str, tuple[float, int, str]] | None`

**Line:** 1068

---

### `def read_deps_cache(manager: BuildManager, graph: Graph) -> dict[str, FgDepMeta] | None`

**Description:**
Read and validate the fine-grained dependencies cache.

See the write_deps_cache documentation for more information on
the details of the cache.

Returns None if the cache was invalid in some way.

**Line:** 1088

---

### `def _load_json_file(file: str, manager: BuildManager, log_success: str, log_error: str) -> dict[str, Any] | None`

**Description:**
A simple helper to read a JSON file with logging.

**Line:** 1133

---

### `def _cache_dir_prefix(options: Options) -> str`

**Description:**
Get current cache directory (or file if id is given).

**Line:** 1168

---

### `def add_catch_all_gitignore(target_dir: str) -> None`

**Description:**
Add catch-all .gitignore to an existing directory.

No-op if the .gitignore already exists.

**Line:** 1179

---

### `def exclude_from_backups(target_dir: str) -> None`

**Description:**
Exclude the directory from various archives and backups supporting CACHEDIR.TAG.

If the CACHEDIR.TAG file exists the function is a no-op.

**Line:** 1193

---

### `def create_metastore(options: Options) -> MetadataStore`

**Description:**
Create the appropriate metadata store.

**Line:** 1211

---

### `def get_cache_names(id: str, path: str, options: Options) -> tuple[(str, str, str | None)]`

**Description:**
Return the file names for the cache files.

Args:
id: module ID
path: module path
cache_dir: cache directory
pyversion: Python version (major, minor)

Returns:
A tuple with the file names to be used for the meta JSON, the
data JSON, and the fine-grained deps JSON, respectively.

**Line:** 1220

---

### `def find_cache_meta(id: str, path: str, manager: BuildManager) -> CacheMeta | None`

**Description:**
Find cache data for a module.

Args:
id: module ID
path: module path
manager: the build manager (for pyversion, log/trace, and build options)

Returns:
A CacheMeta instance if the cache data was found and appears
valid; otherwise None.

**Line:** 1256

---

### `def validate_meta(meta: CacheMeta | None, id: str, path: str | None, ignore_all: bool, manager: BuildManager) -> CacheMeta | None`

**Description:**
Checks whether the cached AST of this module can be used.

Returns:
None, if the cached AST is unusable.
Original meta, if mtime/size matched.
Meta with mtime updated to match source file, if hash/size matched but mtime/path didn't.

**Line:** 1352

---

### `def compute_hash(text: str) -> str`

**Line:** 1496

---

### `def json_dumps(obj: Any, debug_cache: bool) -> str`

**Line:** 1505

---

### `def write_cache(id: str, path: str, tree: MypyFile, dependencies: list[str], suppressed: list[str], dep_prios: list[int], dep_lines: list[int], old_interface_hash: str, source_hash: str, ignore_all: bool, manager: BuildManager) -> tuple[(str, CacheMeta | None)]`

**Description:**
Write cache files for a module.

Note that this mypy's behavior is still correct when any given
write_cache() call is replaced with a no-op, so error handling
code that bails without writing anything is okay.

Args:
id: module ID
path: module path
tree: the fully checked module data
dependencies: module IDs on which this module depends
suppressed: module IDs which were suppressed as dependencies
dep_prios: priorities (parallel array to dependencies)
dep_lines: import line locations (parallel array to dependencies)
old_interface_hash: the hash from the previous version of the data cache file
source_hash: the hash of the source code
ignore_all: the ignore_all flag for this module
manager: the build manager (for pyversion, log/trace)

Returns:
A tuple containing the interface hash and CacheMeta
corresponding to the metadata that was written (the latter may
be None if the cache could not be written).

**Line:** 1512

---

### `def delete_cache(id: str, path: str, manager: BuildManager) -> None`

**Description:**
Delete cache files for a module.

The cache files for a module are deleted when mypy finds errors there.
This avoids inconsistent states with cache files from different mypy runs,
see #4043 for an example.

**Line:** 1648

---

### `def find_module_and_diagnose(manager: BuildManager, id: str, options: Options, caller_state: State | None = None, caller_line: int = 0, ancestor_for: State | None = None, root_source: bool = False, skip_diagnose: bool = False) -> tuple[(str, str)]`

**Description:**
Find a module by name, respecting follow_imports and producing diagnostics.

If the module is not found, then the ModuleNotFound exception is raised.

Args:
id: module to find
options: the options for the module being loaded
caller_state: the state of the importing module, if applicable
caller_line: the line number of the import
ancestor_for: the child module this is an ancestor of, if applicable
root_source: whether this source was specified on the command line
skip_diagnose: skip any error diagnosis and reporting (but ModuleNotFound is
still raised if the module is missing)

The specified value of follow_imports for a module can be overridden
if the module is specified on the command line or if it is a stub,
so we compute and return the "effective" follow_imports of the module.

Returns a tuple containing (file path, target's effective follow_imports setting)

**Line:** 2595

---

### `def exist_added_packages(suppressed: list[str], manager: BuildManager, options: Options) -> bool`

**Description:**
Find if there are any newly added packages that were previously suppressed.

Exclude everything not in build for follow-imports=skip.

**Line:** 2698

---

### `def find_module_simple(id: str, manager: BuildManager) -> str | None`

**Description:**
Find a filesystem path for module `id` or `None` if not found.

**Line:** 2722

---

### `def find_module_with_reason(id: str, manager: BuildManager) -> ModuleSearchResult`

**Description:**
Find a filesystem path for module `id` or the reason it can't be found.

**Line:** 2730

---

### `def in_partial_package(id: str, manager: BuildManager) -> bool`

**Description:**
Check if a missing module can potentially be a part of a package.

This checks if there is any existing parent __init__.pyi stub that
defines a module-level __getattr__ (a.k.a. partial stub package).

**Line:** 2738

---

### `def module_not_found(manager: BuildManager, line: int, caller_state: State, target: str, reason: ModuleNotFoundReason) -> None`

**Line:** 2765

---

### `def skipping_module(manager: BuildManager, line: int, caller_state: State | None, id: str, path: str) -> None`

**Description:**
Produce an error for an import ignored due to --follow_imports=error

**Line:** 2810

---

### `def skipping_ancestor(manager: BuildManager, id: str, path: str, ancestor_for: State) -> None`

**Description:**
Produce an error for an ancestor ignored due to --follow_imports=error

**Line:** 2829

---

### `def log_configuration(manager: BuildManager, sources: list[BuildSource]) -> None`

**Description:**
Output useful configuration information to LOG and TRACE

**Line:** 2849

---

### `def dispatch(sources: list[BuildSource], manager: BuildManager, stdout: TextIO) -> Graph`

**Line:** 2884

---

### `def dump_timing_stats(path: str, graph: Graph) -> None`

**Description:**
Dump timing stats for each file in the given graph.

**Line:** 2987

---

### `def dump_line_checking_stats(path: str, graph: Graph) -> None`

**Description:**
Dump per-line expression type checking stats.

**Line:** 2994

---

### `def dump_graph(graph: Graph, stdout: TextIO | None = None) -> None`

**Description:**
Dump the graph as a JSON string to stdout.

This copies some of the work by process_graph()
(sorted_components() and order_ascc()).

**Line:** 3006

---

### `def load_graph(sources: list[BuildSource], manager: BuildManager, old_graph: Graph | None = None, new_modules: list[State] | None = None) -> Graph`

**Description:**
Given some source files, load the full dependency graph.

If an old_graph is passed in, it is used as the starting point and
modified during graph loading.

If a new_modules is passed in, any modules that are loaded are
added to the list. This is an argument and not a return value
so that the caller can access it even if load_graph fails.

As this may need to parse files, this can raise CompileError in case
there are syntax errors.

**Line:** 3045

---

### `def process_graph(graph: Graph, manager: BuildManager) -> None`

**Description:**
Process everything in dependency order.

**Line:** 3207

---

### `def order_ascc(graph: Graph, ascc: AbstractSet[str], pri_max: int = PRI_ALL) -> list[str]`

**Description:**
Come up with the ideal processing order within an SCC.

Using the priorities assigned by all_imported_modules_in_file(),
try to reduce the cycle to a DAG, by omitting arcs representing
dependencies of lower priority.

In the simplest case, if we have A <--> B where A has a top-level
"import B" (medium priority) but B only has the reverse "import A"
inside a function (low priority), we turn the cycle into a DAG by
dropping the B --> A arc, which leaves only A --> B.

If all arcs have the same priority, we fall back to sorting by
reverse global order (the order in which modules were first
encountered).

The algorithm is recursive, as follows: when as arcs of different
priorities are present, drop all arcs of the lowest priority,
identify SCCs in the resulting graph, and apply the algorithm to
each SCC thus found.  The recursion is bounded because at each
recursion the spread in priorities is (at least) one less.

In practice there are only a few priority levels (less than a
dozen) and in the worst case we just carry out the same algorithm
for finding SCCs N times.  Thus the complexity is no worse than
the complexity of the original SCC-finding algorithm -- see
strongly_connected_components() below for a reference.

**Line:** 3355

---

### `def process_fresh_modules(graph: Graph, modules: list[str], manager: BuildManager) -> None`

**Description:**
Process the modules in one group of modules from their cached data.

This can be used to process an SCC of modules
This involves loading the tree from JSON and then doing various cleanups.

**Line:** 3402

---

### `def process_stale_scc(graph: Graph, scc: list[str], manager: BuildManager) -> None`

**Description:**
Process the modules in one SCC from source code.

Exception: If quick_and_dirty is set, use the cache for fresh modules.

**Line:** 3418

---

### `def sorted_components(graph: Graph, vertices: AbstractSet[str] | None = None, pri_max: int = PRI_ALL) -> list[AbstractSet[str]]`

**Description:**
Return the graph's SCCs, topologically sorted by dependencies.

The sort order is from leaves (nodes without dependencies) to
roots (nodes on which no other nodes depend).

This works for a subset of the full dependency graph too;
dependencies that aren't present in graph.keys() are ignored.

**Line:** 3466

---

### `def deps_filtered(graph: Graph, vertices: AbstractSet[str], id: str, pri_max: int) -> list[str]`

**Description:**
Filter dependencies for id with pri < pri_max.

**Line:** 3497

---

### `def missing_stubs_file(cache_dir: str) -> str`

**Line:** 3509

---

### `def record_missing_stub_packages(cache_dir: str, missing_stub_packages: set[str]) -> None`

**Description:**
Write a file containing missing stub packages.

This allows a subsequent "mypy --install-types" run (without other arguments)
to install missing stub packages.

**Line:** 3513

---

### `def is_silent_import_module(manager: BuildManager, path: str) -> bool`

**Line:** 3529

---

### `def write_undocumented_ref_info(state: State, metastore: MetadataStore, options: Options, type_map: dict[(Expression, Type)]) -> None`

**Line:** 3539

---


## Module: venv2.libthon3.12.site-packages.mypy.checker
**File:** `venv2/lib/python3.12/site-packages/mypy/checker.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- contextlib.contextmanager
- contextlib.nullcontext
- itertools
- mypy.binder.ConditionalTypeBinder
- mypy.binder.Frame
- mypy.binder.get_declaration
- mypy.checkexpr
- mypy.checkmember.MemberContext
- mypy.checkmember.analyze_decorator_or_funcbase_access
- mypy.checkmember.analyze_descriptor_access
- mypy.checkmember.analyze_member_access
- mypy.checkmember.type_object_type
- mypy.checkpattern.PatternChecker
- mypy.constraints.SUPERTYPE_OF
- mypy.erasetype.erase_type
- mypy.erasetype.erase_typevars
- mypy.erasetype.remove_instance_last_known_values
- mypy.errorcodes
- mypy.errorcodes.ErrorCode
- mypy.errorcodes.TYPE_VAR
- mypy.errorcodes.UNUSED_AWAITABLE
- mypy.errorcodes.UNUSED_COROUTINE
- mypy.errors.ErrorWatcher
- mypy.errors.Errors
- mypy.errors.report_internal_error
- mypy.expandtype.expand_self_type
- mypy.expandtype.expand_type
- mypy.expandtype.expand_type_by_instance
- mypy.literals.Key
- mypy.literals.extract_var_from_literal_hash
- mypy.literals.literal
- mypy.literals.literal_hash
- mypy.maptype.map_instance_to_supertype
- mypy.meet.is_overlapping_erased_types
- mypy.meet.is_overlapping_types
- mypy.meet.meet_types
- mypy.message_registry
- mypy.message_registry.ErrorMessage
- mypy.messages.MessageBuilder
- mypy.messages.SUGGESTED_TEST_FIXTURES
- mypy.messages.append_invariance_notes
- mypy.messages.format_type
- mypy.messages.format_type_bare
- mypy.messages.format_type_distinctly
- mypy.messages.make_inferred_type_note
- mypy.messages.pretty_seq
- mypy.mro.MroError
- mypy.mro.calculate_mro
- mypy.nodes
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.AssertStmt
- mypy.nodes.AssignmentExpr
- mypy.nodes.AssignmentStmt
- mypy.nodes.Block
- mypy.nodes.BreakStmt
- mypy.nodes.BytesExpr
- mypy.nodes.CONTRAVARIANT
- mypy.nodes.COVARIANT
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.ComparisonExpr
- mypy.nodes.Context
- mypy.nodes.ContinueStmt
- mypy.nodes.Decorator
- mypy.nodes.DelStmt
- mypy.nodes.EllipsisExpr
- mypy.nodes.Expression
- mypy.nodes.ExpressionStmt
- mypy.nodes.FUNC_NO_INFO
- mypy.nodes.FloatExpr
- mypy.nodes.ForStmt
- mypy.nodes.FuncBase
- mypy.nodes.FuncDef
- mypy.nodes.FuncItem
- mypy.nodes.GDEF
- mypy.nodes.IMPLICITLY_ABSTRACT
- mypy.nodes.INVARIANT
- mypy.nodes.IS_ABSTRACT
- mypy.nodes.IfStmt
- mypy.nodes.Import
- mypy.nodes.ImportAll
- mypy.nodes.ImportBase
- mypy.nodes.ImportFrom
- mypy.nodes.IndexExpr
- mypy.nodes.IntExpr
- mypy.nodes.LDEF
- mypy.nodes.LITERAL_TYPE
- mypy.nodes.LambdaExpr
- mypy.nodes.ListExpr
- mypy.nodes.Lvalue
- mypy.nodes.MDEF
- mypy.nodes.MatchStmt
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NOT_ABSTRACT
- mypy.nodes.NameExpr
- mypy.nodes.Node
- mypy.nodes.OpExpr
- mypy.nodes.OperatorAssignmentStmt
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.PassStmt
- mypy.nodes.PromoteExpr
- mypy.nodes.RaiseStmt
- mypy.nodes.RefExpr
- mypy.nodes.ReturnStmt
- mypy.nodes.StarExpr
- mypy.nodes.Statement
- mypy.nodes.StrExpr
- mypy.nodes.SymbolNode
- mypy.nodes.SymbolTable
- mypy.nodes.SymbolTableNode
- mypy.nodes.TempNode
- mypy.nodes.TryStmt
- mypy.nodes.TupleExpr
- mypy.nodes.TypeAlias
- mypy.nodes.TypeInfo
- mypy.nodes.TypeVarExpr
- mypy.nodes.UnaryExpr
- mypy.nodes.Var
- mypy.nodes.WhileStmt
- mypy.nodes.WithStmt
- mypy.nodes.YieldExpr
- mypy.nodes.is_final_node
- mypy.operators
- mypy.operators.flip_ops
- mypy.operators.int_op_to_method
- mypy.operators.neg_ops
- mypy.options.Options
- mypy.options.PRECISE_TUPLE_TYPES
- mypy.patterns.AsPattern
- mypy.patterns.StarredPattern
- mypy.plugin.CheckerPluginInterface
- mypy.plugin.Plugin
- mypy.plugins.dataclasses
- mypy.scope.Scope
- mypy.semanal.is_trivial_body
- mypy.semanal.refers_to_fullname
- mypy.semanal.set_callable_name
- mypy.semanal_enum.ENUM_BASES
- mypy.semanal_enum.ENUM_SPECIAL_PROPS
- mypy.sharedparse.BINARY_MAGIC_METHODS
- mypy.state.state
- mypy.subtypes.find_member
- mypy.subtypes.is_callable_compatible
- mypy.subtypes.is_equivalent
- mypy.subtypes.is_more_precise
- mypy.subtypes.is_proper_subtype
- mypy.subtypes.is_same_type
- mypy.subtypes.is_subtype
- mypy.subtypes.restrict_subtype_away
- mypy.subtypes.unify_generic_callable
- mypy.traverser.TraverserVisitor
- mypy.traverser.all_return_statements
- mypy.traverser.has_return_statement
- mypy.treetransform.TransformVisitor
- mypy.typeanal.check_for_explicit_any
- mypy.typeanal.has_any_from_unimported_type
- mypy.typeanal.make_optional_type
- mypy.typeops.bind_self
- mypy.typeops.coerce_to_literal
- mypy.typeops.custom_special_method
- mypy.typeops.erase_def_to_union_or_bound
- mypy.typeops.erase_to_bound
- mypy.typeops.erase_to_union_or_bound
- mypy.typeops.false_only
- mypy.typeops.fixup_partial_type
- mypy.typeops.function_type
- mypy.typeops.get_type_vars
- mypy.typeops.is_literal_type_like
- mypy.typeops.is_singleton_type
- mypy.typeops.make_simplified_union
- mypy.typeops.map_type_from_supertype
- mypy.typeops.true_only
- mypy.typeops.try_expanding_sum_type_to_union
- mypy.typeops.try_getting_int_literals_from_type
- mypy.typeops.try_getting_str_literals
- mypy.typeops.try_getting_str_literals_from_type
- mypy.typeops.tuple_fallback
- mypy.types.ANY_STRATEGY
- mypy.types.AnyType
- mypy.types.BoolTypeQuery
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.ErasedType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.MYPYC_NATIVE_INT_NAMES
- mypy.types.NoneType
- mypy.types.OVERLOAD_NAMES
- mypy.types.Overloaded
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeGuardedType
- mypy.types.TypeOfAny
- mypy.types.TypeTranslator
- mypy.types.TypeType
- mypy.types.TypeVarId
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.find_unpack_in_list
- mypy.types.flatten_nested_unions
- mypy.types.get_proper_type
- mypy.types.get_proper_types
- mypy.types.is_literal_type
- mypy.types.is_named_instance
- mypy.types_utils.is_overlapping_none
- mypy.types_utils.remove_optional
- mypy.types_utils.store_argument_type
- mypy.types_utils.strip_type
- mypy.typetraverser.TypeTraverserVisitor
- mypy.typevars.fill_typevars
- mypy.typevars.fill_typevars_with_any
- mypy.typevars.has_no_typevars
- mypy.util.is_dunder
- mypy.util.is_sunder
- mypy.visitor.NodeVisitor
- typing.AbstractSet
- typing.Callable
- typing.Dict
- typing.Final
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.Mapping
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- typing_extensions.TypeAlias

**Functions:**

### `def conditional_types(current_type: Type, proposed_type_ranges: list[TypeRange] | None, default: None = None) -> tuple[(Type | None, Type | None)]`

**Decorators:**
- `@overload`

**Line:** 7309

---

### `def conditional_types(current_type: Type, proposed_type_ranges: list[TypeRange] | None, default: Type) -> tuple[(Type, Type)]`

**Decorators:**
- `@overload`

**Line:** 7316

---

### `def conditional_types(current_type: Type, proposed_type_ranges: list[TypeRange] | None, default: Type | None = None) -> tuple[(Type | None, Type | None)]`

**Description:**
Takes in the current type and a proposed type of an expression.

Returns a 2-tuple: The first element is the proposed type, if the expression
can be the proposed type. The second element is the type it would hold
if it was not the proposed type, if any. UninhabitedType means unreachable.
None means no new information can be inferred. If default is set it is returned
instead.

**Line:** 7322

---

### `def conditional_types_to_typemaps(expr: Expression, yes_type: Type | None, no_type: Type | None) -> tuple[(TypeMap, TypeMap)]`

**Line:** 7374

---

### `def gen_unique_name(base: str, table: SymbolTable) -> str`

**Description:**
Generate a name that does not appear in table by appending numbers to base.

**Line:** 7392

---

### `def is_true_literal(n: Expression) -> bool`

**Description:**
Returns true if this expression is the 'True' literal/keyword.

**Line:** 7402

---

### `def is_false_literal(n: Expression) -> bool`

**Description:**
Returns true if this expression is the 'False' literal/keyword.

**Line:** 7407

---

### `def is_literal_none(n: Expression) -> bool`

**Description:**
Returns true if this expression is the 'None' literal/keyword.

**Line:** 7412

---

### `def is_literal_not_implemented(n: Expression) -> bool`

**Line:** 7417

---

### `def _is_empty_generator_function(func: FuncItem) -> bool`

**Description:**
Checks whether a function's body is 'return; yield' (the yield being added only
to promote the function into a generator function).

**Line:** 7421

---

### `def builtin_item_type(tp: Type) -> Type | None`

**Description:**
Get the item type of a builtin container.

If 'tp' is not one of the built containers (these includes NamedTuple and TypedDict)
or if the container is not parameterized (like List or List[Any])
return None. This function is used to narrow optional types in situations like this:

x: Optional[int]
if x in (1, 2, 3):
x + 42  # OK

Note: this is only OK for built-in containers, where we know the behavior
of __contains__.

**Line:** 7437

---

### `def and_conditional_maps(m1: TypeMap, m2: TypeMap, use_meet: bool = False) -> TypeMap`

**Description:**
Calculate what information we can learn from the truth of (e1 and e2)
in terms of the information that we can learn from the truth of e1 and
the truth of e2.

**Line:** 7494

---

### `def or_conditional_maps(m1: TypeMap, m2: TypeMap, coalesce_any: bool = False) -> TypeMap`

**Description:**
Calculate what information we can learn from the truth of (e1 or e2)
in terms of the information that we can learn from the truth of e1 and
the truth of e2. If coalesce_any is True, consider Any a supertype when
joining restrictions.

**Line:** 7524

---

### `def reduce_conditional_maps(type_maps: list[tuple[(TypeMap, TypeMap)]], use_meet: bool = False) -> tuple[(TypeMap, TypeMap)]`

**Description:**
Reduces a list containing pairs of if/else TypeMaps into a single pair.

We "and" together all of the if TypeMaps and "or" together the else TypeMaps. So
for example, if we had the input:

[
({x: TypeIfX, shared: TypeIfShared1}, {x: TypeElseX, shared: TypeElseShared1}),
({y: TypeIfY, shared: TypeIfShared2}, {y: TypeElseY, shared: TypeElseShared2}),
]

...we'd return the output:

(
{x: TypeIfX,   y: TypeIfY,   shared: PseudoIntersection[TypeIfShared1, TypeIfShared2]},
{shared: Union[TypeElseShared1, TypeElseShared2]},
)

...where "PseudoIntersection[X, Y] == Y" because mypy actually doesn't understand intersections
yet, so we settle for just arbitrarily picking the right expr's type.

We only retain the shared expression in the 'else' case because we don't actually know
whether x was refined or y was refined -- only just that one of the two was refined.

**Line:** 7550

---

### `def convert_to_typetype(type_map: TypeMap) -> TypeMap`

**Line:** 7589

---

### `def flatten(t: Expression) -> list[Expression]`

**Description:**
Flatten a nested sequence of tuples/lists into one list of nodes.

**Line:** 7605

---

### `def flatten_types(t: Type) -> list[Type]`

**Description:**
Flatten a nested sequence of tuples into one list of nodes.

**Line:** 7615

---

### `def expand_func(defn: FuncItem, map: dict[(TypeVarId, Type)]) -> FuncItem`

**Line:** 7626

---

### `def are_argument_counts_overlapping(t: CallableType, s: CallableType) -> bool`

**Description:**
Can a single call match both t and s, based just on positional argument counts?

**Line:** 7642

---

### `def is_unsafe_overlapping_overload_signatures(signature: CallableType, other: CallableType, class_type_vars: list[TypeVarLikeType]) -> bool`

**Description:**
Check if two overloaded signatures are unsafely overlapping or partially overlapping.

We consider two functions 's' and 't' to be unsafely overlapping if both
of the following are true:

1.  s's parameters are all more precise or partially overlapping with t's
2.  s's return type is NOT a subtype of t's.

Assumes that 'signature' appears earlier in the list of overload
alternatives then 'other' and that their argument counts are overlapping.

**Line:** 7649

---

### `def detach_callable(typ: CallableType, class_type_vars: list[TypeVarLikeType]) -> CallableType`

**Description:**
Ensures that the callable's type variables are 'detached' and independent of the context.

A callable normally keeps track of the type variables it uses within its 'variables' field.
However, if the callable is from a method and that method is using a class type variable,
the callable will not keep track of that type variable since it belongs to the class.

This function will traverse the callable and find all used type vars and add them to the
variables field if it isn't already present.

The caller can then unify on all type variables whether the callable is originally from
the class or not.

**Line:** 7713

---

### `def overload_can_never_match(signature: CallableType, other: CallableType) -> bool`

**Description:**
Check if the 'other' method can never be matched due to 'signature'.

This can happen if signature's parameters are all strictly broader then
other's parameters.

Assumes that both signatures have overlapping argument counts.

**Line:** 7736

---

### `def is_more_general_arg_prefix(t: FunctionLike, s: FunctionLike) -> bool`

**Description:**
Does t have wider arguments than s?

**Line:** 7759

---

### `def is_same_arg_prefix(t: CallableType, s: CallableType) -> bool`

**Line:** 7777

---

### `def infer_operator_assignment_method(typ: Type, operator: str) -> tuple[(bool, str)]`

**Description:**
Determine if operator assignment on given value type is in-place, and the method name.

For example, if operator is '+', return (True, '__iadd__') or (False, '__add__')
depending on which method is supported by the type.

**Line:** 7789

---

### `def _find_inplace_method(inst: Instance, method: str, operator: str) -> str | None`

**Line:** 7808

---

### `def is_valid_inferred_type(typ: Type, is_lvalue_final: bool = False) -> bool`

**Description:**
Is an inferred type valid and needs no further refinement?

Examples of invalid types include the None type (when we are not assigning
None to a final lvalue) or List[<uninhabited>].

When not doing strict Optional checking, all types containing None are
invalid.  When doing strict Optional checking, only None and types that are
incompletely defined (i.e. contain UninhabitedType) are invalid.

**Line:** 7816

---

### `def is_node_static(node: Node | None) -> bool | None`

**Description:**
Find out if a node describes a static function method.

**Line:** 7878

---

### `def group_comparison_operands(pairwise_comparisons: Iterable[tuple[(str, Expression, Expression)]], operand_to_literal_hash: Mapping[(int, Key)], operators_to_group: set[str]) -> list[tuple[(str, list[int])]]`

**Description:**
Group a series of comparison operands together chained by any operand
in the 'operators_to_group' set. All other pairwise operands are kept in
groups of size 2.

For example, suppose we have the input comparison expression:

x0 == x1 == x2 < x3 < x4 is x5 is x6 is not x7 is not x8

If we get these expressions in a pairwise way (e.g. by calling ComparisionExpr's
'pairwise()' method), we get the following as input:

[('==', x0, x1), ('==', x1, x2), ('<', x2, x3), ('<', x3, x4),
('is', x4, x5), ('is', x5, x6), ('is not', x6, x7), ('is not', x7, x8)]

If `operators_to_group` is the set {'==', 'is'}, this function will produce
the following "simplified operator list":

[("==", [0, 1, 2]), ("<", [2, 3]), ("<", [3, 4]),
("is", [4, 5, 6]), ("is not", [6, 7]), ("is not", [7, 8])]

Note that (a) we yield *indices* to the operands rather then the operand
expressions themselves and that (b) operands used in a consecutive chain
of '==' or 'is' are grouped together.

If two of these chains happen to contain operands with the same underlying
literal hash (e.g. are assignable and correspond to the same expression),
we combine those chains together. For example, if we had:

same == x < y == same

...and if 'operand_to_literal_hash' contained the same values for the indices
0 and 3, we'd produce the following output:

[("==", [0, 1, 2, 3]), ("<", [1, 2])]

But if the 'operand_to_literal_hash' did *not* contain an entry, we'd instead
default to returning:

[("==", [0, 1]), ("<", [1, 2]), ("==", [2, 3])]

This function is currently only used to assist with type-narrowing refinements
and is extracted out to a helper function so we can unit test it.

**Line:** 8050

---

### `def is_typed_callable(c: Type | None) -> bool`

**Line:** 8150

---

### `def is_untyped_decorator(typ: Type | None) -> bool`

**Line:** 8160

---

### `def is_static(func: FuncBase | Decorator) -> bool`

**Line:** 8185

---

### `def is_property(defn: SymbolNode) -> bool`

**Line:** 8193

---

### `def get_property_type(t: ProperType) -> ProperType`

**Line:** 8202

---

### `def is_subtype_no_promote(left: Type, right: Type) -> bool`

**Line:** 8210

---

### `def is_overlapping_types_no_promote_no_uninhabited_no_none(left: Type, right: Type) -> bool`

**Line:** 8214

---

### `def is_private(node_name: str) -> bool`

**Description:**
Check if node is private to class definition.

**Line:** 8228

---

### `def is_string_literal(typ: Type) -> bool`

**Line:** 8233

---

### `def has_bool_item(typ: ProperType) -> bool`

**Description:**
Return True if type is 'bool' or a union with a 'bool' item.

**Line:** 8238

---

### `def collapse_walrus(e: Expression) -> Expression`

**Description:**
If an expression is an AssignmentExpr, pull out the assignment target.

We don't make any attempt to pull out all the targets in code like `x := (y := z)`.
We could support narrowing those if that sort of code turns out to be common.

**Line:** 8247

---

### `def find_last_var_assignment_line(n: Node, v: Var) -> int`

**Description:**
Find the highest line number of a potential assignment to variable within node.

This supports local and global variables.

Return -1 if no assignment was found.

**Line:** 8258

---


## Module: venv2.libthon3.12.site-packages.mypy.checkexpr
**File:** `venv2/lib/python3.12/site-packages/mypy/checkexpr.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- contextlib.contextmanager
- enum
- itertools
- mypy.applytype
- mypy.argmap.ArgTypeExpander
- mypy.argmap.map_actuals_to_formals
- mypy.argmap.map_formals_to_actuals
- mypy.checker
- mypy.checkmember.analyze_member_access
- mypy.checkmember.freeze_all_type_vars
- mypy.checkmember.type_object_type
- mypy.checkstrformat.StringFormatterChecker
- mypy.erasetype
- mypy.erasetype.erase_type
- mypy.erasetype.remove_instance_last_known_values
- mypy.erasetype.replace_meta_vars
- mypy.errorcodes
- mypy.errors.ErrorWatcher
- mypy.errors.report_internal_error
- mypy.expandtype.expand_type
- mypy.expandtype.expand_type_by_instance
- mypy.expandtype.freshen_all_functions_type_vars
- mypy.expandtype.freshen_function_type_vars
- mypy.infer.ArgumentInferContext
- mypy.infer.infer_function_type_arguments
- mypy.infer.infer_type_arguments
- mypy.join
- mypy.literals.literal
- mypy.maptype.map_instance_to_supertype
- mypy.meet.is_overlapping_types
- mypy.meet.narrow_declared_type
- mypy.message_registry
- mypy.message_registry.ErrorMessage
- mypy.messages.MessageBuilder
- mypy.messages.format_type
- mypy.nodes
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.ArgKind
- mypy.nodes.AssertTypeExpr
- mypy.nodes.AssignmentExpr
- mypy.nodes.AwaitExpr
- mypy.nodes.BytesExpr
- mypy.nodes.CallExpr
- mypy.nodes.CastExpr
- mypy.nodes.ComparisonExpr
- mypy.nodes.ComplexExpr
- mypy.nodes.ConditionalExpr
- mypy.nodes.Context
- mypy.nodes.Decorator
- mypy.nodes.DictExpr
- mypy.nodes.DictionaryComprehension
- mypy.nodes.EllipsisExpr
- mypy.nodes.EnumCallExpr
- mypy.nodes.Expression
- mypy.nodes.FloatExpr
- mypy.nodes.FuncDef
- mypy.nodes.GeneratorExpr
- mypy.nodes.IMPLICITLY_ABSTRACT
- mypy.nodes.IndexExpr
- mypy.nodes.IntExpr
- mypy.nodes.LITERAL_TYPE
- mypy.nodes.LambdaExpr
- mypy.nodes.ListComprehension
- mypy.nodes.ListExpr
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.NamedTupleExpr
- mypy.nodes.NewTypeExpr
- mypy.nodes.OpExpr
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.ParamSpecExpr
- mypy.nodes.PlaceholderNode
- mypy.nodes.PromoteExpr
- mypy.nodes.REVEAL_LOCALS
- mypy.nodes.REVEAL_TYPE
- mypy.nodes.RefExpr
- mypy.nodes.RevealExpr
- mypy.nodes.SetComprehension
- mypy.nodes.SetExpr
- mypy.nodes.SliceExpr
- mypy.nodes.StarExpr
- mypy.nodes.StrExpr
- mypy.nodes.SuperExpr
- mypy.nodes.SymbolNode
- mypy.nodes.TempNode
- mypy.nodes.TupleExpr
- mypy.nodes.TypeAlias
- mypy.nodes.TypeAliasExpr
- mypy.nodes.TypeApplication
- mypy.nodes.TypeInfo
- mypy.nodes.TypeVarExpr
- mypy.nodes.TypeVarTupleExpr
- mypy.nodes.TypedDictExpr
- mypy.nodes.UnaryExpr
- mypy.nodes.Var
- mypy.nodes.YieldExpr
- mypy.nodes.YieldFromExpr
- mypy.operators
- mypy.options.PRECISE_TUPLE_TYPES
- mypy.plugin.FunctionContext
- mypy.plugin.FunctionSigContext
- mypy.plugin.MethodContext
- mypy.plugin.MethodSigContext
- mypy.plugin.Plugin
- mypy.semanal_enum.ENUM_BASES
- mypy.state.state
- mypy.subtypes.find_member
- mypy.subtypes.is_equivalent
- mypy.subtypes.is_same_type
- mypy.subtypes.is_subtype
- mypy.subtypes.non_method_protocol_members
- mypy.traverser.has_await_expression
- mypy.type_visitor.TypeTranslator
- mypy.typeanal.check_for_explicit_any
- mypy.typeanal.fix_instance
- mypy.typeanal.has_any_from_unimported_type
- mypy.typeanal.instantiate_type_alias
- mypy.typeanal.make_optional_type
- mypy.typeanal.set_any_tvars
- mypy.typeanal.validate_instance
- mypy.typeops.callable_type
- mypy.typeops.custom_special_method
- mypy.typeops.erase_to_union_or_bound
- mypy.typeops.false_only
- mypy.typeops.fixup_partial_type
- mypy.typeops.function_type
- mypy.typeops.get_all_type_vars
- mypy.typeops.get_type_vars
- mypy.typeops.is_literal_type_like
- mypy.typeops.make_simplified_union
- mypy.typeops.simple_literal_type
- mypy.typeops.true_only
- mypy.typeops.try_expanding_sum_type_to_union
- mypy.typeops.try_getting_str_literals
- mypy.typeops.tuple_fallback
- mypy.types
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.ErasedType
- mypy.types.ExtraAttrs
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LITERAL_TYPE_NAMES
- mypy.types.LiteralType
- mypy.types.LiteralValue
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ParamSpecFlavor
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TUPLE_LIKE_INSTANCE_NAMES
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.find_unpack_in_list
- mypy.types.flatten_nested_tuples
- mypy.types.flatten_nested_unions
- mypy.types.get_proper_type
- mypy.types.get_proper_types
- mypy.types.has_recursive_types
- mypy.types.is_named_instance
- mypy.types.remove_dups
- mypy.types.split_with_prefix_and_suffix
- mypy.types_utils.is_generic_instance
- mypy.types_utils.is_overlapping_none
- mypy.types_utils.is_self_type_like
- mypy.types_utils.remove_optional
- mypy.typestate.type_state
- mypy.typevars.fill_typevars
- mypy.util.split_module_names
- mypy.visitor.ExpressionVisitor
- time
- typing.Callable
- typing.ClassVar
- typing.Final
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Optional
- typing.Sequence
- typing.cast
- typing_extensions.TypeAlias
- typing_extensions.assert_never
- typing_extensions.overload

**Functions:**

### `def allow_fast_container_literal(t: Type) -> bool`

**Line:** 236

---

### `def extract_refexpr_names(expr: RefExpr) -> set[str]`

**Description:**
Recursively extracts all module references from a reference expression.

Note that currently, the only two subclasses of RefExpr are NameExpr and
MemberExpr.

**Line:** 245

---

### `def has_any_type(t: Type, ignore_in_type_obj: bool = False) -> bool`

**Description:**
Whether t contains an Any type

**Line:** 6086

---

### `def has_coroutine_decorator(t: Type) -> bool`

**Description:**
Whether t came from a function decorated with `@coroutine`.

**Line:** 6117

---

### `def is_async_def(t: Type) -> bool`

**Description:**
Whether t came from a function defined using `async def`.

**Line:** 6123

---

### `def is_non_empty_tuple(t: Type) -> bool`

**Line:** 6147

---

### `def is_duplicate_mapping(mapping: list[int], actual_types: list[Type], actual_kinds: list[ArgKind]) -> bool`

**Line:** 6152

---

### `def replace_callable_return_type(c: CallableType, new_ret_type: Type) -> CallableType`

**Description:**
Return a copy of a callable type with a different return type.

**Line:** 6177

---

### `def apply_poly(tp: CallableType, poly_tvars: Sequence[TypeVarLikeType]) -> CallableType | None`

**Description:**
Make free type variables generic in the type if possible.

This will translate the type `tp` while trying to create valid bindings for
type variables `poly_tvars` while traversing the type. This follows the same rules
as we do during semantic analysis phase, examples:
* Callable[Callable[[T], T], T] -> def [T] (def (T) -> T) -> T
* Callable[[], Callable[[T], T]] -> def () -> def [T] (T -> T)
* List[T] -> None (not possible)

**Line:** 6182

---

### `def has_erased_component(t: Type | None) -> bool`

**Line:** 6337

---

### `def has_uninhabited_component(t: Type | None) -> bool`

**Line:** 6351

---

### `def arg_approximate_similarity(actual: Type, formal: Type) -> bool`

**Description:**
Return if caller argument (actual) is roughly compatible with signature arg (formal).

This function is deliberately loose and will report two types are similar
as long as their "shapes" are plausibly the same.

This is useful when we're doing error reporting: for example, if we're trying
to select an overload alternative and there's no exact match, we can use
this function to help us identify which alternative the user might have
*meant* to match.

**Line:** 6365

---

### `def any_causes_overload_ambiguity(items: list[CallableType], return_types: list[Type], arg_types: list[Type], arg_kinds: list[ArgKind], arg_names: Sequence[str | None] | None) -> bool`

**Description:**
May an argument containing 'Any' cause ambiguous result type on call to overloaded function?

Note that this sometimes returns True even if there is no ambiguity, since a correct
implementation would be complex (and the call would be imprecisely typed due to Any
types anyway).

Args:
items: Overload items matching the actual arguments
arg_types: Actual argument types
arg_kinds: Actual argument kinds
arg_names: Actual argument names

**Line:** 6428

---

### `def all_same_types(types: list[Type]) -> bool`

**Line:** 6486

---

### `def merge_typevars_in_callables_by_name(callables: Sequence[CallableType]) -> tuple[(list[CallableType], list[TypeVarType])]`

**Description:**
Takes all the typevars present in the callables and 'combines' the ones with the same name.

For example, suppose we have two callables with signatures "f(x: T, y: S) -> T" and
"f(x: List[Tuple[T, S]]) -> Tuple[T, S]". Both callables use typevars named "T" and
"S", but we treat them as distinct, unrelated typevars. (E.g. they could both have
distinct ids.)

If we pass in both callables into this function, it returns a list containing two
new callables that are identical in signature, but use the same underlying TypeVarType
for T and S.

This is useful if we want to take the output lists and "merge" them into one callable
in some way -- for example, when unioning together overloads.

Returns both the new list of callables and a list of all distinct TypeVarType objects used.

**Line:** 6492

---

### `def try_getting_literal(typ: Type) -> ProperType`

**Description:**
If possible, get a more precise literal type for a given type.

**Line:** 6537

---

### `def is_expr_literal_type(node: Expression) -> bool`

**Description:**
Returns 'true' if the given node is a Literal

**Line:** 6545

---

### `def has_bytes_component(typ: Type) -> bool`

**Description:**
Is this one of builtin byte types, or a union that contains it?

**Line:** 6558

---

### `def type_info_from_type(typ: Type) -> TypeInfo | None`

**Description:**
Gets the TypeInfo for a type, indirecting through things like type variables and tuples.

**Line:** 6569

---

### `def is_operator_method(fullname: str | None) -> bool`

**Line:** 6588

---

### `def get_partial_instance_type(t: Type | None) -> PartialType | None`

**Line:** 6599

---


## Module: venv2.libthon3.12.site-packages.mypy.checkmember
**File:** `venv2/lib/python3.12/site-packages/mypy/checkmember.py`

**Imports:**
- __future__.annotations
- mypy.checker
- mypy.erasetype.erase_typevars
- mypy.expandtype.expand_self_type
- mypy.expandtype.expand_type_by_instance
- mypy.expandtype.freshen_all_functions_type_vars
- mypy.maptype.map_instance_to_supertype
- mypy.meet
- mypy.message_registry
- mypy.messages.MessageBuilder
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.Context
- mypy.nodes.Decorator
- mypy.nodes.FuncBase
- mypy.nodes.FuncDef
- mypy.nodes.IndexExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.SYMBOL_FUNCBASE_TYPES
- mypy.nodes.SymbolNode
- mypy.nodes.SymbolTable
- mypy.nodes.TempNode
- mypy.nodes.TypeAlias
- mypy.nodes.TypeInfo
- mypy.nodes.TypeVarExpr
- mypy.nodes.Var
- mypy.nodes.is_final_node
- mypy.plugin.AttributeContext
- mypy.state
- mypy.subtypes
- mypy.typeops.bind_self
- mypy.typeops.class_callable
- mypy.typeops.erase_to_bound
- mypy.typeops.function_type
- mypy.typeops.get_type_vars
- mypy.typeops.make_simplified_union
- mypy.typeops.supported_self_type
- mypy.typeops.tuple_fallback
- mypy.typeops.type_object_type_from_function
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.ENUM_REMOVED_PROPS
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypedDictType
- mypy.types.UnionType
- mypy.types.get_proper_type
- mypy.typetraverser.TypeTraverserVisitor
- typing.Callable
- typing.Sequence
- typing.TYPE_CHECKING
- typing.cast

**Functions:**

### `def analyze_member_access(name: str, typ: Type, context: Context, is_lvalue: bool, is_super: bool, is_operator: bool, msg: MessageBuilder, original_type: Type, chk: mypy.checker.TypeChecker, override_info: TypeInfo | None = None, in_literal_context: bool = False, self_type: Type | None = None, module_symbol_table: SymbolTable | None = None, no_deferral: bool = False, is_self: bool = False) -> Type`

**Description:**
Return the type of attribute 'name' of 'typ'.

The actual implementation is in '_analyze_member_access' and this docstring
also applies to it.

This is a general operation that supports various different variations:

1. lvalue or non-lvalue access (setter or getter access)
2. supertype access when using super() (is_super == True and
'override_info' should refer to the supertype)

'original_type' is the most precise inferred or declared type of the base object
that we have available. When looking for an attribute of 'typ', we may perform
recursive calls targeting the fallback type, and 'typ' may become some supertype
of 'original_type'. 'original_type' is always preserved as the 'typ' type used in
the initial, non-recursive call. The 'self_type' is a component of 'original_type'
to which generic self should be bound (a narrower type that has a fallback to instance).
Currently this is used only for union types.

'module_symbol_table' is passed to this function if 'typ' is actually a module
and we want to keep track of the available attributes of the module (since they
are not available via the type object directly)

**Line:** 148

---

### `def _analyze_member_access(name: str, typ: Type, mx: MemberContext, override_info: TypeInfo | None = None) -> Type`

**Line:** 214

---

### `def may_be_awaitable_attribute(name: str, typ: Type, mx: MemberContext, override_info: TypeInfo | None = None) -> bool`

**Description:**
Check if the given type has the attribute when awaited.

**Line:** 253

---

### `def report_missing_attribute(original_type: Type, typ: Type, name: str, mx: MemberContext, override_info: TypeInfo | None = None) -> Type`

**Line:** 268

---

### `def analyze_instance_member_access(name: str, typ: Instance, mx: MemberContext, override_info: TypeInfo | None) -> Type`

**Line:** 286

---

### `def validate_super_call(node: FuncBase, mx: MemberContext) -> None`

**Line:** 352

---

### `def analyze_type_callable_member_access(name: str, typ: FunctionLike, mx: MemberContext) -> Type`

**Line:** 371

---

### `def analyze_type_type_member_access(name: str, typ: TypeType, mx: MemberContext, override_info: TypeInfo | None) -> Type`

**Line:** 407

---

### `def analyze_union_member_access(name: str, typ: UnionType, mx: MemberContext) -> Type`

**Line:** 463

---

### `def analyze_none_member_access(name: str, typ: NoneType, mx: MemberContext) -> Type`

**Line:** 473

---

### `def analyze_member_var_access(name: str, itype: Instance, info: TypeInfo, mx: MemberContext) -> Type`

**Description:**
Analyse attribute access that does not target a method.

This is logically part of analyze_member_access and the arguments are similar.

original_type is the type of E in the expression E.var

**Line:** 487

---

### `def check_final_member(name: str, info: TypeInfo, msg: MessageBuilder, ctx: Context) -> None`

**Description:**
Give an error if the name being assigned was declared as final.

**Line:** 626

---

### `def analyze_descriptor_access(descriptor_type: Type, mx: MemberContext) -> Type`

**Description:**
Type check descriptor access.

Arguments:
descriptor_type: The type of the descriptor attribute being accessed
(the type of ``f`` in ``a.f`` when ``f`` is a descriptor).
mx: The current member access context.
Return:
The return type of the appropriate ``__get__`` overload for the descriptor.

**Line:** 634

---

### `def is_instance_var(var: Var) -> bool`

**Description:**
Return if var is an instance variable according to PEP 526.

**Line:** 732

---

### `def analyze_var(name: str, var: Var, itype: Instance, info: TypeInfo, mx: MemberContext, implicit: bool = False) -> Type`

**Description:**
Analyze access to an attribute via a Var node.

This is conceptually part of analyze_member_access and the arguments are similar.
itype is the instance type in which attribute should be looked up
original_type is the type of E in the expression E.var
if implicit is True, the original Var was created as an assignment to self

**Line:** 744

---

### `def freeze_all_type_vars(member_type: Type) -> None`

**Line:** 853

---

### `def lookup_member_var_or_accessor(info: TypeInfo, name: str, is_lvalue: bool) -> SymbolNode | None`

**Description:**
Find the attribute/accessor node that refers to a member of a type.

**Line:** 864

---

### `def check_self_arg(functype: FunctionLike, dispatched_arg_type: Type, is_classmethod: bool, context: Context, name: str, msg: MessageBuilder) -> FunctionLike`

**Description:**
Check that an instance has a valid type for a method with annotated 'self'.

For example if the method is defined as:
class A:
def f(self: S) -> T: ...
then for 'x.f' we check that meet(type(x), A) <: S. If the method is overloaded, we
select only overloads items that satisfy this requirement. If there are no matching
overloads, an error is generated.

Note: dispatched_arg_type uses a meet to select a relevant item in case if the
original type of 'x' is a union. This is done because several special methods
treat union types in ad-hoc manner, so we can't use MemberContext.self_type yet.

**Line:** 874

---

### `def analyze_class_attribute_access(itype: Instance, name: str, mx: MemberContext, mcs_fallback: Instance, override_info: TypeInfo | None = None, original_vars: Sequence[TypeVarLikeType] | None = None) -> Type | None`

**Description:**
Analyze access to an attribute on a class object.

itype is the return type of the class object callable, original_type is the type
of E in the expression E.var, original_vars are type variables of the class callable
(for generic classes).

**Line:** 931

---

### `def apply_class_attr_hook(mx: MemberContext, hook: Callable[[AttributeContext], Type] | None, result: Type) -> Type | None`

**Line:** 1116

---

### `def analyze_enum_class_attribute_access(itype: Instance, name: str, mx: MemberContext) -> Type | None`

**Line:** 1126

---

### `def analyze_typeddict_access(name: str, typ: TypedDictType, mx: MemberContext, override_info: TypeInfo | None) -> Type`

**Line:** 1140

---

### `def add_class_tvars(t: ProperType, isuper: Instance | None, is_classmethod: bool, original_type: Type, original_vars: Sequence[TypeVarLikeType] | None = None) -> Type`

**Description:**
Instantiate type variables during analyze_class_attribute_access,
e.g T and Q in the following:

class A(Generic[T]):
@classmethod
def foo(cls: Type[Q]) -> Tuple[T, Q]: ...

class B(A[str]): pass
B.foo()

Args:
t: Declared type of the method (or property)
isuper: Current instance mapped to the superclass where method was defined, this
is usually done by map_instance_to_supertype()
is_classmethod: True if this method is decorated with @classmethod
original_type: The value of the type B in the expression B.foo() or the corresponding
component in case of a union (this is used to bind the self-types)
original_vars: Type variables of the class callable on which the method was accessed
Returns:
Expanded method type with added type variables (when needed).

**Line:** 1176

---

### `def type_object_type(info: TypeInfo, named_type: Callable[([str], Instance)]) -> ProperType`

**Description:**
Return the type of a type object.

For a generic type G with type variables T and S the type is generally of form

Callable[..., G[T, S]]

where ... are argument types for the __init__/__new__ method (without the self
argument). Also, the fallback type will be 'type' instead of 'function'.

**Line:** 1244

---

### `def analyze_decorator_or_funcbase_access(defn: Decorator | FuncBase, itype: Instance, info: TypeInfo, self_type: Type | None, name: str, mx: MemberContext) -> Type`

**Description:**
Analyzes the type behind method access.

The function itself can possibly be decorated.
See: https://github.com/python/mypy/issues/10409

**Line:** 1315

---

### `def is_valid_constructor(n: SymbolNode | None) -> bool`

**Description:**
Does this node represents a valid constructor method?

This includes normal functions, overloaded functions, and decorators
that return a callable type.

**Line:** 1335

---


## Module: venv2.libthon3.12.site-packages.mypy.checkpattern
**File:** `venv2/lib/python3.12/site-packages/mypy/checkpattern.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- mypy.checker
- mypy.checkmember.analyze_member_access
- mypy.expandtype.expand_type_by_instance
- mypy.join.join_types
- mypy.literals.literal_hash
- mypy.maptype.map_instance_to_supertype
- mypy.meet.narrow_declared_type
- mypy.message_registry
- mypy.messages.MessageBuilder
- mypy.nodes.ARG_POS
- mypy.nodes.Context
- mypy.nodes.Expression
- mypy.nodes.NameExpr
- mypy.nodes.TypeAlias
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.options.Options
- mypy.patterns.AsPattern
- mypy.patterns.ClassPattern
- mypy.patterns.MappingPattern
- mypy.patterns.OrPattern
- mypy.patterns.Pattern
- mypy.patterns.SequencePattern
- mypy.patterns.SingletonPattern
- mypy.patterns.StarredPattern
- mypy.patterns.ValuePattern
- mypy.plugin.Plugin
- mypy.subtypes.is_subtype
- mypy.typeops.coerce_to_literal
- mypy.typeops.make_simplified_union
- mypy.typeops.try_getting_str_literals_from_type
- mypy.typeops.tuple_fallback
- mypy.types.AnyType
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeVarTupleType
- mypy.types.TypedDictType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.find_unpack_in_list
- mypy.types.get_proper_type
- mypy.types.split_with_prefix_and_suffix
- mypy.typevars.fill_typevars
- mypy.visitor.PatternVisitor
- typing.Final
- typing.NamedTuple

**Functions:**

### `def get_match_arg_names(typ: TupleType) -> list[str | None]`

**Line:** 768

---

### `def get_var(expr: Expression) -> Var`

**Description:**
Warning: this in only true for expressions captured by a match statement.
Don't call it from anywhere else

**Line:** 779

---

### `def get_type_range(typ: Type) -> mypy.checker.TypeRange`

**Line:** 790

---

### `def is_uninhabited(typ: Type) -> bool`

**Line:** 801

---


## Module: venv2.libthon3.12.site-packages.mypy.checkstrformat
**File:** `venv2/lib/python3.12/site-packages/mypy/checkstrformat.py`

**Imports:**
- __future__.annotations
- mypy.checker
- mypy.checkexpr
- mypy.errorcodes
- mypy.errors.Errors
- mypy.maptype.map_instance_to_supertype
- mypy.message_registry
- mypy.messages.MessageBuilder
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.BytesExpr
- mypy.nodes.CallExpr
- mypy.nodes.Context
- mypy.nodes.DictExpr
- mypy.nodes.Expression
- mypy.nodes.ExpressionStmt
- mypy.nodes.IndexExpr
- mypy.nodes.IntExpr
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.Node
- mypy.nodes.StarExpr
- mypy.nodes.StrExpr
- mypy.nodes.TempNode
- mypy.nodes.TupleExpr
- mypy.parse.parse
- mypy.subtypes.is_subtype
- mypy.typeops.custom_special_method
- mypy.types.AnyType
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.find_unpack_in_list
- mypy.types.get_proper_type
- mypy.types.get_proper_types
- re
- typing.Callable
- typing.Dict
- typing.Final
- typing.Match
- typing.Pattern
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- typing.cast
- typing_extensions.TypeAlias

**Functions:**

### `def compile_format_re() -> Pattern[str]`

**Description:**
Construct regexp to match format conversion specifiers in % interpolation.

See https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting
The regexp is intentionally a bit wider to report better errors.

**Line:** 76

---

### `def compile_new_format_re(custom_spec: bool) -> Pattern[str]`

**Description:**
Construct regexps to match format conversion specifiers in str.format() calls.

See After https://docs.python.org/3/library/string.html#formatspec for
specifications. The regexps are intentionally wider, to report better errors,
instead of just not matching.

**Line:** 92

---

### `def parse_conversion_specifiers(format_str: str) -> list[ConversionSpecifier]`

**Description:**
Parse c-printf-style format string into list of conversion specifiers.

**Line:** 173

---

### `def parse_format_value(format_value: str, ctx: Context, msg: MessageBuilder, nested: bool = False) -> list[ConversionSpecifier] | None`

**Description:**
Parse format string into list of conversion specifiers.

The specifiers may be nested (two levels maximum), in this case they are ordered as
'{0:{1}}, {2:{3}{4}}'. Return None in case of an error.

**Line:** 181

---

### `def find_non_escaped_targets(format_value: str, ctx: Context, msg: MessageBuilder) -> list[tuple[str, int]] | None`

**Description:**
Return list of raw (un-parsed) format specifiers in format string.

Format specifiers don't include enclosing braces. We don't use regexp for
this because they don't work well with nested/repeated patterns
(both greedy and non-greedy), and these are heavily used internally for
representation of f-strings.

Return None in case of an error.

**Line:** 237

---

### `def has_type_component(typ: Type, fullname: str) -> bool`

**Description:**
Is this a specific instance type, or a union that contains it?

We use this ad-hoc function instead of a proper visitor or subtype check
because some str vs bytes errors are strictly speaking not runtime errors,
but rather highly counter-intuitive behavior. This is similar to what is used for
--strict-equality.

**Line:** 1092

---


## Module: venv2.libthon3.12.site-packages.mypy.config_parser
**File:** `venv2/lib/python3.12/site-packages/mypy/config_parser.py`

**Imports:**
- __future__.annotations
- argparse
- configparser
- glob
- io.StringIO
- mypy.defaults
- mypy.errorcodes.error_codes
- mypy.options.Options
- mypy.options.PER_MODULE_OPTIONS
- os
- re
- sys
- tomli
- tomllib
- typing.Any
- typing.Callable
- typing.Dict
- typing.Final
- typing.Iterable
- typing.List
- typing.Mapping
- typing.MutableMapping
- typing.Sequence
- typing.TextIO
- typing.Tuple
- typing.Union
- typing_extensions.TypeAlias

**Functions:**

### `def parse_version(v: str | float) -> tuple[(int, int)]`

**Line:** 43

---

### `def try_split(v: str | Sequence[str], split_regex: str = '[,]') -> list[str]`

**Description:**
Split and trim a str or list of str into a list of str

**Line:** 67

---

### `def validate_codes(codes: list[str]) -> list[str]`

**Line:** 75

---

### `def validate_package_allow_list(allow_list: list[str]) -> list[str]`

**Line:** 84

---

### `def expand_path(path: str) -> str`

**Description:**
Expand the user home directory and any environment variables contained within
the provided path.

**Line:** 98

---

### `def str_or_array_as_list(v: str | Sequence[str]) -> list[str]`

**Line:** 106

---

### `def split_and_match_files_list(paths: Sequence[str]) -> list[str]`

**Description:**
Take a list of files/directories (with support for globbing through the glob library).

Where a path/glob matches no file, we still include the raw path in the resulting list.

Returns a list of file paths

**Line:** 112

---

### `def split_and_match_files(paths: str) -> list[str]`

**Description:**
Take a string representing a list of files/directories (with support for globbing
through the glob library).

Where a path/glob matches no file, we still include the raw path in the resulting list.

Returns a list of file paths

**Line:** 132

---

### `def check_follow_imports(choice: str) -> str`

**Line:** 144

---

### `def split_commas(value: str) -> list[str]`

**Line:** 155

---

### `def parse_config_file(options: Options, set_strict_flags: Callable[([], None)], filename: str | None, stdout: TextIO | None = None, stderr: TextIO | None = None) -> None`

**Description:**
Parse a config file into an Options object.

Errors are written to stderr but are not fatal.

If filename is None, fall back to default config files.

**Line:** 219

---

### `def get_prefix(file_read: str, name: str) -> str`

**Line:** 331

---

### `def is_toml(filename: str) -> bool`

**Line:** 340

---

### `def destructure_overrides(toml_data: dict[(str, Any)]) -> dict[(str, Any)]`

**Description:**
Take the new [[tool.mypy.overrides]] section array in the pyproject.toml file,
and convert it back to a flatter structure that the existing config_parser can handle.

E.g. the following pyproject.toml file:

[[tool.mypy.overrides]]
module = [
"a.b",
"b.*"
]
disallow_untyped_defs = true

[[tool.mypy.overrides]]
module = 'c'
disallow_untyped_defs = false

Would map to the following config dict that it would have gotten from parsing an equivalent
ini file:

{
"mypy-a.b": {
disallow_untyped_defs = true,
},
"mypy-b.*": {
disallow_untyped_defs = true,
},
"mypy-c": {
disallow_untyped_defs: false,
},
}

**Line:** 344

---

### `def parse_section(prefix: str, template: Options, set_strict_flags: Callable[([], None)], section: Mapping[(str, Any)], config_types: dict[(str, Any)], stderr: TextIO = sys.stderr) -> tuple[(dict[str, object], dict[str, str])]`

**Description:**
Parse one section of a config file.

Returns a dict of option values encountered, and a dict of report directories.

**Line:** 427

---

### `def convert_to_boolean(value: Any | None) -> bool`

**Description:**
Return a boolean value translating from other types if necessary.

**Line:** 538

---

### `def split_directive(s: str) -> tuple[(list[str], list[str])]`

**Description:**
Split s on commas, except during quoted sections.

Returns the parts and a list of error messages.

**Line:** 549

---

### `def mypy_comments_to_config_map(line: str, template: Options) -> tuple[(dict[str, str], list[str])]`

**Description:**
Rewrite the mypy comment syntax into ini file syntax.

**Line:** 578

---

### `def parse_mypy_comments(args: list[tuple[(int, str)]], template: Options) -> tuple[(dict[str, object], list[tuple[int, str]])]`

**Description:**
Parse a collection of inline mypy: configuration comments.

Returns a dictionary of options to be applied and a list of error messages
generated.

**Line:** 597

---

### `def get_config_module_names(filename: str | None, modules: list[str]) -> str`

**Line:** 646

---


## Module: venv2.libthon3.12.site-packages.mypy.constant_fold
**File:** `venv2/lib/python3.12/site-packages/mypy/constant_fold.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ComplexExpr
- mypy.nodes.Expression
- mypy.nodes.FloatExpr
- mypy.nodes.IntExpr
- mypy.nodes.NameExpr
- mypy.nodes.OpExpr
- mypy.nodes.StrExpr
- mypy.nodes.UnaryExpr
- mypy.nodes.Var
- typing.Final
- typing.Union

**Functions:**

### `def constant_fold_expr(expr: Expression, cur_mod_id: str) -> ConstantValue | None`

**Description:**
Return the constant value of an expression for supported operations.

Among other things, support int arithmetic and string
concatenation. For example, the expression 3 + 5 has the constant
value 8.

Also bind simple references to final constants defined in the
current module (cur_mod_id). Binding to references is best effort
-- we don't bind references to other modules. Mypyc trusts these
to be correct in compiled modules, so that it can replace a
constant expression (or a reference to one) with the statically
computed value. We don't want to infer constant values based on
stubs, in particular, as these might not match the implementation
(due to version skew, for example).

Return None if unsuccessful.

**Line:** 27

---

### `def constant_fold_binary_op(op: str, left: ConstantValue, right: ConstantValue) -> ConstantValue | None`

**Line:** 79

---

### `def constant_fold_binary_int_op(op: str, left: int, right: int) -> int | float | None`

**Line:** 114

---

### `def constant_fold_binary_float_op(op: str, left: int | float, right: int | float) -> float | None`

**Line:** 150

---

### `def constant_fold_unary_op(op: str, value: ConstantValue) -> int | float | None`

**Line:** 180

---


## Module: venv2.libthon3.12.site-packages.mypy.constraints
**File:** `venv2/lib/python3.12/site-packages/mypy/constraints.py`

**Imports:**
- __future__.annotations
- mypy.argmap.ArgTypeExpander
- mypy.erasetype.erase_typevars
- mypy.infer.ArgumentInferContext
- mypy.maptype.map_instance_to_supertype
- mypy.nodes.ARG_OPT
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.ArgKind
- mypy.nodes.CONTRAVARIANT
- mypy.nodes.COVARIANT
- mypy.nodes.TypeInfo
- mypy.subtypes
- mypy.typeops
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.ErasedType
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.NormalizedCallableType
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TUPLE_LIKE_INSTANCE_NAMES
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeOfAny
- mypy.types.TypeQuery
- mypy.types.TypeType
- mypy.types.TypeVarId
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypeVisitor
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.find_unpack_in_list
- mypy.types.get_proper_type
- mypy.types.has_recursive_types
- mypy.types.has_type_vars
- mypy.types.is_named_instance
- mypy.types.split_with_prefix_and_suffix
- mypy.types_utils.is_union_with_any
- mypy.typestate.type_state
- typing.Final
- typing.Iterable
- typing.List
- typing.Sequence
- typing.TYPE_CHECKING

**Functions:**

### `def infer_constraints_for_callable(callee: CallableType, arg_types: Sequence[Type | None], arg_kinds: list[ArgKind], arg_names: Sequence[str | None] | None, formal_to_actual: list[list[int]], context: ArgumentInferContext) -> list[Constraint]`

**Description:**
Infer type variable constraints for a callable and actual arguments.

Return a list of constraints.

**Line:** 107

---

### `def infer_constraints(template: Type, actual: Type, direction: int, skip_neg_op: bool = False) -> list[Constraint]`

**Description:**
Infer type constraints.

Match a template type, which may contain type variable references,
recursively against a type which does not contain (the same) type
variable references. The result is a list of type constrains of
form 'T is a supertype/subtype of x', where T is a type variable
present in the template and x is a type without reference to type
variables present in the template.

Assume T and S are type variables. Now the following results can be
calculated (read as '(template, actual) --> result'):

(T, X)            -->  T :> X
(X[T], X[Y])      -->  T <: Y and T :> Y
((T, T), (X, Y))  -->  T :> X and T :> Y
((T, S), (X, Y))  -->  T :> X and S :> Y
(X[T], Any)       -->  T <: Any and T :> Any

The constraints are represented as Constraint objects. If skip_neg_op == True,
then skip adding reverse (polymorphic) constraints (since this is already a call
to infer such constraints).

**Line:** 273

---

### `def _infer_constraints(template: Type, actual: Type, direction: int, skip_neg_op: bool) -> list[Constraint]`

**Line:** 317

---

### `def infer_constraints_if_possible(template: Type, actual: Type, direction: int) -> list[Constraint] | None`

**Description:**
Like infer_constraints, but return None if the input relation is
known to be unsatisfiable, for example if template=List[T] and actual=int.
(In this case infer_constraints would return [], just like it would for
an automatically satisfied relation like template=List[T] and actual=object.)

**Line:** 410

---

### `def select_trivial(options: Sequence[list[Constraint] | None]) -> list[list[Constraint]]`

**Description:**
Select only those lists where each item is a constraint against Any.

**Line:** 435

---

### `def merge_with_any(constraint: Constraint) -> Constraint`

**Description:**
Transform a constraint target into a union with given Any type.

**Line:** 446

---

### `def handle_recursive_union(template: UnionType, actual: Type, direction: int) -> list[Constraint]`

**Line:** 461

---

### `def any_constraints(options: list[list[Constraint] | None], eager: bool) -> list[Constraint]`

**Description:**
Deduce what we can from a collection of constraint lists.

It's a given that at least one of the lists must be satisfied. A
None element in the list of options represents an unsatisfiable
constraint and is ignored.  Ignore empty constraint lists if eager
is true -- they are always trivially satisfiable.

**Line:** 474

---

### `def filter_satisfiable(option: list[Constraint] | None) -> list[Constraint] | None`

**Description:**
Keep only constraints that can possibly be satisfied.

Currently, we filter out constraints where target is not a subtype of the upper bound.
Since those can be never satisfied. We may add more cases in future if it improves type
inference.

**Line:** 526

---

### `def is_same_constraints(x: list[Constraint], y: list[Constraint]) -> bool`

**Line:** 549

---

### `def is_same_constraint(c1: Constraint, c2: Constraint) -> bool`

**Line:** 559

---

### `def is_similar_constraints(x: list[Constraint], y: list[Constraint]) -> bool`

**Description:**
Check that two lists of constraints have similar structure.

This means that each list has same type variable plus direction pairs (i.e we
ignore the target). Except for constraints where target is Any type, there
we ignore direction as well.

**Line:** 571

---

### `def _is_similar_constraints(x: list[Constraint], y: list[Constraint]) -> bool`

**Description:**
Check that every constraint in the first list has a similar one in the second.

See docstring above for definition of similarity.

**Line:** 581

---

### `def simplify_away_incomplete_types(types: Iterable[Type]) -> list[Type]`

**Line:** 601

---

### `def is_complete_type(typ: Type) -> bool`

**Description:**
Is a type complete?

A complete doesn't have uninhabited type components or (when not in strict
optional mode) None components.

**Line:** 609

---

### `def neg_op(op: int) -> int`

**Description:**
Map SubtypeOf to SupertypeOf and vice versa.

**Line:** 1338

---

### `def find_matching_overload_item(overloaded: Overloaded, template: CallableType) -> CallableType`

**Description:**
Disambiguate overload item against a template.

**Line:** 1349

---

### `def find_matching_overload_items(overloaded: Overloaded, template: CallableType) -> list[CallableType]`

**Description:**
Like find_matching_overload_item, but return all matches, not just the first.

**Line:** 1368

---

### `def get_tuple_fallback_from_unpack(unpack: UnpackType) -> TypeInfo`

**Description:**
Get builtins.tuple type from available types to construct homogeneous tuples.

**Line:** 1392

---

### `def repack_callable_args(callable: CallableType, tuple_type: TypeInfo) -> list[Type]`

**Description:**
Present callable with star unpack in a normalized form.

Since positional arguments cannot follow star argument, they are packed in a suffix,
while prefix is represented as individual positional args. We want to put all in a single
list with unpack in the middle, and prefix/suffix on the sides (as they would appear
in e.g. a TupleType).

**Line:** 1406

---

### `def build_constraints_for_simple_unpack(template_args: list[Type], actual_args: list[Type], direction: int) -> list[Constraint]`

**Description:**
Infer constraints between two lists of types with variadic items.

This function is only supposed to be called when a variadic item is present in templates.
If there is no variadic item the actuals, we simply use split_with_prefix_and_suffix()
and infer prefix <: prefix, suffix <: suffix, variadic <: middle. If there is a variadic
item in the actuals we need to be more careful, only common prefix/suffix can generate
constraints, also we can only infer constraints for variadic template item, if template
prefix/suffix are shorter that actual ones, otherwise there may be partial overlap
between variadic items, for example if template prefix is longer:

templates: T1, T2, Ts, Ts, Ts, ...
actuals:   A1, As, As, As, ...

Note: this function can only be called for builtin variadic constructors: Tuple and Callable.
For instances, you should first find correct type argument mapping.

**Line:** 1432

---

### `def infer_directed_arg_constraints(left: Type, right: Type, direction: int) -> list[Constraint]`

**Description:**
Infer constraints between two arguments using direction between original callables.

**Line:** 1528

---

### `def infer_callable_arguments_constraints(template: NormalizedCallableType | Parameters, actual: NormalizedCallableType | Parameters, direction: int) -> list[Constraint]`

**Description:**
Infer constraints between argument types of two callables.

This function essentially extracts four steps from are_parameters_compatible() in
subtypes.py that involve subtype checks between argument types. We keep the argument
matching logic, but ignore various strictness flags present there, and checks that
do not involve subtyping. Then in place of every subtype check we put an infer_constraints()
call for the same types.

**Line:** 1543

---


## Module: venv2.libthon3.12.site-packages.mypy.copytype
**File:** `venv2/lib/python3.12/site-packages/mypy/copytype.py`

**Imports:**
- __future__.annotations
- mypy.type_visitor.TypeVisitor
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.ErasedType
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.TypeAliasType
- mypy.types.TypeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- typing.Any
- typing.cast

**Functions:**

### `def copy_type(t: ProperType) -> ProperType`

**Description:**
Create a shallow copy of a type.

This can be used to mutate the copy with truthiness information.

Classes compiled with mypyc don't support copy.copy(), so we need
a custom implementation.

**Line:** 34

---


## Module: venv2.libthon3.12.site-packages.mypy.dmypy.client
**File:** `venv2/lib/python3.12/site-packages/mypy/dmypy/client.py`

**Imports:**
- __future__.annotations
- argparse
- base64
- json
- mypy.dmypy_os.alive
- mypy.dmypy_os.kill
- mypy.dmypy_server.Server
- mypy.dmypy_server.daemonize
- mypy.dmypy_server.process_start_options
- mypy.dmypy_util.DEFAULT_STATUS_FILE
- mypy.dmypy_util.receive
- mypy.dmypy_util.send
- mypy.ipc.IPCClient
- mypy.ipc.IPCException
- mypy.options.Options
- mypy.util.check_python_version
- mypy.util.get_terminal_width
- mypy.util.should_force_color
- mypy.util.write_junit_xml
- mypy.version.__version__
- os
- pickle
- sys
- time
- traceback
- typing.Any
- typing.Callable
- typing.Mapping
- typing.NoReturn

**Functions:**

### `def main(argv: list[str]) -> None`

**Description:**
The code is top-down.

**Line:** 267

---

### `def fail(msg: str) -> NoReturn`

**Line:** 285

---

### `def action(subparser: argparse.ArgumentParser) -> Callable[([ActionFunction], ActionFunction)]`

**Description:**
Decorator to tie an action function to a subparser.

**Line:** 293

---

### `def do_start(args: argparse.Namespace) -> None`

**Decorators:**
- `@action(...)`

**Description:**
Start daemon (it must not already be running).

This is where mypy flags are set from the command line.

Setting flags is a bit awkward; you have to use e.g.:

dmypy start -- --strict

since we don't want to duplicate mypy's huge list of flags.

**Line:** 307

---

### `def do_restart(args: argparse.Namespace) -> None`

**Decorators:**
- `@action(...)`

**Description:**
Restart daemon (it may or may not be running; but not hanging).

We first try to stop it politely if it's running.  This also sets
mypy flags from the command line (see do_start()).

**Line:** 329

---

### `def restart_server(args: argparse.Namespace, allow_sources: bool = False) -> None`

**Description:**
Restart daemon (it may or may not be running; but not hanging).

**Line:** 338

---

### `def start_server(args: argparse.Namespace, allow_sources: bool = False) -> None`

**Description:**
Start the server from command arguments and wait for it.

**Line:** 348

---

### `def wait_for_server(status_file: str, timeout: float = 5.0) -> None`

**Description:**
Wait until the server is up.

Exit if it doesn't happen within the timeout.

**Line:** 359

---

### `def do_run(args: argparse.Namespace) -> None`

**Decorators:**
- `@action(...)`

**Description:**
Do a check, starting (or restarting) the daemon as necessary

Restarts the daemon if the running daemon reports that it is
required (due to a configuration change, for example).

Setting flags is a bit awkward; you have to use e.g.:

dmypy run -- --strict a.py b.py ...

since we don't want to duplicate mypy's huge list of flags.
(The -- is only necessary if flags are specified.)

**Line:** 380

---

### `def do_status(args: argparse.Namespace) -> None`

**Decorators:**
- `@action(...)`

**Description:**
Print daemon status.

This verifies that it is responsive to requests.

**Line:** 422

---

### `def do_stop(args: argparse.Namespace) -> None`

**Decorators:**
- `@action(...)`

**Description:**
Stop daemon via a 'stop' request.

**Line:** 444

---

### `def do_kill(args: argparse.Namespace) -> None`

**Decorators:**
- `@action(...)`

**Description:**
Kill daemon process with SIGKILL.

**Line:** 456

---

### `def do_check(args: argparse.Namespace) -> None`

**Decorators:**
- `@action(...)`

**Description:**
Ask the daemon to check a list of files.

**Line:** 468

---

### `def do_recheck(args: argparse.Namespace) -> None`

**Decorators:**
- `@action(...)`

**Description:**
Ask the daemon to recheck the previous list of files, with optional modifications.

If at least one of --remove or --update is given, the server will
update the list of files to check accordingly and assume that any other files
are unchanged.  If none of these flags are given, the server will call stat()
on each file last checked to determine its status.

Files given in --update ought to exist.  Files given in --remove need not exist;
if they don't they will be ignored.
The lists may be empty but oughtn't contain duplicates or overlap.

NOTE: The list of files is lost when the daemon is restarted.

**Line:** 478

---

### `def do_suggest(args: argparse.Namespace) -> None`

**Decorators:**
- `@action(...)`

**Description:**
Ask the daemon for a suggested signature.

This just prints whatever the daemon reports as output.
For now it may be closer to a list of call sites.

**Line:** 509

---

### `def do_inspect(args: argparse.Namespace) -> None`

**Decorators:**
- `@action(...)`

**Description:**
Ask daemon to print the type of an expression.

**Line:** 531

---

### `def check_output(response: dict[(str, Any)], verbose: bool, junit_xml: str | None, perf_stats_file: str | None) -> None`

**Description:**
Print the output from a check or recheck command.

Call sys.exit() unless the status code is zero.

**Line:** 549

---

### `def show_stats(response: Mapping[(str, object)]) -> None`

**Line:** 590

---

### `def do_hang(args: argparse.Namespace) -> None`

**Decorators:**
- `@action(...)`

**Description:**
Hang for 100 seconds, as a debug hack.

**Line:** 603

---

### `def do_daemon(args: argparse.Namespace) -> None`

**Decorators:**
- `@action(...)`

**Description:**
Serve requests in the foreground.

**Line:** 609

---

### `def do_help(args: argparse.Namespace) -> None`

**Decorators:**
- `@action(...)`

**Description:**
Print full help (same as dmypy --help).

**Line:** 633

---

### `def request(status_file: str, command: str, timeout: int | None = None, **kwds: object) -> dict[(str, Any)]`

**Description:**
Send a request to the daemon.

Return the JSON dict with the response.

Raise BadStatus if there is something wrong with the status file
or if the process whose pid is in the status file has died.

Return {'error': <message>} if an IPC operation or receive()
raised OSError.  This covers cases such as connection refused or
closed prematurely as well as invalid JSON received.

**Line:** 641

---

### `def get_status(status_file: str) -> tuple[(int, str)]`

**Description:**
Read status file and check if the process is alive.

Return (pid, connection_name) on success.

Raise BadStatus if something's wrong.

**Line:** 687

---

### `def check_status(data: dict[(str, Any)]) -> tuple[(int, str)]`

**Description:**
Check if the process is alive.

Return (pid, connection_name) on success.

Raise BadStatus if something's wrong.

**Line:** 698

---

### `def read_status(status_file: str) -> dict[(str, object)]`

**Description:**
Read status file.

Raise BadStatus if the status file doesn't exist or contains
invalid JSON or the JSON is not a dict.

**Line:** 720

---

### `def is_running(status_file: str) -> bool`

**Description:**
Check if the server is running cleanly

**Line:** 738

---

### `def console_entry() -> None`

**Line:** 748

---


## Module: venv2.libthon3.12.site-packages.mypy.dmypy_os
**File:** `venv2/lib/python3.12/site-packages/mypy/dmypy_os.py`

**Imports:**
- __future__.annotations
- ctypes
- ctypes.wintypes.DWORD
- ctypes.wintypes.HANDLE
- os
- signal
- subprocess
- sys
- typing.Any
- typing.Callable

**Functions:**

### `def alive(pid: int) -> bool`

**Description:**
Is the process alive?

**Line:** 21

---

### `def kill(pid: int) -> None`

**Description:**
Kill the process.

**Line:** 37

---


## Module: venv2.libthon3.12.site-packages.mypy.dmypy_server
**File:** `venv2/lib/python3.12/site-packages/mypy/dmypy_server.py`

**Imports:**
- __future__.annotations
- argparse
- base64
- contextlib.redirect_stderr
- contextlib.redirect_stdout
- io
- json
- mypy.build
- mypy.dmypy_util.WriteToConn
- mypy.dmypy_util.receive
- mypy.dmypy_util.send
- mypy.errors
- mypy.find_sources.InvalidSourceList
- mypy.find_sources.create_source_list
- mypy.fscache.FileSystemCache
- mypy.fswatcher.FileData
- mypy.fswatcher.FileSystemWatcher
- mypy.inspections.InspectionEngine
- mypy.ipc.IPCServer
- mypy.main
- mypy.memprofile.print_memory_profile
- mypy.modulefinder.BuildSource
- mypy.modulefinder.FindModuleCache
- mypy.modulefinder.SearchPaths
- mypy.modulefinder.compute_search_paths
- mypy.options.Options
- mypy.server.update.FineGrainedBuildManager
- mypy.server.update.refresh_suppressed_submodules
- mypy.suggestions.SuggestionEngine
- mypy.suggestions.SuggestionFailure
- mypy.typestate.reset_global_state
- mypy.util.FancyFormatter
- mypy.util.count_stats
- mypy.version.__version__
- os
- pickle
- psutil
- resource
- subprocess
- subprocess.STARTUPINFO
- sys
- time
- traceback
- typing.AbstractSet
- typing.Any
- typing.Callable
- typing.Final
- typing.List
- typing.Sequence
- typing.Tuple
- typing_extensions.TypeAlias

**Functions:**

### `def daemonize(options: Options, status_file: str, timeout: int | None = None, log_file: str | None = None) -> int`

**Description:**
Create the daemon process via "dmypy daemon" and pass options via command line

When creating the daemon grandchild, we create it in a new console, which is
started hidden. We cannot use DETACHED_PROCESS since it will cause console windows
to pop up when starting. See
https://github.com/python/cpython/pull/4150#issuecomment-340215696
for more on why we can't have nice things.

It also pickles the options to be unpickled by mypy.

**Line:** 45

---

### `def _daemonize_cb(func: Callable[([], None)], log_file: str | None = None) -> int`

**Description:**
Arrange to call func() in a grandchild of the current process.

Return 0 for success, exit status for failure, negative if
subprocess killed by signal.

**Line:** 76

---

### `def daemonize(options: Options, status_file: str, timeout: int | None = None, log_file: str | None = None) -> int`

**Description:**
Run the mypy daemon in a grandchild of the current process

Return 0 for success, exit status for failure, negative if
subprocess killed by signal.

**Line:** 121

---

### `def process_start_options(flags: list[str], allow_sources: bool) -> Options`

**Line:** 137

---

### `def ignore_suppressed_imports(module: str) -> bool`

**Description:**
Can we skip looking for newly unsuppressed imports to module?

**Line:** 156

---

### `def get_meminfo() -> dict[(str, Any)]`

**Line:** 996

---

### `def find_all_sources_in_build(graph: mypy.build.Graph, extra: Sequence[BuildSource] = ()) -> list[BuildSource]`

**Line:** 1025

---

### `def add_all_sources_to_changed(sources: list[BuildSource], changed: list[tuple[(str, str)]]) -> None`

**Description:**
Add all (explicit) sources to the list changed files in place.

Use this when re-processing of unchanged files is needed (e.g. for
the purpose of exporting types for inspections).

**Line:** 1036

---

### `def fix_module_deps(graph: mypy.build.Graph) -> None`

**Description:**
After an incremental update, update module dependencies to reflect the new state.

This can make some suppressed dependencies non-suppressed, and vice versa (if modules
have been added to or removed from the build).

**Line:** 1052

---

### `def filter_out_missing_top_level_packages(packages: set[str], search_paths: SearchPaths, fscache: FileSystemCache) -> set[str]`

**Description:**
Quickly filter out obviously missing top-level packages.

Return packages with entries that can't be found removed.

This is approximate: some packages that aren't actually valid may be
included. However, all potentially valid packages must be returned.

**Line:** 1072

---


## Module: venv2.libthon3.12.site-packages.mypy.dmypy_util
**File:** `venv2/lib/python3.12/site-packages/mypy/dmypy_util.py`

**Imports:**
- __future__.annotations
- json
- mypy.ipc.IPCBase
- typing.Any
- typing.Final
- typing.Iterable

**Functions:**

### `def receive(connection: IPCBase) -> Any`

**Description:**
Receive single JSON data frame from a connection.

Raise OSError if the data received is not valid JSON or if it is
not a dict.

**Line:** 16

---

### `def send(connection: IPCBase, data: Any) -> None`

**Description:**
Send data to a connection encoded and framed.

The data must be JSON-serializable. We assume that a single send call is a
single frame to be sent on the connect.

**Line:** 34

---


## Module: venv2.libthon3.12.site-packages.mypy.erasetype
**File:** `venv2/lib/python3.12/site-packages/mypy/erasetype.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.typeops.make_simplified_union
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.ErasedType
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeOfAny
- mypy.types.TypeTranslator
- mypy.types.TypeType
- mypy.types.TypeVarId
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypeVisitor
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.get_proper_type
- mypy.types.get_proper_types
- typing.Callable
- typing.Container
- typing.cast

**Functions:**

### `def erase_type(typ: Type) -> ProperType`

**Description:**
Erase any type variables from a type.

Also replace tuple types with the corresponding concrete types.

Examples:
A -> A
B[X] -> B[Any]
Tuple[A, B] -> tuple
Callable[[A1, A2, ...], R] -> Callable[..., Any]
Type[X] -> Type[Any]

**Line:** 39

---

### `def erase_typevars(t: Type, ids_to_erase: Container[TypeVarId] | None = None) -> Type`

**Description:**
Replace all type variables in a type with any,
or just the ones in the provided collection.

**Line:** 151

---

### `def replace_meta_vars(t: Type, target_type: Type) -> Type`

**Description:**
Replace unification variables in a type with the target type.

**Line:** 164

---

### `def remove_instance_last_known_values(t: Type) -> Type`

**Line:** 229

---


## Module: venv2.libthon3.12.site-packages.mypy.errors
**File:** `venv2/lib/python3.12/site-packages/mypy/errors.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- mypy.errorcodes
- mypy.errorcodes.ErrorCode
- mypy.errorcodes.IMPORT
- mypy.errorcodes.IMPORT_NOT_FOUND
- mypy.errorcodes.IMPORT_UNTYPED
- mypy.message_registry.ErrorMessage
- mypy.options.Options
- mypy.scope.Scope
- mypy.util.DEFAULT_SOURCE_OFFSET
- mypy.util.is_typeshed_file
- mypy.version.__version__
- os.path
- pdb
- sys
- traceback
- typing.Callable
- typing.Final
- typing.Iterable
- typing.NoReturn
- typing.Optional
- typing.TextIO
- typing.Tuple
- typing.TypeVar
- typing_extensions.Literal
- typing_extensions.TypeAlias

**Functions:**

### `def remove_path_prefix(path: str, prefix: str | None) -> str`

**Description:**
If path starts with prefix, return copy of path with the prefix removed.
Otherwise, return path. If path is None, return None.

**Line:** 1191

---

### `def report_internal_error(err: Exception, file: str | None, line: int, errors: Errors, options: Options, stdout: TextIO | None = None, stderr: TextIO | None = None) -> NoReturn`

**Description:**
Report internal error and exit.

This optionally starts pdb or shows a traceback.

**Line:** 1201

---


## Module: venv2.libthon3.12.site-packages.mypy.evalexpr
**File:** `venv2/lib/python3.12/site-packages/mypy/evalexpr.py`

**Imports:**
- ast
- mypy.nodes
- mypy.visitor.ExpressionVisitor
- typing.Final

**Functions:**

### `def evaluate_expression(expr: mypy.nodes.Expression) -> object`

**Description:**
Evaluate an expression at runtime.

Return the result of the expression, or UNKNOWN if the expression cannot be
evaluated.

**Line:** 198

---


## Module: venv2.libthon3.12.site-packages.mypy.expandtype
**File:** `venv2/lib/python3.12/site-packages/mypy/expandtype.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ARG_STAR
- mypy.nodes.Var
- mypy.state.state
- mypy.type_visitor
- mypy.types.ANY_STRATEGY
- mypy.types.AnyType
- mypy.types.BoolTypeQuery
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.ErasedType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ParamSpecFlavor
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TrivialSyntheticTypeTranslator
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeType
- mypy.types.TypeVarId
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.flatten_nested_unions
- mypy.types.get_proper_type
- mypy.types.split_with_prefix_and_suffix
- mypy.typevartuples.split_with_instance
- typing.Final
- typing.Iterable
- typing.Mapping
- typing.Sequence
- typing.TypeVar
- typing.cast
- typing.overload

**Functions:**

### `def expand_type(typ: CallableType, env: Mapping[(TypeVarId, Type)]) -> CallableType`

**Decorators:**
- `@overload`

**Line:** 53

---

### `def expand_type(typ: ProperType, env: Mapping[(TypeVarId, Type)]) -> ProperType`

**Decorators:**
- `@overload`

**Line:** 58

---

### `def expand_type(typ: Type, env: Mapping[(TypeVarId, Type)]) -> Type`

**Decorators:**
- `@overload`

**Line:** 63

---

### `def expand_type(typ: Type, env: Mapping[(TypeVarId, Type)]) -> Type`

**Description:**
Substitute any type variable references in a type given by a type
environment.

**Line:** 67

---

### `def expand_type_by_instance(typ: CallableType, instance: Instance) -> CallableType`

**Decorators:**
- `@overload`

**Line:** 75

---

### `def expand_type_by_instance(typ: ProperType, instance: Instance) -> ProperType`

**Decorators:**
- `@overload`

**Line:** 80

---

### `def expand_type_by_instance(typ: Type, instance: Instance) -> Type`

**Decorators:**
- `@overload`

**Line:** 85

---

### `def expand_type_by_instance(typ: Type, instance: Instance) -> Type`

**Description:**
Substitute type variables in type using values from an Instance.
Type variables are considered to be bound by the class declaration.

**Line:** 89

---

### `def freshen_function_type_vars(callee: F) -> F`

**Description:**
Substitute fresh type variables for generic function type variables.

**Line:** 125

---

### `def freshen_all_functions_type_vars(t: T) -> T`

**Line:** 159

---

### `def expand_self_type(var: Var, typ: ProperType, replacement: ProperType) -> ProperType`

**Decorators:**
- `@overload`

**Line:** 466

---

### `def expand_self_type(var: Var, typ: Type, replacement: Type) -> Type`

**Decorators:**
- `@overload`

**Line:** 471

---

### `def expand_self_type(var: Var, typ: Type, replacement: Type) -> Type`

**Description:**
Expand appearances of Self type in a variable type.

**Line:** 475

---

### `def remove_trivial(types: Iterable[Type]) -> list[Type]`

**Description:**
Make trivial simplifications on a list of types without calling is_subtype().

This makes following simplifications:
* Remove bottom types (taking into account strict optional setting)
* Remove everything else if there is an `object`
* Remove strict duplicate types

**Line:** 482

---


## Module: venv2.libthon3.12.site-packages.mypy.exprtotype
**File:** `venv2/lib/python3.12/site-packages/mypy/exprtotype.py`

**Imports:**
- __future__.annotations
- mypy.fastparse.parse_type_string
- mypy.nodes.BytesExpr
- mypy.nodes.CallExpr
- mypy.nodes.ComplexExpr
- mypy.nodes.EllipsisExpr
- mypy.nodes.Expression
- mypy.nodes.FloatExpr
- mypy.nodes.IndexExpr
- mypy.nodes.IntExpr
- mypy.nodes.ListExpr
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.OpExpr
- mypy.nodes.RefExpr
- mypy.nodes.StarExpr
- mypy.nodes.StrExpr
- mypy.nodes.TupleExpr
- mypy.nodes.UnaryExpr
- mypy.nodes.get_member_expr_fullname
- mypy.options.Options
- mypy.types.ANNOTATED_TYPE_NAMES
- mypy.types.AnyType
- mypy.types.CallableArgument
- mypy.types.EllipsisType
- mypy.types.ProperType
- mypy.types.RawExpressionType
- mypy.types.Type
- mypy.types.TypeList
- mypy.types.TypeOfAny
- mypy.types.UnboundType
- mypy.types.UnionType
- mypy.types.UnpackType

**Functions:**

### `def _extract_argument_name(expr: Expression) -> str | None`

**Line:** 47

---

### `def expr_to_unanalyzed_type(expr: Expression, options: Options | None = None, allow_new_syntax: bool = False, _parent: Expression | None = None, allow_unpack: bool = False) -> ProperType`

**Description:**
Translate an expression to the corresponding type.

The result is not semantically analyzed. It can be UnboundType or TypeList.
Raise TypeTranslationError if the expression cannot represent a type.

If allow_new_syntax is True, allow all type syntax independent of the target
Python version (used in stubs).

**Line:** 56

---


## Module: venv2.libthon3.12.site-packages.mypy.fastparse
**File:** `venv2/lib/python3.12/site-packages/mypy/fastparse.py`

**Imports:**
- __future__.annotations
- ast
- ast.AST
- ast.Attribute
- ast.Call
- ast.FunctionType
- ast.Index
- ast.Name
- ast.Starred
- ast.USub
- ast.UnaryOp
- copy
- mypy.defaults
- mypy.errorcodes
- mypy.errors.Errors
- mypy.message_registry
- mypy.message_registry.ErrorMessage
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_NAMED_OPT
- mypy.nodes.ARG_OPT
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.ArgKind
- mypy.nodes.Argument
- mypy.nodes.AssertStmt
- mypy.nodes.AssignmentExpr
- mypy.nodes.AssignmentStmt
- mypy.nodes.AwaitExpr
- mypy.nodes.Block
- mypy.nodes.BreakStmt
- mypy.nodes.BytesExpr
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.ComparisonExpr
- mypy.nodes.ComplexExpr
- mypy.nodes.ConditionalExpr
- mypy.nodes.ContinueStmt
- mypy.nodes.Decorator
- mypy.nodes.DelStmt
- mypy.nodes.DictExpr
- mypy.nodes.DictionaryComprehension
- mypy.nodes.EllipsisExpr
- mypy.nodes.Expression
- mypy.nodes.ExpressionStmt
- mypy.nodes.FakeInfo
- mypy.nodes.FloatExpr
- mypy.nodes.ForStmt
- mypy.nodes.FuncDef
- mypy.nodes.GeneratorExpr
- mypy.nodes.GlobalDecl
- mypy.nodes.IfStmt
- mypy.nodes.Import
- mypy.nodes.ImportAll
- mypy.nodes.ImportBase
- mypy.nodes.ImportFrom
- mypy.nodes.IndexExpr
- mypy.nodes.IntExpr
- mypy.nodes.LambdaExpr
- mypy.nodes.ListComprehension
- mypy.nodes.ListExpr
- mypy.nodes.MatchStmt
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.Node
- mypy.nodes.NonlocalDecl
- mypy.nodes.OpExpr
- mypy.nodes.OperatorAssignmentStmt
- mypy.nodes.OverloadPart
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.PassStmt
- mypy.nodes.RaiseStmt
- mypy.nodes.RefExpr
- mypy.nodes.ReturnStmt
- mypy.nodes.SetComprehension
- mypy.nodes.SetExpr
- mypy.nodes.SliceExpr
- mypy.nodes.StarExpr
- mypy.nodes.Statement
- mypy.nodes.StrExpr
- mypy.nodes.SuperExpr
- mypy.nodes.TempNode
- mypy.nodes.TryStmt
- mypy.nodes.TupleExpr
- mypy.nodes.UnaryExpr
- mypy.nodes.Var
- mypy.nodes.WhileStmt
- mypy.nodes.WithStmt
- mypy.nodes.YieldExpr
- mypy.nodes.YieldFromExpr
- mypy.nodes.check_arg_names
- mypy.options.Options
- mypy.patterns.AsPattern
- mypy.patterns.ClassPattern
- mypy.patterns.MappingPattern
- mypy.patterns.OrPattern
- mypy.patterns.SequencePattern
- mypy.patterns.SingletonPattern
- mypy.patterns.StarredPattern
- mypy.patterns.ValuePattern
- mypy.reachability.infer_reachability_of_if_statement
- mypy.reachability.mark_block_unreachable
- mypy.sharedparse.argument_elide_name
- mypy.sharedparse.special_function_elide_names
- mypy.traverser.TraverserVisitor
- mypy.types.AnyType
- mypy.types.CallableArgument
- mypy.types.CallableType
- mypy.types.EllipsisType
- mypy.types.Instance
- mypy.types.ProperType
- mypy.types.RawExpressionType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeList
- mypy.types.TypeOfAny
- mypy.types.UnboundType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.util.bytes_to_human_readable_repr
- mypy.util.unnamed_function
- re
- sys
- typing.Any
- typing.Callable
- typing.Final
- typing.List
- typing.Optional
- typing.Sequence
- typing.TypeVar
- typing.Union
- typing.cast
- typing_extensions.Literal
- typing_extensions.overload
- warnings

**Functions:**

### `def ast3_parse(source: str | bytes, filename: str, mode: str, feature_version: int = PY_MINOR_VERSION) -> AST`

**Line:** 132

---

### `def parse(source: str | bytes, fnam: str, module: str | None, errors: Errors | None = None, options: Options | None = None) -> MypyFile`

**Description:**
Parse a source file, without doing any semantic analysis.

Return the parse tree. If errors is not provided, raise ParseError
on failure. Otherwise, use the errors object to report parse errors.

**Line:** 189

---

### `def parse_type_ignore_tag(tag: str | None) -> list[str] | None`

**Description:**
Parse optional "[code, ...]" tag after "# type: ignore".

Return:
* [] if no tag was found (ignore all errors)
* list of ignored error codes if a tag was found
* None if the tag was invalid.

**Line:** 264

---

### `def parse_type_comment(type_comment: str, line: int, column: int, errors: Errors | None) -> tuple[(list[str] | None, ProperType | None)]`

**Description:**
Parse type portion of a type comment (+ optional type ignore).

Return (ignore info, parsed type).

**Line:** 282

---

### `def parse_type_string(expr_string: str, expr_fallback_name: str, line: int, column: int) -> ProperType`

**Description:**
Parses a type that was originally present inside of an explicit string.

For example, suppose we have the type `Foo["blah"]`. We should parse the
string expression "blah" using this function.

**Line:** 320

---

### `def is_no_type_check_decorator(expr: ast3.expr) -> bool`

**Line:** 344

---

### `def stringify_name(n: AST) -> str | None`

**Line:** 2052

---

### `def is_possible_trivial_body(s: list[Statement]) -> bool`

**Description:**
Could the statements form a "trivial" function body, such as 'pass'?

This mimics mypy.semanal.is_trivial_body, but this runs before
semantic analysis so some checks must be conservative.

**Line:** 2121

---


## Module: venv2.libthon3.12.site-packages.mypy.find_sources
**File:** `venv2/lib/python3.12/site-packages/mypy/find_sources.py`

**Imports:**
- __future__.annotations
- functools
- mypy.fscache.FileSystemCache
- mypy.modulefinder.BuildSource
- mypy.modulefinder.PYTHON_EXTENSIONS
- mypy.modulefinder.matches_exclude
- mypy.modulefinder.mypy_path
- mypy.options.Options
- os
- typing.Final
- typing.Sequence

**Functions:**

### `def create_source_list(paths: Sequence[str], options: Options, fscache: FileSystemCache | None = None, allow_empty_dir: bool = False) -> list[BuildSource]`

**Description:**
From a list of source files/directories, makes a list of BuildSources.

Raises InvalidSourceList on errors.

**Line:** 20

---

### `def keyfunc(name: str) -> tuple[(bool, int, str)]`

**Description:**
Determines sort order for directory listing.

The desirable properties are:
1) foo < foo.pyi < foo.py
2) __init__.py[i] < foo

**Line:** 51

---

### `def normalise_package_base(root: str) -> str`

**Line:** 65

---

### `def get_explicit_package_bases(options: Options) -> list[str] | None`

**Description:**
Returns explicit package bases to use if the option is enabled, or None if disabled.

We currently use MYPYPATH and the current directory as the package bases. In the future,
when --namespace-packages is the default could also use the values passed with the
--package-root flag, see #9632.

Values returned are normalised so we can use simple string comparisons in
SourceFinder.is_explicit_package_base

**Line:** 74

---

### `def module_join(parent: str, child: str) -> str`

**Description:**
Join module ids, accounting for a possibly empty parent.

**Line:** 228

---

### `def strip_py(arg: str) -> str | None`

**Description:**
Strip a trailing .py or .pyi suffix.

Return None if no such suffix is found.

**Line:** 235

---


## Module: venv2.libthon3.12.site-packages.mypy.fixup
**File:** `venv2/lib/python3.12/site-packages/mypy/fixup.py`

**Imports:**
- __future__.annotations
- mypy.lookup.lookup_fully_qualified
- mypy.nodes.Block
- mypy.nodes.ClassDef
- mypy.nodes.Decorator
- mypy.nodes.FuncDef
- mypy.nodes.MypyFile
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.ParamSpecExpr
- mypy.nodes.SymbolTable
- mypy.nodes.TypeAlias
- mypy.nodes.TypeInfo
- mypy.nodes.TypeVarExpr
- mypy.nodes.TypeVarTupleExpr
- mypy.nodes.Var
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NOT_READY
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.TupleType
- mypy.types.TypeAliasType
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypeVisitor
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.visitor.NodeVisitor
- typing.Any
- typing.Final

**Functions:**

### `def fixup_module(tree: MypyFile, modules: dict[(str, MypyFile)], allow_missing: bool) -> None`

**Line:** 50

---

### `def lookup_fully_qualified_typeinfo(modules: dict[(str, MypyFile)], name: str, allow_missing: bool) -> TypeInfo`

**Line:** 362

---

### `def lookup_fully_qualified_alias(modules: dict[(str, MypyFile)], name: str, allow_missing: bool) -> TypeAlias`

**Line:** 379

---

### `def missing_info(modules: dict[(str, MypyFile)]) -> TypeInfo`

**Line:** 412

---

### `def missing_alias() -> TypeAlias`

**Line:** 424

---


## Module: venv2.libthon3.12.site-packages.mypy.freetree
**File:** `venv2/lib/python3.12/site-packages/mypy/freetree.py`

**Imports:**
- __future__.annotations
- mypy.nodes.Block
- mypy.nodes.MypyFile
- mypy.traverser.TraverserVisitor

**Functions:**

### `def free_tree(tree: MypyFile) -> None`

**Description:**
Free all the ASTs associated with a module.

This needs to be done recursively, since symbol tables contain
references to definitions, so those won't be freed but we want their
contents to be.

**Line:** 15

---


## Module: venv2.libthon3.12.site-packages.mypy.fscache
**File:** `venv2/lib/python3.12/site-packages/mypy/fscache.py`

**Imports:**
- __future__.annotations
- mypy.util.hash_digest
- mypy_extensions.mypyc_attr
- os
- stat

**Functions:**

### `def copy_os_error(e: OSError) -> OSError`

**Line:** 302

---


## Module: venv2.libthon3.12.site-packages.mypy.git
**File:** `venv2/lib/python3.12/site-packages/mypy/git.py`

**Imports:**
- __future__.annotations
- os
- subprocess

**Functions:**

### `def is_git_repo(dir: str) -> bool`

**Description:**
Is the given directory version-controlled with git?

**Line:** 10

---

### `def have_git() -> bool`

**Description:**
Can we run the git executable?

**Line:** 15

---

### `def git_revision(dir: str) -> bytes`

**Description:**
Get the SHA-1 of the HEAD of a git repository.

**Line:** 26

---

### `def is_dirty(dir: str) -> bool`

**Description:**
Check whether a git repository has uncommitted changes.

**Line:** 31

---


## Module: venv2.libthon3.12.site-packages.mypy.graph_utils
**File:** `venv2/lib/python3.12/site-packages/mypy/graph_utils.py`

**Imports:**
- __future__.annotations
- typing.AbstractSet
- typing.Iterable
- typing.Iterator
- typing.TypeVar

**Functions:**

### `def strongly_connected_components(vertices: AbstractSet[T], edges: dict[(T, list[T])]) -> Iterator[set[T]]`

**Description:**
Compute Strongly Connected Components of a directed graph.

Args:
vertices: the labels for the vertices
edges: for each vertex, gives the target vertices of its outgoing edges

Returns:
An iterator yielding strongly connected components, each
represented as a set of vertices.  Each input vertex will occur
exactly once; vertices not part of a SCC are returned as
singleton sets.

From https://code.activestate.com/recipes/578507/.

**Line:** 10

---

### `def prepare_sccs(sccs: list[set[T]], edges: dict[(T, list[T])]) -> dict[(AbstractSet[T], set[AbstractSet[T]])]`

**Description:**
Use original edges to organize SCCs in a graph by dependencies between them.

**Line:** 56

---

### `def topsort(data: dict[(T, set[T])]) -> Iterable[set[T]]`

**Description:**
Topological sort.

Args:
data: A map from vertices to all vertices that it has an edge
connecting it to.  NOTE: This data structure
is modified in place -- for normalization purposes,
self-dependencies are removed and entries representing
orphans are added.

Returns:
An iterator yielding sets of vertices that have an equivalent
ordering.

Example:
Suppose the input has the following structure:

{A: {B, C}, B: {D}, C: {D}}

This is normalized to:

{A: {B, C}, B: {D}, C: {D}, D: {}}

The algorithm will yield the following values:

{D}
{B, C}
{A}

From https://code.activestate.com/recipes/577413/.

**Line:** 70

---


## Module: venv2.libthon3.12.site-packages.mypy.indirection
**File:** `venv2/lib/python3.12/site-packages/mypy/indirection.py`

**Imports:**
- __future__.annotations
- mypy.types
- mypy.types.TypeVisitor
- mypy.util.split_module_names
- typing.Iterable
- typing.Set

**Functions:**

### `def extract_module_names(type_name: str | None) -> list[str]`

**Description:**
Returns the module names of a fully qualified type name.

**Line:** 10

---


## Module: venv2.libthon3.12.site-packages.mypy.infer
**File:** `venv2/lib/python3.12/site-packages/mypy/infer.py`

**Imports:**
- __future__.annotations
- mypy.constraints.SUBTYPE_OF
- mypy.constraints.SUPERTYPE_OF
- mypy.constraints.infer_constraints
- mypy.constraints.infer_constraints_for_callable
- mypy.nodes.ArgKind
- mypy.solve.solve_constraints
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.Type
- mypy.types.TypeVarLikeType
- typing.NamedTuple
- typing.Sequence

**Functions:**

### `def infer_function_type_arguments(callee_type: CallableType, arg_types: Sequence[Type | None], arg_kinds: list[ArgKind], arg_names: Sequence[str | None] | None, formal_to_actual: list[list[int]], context: ArgumentInferContext, strict: bool = True, allow_polymorphic: bool = False) -> tuple[(list[Type | None], list[TypeVarLikeType])]`

**Description:**
Infer the type arguments of a generic function.

Return an array of lower bound types for the type variables -1 (at
index 0), -2 (at index 1), etc. A lower bound is None if a value
could not be inferred.

Arguments:
callee_type: the target generic function
arg_types: argument types at the call site (each optional; if None,
we are not considering this argument in the current pass)
arg_kinds: nodes.ARG_* values for arg_types
formal_to_actual: mapping from formal to actual variable indices

**Line:** 32

---

### `def infer_type_arguments(type_vars: Sequence[TypeVarLikeType], template: Type, actual: Type, is_supertype: bool = False, skip_unsatisfied: bool = False) -> list[Type | None]`

**Line:** 65

---


## Module: venv2.libthon3.12.site-packages.mypy.inspections
**File:** `venv2/lib/python3.12/site-packages/mypy/inspections.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- functools.cmp_to_key
- mypy.build.State
- mypy.messages.format_type
- mypy.modulefinder.PYTHON_EXTENSIONS
- mypy.nodes.Decorator
- mypy.nodes.Expression
- mypy.nodes.FuncBase
- mypy.nodes.LDEF
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.Node
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.RefExpr
- mypy.nodes.SymbolNode
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.server.update.FineGrainedBuildManager
- mypy.traverser.ExtendedTraverserVisitor
- mypy.typeops.tuple_fallback
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.TypeVarType
- mypy.types.TypedDictType
- mypy.types.UnionType
- mypy.types.get_proper_type
- mypy.typevars.fill_typevars_with_any
- os
- typing.Callable

**Functions:**

### `def node_starts_after(o: Node, line: int, column: int) -> bool`

**Line:** 42

---

### `def node_ends_before(o: Node, line: int, column: int) -> bool`

**Line:** 46

---

### `def expr_span(expr: Expression) -> str`

**Description:**
Format expression span as in mypy error messages.

**Line:** 55

---

### `def get_instance_fallback(typ: ProperType) -> list[Instance]`

**Description:**
Returns the Instance fallback for this type if one exists or None.

**Line:** 60

---

### `def find_node(name: str, info: TypeInfo) -> Var | FuncBase | None`

**Description:**
Find the node defining member 'name' in given TypeInfo.

**Line:** 87

---

### `def find_module_by_fullname(fullname: str, modules: dict[(str, State)]) -> State | None`

**Description:**
Find module by a node fullname.

This logic mimics the one we use in fixup, so should be good enough.

**Line:** 109

---

### `def find_by_location(tree: MypyFile, line: int, column: int, end_line: int, end_column: int) -> Expression | None`

**Description:**
Find an expression matching given span, or None if not found.

**Line:** 154

---

### `def find_all_by_location(tree: MypyFile, line: int, column: int) -> list[Expression]`

**Description:**
Find all expressions enclosing given position starting from innermost.

**Line:** 185

---

### `def parse_location(location: str) -> tuple[(str, list[int])]`

**Line:** 615

---


## Module: venv2.libthon3.12.site-packages.mypy.join
**File:** `venv2/lib/python3.12/site-packages/mypy/join.py`

**Imports:**
- __future__.annotations
- mypy.maptype.map_instance_to_supertype
- mypy.meet.meet_types
- mypy.nodes.CONTRAVARIANT
- mypy.nodes.COVARIANT
- mypy.nodes.INVARIANT
- mypy.state.state
- mypy.subtypes.SubtypeContext
- mypy.subtypes.find_member
- mypy.subtypes.is_equivalent
- mypy.subtypes.is_proper_subtype
- mypy.subtypes.is_protocol_implementation
- mypy.subtypes.is_subtype
- mypy.typeops
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.ErasedType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypeVisitor
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.find_unpack_in_list
- mypy.types.get_proper_type
- mypy.types.get_proper_types
- mypy.types.split_with_prefix_and_suffix
- typing.overload

**Functions:**

### `def join_simple(declaration: Type | None, s: Type, t: Type) -> ProperType`

**Description:**
Return a simple least upper bound given the declared type.

This function should be only used by binder, and should not recurse.
For all other uses, use `join_types()`.

**Line:** 178

---

### `def trivial_join(s: Type, t: Type) -> Type`

**Description:**
Return one of types (expanded) if it is a supertype of other, otherwise top type.

**Line:** 227

---

### `def join_types(s: ProperType, t: ProperType, instance_joiner: InstanceJoiner | None = None) -> ProperType`

**Decorators:**
- `@overload`

**Line:** 238

---

### `def join_types(s: Type, t: Type, instance_joiner: InstanceJoiner | None = None) -> Type`

**Decorators:**
- `@overload`

**Line:** 245

---

### `def join_types(s: Type, t: Type, instance_joiner: InstanceJoiner | None = None) -> Type`

**Description:**
Return the least upper bound of s and t.

For example, the join of 'int' and 'object' is 'object'.

**Line:** 249

---

### `def is_better(t: Type, s: Type) -> bool`

**Line:** 684

---

### `def normalize_callables(s: ProperType, t: ProperType) -> tuple[(ProperType, ProperType)]`

**Line:** 699

---

### `def is_similar_callables(t: CallableType, s: CallableType) -> bool`

**Description:**
Return True if t and s have identical numbers of
arguments, default arguments and varargs.

**Line:** 707

---

### `def join_similar_callables(t: CallableType, s: CallableType) -> CallableType`

**Line:** 718

---

### `def safe_join(t: Type, s: Type) -> Type`

**Line:** 738

---

### `def safe_meet(t: Type, s: Type) -> Type`

**Line:** 748

---

### `def combine_similar_callables(t: CallableType, s: CallableType) -> CallableType`

**Line:** 770

---

### `def combine_arg_names(t: CallableType | Parameters, s: CallableType | Parameters) -> list[str | None]`

**Description:**
Produces a list of argument names compatible with both callables.

For example, suppose 't' and 's' have the following signatures:

- t: (a: int, b: str, X: str) -> None
- s: (a: int, b: str, Y: str) -> None

This function would return ["a", "b", None]. This information
is then used above to compute the join of t and s, which results
in a signature of (a: int, b: str, str) -> None.

Note that the third argument's name is omitted and 't' and 's'
are both valid subtypes of this inferred signature.

Precondition: is_similar_types(t, s) is true.

**Line:** 791

---

### `def object_from_instance(instance: Instance) -> Instance`

**Description:**
Construct the type 'builtins.object' from an instance type.

**Line:** 822

---

### `def object_or_any_from_type(typ: ProperType) -> ProperType`

**Line:** 829

---

### `def join_type_list(types: list[Type]) -> Type`

**Line:** 853

---

### `def unpack_callback_protocol(t: Instance) -> ProperType | None`

**Line:** 864

---


## Module: venv2.libthon3.12.site-packages.mypy.literals
**File:** `venv2/lib/python3.12/site-packages/mypy/literals.py`

**Imports:**
- __future__.annotations
- mypy.nodes.AssertTypeExpr
- mypy.nodes.AssignmentExpr
- mypy.nodes.AwaitExpr
- mypy.nodes.BytesExpr
- mypy.nodes.CallExpr
- mypy.nodes.CastExpr
- mypy.nodes.ComparisonExpr
- mypy.nodes.ComplexExpr
- mypy.nodes.ConditionalExpr
- mypy.nodes.DictExpr
- mypy.nodes.DictionaryComprehension
- mypy.nodes.EllipsisExpr
- mypy.nodes.EnumCallExpr
- mypy.nodes.Expression
- mypy.nodes.FloatExpr
- mypy.nodes.GeneratorExpr
- mypy.nodes.IndexExpr
- mypy.nodes.IntExpr
- mypy.nodes.LITERAL_NO
- mypy.nodes.LITERAL_TYPE
- mypy.nodes.LITERAL_YES
- mypy.nodes.LambdaExpr
- mypy.nodes.ListComprehension
- mypy.nodes.ListExpr
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.NamedTupleExpr
- mypy.nodes.NewTypeExpr
- mypy.nodes.OpExpr
- mypy.nodes.ParamSpecExpr
- mypy.nodes.PromoteExpr
- mypy.nodes.RevealExpr
- mypy.nodes.SetComprehension
- mypy.nodes.SetExpr
- mypy.nodes.SliceExpr
- mypy.nodes.StarExpr
- mypy.nodes.StrExpr
- mypy.nodes.SuperExpr
- mypy.nodes.TempNode
- mypy.nodes.TupleExpr
- mypy.nodes.TypeAliasExpr
- mypy.nodes.TypeApplication
- mypy.nodes.TypeVarExpr
- mypy.nodes.TypeVarTupleExpr
- mypy.nodes.TypedDictExpr
- mypy.nodes.UnaryExpr
- mypy.nodes.Var
- mypy.nodes.YieldExpr
- mypy.nodes.YieldFromExpr
- mypy.visitor.ExpressionVisitor
- typing.Any
- typing.Final
- typing.Iterable
- typing.Optional
- typing.Tuple
- typing_extensions.TypeAlias

**Functions:**

### `def literal(e: Expression) -> int`

**Line:** 98

---

### `def subkeys(key: Key) -> Iterable[Key]`

**Line:** 134

---

### `def literal_hash(e: Expression) -> Key | None`

**Line:** 138

---

### `def extract_var_from_literal_hash(key: Key) -> Var | None`

**Description:**
If key refers to a Var node, return it.

Return None otherwise.

**Line:** 142

---


## Module: venv2.libthon3.12.site-packages.mypy.lookup
**File:** `venv2/lib/python3.12/site-packages/mypy/lookup.py`

**Imports:**
- __future__.annotations
- mypy.nodes.MypyFile
- mypy.nodes.SymbolTableNode
- mypy.nodes.TypeInfo

**Functions:**

### `def lookup_fully_qualified(name: str, modules: dict[(str, MypyFile)], raise_on_missing: bool = False) -> SymbolTableNode | None`

**Description:**
Find a symbol using it fully qualified name.

The algorithm has two steps: first we try splitting the name on '.' to find
the module, then iteratively look for each next chunk after a '.' (e.g. for
nested classes).

This function should *not* be used to find a module. Those should be looked
in the modules dictionary.

**Line:** 13

---


## Module: venv2.libthon3.12.site-packages.mypy.main
**File:** `venv2/lib/python3.12/site-packages/mypy/main.py`

**Imports:**
- __future__.annotations
- argparse
- gettext.gettext
- mypy.build
- mypy.config_parser.get_config_module_names
- mypy.config_parser.parse_config_file
- mypy.config_parser.parse_version
- mypy.config_parser.validate_package_allow_list
- mypy.defaults
- mypy.errorcodes.error_codes
- mypy.errors.CompileError
- mypy.find_sources.InvalidSourceList
- mypy.find_sources.create_source_list
- mypy.fscache.FileSystemCache
- mypy.memprofile.print_memory_profile
- mypy.modulefinder.BuildSource
- mypy.modulefinder.FindModuleCache
- mypy.modulefinder.SearchPaths
- mypy.modulefinder.get_search_dirs
- mypy.modulefinder.mypy_path
- mypy.options.BuildType
- mypy.options.COMPLETE_FEATURES
- mypy.options.INCOMPLETE_FEATURES
- mypy.options.Options
- mypy.split_namespace.SplitNamespace
- mypy.state
- mypy.util
- mypy.version.__version__
- os
- subprocess
- sys
- time
- typing.Any
- typing.Final
- typing.IO
- typing.NoReturn
- typing.Sequence
- typing.TextIO

**Functions:**

### `def stat_proxy(path: str) -> os.stat_result`

**Line:** 33

---

### `def main(args: list[str] | None = None, stdout: TextIO = sys.stdout, stderr: TextIO = sys.stderr, clean_exit: bool = False) -> None`

**Description:**
Main entry point to the type checker.

Args:
args: Custom command-line arguments.  If not given, sys.argv[1:] will
be used.
clean_exit: Don't hard kill the process on exit. This allows catching
SystemExit.

**Line:** 47

---

### `def run_build(sources: list[BuildSource], options: Options, fscache: FileSystemCache, t0: float, stdout: TextIO, stderr: TextIO) -> tuple[(build.BuildResult | None, list[str], bool)]`

**Line:** 150

---

### `def show_messages(messages: list[str], f: TextIO, formatter: util.FancyFormatter, options: Options) -> None`

**Line:** 207

---

### `def invert_flag_name(flag: str) -> str`

**Line:** 240

---

### `def python_executable_prefix(v: str) -> list[str]`

**Line:** 256

---

### `def _python_executable_from_version(python_version: tuple[(int, int)]) -> str`

**Line:** 267

---

### `def infer_python_executable(options: Options, special_opts: argparse.Namespace) -> None`

**Description:**
Infer the Python executable from the given version.

This function mutates options based on special_opts to infer the correct Python executable
to use.

**Line:** 288

---

### `def process_options(args: list[str], stdout: TextIO | None = None, stderr: TextIO | None = None, require_targets: bool = True, server_options: bool = False, fscache: FileSystemCache | None = None, program: str = 'mypy', header: str = HEADER) -> tuple[(list[BuildSource], Options)]`

**Description:**
Parse command line arguments.

If a FileSystemCache is passed in, and package_root options are given,
call fscache.set_package_root() to set the cache's package root.

**Line:** 434

---

### `def process_package_roots(fscache: FileSystemCache | None, parser: argparse.ArgumentParser, options: Options) -> None`

**Description:**
Validate and normalize package_root.

**Line:** 1427

---

### `def process_cache_map(parser: argparse.ArgumentParser, special_opts: argparse.Namespace, options: Options) -> None`

**Description:**
Validate cache_map and copy into options.cache_map.

**Line:** 1462

---

### `def maybe_write_junit_xml(td: float, serious: bool, messages: list[str], options: Options) -> None`

**Line:** 1486

---

### `def fail(msg: str, stderr: TextIO, options: Options) -> NoReturn`

**Description:**
Fail with a serious error.

**Line:** 1494

---

### `def read_types_packages_to_install(cache_dir: str, after_run: bool) -> list[str]`

**Line:** 1501

---

### `def install_types(formatter: util.FancyFormatter, options: Options, after_run: bool = False, non_interactive: bool = False) -> bool`

**Description:**
Install stub packages using pip if some missing stubs were detected.

**Line:** 1519

---


## Module: venv2.libthon3.12.site-packages.mypy.maptype
**File:** `venv2/lib/python3.12/site-packages/mypy/maptype.py`

**Imports:**
- __future__.annotations
- mypy.expandtype.expand_type_by_instance
- mypy.nodes.TypeInfo
- mypy.typeops
- mypy.types.AnyType
- mypy.types.Instance
- mypy.types.TupleType
- mypy.types.TypeOfAny
- mypy.types.has_type_vars

**Functions:**

### `def map_instance_to_supertype(instance: Instance, superclass: TypeInfo) -> Instance`

**Description:**
Produce a supertype of `instance` that is an Instance
of `superclass`, mapping type arguments up the chain of bases.

If `superclass` is not a nominal superclass of `instance.type`,
then all type arguments are mapped to 'Any'.

**Line:** 8

---

### `def map_instance_to_supertypes(instance: Instance, supertype: TypeInfo) -> list[Instance]`

**Line:** 45

---

### `def class_derivation_paths(typ: TypeInfo, supertype: TypeInfo) -> list[list[TypeInfo]]`

**Description:**
Return an array of non-empty paths of direct base classes from
type to supertype.  Return [] if no such path could be found.

InterfaceImplementationPaths(A, B) == [[B]] if A inherits B
InterfaceImplementationPaths(A, C) == [[B, C]] if A inherits B and
B inherits C

**Line:** 65

---

### `def map_instance_to_direct_supertypes(instance: Instance, supertype: TypeInfo) -> list[Instance]`

**Line:** 89

---


## Module: venv2.libthon3.12.site-packages.mypy.meet
**File:** `venv2/lib/python3.12/site-packages/mypy/meet.py`

**Imports:**
- __future__.annotations
- mypy.erasetype.erase_type
- mypy.join
- mypy.join.join_types
- mypy.join.safe_join
- mypy.maptype.map_instance_to_supertype
- mypy.state.state
- mypy.subtypes.is_callable_compatible
- mypy.subtypes.is_equivalent
- mypy.subtypes.is_proper_subtype
- mypy.subtypes.is_same_type
- mypy.subtypes.is_subtype
- mypy.typeops.is_recursive_pair
- mypy.typeops.make_simplified_union
- mypy.typeops.tuple_fallback
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.ErasedType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.MYPYC_NATIVE_INT_NAMES
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TUPLE_LIKE_INSTANCE_NAMES
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeGuardedType
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypeVisitor
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.find_unpack_in_list
- mypy.types.get_proper_type
- mypy.types.get_proper_types
- mypy.types.split_with_prefix_and_suffix
- typing.Callable

**Functions:**

### `def trivial_meet(s: Type, t: Type) -> ProperType`

**Description:**
Return one of types (expanded) if it is a subtype of other, otherwise bottom type.

**Line:** 57

---

### `def meet_types(s: Type, t: Type) -> ProperType`

**Description:**
Return the greatest lower bound of two types.

**Line:** 70

---

### `def narrow_declared_type(declared: Type, narrowed: Type) -> Type`

**Description:**
Return the declared type narrowed down to another type.

**Line:** 112

---

### `def get_possible_variants(typ: Type) -> list[Type]`

**Description:**
This function takes any "Union-like" type and returns a list of the available "options".

Specifically, there are currently exactly three different types that can have
"variants" or are "union-like":

- Unions
- TypeVars with value restrictions
- Overloads

This function will return a list of each "option" present in those types.

If this function receives any other type, we return a list containing just that
original type. (E.g. pretend the type was contained within a singleton union).

The only current exceptions are regular TypeVars and ParamSpecs. For these "TypeVarLike"s,
we return a list containing that TypeVarLike's upper bound.

This function is useful primarily when checking to see if two types are overlapping:
the algorithm to check if two unions are overlapping is fundamentally the same as
the algorithm for checking if two overloads are overlapping.

Normalizing both kinds of types in the same way lets us reuse the same algorithm
for both.

**Line:** 191

---

### `def is_enum_overlapping_union(x: ProperType, y: ProperType) -> bool`

**Description:**
Return True if x is an Enum, and y is an Union with at least one Literal from x

**Line:** 237

---

### `def is_literal_in_union(x: ProperType, y: ProperType) -> bool`

**Description:**
Return True if x is a Literal and y is an Union that includes x

**Line:** 250

---

### `def is_overlapping_types(left: Type, right: Type, ignore_promotions: bool = False, prohibit_none_typevar_overlap: bool = False, ignore_uninhabited: bool = False, seen_types: set[tuple[Type, Type]] | None = None) -> bool`

**Description:**
Can a value of type 'left' also be of type 'right' or vice-versa?

If 'ignore_promotions' is True, we ignore promotions while checking for overlaps.
If 'prohibit_none_typevar_overlap' is True, we disallow None from overlapping with
TypeVars (in both strict-optional and non-strict-optional mode).

**Line:** 259

---

### `def is_overlapping_erased_types(left: Type, right: Type, ignore_promotions: bool = False) -> bool`

**Description:**
The same as 'is_overlapping_erased_types', except the types are erased first.

**Line:** 554

---

### `def are_typed_dicts_overlapping(left: TypedDictType, right: TypedDictType, ignore_promotions: bool = False, prohibit_none_typevar_overlap: bool = False) -> bool`

**Description:**
Returns 'true' if left and right are overlapping TypeDictTypes.

**Line:** 566

---

### `def are_tuples_overlapping(left: Type, right: Type, ignore_promotions: bool = False, prohibit_none_typevar_overlap: bool = False) -> bool`

**Description:**
Returns true if left and right are overlapping tuples.

**Line:** 601

---

### `def adjust_tuple(left: ProperType, r: ProperType) -> TupleType | None`

**Description:**
Find out if `left` is a Tuple[A, ...], and adjust its length to `right`

**Line:** 627

---

### `def is_tuple(typ: Type) -> bool`

**Line:** 635

---

### `def meet_similar_callables(t: CallableType, s: CallableType) -> CallableType`

**Line:** 1026

---

### `def meet_type_list(types: list[Type]) -> Type`

**Line:** 1047

---

### `def typed_dict_mapping_pair(left: Type, right: Type) -> bool`

**Description:**
Is this a pair where one type is a TypedDict and another one is an instance of Mapping?

This case requires a precise/principled consideration because there are two use cases
that push the boundary the opposite ways: we need to avoid spurious overlaps to avoid
false positives for overloads, but we also need to avoid spuriously non-overlapping types
to avoid false positives with --strict-equality.

**Line:** 1058

---

### `def typed_dict_mapping_overlap(left: Type, right: Type, overlapping: Callable[([Type, Type], bool)]) -> bool`

**Description:**
Check if a TypedDict type is overlapping with a Mapping.

The basic logic here consists of two rules:

* A TypedDict with some required keys is overlapping with Mapping[str, <some type>]
if and only if every key type is overlapping with <some type>. For example:

- TypedDict(x=int, y=str) overlaps with Dict[str, Union[str, int]]
- TypedDict(x=int, y=str) doesn't overlap with Dict[str, int]

Note that any additional non-required keys can't change the above result.

* A TypedDict with no required keys overlaps with Mapping[str, <some type>] if and
only if at least one of key types overlaps with <some type>. For example:

- TypedDict(x=str, y=str, total=False) overlaps with Dict[str, str]
- TypedDict(x=str, y=str, total=False) doesn't overlap with Dict[str, int]
- TypedDict(x=int, y=str, total=False) overlaps with Dict[str, str]

As usual empty, dictionaries lie in a gray area. In general, List[str] and List[str]
are considered non-overlapping despite empty list belongs to both. However, List[int]
and List[Never] are considered overlapping.

So here we follow the same logic: a TypedDict with no required keys is considered
non-overlapping with Mapping[str, <some type>], but is considered overlapping with
Mapping[Never, Never]. This way we avoid false positives for overloads, and also
avoid false positives for comparisons like SomeTypedDict == {} under --strict-equality.

**Line:** 1078

---


## Module: venv2.libthon3.12.site-packages.mypy.memprofile
**File:** `venv2/lib/python3.12/site-packages/mypy/memprofile.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- gc
- mypy.nodes.FakeInfo
- mypy.nodes.Node
- mypy.types.Type
- mypy.util.get_class_descriptors
- resource
- sys
- typing.Dict
- typing.Iterable
- typing.cast

**Functions:**

### `def collect_memory_stats() -> tuple[(dict[str, int], dict[str, int])]`

**Description:**
Return stats about memory use.

Return a tuple with these items:
- Dict from object kind to number of instances of that kind
- Dict from object kind to total bytes used by all instances of that kind

**Line:** 19

---

### `def print_memory_profile(run_gc: bool = True) -> None`

**Line:** 68

---

### `def find_recursive_objects(objs: list[object]) -> None`

**Description:**
Find additional objects referenced by objs and append them to objs.

We use this since gc.get_objects() does not return objects without pointers
in them such as strings.

**Line:** 93

---


## Module: venv2.libthon3.12.site-packages.mypy.messages
**File:** `venv2/lib/python3.12/site-packages/mypy/messages.py`

**Imports:**
- __future__.annotations
- contextlib.contextmanager
- difflib
- itertools
- mypy.erasetype.erase_type
- mypy.errorcodes
- mypy.errorcodes.ErrorCode
- mypy.errors.ErrorInfo
- mypy.errors.ErrorWatcher
- mypy.errors.Errors
- mypy.message_registry
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_NAMED_OPT
- mypy.nodes.ARG_OPT
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.ArgKind
- mypy.nodes.CONTRAVARIANT
- mypy.nodes.COVARIANT
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.Context
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.IndexExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.ReturnStmt
- mypy.nodes.SYMBOL_FUNCBASE_TYPES
- mypy.nodes.StrExpr
- mypy.nodes.SymbolNode
- mypy.nodes.SymbolTable
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.nodes.reverse_builtin_aliases
- mypy.operators.op_methods
- mypy.operators.op_methods_to_symbols
- mypy.options.Options
- mypy.subtypes.IS_CLASSVAR
- mypy.subtypes.IS_CLASS_OR_STATIC
- mypy.subtypes.IS_SETTABLE
- mypy.subtypes.IS_VAR
- mypy.subtypes.find_member
- mypy.subtypes.get_member_flags
- mypy.subtypes.is_same_type
- mypy.subtypes.is_subtype
- mypy.typeops
- mypy.typeops.separate_union_literals
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeOfAny
- mypy.types.TypeStrVisitor
- mypy.types.TypeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.get_proper_type
- mypy.types.get_proper_types
- mypy.typetraverser.TypeTraverserVisitor
- mypy.util.plural_s
- mypy.util.unmangle
- re
- textwrap.dedent
- typing.Any
- typing.Callable
- typing.Collection
- typing.Final
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Sequence
- typing.cast

**Functions:**

### `def quote_type_string(type_string: str) -> str`

**Description:**
Quotes a type representation for use in messages.

**Line:** 2404

---

### `def format_callable_args(arg_types: list[Type], arg_kinds: list[ArgKind], arg_names: list[str | None], format: Callable[([Type], str)], verbosity: int) -> str`

**Description:**
Format a bunch of Callable arguments into a string

**Line:** 2419

---

### `def format_type_inner(typ: Type, verbosity: int, options: Options, fullnames: set[str] | None, module_names: bool = False) -> str`

**Description:**
Convert a type to a relatively short string suitable for error messages.

Args:
verbosity: a coarse grained control on the verbosity of the type
fullnames: a set of names that should be printed in full

**Line:** 2441

---

### `def collect_all_instances(t: Type) -> list[Instance]`

**Description:**
Return all instances that `t` contains (including `t`).

This is similar to collect_all_inner_types from typeanal but only
returns instances and will recurse into fallbacks.

**Line:** 2655

---

### `def find_type_overlaps(*types: Type) -> set[str]`

**Description:**
Return a set of fullnames that share a short name and appear in either type.

This is used to ensure that distinct types with the same short name are printed
with their fullname.

**Line:** 2680

---

### `def format_type(typ: Type, options: Options, verbosity: int = 0, module_names: bool = False) -> str`

**Description:**
Convert a type to a relatively short string suitable for error messages.

`verbosity` is a coarse grained control on the verbosity of the type

This function returns a string appropriate for unmodified use in error
messages; this means that it will be quoted in most cases.  If
modification of the formatted string is required, callers should use
format_type_bare.

**Line:** 2701

---

### `def format_type_bare(typ: Type, options: Options, verbosity: int = 0, module_names: bool = False) -> str`

**Description:**
Convert a type to a relatively short string suitable for error messages.

`verbosity` is a coarse grained control on the verbosity of the type
`fullnames` specifies a set of names that should be printed in full

This function will return an unquoted string.  If a caller doesn't need to
perform post-processing on the string output, format_type should be used
instead.  (The caller may want to use quote_type_string after
processing has happened, to maintain consistent quoting in messages.)

**Line:** 2717

---

### `def format_type_distinctly(options: Options, bare: bool = False, *types: Type) -> tuple[(str, ...)]`

**Description:**
Jointly format types to distinct strings.

Increase the verbosity of the type strings until they become distinct
while also requiring that distinct types with the same short name are
formatted distinctly.

By default, the returned strings are created using format_type() and will be
quoted accordingly. If ``bare`` is True, the returned strings will not
be quoted; callers who need to do post-processing of the strings before
quoting them (such as prepending * or **) should use this.

**Line:** 2734

---

### `def pretty_class_or_static_decorator(tp: CallableType) -> str | None`

**Description:**
Return @classmethod or @staticmethod, if any, for the given callable type.

**Line:** 2760

---

### `def pretty_callable(tp: CallableType, options: Options, skip_self: bool = False) -> str`

**Description:**
Return a nice easily-readable representation of a callable type.
For example:
def [T <: int] f(self, x: int, y: T) -> None

If skip_self is True, print an actual callable type, as it would appear
when bound on an instance/class, rather than how it would appear in the
defining statement.

**Line:** 2770

---

### `def variance_string(variance: int) -> str`

**Line:** 2872

---

### `def get_missing_protocol_members(left: Instance, right: Instance, skip: list[str]) -> list[str]`

**Description:**
Find all protocol members of 'right' that are not implemented
(i.e. completely missing) in 'left'.

**Line:** 2881

---

### `def get_conflict_protocol_types(left: Instance, right: Instance, class_obj: bool = False, options: Options | None = None) -> list[tuple[(str, Type, Type)]]`

**Description:**
Find members that are defined in 'left' but have incompatible types.
Return them as a list of ('member', 'got', 'expected').

**Line:** 2895

---

### `def get_bad_protocol_flags(left: Instance, right: Instance, class_obj: bool = False) -> list[tuple[(str, set[int], set[int])]]`

**Description:**
Return all incompatible attribute flags for members that are present in both
'left' and 'right'.

**Line:** 2919

---

### `def capitalize(s: str) -> str`

**Description:**
Capitalize the first character of a string.

**Line:** 2953

---

### `def extract_type(name: str) -> str`

**Description:**
If the argument is the name of a method (of form C.m), return
the type portion in quotes (e.g. "y"). Otherwise, return the string
unmodified.

**Line:** 2961

---

### `def strip_quotes(s: str) -> str`

**Description:**
Strip a double quote at the beginning and end of the string, if any.

**Line:** 2970

---

### `def format_string_list(lst: list[str]) -> str`

**Line:** 2977

---

### `def format_item_name_list(s: Iterable[str]) -> str`

**Line:** 2991

---

### `def callable_name(type: FunctionLike) -> str | None`

**Line:** 2999

---

### `def for_function(callee: CallableType) -> str`

**Line:** 3006

---

### `def wrong_type_arg_count(n: int, act: str, name: str) -> str`

**Line:** 3013

---

### `def find_defining_module(modules: dict[(str, MypyFile)], typ: CallableType) -> MypyFile | None`

**Line:** 3024

---

### `def _real_quick_ratio(a: str, b: str) -> float`

**Line:** 3043

---

### `def best_matches(current: str, options: Collection[str], n: int) -> list[str]`

**Line:** 3051

---

### `def pretty_seq(args: Sequence[str], conjunction: str) -> str`

**Line:** 3064

---

### `def append_invariance_notes(notes: list[str], arg_type: Instance, expected_type: Instance) -> list[str]`

**Description:**
Explain that the type is invariant and give notes for how to solve the issue.

**Line:** 3074

---

### `def append_numbers_notes(notes: list[str], arg_type: Instance, expected_type: Instance) -> list[str]`

**Description:**
Explain if an unsupported type from "numbers" is used in a subtype check.

**Line:** 3106

---

### `def make_inferred_type_note(context: Context, subtype: Type, supertype: Type, supertype_str: str) -> str`

**Description:**
Explain that the user may have forgotten to type a variable.

The user does not expect an error if the inferred container type is the same as the return
type of a function and the argument type(s) are a subtype of the argument type(s) of the
return type. This note suggests that they add a type annotation with the return type instead
of relying on the inferred type.

**Line:** 3117

---

### `def format_key_list(keys: list[str], short: bool = False) -> str`

**Line:** 3150

---


## Module: venv2.libthon3.12.site-packages.mypy.metastore
**File:** `venv2/lib/python3.12/site-packages/mypy/metastore.py`

**Imports:**
- __future__.annotations
- abc.abstractmethod
- binascii
- os
- sqlite3
- sqlite3.dbapi2
- time
- typing.Any
- typing.Iterable
- typing.TYPE_CHECKING

**Functions:**

### `def random_string() -> str`

**Line:** 70

---

### `def connect_db(db_file: str) -> sqlite3.Connection`

**Line:** 150

---


## Module: venv2.libthon3.12.site-packages.mypy.modulefinder
**File:** `venv2/lib/python3.12/site-packages/mypy/modulefinder.py`

**Imports:**
- __future__.annotations
- ast
- collections
- enum.Enum
- enum.unique
- functools
- mypy.errors.CompileError
- mypy.fscache.FileSystemCache
- mypy.nodes.MypyFile
- mypy.options.Options
- mypy.pyinfo
- mypy.stubinfo.approved_stub_package_exists
- os
- re
- subprocess
- sys
- tomli
- tomllib
- typing.Dict
- typing.Final
- typing.List
- typing.NamedTuple
- typing.Optional
- typing.Tuple
- typing.Union
- typing_extensions.TypeAlias

**Functions:**

### `def matches_exclude(subpath: str, excludes: list[str], fscache: FileSystemCache, verbose: bool) -> bool`

**Line:** 630

---

### `def is_init_file(path: str) -> bool`

**Line:** 648

---

### `def verify_module(fscache: FileSystemCache, id: str, path: str, prefix: str) -> bool`

**Description:**
Check that all packages containing id have a __init__ file.

**Line:** 652

---

### `def highest_init_level(fscache: FileSystemCache, id: str, path: str, prefix: str) -> int`

**Description:**
Compute the highest level where an __init__ file is found.

**Line:** 666

---

### `def mypy_path() -> list[str]`

**Line:** 681

---

### `def default_lib_path(data_dir: str, pyversion: tuple[(int, int)], custom_typeshed_dir: str | None) -> list[str]`

**Description:**
Return default standard library search paths.

**Line:** 688

---

### `def get_search_dirs(python_executable: str | None) -> tuple[(list[str], list[str])]`

**Decorators:**
- `@functools.lru_cache(...)`

**Description:**
Find package directories for given python.

This runs a subprocess call, which generates a list of the directories in sys.path.
To avoid repeatedly calling a subprocess (which can be slow!) we
lru_cache the results.

**Line:** 733

---

### `def compute_search_paths(sources: list[BuildSource], options: Options, data_dir: str, alt_lib_path: str | None = None) -> SearchPaths`

**Description:**
Compute the search paths as specified in PEP 561.

There are the following 4 members created:
- User code (from `sources`)
- MYPYPATH (set either via config or environment variable)
- installed package directories (which will later be split into stub-only and inline)
- typeshed

**Line:** 770

---

### `def load_stdlib_py_versions(custom_typeshed_dir: str | None) -> StdlibVersions`

**Description:**
Return dict with minimum and maximum Python versions of stdlib modules.

The contents look like
{..., 'secrets': ((3, 6), None), 'symbol': ((2, 7), (3, 9)), ...}

None means there is no maximum version.

**Line:** 857

---

### `def parse_version(version: str) -> tuple[(int, int)]`

**Line:** 886

---

### `def typeshed_py_version(options: Options) -> tuple[(int, int)]`

**Description:**
Return Python version used for checking whether module supports typeshed.

**Line:** 891

---


## Module: venv2.libthon3.12.site-packages.mypy.moduleinspect
**File:** `venv2/lib/python3.12/site-packages/mypy/moduleinspect.py`

**Imports:**
- __future__.annotations
- importlib
- inspect
- multiprocessing.Process
- multiprocessing.Queue
- os
- pkgutil
- queue
- sys
- types.ModuleType

**Functions:**

### `def is_c_module(module: ModuleType) -> bool`

**Line:** 34

---

### `def is_pyc_only(file: str | None) -> bool`

**Line:** 42

---

### `def get_package_properties(package_id: str) -> ModuleProperties`

**Description:**
Use runtime introspection to get information about a module/package.

**Line:** 50

---

### `def worker(tasks: Queue[str], results: Queue[str | ModuleProperties], sys_path: list[str]) -> None`

**Description:**
The main loop of a worker introspection process.

**Line:** 93

---


## Module: venv2.libthon3.12.site-packages.mypy.mro
**File:** `venv2/lib/python3.12/site-packages/mypy/mro.py`

**Imports:**
- __future__.annotations
- mypy.nodes.TypeInfo
- mypy.types.Instance
- mypy.typestate.type_state
- typing.Callable

**Functions:**

### `def calculate_mro(info: TypeInfo, obj_type: Callable[[], Instance] | None = None) -> None`

**Description:**
Calculate and set mro (method resolution order).

Raise MroError if cannot determine mro.

**Line:** 10

---

### `def linearize_hierarchy(info: TypeInfo, obj_type: Callable[[], Instance] | None = None) -> list[TypeInfo]`

**Line:** 27

---

### `def merge(seqs: list[list[TypeInfo]]) -> list[TypeInfo]`

**Line:** 46

---


## Module: venv2.libthon3.12.site-packages.mypy.nodes
**File:** `venv2/lib/python3.12/site-packages/mypy/nodes.py`

**Imports:**
- __future__.annotations
- abc.abstractmethod
- collections.defaultdict
- enum.Enum
- enum.unique
- mypy.options.Options
- mypy.patterns.Pattern
- mypy.strconv
- mypy.types
- mypy.util.is_typeshed_file
- mypy.util.short_type
- mypy.visitor.ExpressionVisitor
- mypy.visitor.NodeVisitor
- mypy.visitor.StatementVisitor
- mypy_extensions.trait
- os
- typing.Any
- typing.Callable
- typing.Dict
- typing.Final
- typing.Iterator
- typing.List
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.cast
- typing_extensions.TypeAlias
- typing_extensions.TypeGuard

**Functions:**

### `def get_nongen_builtins(python_version: tuple[(int, int)]) -> dict[(str, str)]`

**Line:** 166

---

### `def is_StrExpr_list(seq: list[Expression]) -> TypeGuard[list[StrExpr]]`

**Line:** 1651

---

### `def get_flags(node: Node, names: list[str]) -> list[str]`

**Line:** 3989

---

### `def set_flags(node: Node, flags: list[str]) -> None`

**Line:** 3993

---

### `def get_member_expr_fullname(expr: MemberExpr) -> str | None`

**Description:**
Return the qualified name representation of a member expression.

Return a string of form foo.bar, foo.bar.baz, or similar, or None if the
argument cannot be represented in this form.

**Line:** 3998

---

### `def check_arg_kinds(arg_kinds: list[ArgKind], nodes: list[T], fail: Callable[([str, T], None)]) -> None`

**Line:** 4024

---

### `def check_arg_names(names: Sequence[str | None], nodes: list[T], fail: Callable[([str, T], None)], description: str = 'function definition') -> None`

**Line:** 4061

---

### `def is_class_var(expr: NameExpr) -> bool`

**Description:**
Return whether the expression is ClassVar[...]

**Line:** 4075

---

### `def is_final_node(node: SymbolNode | None) -> bool`

**Description:**
Check whether `node` corresponds to a final attribute.

**Line:** 4082

---

### `def local_definitions(names: SymbolTable, name_prefix: str, info: TypeInfo | None = None) -> Iterator[Definition]`

**Description:**
Iterate over local definitions (not imported) in a symbol table.

Recursively iterate over class members and nested classes.

**Line:** 4087

---


## Module: venv2.libthon3.12.site-packages.mypy.parse
**File:** `venv2/lib/python3.12/site-packages/mypy/parse.py`

**Imports:**
- __future__.annotations
- mypy.errors.Errors
- mypy.fastparse
- mypy.nodes.MypyFile
- mypy.options.Options

**Functions:**

### `def parse(source: str | bytes, fnam: str, module: str | None, errors: Errors | None, options: Options) -> MypyFile`

**Description:**
Parse a source file, without doing any semantic analysis.

Return the parse tree. If errors is not provided, raise ParseError
on failure. Otherwise, use the errors object to report parse errors.

The python_version (major, minor) option determines the Python syntax variant.

**Line:** 8

---


## Module: venv2.libthon3.12.site-packages.mypy.plugins.attrs
**File:** `venv2/lib/python3.12/site-packages/mypy/plugins/attrs.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- functools.reduce
- mypy.applytype.apply_generic_arguments
- mypy.checkmember.type_object_type
- mypy.errorcodes.LITERAL_REQ
- mypy.expandtype.expand_type
- mypy.expandtype.expand_type_by_instance
- mypy.exprtotype.TypeTranslationError
- mypy.exprtotype.expr_to_unanalyzed_type
- mypy.meet.meet_types
- mypy.messages.format_type_bare
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_NAMED_OPT
- mypy.nodes.ARG_OPT
- mypy.nodes.ARG_POS
- mypy.nodes.Argument
- mypy.nodes.AssignmentStmt
- mypy.nodes.CallExpr
- mypy.nodes.Context
- mypy.nodes.Decorator
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.IndexExpr
- mypy.nodes.JsonDict
- mypy.nodes.LambdaExpr
- mypy.nodes.ListExpr
- mypy.nodes.MDEF
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.PlaceholderNode
- mypy.nodes.RefExpr
- mypy.nodes.SymbolTableNode
- mypy.nodes.TempNode
- mypy.nodes.TupleExpr
- mypy.nodes.TypeApplication
- mypy.nodes.TypeInfo
- mypy.nodes.TypeVarExpr
- mypy.nodes.Var
- mypy.nodes.is_class_var
- mypy.plugin
- mypy.plugin.SemanticAnalyzerPluginInterface
- mypy.plugins.common._get_argument
- mypy.plugins.common._get_bool_argument
- mypy.plugins.common._get_decorator_bool_argument
- mypy.plugins.common.add_attribute_to_class
- mypy.plugins.common.add_method_to_class
- mypy.plugins.common.deserialize_and_fixup_type
- mypy.server.trigger.make_wildcard_trigger
- mypy.typeops.get_type_vars
- mypy.typeops.make_simplified_union
- mypy.typeops.map_type_from_supertype
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.TypeVarType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.get_proper_type
- mypy.typevars.fill_typevars
- mypy.util.unmangle
- typing.Final
- typing.Iterable
- typing.List
- typing.Mapping
- typing.cast
- typing_extensions.Literal

**Functions:**

### `def _determine_eq_order(ctx: mypy.plugin.ClassDefContext) -> bool`

**Description:**
Validate the combination of *cmp*, *eq*, and *order*. Derive the effective
value of order.

**Line:** 226

---

### `def _get_decorator_optional_bool_argument(ctx: mypy.plugin.ClassDefContext, name: str, default: bool | None = None) -> bool | None`

**Description:**
Return the Optional[bool] argument for the decorator.

This handles both @decorator(...) and @decorator.

**Line:** 255

---

### `def attr_tag_callback(ctx: mypy.plugin.ClassDefContext) -> None`

**Description:**
Record that we have an attrs class in the main semantic analysis pass.

The later pass implemented by attr_class_maker_callback will use this
to detect attrs classes in base classes.

**Line:** 283

---

### `def attr_class_maker_callback(ctx: mypy.plugin.ClassDefContext, auto_attribs_default: bool | None = False, frozen_default: bool = False, slots_default: bool = False) -> bool`

**Description:**
Add necessary dunder methods to classes decorated with attr.s.

attrs is a package that lets you define classes without writing dull boilerplate code.

At a quick glance, the decorator searches the class body for assignments of `attr.ib`s (or
annotated variables if auto_attribs=True), then depending on how the decorator is called,
it will add an __init__ or all the compare methods.
For frozen=True it will turn the attrs into properties.

See https://www.attrs.org/en/stable/how-does-it-work.html for information on how attrs works.

If this returns False, some required metadata was not ready yet and we need another
pass.

**Line:** 293

---

### `def _get_frozen(ctx: mypy.plugin.ClassDefContext, frozen_default: bool) -> bool`

**Description:**
Return whether this class is frozen.

**Line:** 365

---

### `def _analyze_class(ctx: mypy.plugin.ClassDefContext, auto_attribs: bool | None, kw_only: bool) -> list[Attribute]`

**Description:**
Analyze the class body of an attr maker, its parents, and return the Attributes found.

auto_attribs=True means we'll generate attributes from type annotations also.
auto_attribs=None means we'll detect which mode to use.
kw_only=True means that all attributes created here will be keyword only args in __init__.

**Line:** 376

---

### `def _add_empty_metadata(info: TypeInfo) -> None`

**Description:**
Add empty metadata to mark that we've finished processing this class.

**Line:** 455

---

### `def _detect_auto_attribs(ctx: mypy.plugin.ClassDefContext) -> bool`

**Description:**
Return whether auto_attribs should be enabled or disabled.

It's disabled if there are any unannotated attribs()

**Line:** 460

---

### `def _attributes_from_assignment(ctx: mypy.plugin.ClassDefContext, stmt: AssignmentStmt, auto_attribs: bool, kw_only: bool) -> Iterable[Attribute]`

**Description:**
Return Attribute objects that are created by this assignment.

The assignments can look like this:
x = attr.ib()
x = y = attr.ib()
x, y = attr.ib(), attr.ib()
or if auto_attribs is enabled also like this:
x: type
x: type = default_value

**Line:** 489

---

### `def _cleanup_decorator(stmt: Decorator, attr_map: dict[(str, Attribute)]) -> None`

**Description:**
Handle decorators in class bodies.

`x.default` will set a default value on x
`x.validator` and `x.default` will get removed to avoid throwing a type error.

**Line:** 524

---

### `def _attribute_from_auto_attrib(ctx: mypy.plugin.ClassDefContext, kw_only: bool, lhs: NameExpr, rvalue: Expression, stmt: AssignmentStmt) -> Attribute`

**Description:**
Return an Attribute for a new type assignment.

**Line:** 554

---

### `def _attribute_from_attrib_maker(ctx: mypy.plugin.ClassDefContext, auto_attribs: bool, kw_only: bool, lhs: NameExpr, rvalue: CallExpr, stmt: AssignmentStmt) -> Attribute | None`

**Description:**
Return an Attribute from the assignment or None if you can't make one.

**Line:** 570

---

### `def _parse_converter(ctx: mypy.plugin.ClassDefContext, converter_expr: Expression | None) -> Converter | None`

**Description:**
Return the Converter object from an Expression.

**Line:** 637

---

### `def is_valid_overloaded_converter(defn: OverloadedFuncDef) -> bool`

**Line:** 737

---

### `def _parse_assignments(lvalue: Expression, stmt: AssignmentStmt) -> tuple[(list[NameExpr], list[Expression])]`

**Description:**
Convert a possibly complex assignment expression into lists of lvalues and rvalues.

**Line:** 744

---

### `def _add_order(ctx: mypy.plugin.ClassDefContext, adder: MethodAdder) -> None`

**Description:**
Generate all the ordering methods for this class.

**Line:** 761

---

### `def _make_frozen(ctx: mypy.plugin.ClassDefContext, attributes: list[Attribute]) -> None`

**Description:**
Turn all the attributes into properties to simulate frozen classes.

**Line:** 791

---

### `def _add_init(ctx: mypy.plugin.ClassDefContext, attributes: list[Attribute], adder: MethodAdder, method_name: Literal[('__init__', '__attrs_init__')]) -> None`

**Description:**
Generate an __init__ method for the attributes and add it to the class.

**Line:** 813

---

### `def _add_attrs_magic_attribute(ctx: mypy.plugin.ClassDefContext, attrs: list[tuple[(str, Type | None)]]) -> None`

**Line:** 856

---

### `def _add_slots(ctx: mypy.plugin.ClassDefContext, attributes: list[Attribute]) -> None`

**Line:** 895

---

### `def _add_match_args(ctx: mypy.plugin.ClassDefContext, attributes: list[Attribute]) -> None`

**Line:** 912

---

### `def _get_attrs_init_type(typ: Instance) -> CallableType | None`

**Description:**
If `typ` refers to an attrs class, get the type of its initializer method.

**Line:** 960

---

### `def _fail_not_attrs_class(ctx: mypy.plugin.FunctionSigContext, t: Type, parent_t: Type) -> None`

**Line:** 973

---

### `def _get_expanded_attr_types(ctx: mypy.plugin.FunctionSigContext, typ: ProperType, display_typ: ProperType, parent_typ: ProperType) -> list[Mapping[str, Type]] | None`

**Description:**
For a given type, determine what attrs classes it can be: for each class, return the field types.
For generic classes, the field types are expanded.
If the type contains Any or a non-attrs type, returns None; in the latter case, also reports an error.

**Line:** 992

---

### `def _meet_fields(types: list[Mapping[(str, Type)]]) -> Mapping[(str, Type)]`

**Description:**
"Meet" the fields of a list of attrs classes, i.e. for each field, its new type will be the lower bound.

**Line:** 1034

---

### `def evolve_function_sig_callback(ctx: mypy.plugin.FunctionSigContext) -> CallableType`

**Description:**
Generate a signature for the 'attr.evolve' function that's specific to the call site
and dependent on the type of the first argument.

**Line:** 1051

---

### `def fields_function_sig_callback(ctx: mypy.plugin.FunctionSigContext) -> CallableType`

**Description:**
Provide the signature for `attrs.fields`.

**Line:** 1083

---


## Module: venv2.libthon3.12.site-packages.mypy.plugins.common
**File:** `venv2/lib/python3.12/site-packages/mypy/plugins/common.py`

**Imports:**
- __future__.annotations
- mypy.argmap.map_actuals_to_formals
- mypy.fixup.TypeFixer
- mypy.nodes.ARG_POS
- mypy.nodes.Argument
- mypy.nodes.Block
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.Decorator
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.JsonDict
- mypy.nodes.MDEF
- mypy.nodes.NameExpr
- mypy.nodes.Node
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.PassStmt
- mypy.nodes.RefExpr
- mypy.nodes.SYMBOL_FUNCBASE_TYPES
- mypy.nodes.SymbolTableNode
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.plugin.CheckerPluginInterface
- mypy.plugin.ClassDefContext
- mypy.plugin.SemanticAnalyzerPluginInterface
- mypy.semanal_shared.ALLOW_INCOMPATIBLE_OVERRIDE
- mypy.semanal_shared.parse_bool
- mypy.semanal_shared.require_bool_literal_argument
- mypy.semanal_shared.set_callable_name
- mypy.typeops.try_getting_str_literals
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.TypeVarType
- mypy.types.deserialize_type
- mypy.types.get_proper_type
- mypy.types_utils.is_overlapping_none
- mypy.typevars.fill_typevars
- mypy.util.get_unique_redefinition_name
- typing.NamedTuple

**Functions:**

### `def _get_decorator_bool_argument(ctx: ClassDefContext, name: str, default: bool) -> bool`

**Description:**
Return the bool argument for the decorator.

This handles both @decorator(...) and @decorator.

**Line:** 55

---

### `def _get_bool_argument(ctx: ClassDefContext, expr: CallExpr, name: str, default: bool) -> bool`

**Description:**
Return the boolean value for an argument to a call or the
default if it's not found.

**Line:** 66

---

### `def _get_argument(call: CallExpr, name: str) -> Expression | None`

**Description:**
Return the expression for the specific argument.

**Line:** 76

---

### `def find_shallow_matching_overload_item(overload: Overloaded, call: CallExpr) -> CallableType`

**Description:**
Perform limited lookup of a matching overload item.

Full overload resolution is only supported during type checking, but plugins
sometimes need to resolve overloads. This can be used in some such use cases.

Resolve overloads based on these things only:

* Match using argument kinds and names
* If formal argument has type None, only accept the "None" expression in the callee
* If formal argument has type Literal[True] or Literal[False], only accept the
relevant bool literal

Return the first matching overload item, or the last one if nothing matches.

**Line:** 101

---

### `def _get_callee_type(call: CallExpr) -> CallableType | None`

**Description:**
Return the type of the callee, regardless of its syntatic form.

**Line:** 166

---

### `def add_method(ctx: ClassDefContext, name: str, args: list[Argument], return_type: Type, self_type: Type | None = None, tvar_def: TypeVarType | None = None, is_classmethod: bool = False, is_staticmethod: bool = False) -> None`

**Description:**
Adds a new method to a class.
Deprecated, use add_method_to_class() instead.

**Line:** 189

---

### `def add_method_to_class(api: SemanticAnalyzerPluginInterface | CheckerPluginInterface, cls: ClassDef, name: str, args: list[Argument], return_type: Type, self_type: Type | None = None, tvar_def: list[TypeVarType] | TypeVarType | None = None, is_classmethod: bool = False, is_staticmethod: bool = False) -> FuncDef | Decorator`

**Description:**
Adds a new method to a class definition.

**Line:** 225

---

### `def add_overloaded_method_to_class(api: SemanticAnalyzerPluginInterface | CheckerPluginInterface, cls: ClassDef, name: str, items: list[MethodSpec], is_classmethod: bool = False, is_staticmethod: bool = False) -> OverloadedFuncDef`

**Description:**
Adds a new overloaded method to a class definition.

**Line:** 256

---

### `def _prepare_class_namespace(cls: ClassDef, name: str) -> None`

**Line:** 306

---

### `def _add_method_by_spec(api: SemanticAnalyzerPluginInterface | CheckerPluginInterface, info: TypeInfo, name: str, spec: MethodSpec, is_classmethod: bool, is_staticmethod: bool) -> tuple[(FuncDef | Decorator, SymbolTableNode)]`

**Line:** 325

---

### `def add_attribute_to_class(api: SemanticAnalyzerPluginInterface, cls: ClassDef, name: str, typ: Type, final: bool = False, no_serialize: bool = False, override_allow_incompatible: bool = False, fullname: str | None = None, is_classvar: bool = False) -> Var`

**Description:**
Adds a new attribute to a class definition.
This currently only generates the symbol table entry and no corresponding AssignmentStatement

**Line:** 392

---

### `def deserialize_and_fixup_type(data: str | JsonDict, api: SemanticAnalyzerPluginInterface) -> Type`

**Line:** 436

---


## Module: venv2.libthon3.12.site-packages.mypy.plugins.ctypes
**File:** `venv2/lib/python3.12/site-packages/mypy/plugins/ctypes.py`

**Imports:**
- __future__.annotations
- mypy.maptype.map_instance_to_supertype
- mypy.messages.format_type
- mypy.nodes
- mypy.plugin
- mypy.subtypes.is_subtype
- mypy.typeops.make_simplified_union
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.NoneType
- mypy.types.ProperType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.UnionType
- mypy.types.flatten_nested_unions
- mypy.types.get_proper_type

**Functions:**

### `def _find_simplecdata_base_arg(tp: Instance, api: mypy.plugin.CheckerPluginInterface) -> ProperType | None`

**Description:**
Try to find a parametrized _SimpleCData in tp's bases and return its single type argument.

None is returned if _SimpleCData appears nowhere in tp's (direct or indirect) bases.

**Line:** 26

---

### `def _autoconvertible_to_cdata(tp: Type, api: mypy.plugin.CheckerPluginInterface) -> Type`

**Description:**
Get a type that is compatible with all types that can be implicitly converted to the given
CData type.

Examples:
* c_int -> Union[c_int, int]
* c_char_p -> Union[c_char_p, bytes, int, NoneType]
* MyStructure -> MyStructure

**Line:** 43

---

### `def _autounboxed_cdata(tp: Type) -> ProperType`

**Description:**
Get the auto-unboxed version of a CData type, if applicable.

For *direct* _SimpleCData subclasses, the only type argument of _SimpleCData in the bases list
is returned.
For all other CData types, including indirect _SimpleCData subclasses, tp is returned as-is.

**Line:** 78

---

### `def _get_array_element_type(tp: Type) -> ProperType | None`

**Description:**
Get the element type of the Array type tp, or None if not specified.

**Line:** 101

---

### `def array_constructor_callback(ctx: mypy.plugin.FunctionContext) -> Type`

**Description:**
Callback to provide an accurate signature for the ctypes.Array constructor.

**Line:** 111

---

### `def array_getitem_callback(ctx: mypy.plugin.MethodContext) -> Type`

**Description:**
Callback to provide an accurate return type for ctypes.Array.__getitem__.

**Line:** 149

---

### `def array_setitem_callback(ctx: mypy.plugin.MethodSigContext) -> CallableType`

**Description:**
Callback to provide an accurate signature for ctypes.Array.__setitem__.

**Line:** 169

---

### `def array_iter_callback(ctx: mypy.plugin.MethodContext) -> Type`

**Description:**
Callback to provide an accurate return type for ctypes.Array.__iter__.

**Line:** 191

---

### `def array_value_callback(ctx: mypy.plugin.AttributeContext) -> Type`

**Description:**
Callback to provide an accurate type for ctypes.Array.value.

**Line:** 200

---

### `def array_raw_callback(ctx: mypy.plugin.AttributeContext) -> Type`

**Description:**
Callback to provide an accurate type for ctypes.Array.raw.

**Line:** 225

---


## Module: venv2.libthon3.12.site-packages.mypy.plugins.dataclasses
**File:** `venv2/lib/python3.12/site-packages/mypy/plugins/dataclasses.py`

**Imports:**
- __future__.annotations
- mypy.checker.TypeChecker
- mypy.errorcodes
- mypy.expandtype.expand_type
- mypy.expandtype.expand_type_by_instance
- mypy.meet.meet_types
- mypy.message_registry
- mypy.messages.format_type_bare
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_NAMED_OPT
- mypy.nodes.ARG_OPT
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.Argument
- mypy.nodes.AssignmentStmt
- mypy.nodes.Block
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.Context
- mypy.nodes.DataclassTransformSpec
- mypy.nodes.Decorator
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.FuncItem
- mypy.nodes.IfStmt
- mypy.nodes.JsonDict
- mypy.nodes.MDEF
- mypy.nodes.NameExpr
- mypy.nodes.Node
- mypy.nodes.PlaceholderNode
- mypy.nodes.RefExpr
- mypy.nodes.Statement
- mypy.nodes.SymbolTableNode
- mypy.nodes.TempNode
- mypy.nodes.TypeAlias
- mypy.nodes.TypeInfo
- mypy.nodes.TypeVarExpr
- mypy.nodes.Var
- mypy.plugin.ClassDefContext
- mypy.plugin.FunctionSigContext
- mypy.plugin.SemanticAnalyzerPluginInterface
- mypy.plugins.common._get_callee_type
- mypy.plugins.common._get_decorator_bool_argument
- mypy.plugins.common.add_attribute_to_class
- mypy.plugins.common.add_method_to_class
- mypy.plugins.common.deserialize_and_fixup_type
- mypy.semanal_shared.find_dataclass_transform_spec
- mypy.semanal_shared.require_bool_literal_argument
- mypy.server.trigger.make_wildcard_trigger
- mypy.state.state
- mypy.typeops.map_type_from_supertype
- mypy.typeops.try_getting_literals_from_type
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeVarType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.get_proper_type
- mypy.typevars.fill_typevars
- typing.Final
- typing.Iterator
- typing.Literal
- typing.TYPE_CHECKING

**Functions:**

### `def add_dataclass_tag(info: TypeInfo) -> None`

**Line:** 921

---

### `def dataclass_tag_callback(ctx: ClassDefContext) -> None`

**Description:**
Record that we have a dataclass in the main semantic analysis pass.

The later pass implemented by DataclassTransformer will use this
to detect dataclasses in base classes.

**Line:** 926

---

### `def dataclass_class_maker_callback(ctx: ClassDefContext) -> bool`

**Description:**
Hooks into the class typechecking process to add support for dataclasses.

**Line:** 935

---

### `def _get_transform_spec(reason: Expression) -> DataclassTransformSpec`

**Description:**
Find the relevant transform parameters from the decorator/parent class/metaclass that
triggered the dataclasses plugin.

Although the resulting DataclassTransformSpec is based on the typing.dataclass_transform
function, we also use it for traditional dataclasses.dataclass classes as well for simplicity.
In those cases, we return a default spec rather than one based on a call to
`typing.dataclass_transform`.

**Line:** 943

---

### `def _is_dataclasses_decorator(node: Node) -> bool`

**Line:** 963

---

### `def _has_direct_dataclass_transform_metaclass(info: TypeInfo) -> bool`

**Line:** 971

---

### `def _get_expanded_dataclasses_fields(ctx: FunctionSigContext, typ: ProperType, display_typ: ProperType, parent_typ: ProperType) -> list[CallableType] | None`

**Description:**
For a given type, determine what dataclasses it can be: for each class, return the field types.
For generic classes, the field types are expanded.
If the type contains Any or a non-dataclass, returns None; in the latter case, also reports an error.

**Line:** 978

---

### `def _meet_replace_sigs(sigs: list[CallableType]) -> CallableType`

**Description:**
Produces the lowest bound of the 'replace' signatures of multiple dataclasses.

**Line:** 1015

---

### `def replace_function_sig_callback(ctx: FunctionSigContext) -> CallableType`

**Description:**
Returns a signature for the 'dataclasses.replace' function that's dependent on the type
of the first positional argument.

**Line:** 1044

---

### `def is_processed_dataclass(info: TypeInfo) -> bool`

**Line:** 1076

---

### `def check_post_init(api: TypeChecker, defn: FuncItem, info: TypeInfo) -> None`

**Line:** 1080

---


## Module: venv2.libthon3.12.site-packages.mypy.plugins.default
**File:** `venv2/lib/python3.12/site-packages/mypy/plugins/default.py`

**Imports:**
- __future__.annotations
- functools.partial
- mypy.errorcodes
- mypy.message_registry
- mypy.nodes.DictExpr
- mypy.nodes.IntExpr
- mypy.nodes.StrExpr
- mypy.nodes.UnaryExpr
- mypy.plugin.AttributeContext
- mypy.plugin.ClassDefContext
- mypy.plugin.FunctionContext
- mypy.plugin.FunctionSigContext
- mypy.plugin.MethodContext
- mypy.plugin.MethodSigContext
- mypy.plugin.Plugin
- mypy.plugins.attrs
- mypy.plugins.common.try_getting_str_literals
- mypy.plugins.ctypes
- mypy.plugins.dataclasses
- mypy.plugins.enums
- mypy.plugins.functools
- mypy.plugins.singledispatch
- mypy.subtypes.is_subtype
- mypy.typeops.is_literal_type_like
- mypy.typeops.make_simplified_union
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.TPDICT_FB_NAMES
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeVarType
- mypy.types.TypedDictType
- mypy.types.UnionType
- mypy.types.get_proper_type
- mypy.types.get_proper_types
- typing.Callable

**Functions:**

### `def typed_dict_get_signature_callback(ctx: MethodSigContext) -> CallableType`

**Description:**
Try to infer a better signature type for TypedDict.get.

This is used to get better type context for the second argument that
depends on a TypedDict value type.

**Line:** 178

---

### `def typed_dict_get_callback(ctx: MethodContext) -> Type`

**Description:**
Infer a precise return type for TypedDict.get with literal first argument.

**Line:** 218

---

### `def typed_dict_pop_signature_callback(ctx: MethodSigContext) -> CallableType`

**Description:**
Try to infer a better signature type for TypedDict.pop.

This is used to get better type context for the second argument that
depends on a TypedDict value type.

**Line:** 257

---

### `def typed_dict_pop_callback(ctx: MethodContext) -> Type`

**Description:**
Type check and infer a precise return type for TypedDict.pop.

**Line:** 287

---

### `def typed_dict_setdefault_signature_callback(ctx: MethodSigContext) -> CallableType`

**Description:**
Try to infer a better signature type for TypedDict.setdefault.

This is used to get better type context for the second argument that
depends on a TypedDict value type.

**Line:** 322

---

### `def typed_dict_setdefault_callback(ctx: MethodContext) -> Type`

**Description:**
Type check TypedDict.setdefault and infer a precise return type.

**Line:** 345

---

### `def typed_dict_delitem_callback(ctx: MethodContext) -> Type`

**Description:**
Type check TypedDict.__delitem__.

**Line:** 388

---

### `def typed_dict_update_signature_callback(ctx: MethodSigContext) -> CallableType`

**Description:**
Try to infer a better signature type for methods that update `TypedDict`.

This includes: `TypedDict.update`, `TypedDict.__or__`, `TypedDict.__ror__`,
and `TypedDict.__ior__`.

**Line:** 412

---

### `def int_pow_callback(ctx: MethodContext) -> Type`

**Description:**
Infer a more precise return type for int.__pow__.

**Line:** 454

---

### `def int_neg_callback(ctx: MethodContext) -> Type`

**Description:**
Infer a more precise return type for int.__neg__.

This is mainly used to infer the return type as LiteralType
if the original underlying object is a LiteralType object

**Line:** 474

---

### `def tuple_mul_callback(ctx: MethodContext) -> Type`

**Description:**
Infer a more precise return type for tuple.__mul__ and tuple.__rmul__.

This is used to return a specific sized tuple if multiplied by Literal int

**Line:** 500

---


## Module: venv2.libthon3.12.site-packages.mypy.plugins.enums
**File:** `venv2/lib/python3.12/site-packages/mypy/plugins/enums.py`

**Imports:**
- __future__.annotations
- mypy.nodes.TypeInfo
- mypy.plugin
- mypy.semanal_enum.ENUM_BASES
- mypy.subtypes.is_equivalent
- mypy.typeops.fixup_partial_type
- mypy.typeops.make_simplified_union
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.ProperType
- mypy.types.Type
- mypy.types.get_proper_type
- typing.Final
- typing.Iterable
- typing.Sequence
- typing.TypeVar
- typing.cast

**Functions:**

### `def enum_name_callback(ctx: mypy.plugin.AttributeContext) -> Type`

**Description:**
This plugin refines the 'name' attribute in enums to act as if
they were declared to be final.

For example, the expression 'MyEnum.FOO.name' normally is inferred
to be of type 'str'.

This plugin will instead make the inferred type be a 'str' where the
last known value is 'Literal["FOO"]'. This means it would be legal to
use 'MyEnum.FOO.name' in contexts that expect a Literal type, just like
any other Final variable or attribute.

This plugin assumes that the provided context is an attribute access
matching one of the strings found in 'ENUM_NAME_ACCESS'.

**Line:** 32

---

### `def _first(it: Iterable[_T]) -> _T | None`

**Description:**
Return the first value from any iterable.

Returns ``None`` if the iterable is empty.

**Line:** 59

---

### `def _infer_value_type_with_auto_fallback(ctx: mypy.plugin.AttributeContext, proper_type: ProperType | None) -> Type | None`

**Description:**
Figure out the type of an enum value accounting for `auto()`.

This method is a no-op for a `None` proper_type and also in the case where
the type is not "enum.auto"

**Line:** 69

---

### `def _implements_new(info: TypeInfo) -> bool`

**Description:**
Check whether __new__ comes from enum.Enum or was implemented in a
subclass. In the latter case, we must infer Any as long as mypy can't infer
the type of _value_ from assignments in __new__.

**Line:** 105

---

### `def enum_value_callback(ctx: mypy.plugin.AttributeContext) -> Type`

**Description:**
This plugin refines the 'value' attribute in enums to refer to
the original underlying value. For example, suppose we have the
following:

class SomeEnum:
FOO = A()
BAR = B()

By default, mypy will infer that 'SomeEnum.FOO.value' and
'SomeEnum.BAR.value' both are of type 'Any'. This plugin refines
this inference so that mypy understands the expressions are
actually of types 'A' and 'B' respectively. This better reflects
the actual runtime behavior.

This plugin works simply by looking up the original value assigned
to the enum. For example, when this plugin sees 'SomeEnum.BAR.value',
it will look up whatever type 'BAR' had in the SomeEnum TypeInfo and
use that as the inferred type of the overall expression.

This plugin assumes that the provided context is an attribute access
matching one of the strings found in 'ENUM_VALUE_ACCESS'.

**Line:** 120

---

### `def _extract_underlying_field_name(typ: Type) -> str | None`

**Description:**
If the given type corresponds to some Enum instance, returns the
original name of that enum. For example, if we receive in the type
corresponding to 'SomeEnum.FOO', we return the string "SomeEnum.Foo".

This helper takes advantage of the fact that Enum instances are valid
to use inside Literal[...] types. An expression like 'SomeEnum.FOO' is
actually represented by an Instance type with a Literal enum fallback.

We can examine this Literal fallback to retrieve the string.

**Line:** 232

---


## Module: venv2.libthon3.12.site-packages.mypy.plugins.functools
**File:** `venv2/lib/python3.12/site-packages/mypy/plugins/functools.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR2
- mypy.nodes.Argument
- mypy.nodes.FuncItem
- mypy.nodes.Var
- mypy.plugin
- mypy.plugins.common.add_method_to_class
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.UnboundType
- mypy.types.get_proper_type
- typing.Final
- typing.NamedTuple

**Functions:**

### `def functools_total_ordering_maker_callback(ctx: mypy.plugin.ClassDefContext, auto_attribs_default: bool = False) -> bool`

**Description:**
Add dunder methods to classes decorated with functools.total_ordering.

**Line:** 21

---

### `def _find_other_type(method: _MethodInfo) -> Type`

**Description:**
Find the type of the ``other`` argument in a comparison method.

**Line:** 60

---

### `def _analyze_class(ctx: mypy.plugin.ClassDefContext) -> dict[(str, _MethodInfo | None)]`

**Description:**
Analyze the class body, its parents, and return the comparison methods found.

**Line:** 82

---


## Module: venv2.libthon3.12.site-packages.mypy.plugins.proper_plugin
**File:** `venv2/lib/python3.12/site-packages/mypy/plugins/proper_plugin.py`

**Imports:**
- __future__.annotations
- mypy.checker.TypeChecker
- mypy.nodes.TypeInfo
- mypy.plugin.FunctionContext
- mypy.plugin.Plugin
- mypy.subtypes.is_proper_subtype
- mypy.types.AnyType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.NoneTyp
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.UnionType
- mypy.types.get_proper_type
- mypy.types.get_proper_types
- typing.Callable

**Functions:**

### `def isinstance_proper_hook(ctx: FunctionContext) -> Type`

**Line:** 55

---

### `def is_special_target(right: ProperType) -> bool`

**Description:**
Whitelist some special cases for use in isinstance() with improper types.

**Line:** 79

---

### `def is_improper_type(typ: Type) -> bool`

**Description:**
Is this a type that is not a subtype of ProperType?

**Line:** 118

---

### `def is_dangerous_target(typ: ProperType) -> bool`

**Description:**
Is this a dangerous target (right argument) for an isinstance() check?

**Line:** 129

---

### `def proper_type_hook(ctx: FunctionContext) -> Type`

**Description:**
Check if this get_proper_type() call is not redundant.

**Line:** 138

---

### `def proper_types_hook(ctx: FunctionContext) -> Type`

**Description:**
Check if this get_proper_types() call is not redundant.

**Line:** 152

---

### `def get_proper_type_instance(ctx: FunctionContext) -> Instance`

**Line:** 165

---

### `def plugin(version: str) -> type[ProperTypePlugin]`

**Line:** 174

---


## Module: venv2.libthon3.12.site-packages.mypy.plugins.singledispatch
**File:** `venv2/lib/python3.12/site-packages/mypy/plugins/singledispatch.py`

**Imports:**
- __future__.annotations
- mypy.messages.format_type
- mypy.nodes.ARG_POS
- mypy.nodes.Argument
- mypy.nodes.Block
- mypy.nodes.ClassDef
- mypy.nodes.Context
- mypy.nodes.SymbolTable
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.options.Options
- mypy.plugin.CheckerPluginInterface
- mypy.plugin.FunctionContext
- mypy.plugin.MethodContext
- mypy.plugin.MethodSigContext
- mypy.plugins.common.add_method_to_class
- mypy.subtypes.is_subtype
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.get_proper_type
- typing.Final
- typing.NamedTuple
- typing.Sequence
- typing.TypeVar
- typing.Union
- typing_extensions.TypeAlias

**Functions:**

### `def get_singledispatch_info(typ: Instance) -> SingledispatchTypeVars | None`

**Line:** 42

---

### `def get_first_arg(args: list[list[T]]) -> T | None`

**Description:**
Get the element that corresponds to the first argument passed to the function

**Line:** 51

---

### `def make_fake_register_class_instance(api: CheckerPluginInterface, type_args: Sequence[Type]) -> Instance`

**Line:** 63

---

### `def fail(ctx: PluginContext, msg: str, context: Context | None) -> None`

**Description:**
Emit an error message.

This tries to emit an error message at the location specified by `context`, falling back to the
location specified by `ctx.context`. This is helpful when the only context information about
where you want to put the error message may be None (like it is for `CallableType.definition`)
and falling back to the location of the calling function is fine.

**Line:** 83

---

### `def create_singledispatch_function_callback(ctx: FunctionContext) -> Type`

**Description:**
Called for functools.singledispatch

**Line:** 99

---

### `def singledispatch_register_callback(ctx: MethodContext) -> Type`

**Description:**
Called for functools._SingleDispatchCallable.register

**Line:** 126

---

### `def register_function(ctx: PluginContext, singledispatch_obj: Instance, func: Type, options: Options, register_arg: Type | None = None) -> None`

**Description:**
Register a function

**Line:** 157

---

### `def get_dispatch_type(func: CallableType, register_arg: Type | None) -> Type | None`

**Line:** 194

---

### `def call_singledispatch_function_after_register_argument(ctx: MethodContext) -> Type`

**Description:**
Called on the function after passing a type to register

**Line:** 202

---

### `def call_singledispatch_function_callback(ctx: MethodSigContext) -> FunctionLike`

**Description:**
Called for functools._SingleDispatchCallable.__call__

**Line:** 217

---


## Module: venv2.libthon3.12.site-packages.mypy.reachability
**File:** `venv2/lib/python3.12/site-packages/mypy/reachability.py`

**Imports:**
- __future__.annotations
- mypy.literals.literal
- mypy.nodes.AssertStmt
- mypy.nodes.Block
- mypy.nodes.CallExpr
- mypy.nodes.ComparisonExpr
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.IfStmt
- mypy.nodes.Import
- mypy.nodes.ImportAll
- mypy.nodes.ImportFrom
- mypy.nodes.IndexExpr
- mypy.nodes.IntExpr
- mypy.nodes.LITERAL_YES
- mypy.nodes.MatchStmt
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.OpExpr
- mypy.nodes.SliceExpr
- mypy.nodes.StrExpr
- mypy.nodes.TupleExpr
- mypy.nodes.UnaryExpr
- mypy.options.Options
- mypy.patterns.AsPattern
- mypy.patterns.OrPattern
- mypy.patterns.Pattern
- mypy.traverser.TraverserVisitor
- typing.Final
- typing.Tuple
- typing.TypeVar

**Functions:**

### `def infer_reachability_of_if_statement(s: IfStmt, options: Options) -> None`

**Line:** 53

---

### `def infer_reachability_of_match_statement(s: MatchStmt, options: Options) -> None`

**Line:** 79

---

### `def assert_will_always_fail(s: AssertStmt, options: Options) -> bool`

**Line:** 107

---

### `def infer_condition_value(expr: Expression, options: Options) -> int`

**Description:**
Infer whether the given condition is always true/false.

Return ALWAYS_TRUE if always true, ALWAYS_FALSE if always false,
MYPY_TRUE if true under mypy and false at runtime, MYPY_FALSE if
false under mypy and true at runtime, else TRUTH_VALUE_UNKNOWN.

**Line:** 111

---

### `def infer_pattern_value(pattern: Pattern) -> int`

**Line:** 163

---

### `def consider_sys_version_info(expr: Expression, pyversion: tuple[(int, ...)]) -> int`

**Description:**
Consider whether expr is a comparison involving sys.version_info.

Return ALWAYS_TRUE, ALWAYS_FALSE, or TRUTH_VALUE_UNKNOWN.

**Line:** 174

---

### `def consider_sys_platform(expr: Expression, platform: str) -> int`

**Description:**
Consider whether expr is a comparison involving sys.platform.

Return ALWAYS_TRUE, ALWAYS_FALSE, or TRUTH_VALUE_UNKNOWN.

**Line:** 218

---

### `def fixed_comparison(left: Targ, op: str, right: Targ) -> int`

**Line:** 260

---

### `def contains_int_or_tuple_of_ints(expr: Expression) -> None | int | tuple[int, ...]`

**Line:** 277

---

### `def contains_sys_version_info(expr: Expression) -> None | int | tuple[int | None, int | None]`

**Line:** 291

---

### `def is_sys_attr(expr: Expression, name: str) -> bool`

**Line:** 315

---

### `def mark_block_unreachable(block: Block) -> None`

**Line:** 327

---

### `def mark_block_mypy_only(block: Block) -> None`

**Line:** 345

---


## Module: venv2.libthon3.12.site-packages.mypy.refinfo
**File:** `venv2/lib/python3.12/site-packages/mypy/refinfo.py`

**Imports:**
- __future__.annotations
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.LDEF
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.RefExpr
- mypy.nodes.SymbolNode
- mypy.nodes.TypeInfo
- mypy.traverser.TraverserVisitor
- mypy.typeops.tuple_fallback
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeType
- mypy.types.TypeVarLikeType
- mypy.types.get_proper_type

**Functions:**

### `def type_fullname(typ: Type, node: SymbolNode | None = None) -> str | None`

**Line:** 70

---

### `def get_undocumented_ref_info_json(tree: MypyFile, type_map: dict[(Expression, Type)]) -> list[dict[(str, object)]]`

**Line:** 87

---


## Module: venv2.libthon3.12.site-packages.mypy.renaming
**File:** `venv2/lib/python3.12/site-packages/mypy/renaming.py`

**Imports:**
- __future__.annotations
- contextlib.contextmanager
- mypy.nodes.AssignmentStmt
- mypy.nodes.Block
- mypy.nodes.BreakStmt
- mypy.nodes.ClassDef
- mypy.nodes.ContinueStmt
- mypy.nodes.ForStmt
- mypy.nodes.FuncDef
- mypy.nodes.Import
- mypy.nodes.ImportAll
- mypy.nodes.ImportFrom
- mypy.nodes.IndexExpr
- mypy.nodes.ListExpr
- mypy.nodes.Lvalue
- mypy.nodes.MatchStmt
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.StarExpr
- mypy.nodes.TryStmt
- mypy.nodes.TupleExpr
- mypy.nodes.WhileStmt
- mypy.nodes.WithStmt
- mypy.patterns.AsPattern
- mypy.traverser.TraverserVisitor
- typing.Final
- typing.Iterator

**Functions:**

### `def rename_refs(names: list[NameExpr], index: int) -> None`

**Line:** 564

---


## Module: venv2.libthon3.12.site-packages.mypy.report
**File:** `venv2/lib/python3.12/site-packages/mypy/report.py`

**Imports:**
- __future__.annotations
- abc.ABCMeta
- abc.abstractmethod
- collections
- itertools
- json
- lxml.etree
- mypy.defaults.REPORTER_NAMES
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.MypyFile
- mypy.options.Options
- mypy.stats
- mypy.traverser.TraverserVisitor
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.version.__version__
- operator.attrgetter
- os
- shutil
- sys
- time
- tokenize
- typing.Any
- typing.Callable
- typing.Dict
- typing.Final
- typing.Iterator
- typing.Tuple
- typing_extensions.TypeAlias
- urllib.request.pathname2url

**Functions:**

### `def register_reporter(report_name: str, reporter: Callable[([Reports, str], AbstractReporter)], needs_lxml: bool = False) -> None`

**Line:** 119

---

### `def alias_reporter(source_reporter: str, target_reporter: str) -> None`

**Line:** 127

---

### `def should_skip_path(path: str) -> bool`

**Line:** 131

---

### `def iterate_python_lines(path: str) -> Iterator[tuple[(int, str)]]`

**Description:**
Return an iterator over (line number, line text) from a Python file.

**Line:** 141

---

### `def get_line_rate(covered_lines: int, total_lines: int) -> str`

**Line:** 577

---


## Module: venv2.libthon3.12.site-packages.mypy.semanal
**File:** `venv2/lib/python3.12/site-packages/mypy/semanal.py`

**Imports:**
- __future__.annotations
- contextlib.contextmanager
- mypy.constant_fold.constant_fold_expr
- mypy.errorcodes
- mypy.errorcodes.ErrorCode
- mypy.errors.Errors
- mypy.errors.report_internal_error
- mypy.exprtotype.TypeTranslationError
- mypy.exprtotype.expr_to_unanalyzed_type
- mypy.message_registry
- mypy.messages.MessageBuilder
- mypy.messages.SUGGESTED_TEST_FIXTURES
- mypy.messages.TYPES_FOR_UNIMPORTED_HINTS
- mypy.messages.best_matches
- mypy.messages.pretty_seq
- mypy.mro.MroError
- mypy.mro.calculate_mro
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.ArgKind
- mypy.nodes.AssertStmt
- mypy.nodes.AssertTypeExpr
- mypy.nodes.AssignmentExpr
- mypy.nodes.AssignmentStmt
- mypy.nodes.AwaitExpr
- mypy.nodes.Block
- mypy.nodes.BreakStmt
- mypy.nodes.CONTRAVARIANT
- mypy.nodes.COVARIANT
- mypy.nodes.CallExpr
- mypy.nodes.CastExpr
- mypy.nodes.ClassDef
- mypy.nodes.ComparisonExpr
- mypy.nodes.ConditionalExpr
- mypy.nodes.Context
- mypy.nodes.ContinueStmt
- mypy.nodes.DataclassTransformSpec
- mypy.nodes.Decorator
- mypy.nodes.DelStmt
- mypy.nodes.DictExpr
- mypy.nodes.DictionaryComprehension
- mypy.nodes.EllipsisExpr
- mypy.nodes.EnumCallExpr
- mypy.nodes.Expression
- mypy.nodes.ExpressionStmt
- mypy.nodes.FakeExpression
- mypy.nodes.ForStmt
- mypy.nodes.FuncBase
- mypy.nodes.FuncDef
- mypy.nodes.FuncItem
- mypy.nodes.GDEF
- mypy.nodes.GeneratorExpr
- mypy.nodes.GlobalDecl
- mypy.nodes.IMPLICITLY_ABSTRACT
- mypy.nodes.INVARIANT
- mypy.nodes.IS_ABSTRACT
- mypy.nodes.IfStmt
- mypy.nodes.Import
- mypy.nodes.ImportAll
- mypy.nodes.ImportBase
- mypy.nodes.ImportFrom
- mypy.nodes.IndexExpr
- mypy.nodes.LDEF
- mypy.nodes.LambdaExpr
- mypy.nodes.ListComprehension
- mypy.nodes.ListExpr
- mypy.nodes.Lvalue
- mypy.nodes.MDEF
- mypy.nodes.MatchStmt
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NOT_ABSTRACT
- mypy.nodes.NameExpr
- mypy.nodes.NamedTupleExpr
- mypy.nodes.Node
- mypy.nodes.NonlocalDecl
- mypy.nodes.OpExpr
- mypy.nodes.OperatorAssignmentStmt
- mypy.nodes.OverloadPart
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.ParamSpecExpr
- mypy.nodes.PassStmt
- mypy.nodes.PlaceholderNode
- mypy.nodes.PromoteExpr
- mypy.nodes.REVEAL_LOCALS
- mypy.nodes.REVEAL_TYPE
- mypy.nodes.RUNTIME_PROTOCOL_DECOS
- mypy.nodes.RaiseStmt
- mypy.nodes.RefExpr
- mypy.nodes.ReturnStmt
- mypy.nodes.RevealExpr
- mypy.nodes.SetComprehension
- mypy.nodes.SetExpr
- mypy.nodes.SliceExpr
- mypy.nodes.StarExpr
- mypy.nodes.Statement
- mypy.nodes.StrExpr
- mypy.nodes.SuperExpr
- mypy.nodes.SymbolNode
- mypy.nodes.SymbolTable
- mypy.nodes.SymbolTableNode
- mypy.nodes.TempNode
- mypy.nodes.TryStmt
- mypy.nodes.TupleExpr
- mypy.nodes.TypeAlias
- mypy.nodes.TypeAliasExpr
- mypy.nodes.TypeApplication
- mypy.nodes.TypeInfo
- mypy.nodes.TypeVarExpr
- mypy.nodes.TypeVarLikeExpr
- mypy.nodes.TypeVarTupleExpr
- mypy.nodes.TypedDictExpr
- mypy.nodes.UnaryExpr
- mypy.nodes.Var
- mypy.nodes.WhileStmt
- mypy.nodes.WithStmt
- mypy.nodes.YieldExpr
- mypy.nodes.YieldFromExpr
- mypy.nodes.get_member_expr_fullname
- mypy.nodes.get_nongen_builtins
- mypy.nodes.implicit_module_attrs
- mypy.nodes.is_final_node
- mypy.nodes.type_aliases
- mypy.nodes.type_aliases_source_versions
- mypy.nodes.typing_extensions_aliases
- mypy.options.Options
- mypy.patterns.AsPattern
- mypy.patterns.ClassPattern
- mypy.patterns.MappingPattern
- mypy.patterns.OrPattern
- mypy.patterns.SequencePattern
- mypy.patterns.StarredPattern
- mypy.patterns.ValuePattern
- mypy.plugin.ClassDefContext
- mypy.plugin.DynamicClassDefContext
- mypy.plugin.Plugin
- mypy.plugin.SemanticAnalyzerPluginInterface
- mypy.plugins.dataclasses
- mypy.reachability.ALWAYS_FALSE
- mypy.reachability.ALWAYS_TRUE
- mypy.reachability.MYPY_FALSE
- mypy.reachability.MYPY_TRUE
- mypy.reachability.infer_condition_value
- mypy.reachability.infer_reachability_of_if_statement
- mypy.reachability.infer_reachability_of_match_statement
- mypy.scope.Scope
- mypy.semanal_enum.EnumCallAnalyzer
- mypy.semanal_namedtuple.NamedTupleAnalyzer
- mypy.semanal_newtype.NewTypeAnalyzer
- mypy.semanal_shared.ALLOW_INCOMPATIBLE_OVERRIDE
- mypy.semanal_shared.PRIORITY_FALLBACKS
- mypy.semanal_shared.SemanticAnalyzerInterface
- mypy.semanal_shared.calculate_tuple_fallback
- mypy.semanal_shared.find_dataclass_transform_spec
- mypy.semanal_shared.has_placeholder
- mypy.semanal_shared.parse_bool
- mypy.semanal_shared.require_bool_literal_argument
- mypy.semanal_shared.set_callable_name
- mypy.semanal_typeddict.TypedDictAnalyzer
- mypy.tvar_scope.TypeVarLikeScope
- mypy.typeanal.SELF_TYPE_NAMES
- mypy.typeanal.TypeAnalyser
- mypy.typeanal.TypeVarLikeList
- mypy.typeanal.TypeVarLikeQuery
- mypy.typeanal.analyze_type_alias
- mypy.typeanal.check_for_explicit_any
- mypy.typeanal.detect_diverging_alias
- mypy.typeanal.find_self_type
- mypy.typeanal.fix_instance
- mypy.typeanal.has_any_from_unimported_type
- mypy.typeanal.no_subscript_builtin_alias
- mypy.typeanal.type_constructors
- mypy.typeanal.validate_instance
- mypy.typeops.function_type
- mypy.typeops.get_type_vars
- mypy.typeops.try_getting_str_literals_from_type
- mypy.types.ASSERT_TYPE_NAMES
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.DATACLASS_TRANSFORM_NAMES
- mypy.types.FINAL_DECORATOR_NAMES
- mypy.types.FINAL_TYPE_NAMES
- mypy.types.FunctionLike
- mypy.types.IMPORTED_REVEAL_TYPE_NAMES
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NEVER_NAMES
- mypy.types.NoneType
- mypy.types.OVERLOAD_NAMES
- mypy.types.OVERRIDE_DECORATOR_NAMES
- mypy.types.Overloaded
- mypy.types.PROTOCOL_NAMES
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PlaceholderType
- mypy.types.ProperType
- mypy.types.REVEAL_TYPE_NAMES
- mypy.types.TPDICT_NAMES
- mypy.types.TYPED_NAMEDTUPLE_NAMES
- mypy.types.TYPE_ALIAS_NAMES
- mypy.types.TrivialSyntheticTypeTranslator
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UnpackType
- mypy.types.get_proper_type
- mypy.types.get_proper_types
- mypy.types.is_named_instance
- mypy.types.remove_dups
- mypy.types.type_vars_as_args
- mypy.types_utils.is_invalid_recursive_alias
- mypy.types_utils.store_argument_type
- mypy.typevars.fill_typevars
- mypy.util.correct_relative_import
- mypy.util.is_dunder
- mypy.util.module_prefix
- mypy.util.unmangle
- mypy.util.unnamed_function
- mypy.visitor.NodeVisitor
- typing.Any
- typing.Callable
- typing.Collection
- typing.Final
- typing.Iterable
- typing.Iterator
- typing.List
- typing.TypeVar
- typing.cast
- typing_extensions.TypeAlias

**Functions:**

### `def replace_implicit_first_type(sig: FunctionLike, new: Type) -> FunctionLike`

**Line:** 6804

---

### `def refers_to_fullname(node: Expression, fullnames: str | tuple[str, ...]) -> bool`

**Description:**
Is node a name or member expression with the given full name?

**Line:** 6817

---

### `def refers_to_class_or_function(node: Expression) -> bool`

**Description:**
Does semantically analyzed node refer to a class?

**Line:** 6831

---

### `def find_duplicate(list: list[T]) -> T | None`

**Description:**
If the list has duplicates, return one of the duplicates.

Otherwise, return None.

**Line:** 6838

---

### `def remove_imported_names_from_symtable(names: SymbolTable, module: str) -> None`

**Description:**
Remove all imported names from the symbol table of a module.

**Line:** 6849

---

### `def make_any_non_explicit(t: Type) -> Type`

**Description:**
Replace all Any types within in with Any that has attribute 'explicit' set to False

**Line:** 6863

---

### `def apply_semantic_analyzer_patches(patches: list[tuple[(int, Callable[[], None])]]) -> None`

**Description:**
Call patch callbacks in the right order.

This should happen after semantic analyzer pass 3.

**Line:** 6878

---

### `def names_modified_by_assignment(s: AssignmentStmt) -> list[NameExpr]`

**Description:**
Return all unqualified (short) names assigned to in an assignment statement.

**Line:** 6888

---

### `def names_modified_in_lvalue(lvalue: Lvalue) -> list[NameExpr]`

**Description:**
Return all NameExpr assignment targets in an Lvalue.

**Line:** 6896

---

### `def is_same_var_from_getattr(n1: SymbolNode | None, n2: SymbolNode | None) -> bool`

**Description:**
Do n1 and n2 refer to the same Var derived from module-level __getattr__?

**Line:** 6910

---

### `def dummy_context() -> Context`

**Line:** 6921

---

### `def is_valid_replacement(old: SymbolTableNode, new: SymbolTableNode) -> bool`

**Description:**
Can symbol table node replace an existing one?

These are the only valid cases:

1. Placeholder gets replaced with a non-placeholder
2. Placeholder that isn't known to become type replaced with a
placeholder that can become a type

**Line:** 6925

---

### `def is_same_symbol(a: SymbolNode | None, b: SymbolNode | None) -> bool`

**Line:** 6942

---

### `def is_trivial_body(block: Block) -> bool`

**Description:**
Returns 'true' if the given body is "trivial" -- if it contains just a "pass",
"..." (ellipsis), or "raise NotImplementedError()". A trivial body may also
start with a statement containing just a string (e.g. a docstring).

Note: Functions that raise other kinds of exceptions do not count as
"trivial". We use this function to help us determine when it's ok to
relax certain checks on body, but functions that raise arbitrary exceptions
are more likely to do non-trivial work. For example:

def halt(self, reason: str = ...) -> NoReturn:
raise MyCustomError("Fatal error: " + reason, self.line, self.context)

A function that raises just NotImplementedError is much less likely to be
this complex.

Note: If you update this, you may also need to update
mypy.fastparse.is_possible_trivial_body!

**Line:** 6950

---


## Module: venv2.libthon3.12.site-packages.mypy.semanal_classprop
**File:** `venv2/lib/python3.12/site-packages/mypy/semanal_classprop.py`

**Imports:**
- __future__.annotations
- mypy.errors.Errors
- mypy.nodes.CallExpr
- mypy.nodes.Decorator
- mypy.nodes.FuncDef
- mypy.nodes.IMPLICITLY_ABSTRACT
- mypy.nodes.IS_ABSTRACT
- mypy.nodes.Node
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.PromoteExpr
- mypy.nodes.SymbolTable
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.options.Options
- mypy.types.Instance
- mypy.types.MYPYC_NATIVE_INT_NAMES
- mypy.types.ProperType
- typing.Final

**Functions:**

### `def calculate_class_abstract_status(typ: TypeInfo, is_stub_file: bool, errors: Errors) -> None`

**Description:**
Calculate abstract status of a class.

Set is_abstract of the type to True if the type has an unimplemented
abstract attribute.  Also compute a list of abstract attributes.
Report error is required ABCMeta metaclass is missing.

**Line:** 42

---

### `def check_protocol_status(info: TypeInfo, errors: Errors) -> None`

**Description:**
Check that all classes in MRO of a protocol are protocols

**Line:** 120

---

### `def calculate_class_vars(info: TypeInfo) -> None`

**Description:**
Try to infer additional class variables.

Subclass attribute assignments with no type annotation are assumed
to be classvar if overriding a declared classvar from the base
class.

This must happen after the main semantic analysis pass, since
this depends on base class bodies having been fully analyzed.

**Line:** 132

---

### `def add_type_promotion(info: TypeInfo, module_names: SymbolTable, options: Options, builtin_names: SymbolTable) -> None`

**Description:**
Setup extra, ad-hoc subtyping relationships between classes (promotion).

This includes things like 'int' being compatible with 'float'.

**Line:** 151

---


## Module: venv2.libthon3.12.site-packages.mypy.semanal_infer
**File:** `venv2/lib/python3.12/site-packages/mypy/semanal_infer.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ARG_POS
- mypy.nodes.CallExpr
- mypy.nodes.Decorator
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.RefExpr
- mypy.nodes.Var
- mypy.semanal_shared.SemanticAnalyzerInterface
- mypy.typeops.function_type
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.ProperType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeVarType
- mypy.types.get_proper_type
- mypy.typevars.has_no_typevars

**Functions:**

### `def infer_decorator_signature_if_simple(dec: Decorator, analyzer: SemanticAnalyzerInterface) -> None`

**Description:**
Try to infer the type of the decorated function.

This lets us resolve additional references to decorated functions
during type checking. Otherwise the type might not be available
when we need it, since module top levels can't be deferred.

This basically uses a simple special-purpose type inference
engine just for decorators.

**Line:** 20

---

### `def is_identity_signature(sig: Type) -> bool`

**Description:**
Is type a callable of form T -> T (where T is a type variable)?

**Line:** 74

---

### `def calculate_return_type(expr: Expression) -> ProperType | None`

**Description:**
Return the return type if we can calculate it.

This only uses information available during semantic analysis so this
will sometimes return None because of insufficient information (as
type inference hasn't run yet).

**Line:** 83

---

### `def find_fixed_callable_return(expr: Expression) -> CallableType | None`

**Description:**
Return the return type, if expression refers to a callable that returns a callable.

But only do this if the return type has no type variables. Return None otherwise.
This approximates things a lot as this is supposed to be called before type checking
when full type information is not available yet.

**Line:** 107

---


## Module: venv2.libthon3.12.site-packages.mypy.semanal_main
**File:** `venv2/lib/python3.12/site-packages/mypy/semanal_main.py`

**Imports:**
- __future__.annotations
- contextlib.nullcontext
- mypy.build
- mypy.build.Graph
- mypy.build.State
- mypy.checker.FineGrainedDeferredNode
- mypy.errors.Errors
- mypy.nodes.Decorator
- mypy.nodes.FuncDef
- mypy.nodes.MypyFile
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.options.Options
- mypy.plugin.ClassDefContext
- mypy.plugins.dataclasses
- mypy.semanal.SemanticAnalyzer
- mypy.semanal.apply_semantic_analyzer_patches
- mypy.semanal.remove_imported_names_from_symtable
- mypy.semanal_classprop.add_type_promotion
- mypy.semanal_classprop.calculate_class_abstract_status
- mypy.semanal_classprop.calculate_class_vars
- mypy.semanal_classprop.check_protocol_status
- mypy.semanal_infer.infer_decorator_signature_if_simple
- mypy.semanal_shared.find_dataclass_transform_spec
- mypy.semanal_typeargs.TypeArgumentAnalyzer
- mypy.server.aststrip.SavedAttributes
- mypy.state
- mypy.util.is_typeshed_file
- typing.Callable
- typing.Final
- typing.List
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- typing_extensions.TypeAlias

**Functions:**

### `def semantic_analysis_for_scc(graph: Graph, scc: list[str], errors: Errors) -> None`

**Description:**
Perform semantic analysis for all modules in a SCC (import cycle).

Assume that reachability analysis has already been performed.

The scc will be processed roughly in the order the modules are included
in the list.

**Line:** 81

---

### `def cleanup_builtin_scc(state: State) -> None`

**Description:**
Remove imported names from builtins namespace.

This way names imported from typing in builtins.pyi aren't available
by default (without importing them). We can only do this after processing
the whole SCC is finished, when the imported names aren't needed for
processing builtins.pyi itself.

**Line:** 109

---

### `def semantic_analysis_for_targets(state: State, nodes: list[FineGrainedDeferredNode], graph: Graph, saved_attrs: SavedAttributes) -> None`

**Description:**
Semantically analyze only selected nodes in a given module.

This essentially mirrors the logic of semantic_analysis_for_scc()
except that we process only some targets. This is used in fine grained
incremental mode, when propagating an update.

The saved_attrs are implicitly declared instance attributes (attributes
defined on self) removed by AST stripper that may need to be reintroduced
here.  They must be added before any methods are analyzed.

**Line:** 121

---

### `def restore_saved_attrs(saved_attrs: SavedAttributes) -> None`

**Description:**
Restore instance variables removed during AST strip that haven't been added yet.

**Line:** 153

---

### `def process_top_levels(graph: Graph, scc: list[str], patches: Patches) -> None`

**Line:** 177

---

### `def process_functions(graph: Graph, scc: list[str], patches: Patches) -> None`

**Line:** 235

---

### `def process_top_level_function(analyzer: SemanticAnalyzer, state: State, module: str, target: str, node: FuncDef | OverloadedFuncDef | Decorator, active_type: TypeInfo | None, patches: Patches) -> None`

**Description:**
Analyze single top-level function or method.

Process the body of the function (including nested functions) again and again,
until all names have been resolved (or iteration limit reached).

**Line:** 257

---

### `def get_all_leaf_targets(file: MypyFile) -> list[TargetInfo]`

**Description:**
Return all leaf targets in a symbol table (module-level and methods).

**Line:** 310

---

### `def semantic_analyze_target(target: str, module: str, state: State, node: MypyFile | FuncDef | OverloadedFuncDef | Decorator, active_type: TypeInfo | None, final_iteration: bool, patches: Patches) -> tuple[(list[str], bool, bool)]`

**Description:**
Semantically analyze a single target.

Return tuple with these items:
- list of deferred targets
- was some definition incomplete (need to run another pass)
- were any new names defined (or placeholders replaced)

**Line:** 319

---

### `def check_type_arguments(graph: Graph, scc: list[str], errors: Errors) -> None`

**Line:** 376

---

### `def check_type_arguments_in_targets(targets: list[FineGrainedDeferredNode], state: State, errors: Errors) -> None`

**Description:**
Check type arguments against type variable bounds and restrictions.

This mirrors the logic in check_type_arguments() except that we process only
some targets. This is used in fine grained incremental mode.

**Line:** 391

---

### `def apply_class_plugin_hooks(graph: Graph, scc: list[str], errors: Errors) -> None`

**Description:**
Apply class plugin hooks within a SCC.

We run these after to the main semantic analysis so that the hooks
don't need to deal with incomplete definitions such as placeholder
types.

Note that some hooks incorrectly run during the main semantic
analysis pass, for historical reasons.

**Line:** 417

---

### `def apply_hooks_to_class(self: SemanticAnalyzer, module: str, info: TypeInfo, options: Options, file_node: MypyFile, errors: Errors) -> bool`

**Line:** 452

---

### `def calculate_class_properties(graph: Graph, scc: list[str], errors: Errors) -> None`

**Line:** 491

---

### `def check_blockers(graph: Graph, scc: list[str]) -> None`

**Line:** 509

---


## Module: venv2.libthon3.12.site-packages.mypy.semanal_shared
**File:** `venv2/lib/python3.12/site-packages/mypy/semanal_shared.py`

**Imports:**
- __future__.annotations
- abc.abstractmethod
- mypy.errorcodes.ErrorCode
- mypy.errorcodes.LITERAL_REQ
- mypy.join
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.Context
- mypy.nodes.DataclassTransformSpec
- mypy.nodes.Decorator
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.NameExpr
- mypy.nodes.Node
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.RefExpr
- mypy.nodes.SymbolNode
- mypy.nodes.SymbolTable
- mypy.nodes.SymbolTableNode
- mypy.nodes.TypeInfo
- mypy.plugin.SemanticAnalyzerPluginInterface
- mypy.tvar_scope.TypeVarLikeScope
- mypy.type_visitor.ANY_STRATEGY
- mypy.type_visitor.BoolTypeQuery
- mypy.types.AnyType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.ParamSpecFlavor
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PlaceholderType
- mypy.types.ProperType
- mypy.types.TPDICT_FB_NAMES
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeVarId
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.UnpackType
- mypy.types.get_proper_type
- mypy_extensions.trait
- typing.Callable
- typing.Final
- typing.overload
- typing_extensions.Literal
- typing_extensions.Protocol

**Functions:**

### `def set_callable_name(sig: Type, fdef: FuncDef) -> ProperType`

**Line:** 259

---

### `def calculate_tuple_fallback(typ: TupleType) -> None`

**Description:**
Calculate a precise item type for the fallback of a tuple type.

This must be called only after the main semantic analysis pass, since joins
aren't available before that.

Note that there is an apparent chicken and egg problem with respect
to verifying type arguments against bounds. Verifying bounds might
require fallbacks, but we might use the bounds to calculate the
fallbacks. In practice this is not a problem, since the worst that
can happen is that we have invalid type argument values, and these
can happen in later stages as well (they will generate errors, but
we don't prevent their existence).

**Line:** 275

---

### `def paramspec_args(name: str, fullname: str, id: TypeVarId | int, named_type_func: _NamedTypeCallback, line: int = -1, column: int = -1, prefix: Parameters | None = None) -> ParamSpecType`

**Line:** 315

---

### `def paramspec_kwargs(name: str, fullname: str, id: TypeVarId | int, named_type_func: _NamedTypeCallback, line: int = -1, column: int = -1, prefix: Parameters | None = None) -> ParamSpecType`

**Line:** 338

---

### `def has_placeholder(typ: Type) -> bool`

**Description:**
Check if a type contains any placeholder types (recursively).

**Line:** 371

---

### `def find_dataclass_transform_spec(node: Node | None) -> DataclassTransformSpec | None`

**Description:**
Find the dataclass transform spec for the given node, if any exists.

Per PEP 681 (https://peps.python.org/pep-0681/#the-dataclass-transform-decorator), dataclass
transforms can be specified in multiple ways, including decorator functions and
metaclasses/base classes. This function resolves the spec from any of these variants.

**Line:** 376

---

### `def require_bool_literal_argument(api: SemanticAnalyzerInterface | SemanticAnalyzerPluginInterface, expression: Expression, name: str, default: Literal[True] | Literal[False]) -> bool`

**Decorators:**
- `@overload`

**Line:** 451

---

### `def require_bool_literal_argument(api: SemanticAnalyzerInterface | SemanticAnalyzerPluginInterface, expression: Expression, name: str, default: None = None) -> bool | None`

**Decorators:**
- `@overload`

**Line:** 461

---

### `def require_bool_literal_argument(api: SemanticAnalyzerInterface | SemanticAnalyzerPluginInterface, expression: Expression, name: str, default: bool | None = None) -> bool | None`

**Description:**
Attempt to interpret an expression as a boolean literal, and fail analysis if we can't.

**Line:** 470

---

### `def parse_bool(expr: Expression) -> bool | None`

**Line:** 487

---


## Module: venv2.libthon3.12.site-packages.mypy.server.astdiff
**File:** `venv2/lib/python3.12/site-packages/mypy/server/astdiff.py`

**Imports:**
- __future__.annotations
- mypy.expandtype.expand_type
- mypy.nodes.Decorator
- mypy.nodes.FuncBase
- mypy.nodes.FuncDef
- mypy.nodes.FuncItem
- mypy.nodes.MypyFile
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.ParamSpecExpr
- mypy.nodes.SymbolNode
- mypy.nodes.SymbolTable
- mypy.nodes.TypeAlias
- mypy.nodes.TypeInfo
- mypy.nodes.TypeVarExpr
- mypy.nodes.TypeVarTupleExpr
- mypy.nodes.UNBOUND_IMPORTED
- mypy.nodes.Var
- mypy.semanal_shared.find_dataclass_transform_spec
- mypy.state.state
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.ErasedType
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeType
- mypy.types.TypeVarId
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypeVisitor
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.util.get_prefix
- typing.Sequence
- typing.Tuple
- typing.Union
- typing_extensions.TypeAlias

**Functions:**

### `def compare_symbol_table_snapshots(name_prefix: str, snapshot1: dict[(str, SymbolSnapshot)], snapshot2: dict[(str, SymbolSnapshot)]) -> set[str]`

**Description:**
Return names that are different in two snapshots of a symbol table.

Only shallow (intra-module) differences are considered. References to things defined
outside the module are compared based on the name of the target only.

Recurse into class symbol tables (if the class is defined in the target module).

Return a set of fully-qualified names (e.g., 'mod.func' or 'mod.Class.method').

**Line:** 123

---

### `def snapshot_symbol_table(name_prefix: str, table: SymbolTable) -> dict[(str, SymbolSnapshot)]`

**Description:**
Create a snapshot description that represents the state of a symbol table.

The snapshot has a representation based on nested tuples and dicts
that makes it easy and fast to find differences.

Only "shallow" state is included in the snapshot -- references to
things defined in other modules are represented just by the names of
the targets.

**Line:** 166

---

### `def snapshot_definition(node: SymbolNode | None, common: SymbolSnapshot) -> SymbolSnapshot`

**Description:**
Create a snapshot description of a symbol table node.

The representation is nested tuples and dicts. Only externally
visible attributes are included.

**Line:** 228

---

### `def snapshot_type(typ: Type) -> SnapshotItem`

**Description:**
Create a snapshot representation of a type using nested tuples.

**Line:** 314

---

### `def snapshot_optional_type(typ: Type | None) -> SnapshotItem`

**Line:** 319

---

### `def snapshot_types(types: Sequence[Type]) -> SnapshotItem`

**Line:** 326

---

### `def snapshot_simple_type(typ: Type) -> SnapshotItem`

**Line:** 330

---

### `def encode_optional_str(s: str | None) -> str`

**Line:** 334

---

### `def snapshot_untyped_signature(func: OverloadedFuncDef | FuncItem) -> SymbolSnapshot`

**Description:**
Create a snapshot of the signature of a function that has no explicit signature.

If the arguments to a function without signature change, it must be
considered as different. We have this special casing since we don't store
the implicit signature anywhere, and we'd rather not construct new
Callable objects in this module (the idea is to only read properties of
the AST here).

**Line:** 497

---


## Module: venv2.libthon3.12.site-packages.mypy.server.astmerge
**File:** `venv2/lib/python3.12/site-packages/mypy/server/astmerge.py`

**Imports:**
- __future__.annotations
- mypy.nodes.AssertTypeExpr
- mypy.nodes.AssignmentStmt
- mypy.nodes.Block
- mypy.nodes.CallExpr
- mypy.nodes.CastExpr
- mypy.nodes.ClassDef
- mypy.nodes.EnumCallExpr
- mypy.nodes.FuncBase
- mypy.nodes.FuncDef
- mypy.nodes.LambdaExpr
- mypy.nodes.MDEF
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.NamedTupleExpr
- mypy.nodes.NewTypeExpr
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.RefExpr
- mypy.nodes.Statement
- mypy.nodes.SuperExpr
- mypy.nodes.SymbolNode
- mypy.nodes.SymbolTable
- mypy.nodes.TypeAlias
- mypy.nodes.TypeInfo
- mypy.nodes.TypedDictExpr
- mypy.nodes.Var
- mypy.traverser.TraverserVisitor
- mypy.types.AnyType
- mypy.types.CallableArgument
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.EllipsisType
- mypy.types.ErasedType
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.PlaceholderType
- mypy.types.RawExpressionType
- mypy.types.SyntheticTypeVisitor
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeList
- mypy.types.TypeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.typestate.type_state
- mypy.util.get_prefix
- mypy.util.replace_object_state
- typing.TypeVar
- typing.cast

**Functions:**

### `def merge_asts(old: MypyFile, old_symbols: SymbolTable, new: MypyFile, new_symbols: SymbolTable) -> None`

**Description:**
Merge a new version of a module AST to a previous version.

The main idea is to preserve the identities of externally visible
nodes in the old AST (that have a corresponding node in the new AST).
All old node state (outside identity) will come from the new AST.

When this returns, 'old' will refer to the merged AST, but 'new_symbols'
will be the new symbol table. 'new' and 'old_symbols' will no longer be
valid.

**Line:** 115

---

### `def replacement_map_from_symbol_table(old: SymbolTable, new: SymbolTable, prefix: str) -> dict[(SymbolNode, SymbolNode)]`

**Description:**
Create a new-to-old object identity map by comparing two symbol table revisions.

Both symbol tables must refer to revisions of the same module id. The symbol tables
are compared recursively (recursing into nested class symbol tables), but only within
the given module prefix. Don't recurse into other modules accessible through the symbol
table.

**Line:** 146

---

### `def replace_nodes_in_ast(node: SymbolNode, replacements: dict[(SymbolNode, SymbolNode)]) -> SymbolNode`

**Description:**
Replace all references to replacement map keys within an AST node, recursively.

Also replace the *identity* of any nodes that have replacements. Return the
*replaced* version of the argument node (which may have a different identity, if
it's included in the replacement map).

**Line:** 180

---

### `def replace_nodes_in_symbol_table(symbols: SymbolTable, replacements: dict[(SymbolNode, SymbolNode)]) -> None`

**Line:** 549

---


## Module: venv2.libthon3.12.site-packages.mypy.server.aststrip
**File:** `venv2/lib/python3.12/site-packages/mypy/server/aststrip.py`

**Imports:**
- __future__.annotations
- contextlib.contextmanager
- contextlib.nullcontext
- mypy.nodes.AssignmentStmt
- mypy.nodes.Block
- mypy.nodes.CLASSDEF_NO_INFO
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.Decorator
- mypy.nodes.ForStmt
- mypy.nodes.FuncDef
- mypy.nodes.ImportAll
- mypy.nodes.ImportFrom
- mypy.nodes.IndexExpr
- mypy.nodes.ListExpr
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.Node
- mypy.nodes.OpExpr
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.RefExpr
- mypy.nodes.StarExpr
- mypy.nodes.SuperExpr
- mypy.nodes.SymbolTableNode
- mypy.nodes.TupleExpr
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.traverser.TraverserVisitor
- mypy.types.CallableType
- mypy.typestate.type_state
- typing.Dict
- typing.Iterator
- typing.Tuple
- typing_extensions.TypeAlias

**Functions:**

### `def strip_target(node: MypyFile | FuncDef | OverloadedFuncDef, saved_attrs: SavedAttributes) -> None`

**Description:**
Reset a fine-grained incremental target to state before semantic analysis.

All TypeInfos are killed. Therefore we need to preserve the variables
defined as attributes on self. This is done by patches (callbacks)
returned from this function that re-add these variables when called.

Args:
node: node to strip
saved_attrs: collect attributes here that may need to be re-added to
classes afterwards if stripping a class body (this dict is mutated)

**Line:** 74

---


## Module: venv2.libthon3.12.site-packages.mypy.server.deps
**File:** `venv2/lib/python3.12/site-packages/mypy/server/deps.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- mypy.nodes.AssertTypeExpr
- mypy.nodes.AssignmentStmt
- mypy.nodes.AwaitExpr
- mypy.nodes.Block
- mypy.nodes.CallExpr
- mypy.nodes.CastExpr
- mypy.nodes.ClassDef
- mypy.nodes.ComparisonExpr
- mypy.nodes.Decorator
- mypy.nodes.DelStmt
- mypy.nodes.DictionaryComprehension
- mypy.nodes.EnumCallExpr
- mypy.nodes.Expression
- mypy.nodes.ForStmt
- mypy.nodes.FuncBase
- mypy.nodes.FuncDef
- mypy.nodes.GDEF
- mypy.nodes.GeneratorExpr
- mypy.nodes.Import
- mypy.nodes.ImportAll
- mypy.nodes.ImportFrom
- mypy.nodes.IndexExpr
- mypy.nodes.LDEF
- mypy.nodes.MDEF
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.NamedTupleExpr
- mypy.nodes.NewTypeExpr
- mypy.nodes.Node
- mypy.nodes.OpExpr
- mypy.nodes.OperatorAssignmentStmt
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.RefExpr
- mypy.nodes.StarExpr
- mypy.nodes.SuperExpr
- mypy.nodes.TupleExpr
- mypy.nodes.TypeAliasExpr
- mypy.nodes.TypeApplication
- mypy.nodes.TypeInfo
- mypy.nodes.TypeVarExpr
- mypy.nodes.TypedDictExpr
- mypy.nodes.UnaryExpr
- mypy.nodes.Var
- mypy.nodes.WithStmt
- mypy.nodes.YieldFromExpr
- mypy.operators.op_methods
- mypy.operators.ops_with_inplace_method
- mypy.operators.reverse_op_methods
- mypy.operators.unary_op_methods
- mypy.options.Options
- mypy.scope.Scope
- mypy.server.trigger.make_trigger
- mypy.server.trigger.make_wildcard_trigger
- mypy.traverser.TraverserVisitor
- mypy.typeops.bind_self
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.ErasedType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypeVisitor
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.get_proper_type
- mypy.typestate.type_state
- mypy.util.correct_relative_import
- typing.List

**Functions:**

### `def get_dependencies(target: MypyFile, type_map: dict[(Expression, Type)], python_version: tuple[(int, int)], options: Options) -> dict[(str, set[str])]`

**Description:**
Get all dependencies of a node, recursively.

**Line:** 179

---

### `def get_dependencies_of_target(module_id: str, module_tree: MypyFile, target: Node, type_map: dict[(Expression, Type)], python_version: tuple[(int, int)]) -> dict[(str, set[str])]`

**Description:**
Get dependencies of a target -- don't recursive into nested targets.

**Line:** 191

---

### `def get_type_triggers(typ: Type, use_logical_deps: bool, seen_aliases: set[TypeAliasType] | None = None) -> list[str]`

**Description:**
Return all triggers that correspond to a type becoming stale.

**Line:** 943

---

### `def merge_dependencies(new_deps: dict[(str, set[str])], deps: dict[(str, set[str])]) -> None`

**Line:** 1102

---

### `def non_trivial_bases(info: TypeInfo) -> list[TypeInfo]`

**Line:** 1107

---

### `def has_user_bases(info: TypeInfo) -> bool`

**Line:** 1111

---

### `def dump_all_dependencies(modules: dict[(str, MypyFile)], type_map: dict[(Expression, Type)], python_version: tuple[(int, int)], options: Options) -> None`

**Description:**
Generate dependencies for all interesting modules and print them to stdout.

**Line:** 1115

---


## Module: venv2.libthon3.12.site-packages.mypy.server.mergecheck
**File:** `venv2/lib/python3.12/site-packages/mypy/server/mergecheck.py`

**Imports:**
- __future__.annotations
- mypy.nodes.Decorator
- mypy.nodes.FakeInfo
- mypy.nodes.FuncDef
- mypy.nodes.SymbolNode
- mypy.nodes.Var
- mypy.server.objgraph.get_path
- mypy.server.objgraph.get_reachable_graph
- typing.Final

**Functions:**

### `def check_consistency(o: object) -> None`

**Description:**
Fail if there are two AST nodes with the same fullname reachable from 'o'.

Raise AssertionError on failure and print some debugging output.

**Line:** 14

---

### `def path_to_str(path: list[tuple[(object, object)]]) -> str`

**Line:** 68

---


## Module: venv2.libthon3.12.site-packages.mypy.server.objgraph
**File:** `venv2/lib/python3.12/site-packages/mypy/server/objgraph.py`

**Imports:**
- __future__.annotations
- collections.abc.Iterable
- types
- typing.Final
- typing.Iterator
- typing.Mapping
- weakref

**Functions:**

### `def isproperty(o: object, attr: str) -> bool`

**Line:** 35

---

### `def get_edge_candidates(o: object) -> Iterator[tuple[(object, object)]]`

**Line:** 39

---

### `def get_edges(o: object) -> Iterator[tuple[(object, object)]]`

**Line:** 59

---

### `def get_reachable_graph(root: object) -> tuple[(dict[int, object], dict[int, tuple[int, object]])]`

**Line:** 76

---

### `def get_path(o: object, seen: dict[(int, object)], parents: dict[(int, tuple[int, object])]) -> list[tuple[(object, object)]]`

**Line:** 92

---


## Module: venv2.libthon3.12.site-packages.mypy.server.subexpr
**File:** `venv2/lib/python3.12/site-packages/mypy/server/subexpr.py`

**Imports:**
- __future__.annotations
- mypy.nodes.AssertTypeExpr
- mypy.nodes.AssignmentExpr
- mypy.nodes.AwaitExpr
- mypy.nodes.CallExpr
- mypy.nodes.CastExpr
- mypy.nodes.ComparisonExpr
- mypy.nodes.ConditionalExpr
- mypy.nodes.DictExpr
- mypy.nodes.DictionaryComprehension
- mypy.nodes.Expression
- mypy.nodes.GeneratorExpr
- mypy.nodes.IndexExpr
- mypy.nodes.LambdaExpr
- mypy.nodes.ListComprehension
- mypy.nodes.ListExpr
- mypy.nodes.MemberExpr
- mypy.nodes.Node
- mypy.nodes.OpExpr
- mypy.nodes.RevealExpr
- mypy.nodes.SetComprehension
- mypy.nodes.SetExpr
- mypy.nodes.SliceExpr
- mypy.nodes.StarExpr
- mypy.nodes.TupleExpr
- mypy.nodes.TypeApplication
- mypy.nodes.UnaryExpr
- mypy.nodes.YieldExpr
- mypy.nodes.YieldFromExpr
- mypy.traverser.TraverserVisitor

**Functions:**

### `def get_subexpressions(node: Node) -> list[Expression]`

**Line:** 38

---


## Module: venv2.libthon3.12.site-packages.mypy.server.target
**File:** `venv2/lib/python3.12/site-packages/mypy/server/target.py`

**Imports:**
- __future__.annotations

**Functions:**

### `def trigger_to_target(s: str) -> str`

**Line:** 4

---


## Module: venv2.libthon3.12.site-packages.mypy.server.trigger
**File:** `venv2/lib/python3.12/site-packages/mypy/server/trigger.py`

**Imports:**
- __future__.annotations
- typing.Final

**Functions:**

### `def make_trigger(name: str) -> str`

**Line:** 13

---

### `def make_wildcard_trigger(module: str) -> str`

**Description:**
Special trigger fired when any top-level name is changed in a module.

Note that this is different from a module trigger, as module triggers are only
fired if the module is created, deleted, or replaced with a non-module, whereas
a wildcard trigger is triggered for namespace changes.

This is used for "from m import *" dependencies.

**Line:** 17

---


## Module: venv2.libthon3.12.site-packages.mypy.server.update
**File:** `venv2/lib/python3.12/site-packages/mypy/server/update.py`

**Imports:**
- __future__.annotations
- mypy.build.BuildManager
- mypy.build.BuildResult
- mypy.build.DEBUG_FINE_GRAINED
- mypy.build.FAKE_ROOT_MODULE
- mypy.build.Graph
- mypy.build.State
- mypy.build.load_graph
- mypy.build.process_fresh_modules
- mypy.checker.FineGrainedDeferredNode
- mypy.errors.CompileError
- mypy.fscache.FileSystemCache
- mypy.modulefinder.BuildSource
- mypy.nodes.Decorator
- mypy.nodes.FuncDef
- mypy.nodes.ImportFrom
- mypy.nodes.MypyFile
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.SymbolNode
- mypy.nodes.SymbolTable
- mypy.nodes.TypeInfo
- mypy.options.Options
- mypy.semanal_main.core_modules
- mypy.semanal_main.semantic_analysis_for_scc
- mypy.semanal_main.semantic_analysis_for_targets
- mypy.server.astdiff.SymbolSnapshot
- mypy.server.astdiff.compare_symbol_table_snapshots
- mypy.server.astdiff.snapshot_symbol_table
- mypy.server.astmerge.merge_asts
- mypy.server.aststrip.SavedAttributes
- mypy.server.aststrip.strip_target
- mypy.server.deps.get_dependencies_of_target
- mypy.server.deps.merge_dependencies
- mypy.server.target.trigger_to_target
- mypy.server.trigger.WILDCARD_TAG
- mypy.server.trigger.make_trigger
- mypy.typestate.type_state
- mypy.util.module_prefix
- mypy.util.split_target
- os
- re
- sys
- time
- typing.Callable
- typing.Final
- typing.NamedTuple
- typing.Sequence
- typing.Union
- typing_extensions.TypeAlias

**Functions:**

### `def find_unloaded_deps(manager: BuildManager, graph: dict[(str, State)], initial: Sequence[str]) -> list[str]`

**Description:**
Find all the deps of the nodes in initial that haven't had their tree loaded.

The key invariant here is that if a module is loaded, so are all
of their dependencies. This means that when we encounter a loaded
module, we don't need to explore its dependencies.  (This
invariant is slightly violated when dependencies are added, which
can be handled by calling find_unloaded_deps directly on the new
dependencies.)

**Line:** 471

---

### `def ensure_deps_loaded(module: str, deps: dict[(str, set[str])], graph: dict[(str, State)]) -> None`

**Description:**
Ensure that the dependencies on a module are loaded.

Dependencies are loaded into the 'deps' dictionary.

This also requires loading dependencies from any parent modules,
since dependencies will get stored with parent modules when a module
doesn't exist.

**Line:** 499

---

### `def ensure_trees_loaded(manager: BuildManager, graph: dict[(str, State)], initial: Sequence[str]) -> None`

**Description:**
Ensure that the modules in initial and their deps have loaded trees.

**Line:** 518

---

### `def update_module_isolated(module: str, path: str, manager: BuildManager, previous_modules: dict[(str, str)], graph: Graph, force_removed: bool, followed: bool) -> UpdateResult`

**Description:**
Build a new version of one changed module only.

Don't propagate changes to elsewhere in the program. Raise CompileError on
encountering a blocking error.

Args:
module: Changed module (modified, created or deleted)
path: Path of the changed module
manager: Build manager
graph: Build graph
force_removed: If True, consider the module removed from the build even it the
file exists

Returns a named tuple describing the result (see above for details).

**Line:** 560

---

### `def find_relative_leaf_module(modules: list[tuple[(str, str)]], graph: Graph) -> tuple[(str, str)]`

**Description:**
Find a module in a list that directly imports no other module in the list.

If no such module exists, return the lexicographically first module from the list.
Always return one of the items in the modules list.

NOTE: If both 'abc' and 'typing' have changed, an effect of the above rule is that
we prefer 'abc', even if both are in the same SCC. This works around a false
positive in 'typing', at least in tests.

Args:
modules: List of (module, path) tuples (non-empty)
graph: Program import graph that contains all modules in the module list

**Line:** 680

---

### `def delete_module(module_id: str, path: str, graph: Graph, manager: BuildManager) -> None`

**Line:** 707

---

### `def dedupe_modules(modules: list[tuple[(str, str)]]) -> list[tuple[(str, str)]]`

**Line:** 729

---

### `def get_module_to_path_map(graph: Graph) -> dict[(str, str)]`

**Line:** 739

---

### `def get_sources(fscache: FileSystemCache, modules: dict[(str, str)], changed_modules: list[tuple[(str, str)]], followed: bool) -> list[BuildSource]`

**Line:** 743

---

### `def calculate_active_triggers(manager: BuildManager, old_snapshots: dict[(str, dict[str, SymbolSnapshot])], new_modules: dict[(str, MypyFile | None)]) -> set[str]`

**Description:**
Determine activated triggers by comparing old and new symbol tables.

For example, if only the signature of function m.f is different in the new
symbol table, return {'<m.f>'}.

**Line:** 756

---

### `def replace_modules_with_new_variants(manager: BuildManager, graph: dict[(str, State)], old_modules: dict[(str, MypyFile | None)], new_modules: dict[(str, MypyFile | None)]) -> None`

**Description:**
Replace modules with newly builds versions.

Retain the identities of externally visible AST nodes in the
old ASTs so that references to the affected modules from other
modules will still be valid (unless something was deleted or
replaced with an incompatible definition, in which case there
will be dangling references that will be handled by
propagate_changes_using_dependencies).

**Line:** 804

---

### `def propagate_changes_using_dependencies(manager: BuildManager, graph: dict[(str, State)], deps: dict[(str, set[str])], triggered: set[str], up_to_date_modules: set[str], targets_with_errors: set[str], processed_targets: list[str]) -> list[tuple[(str, str)]]`

**Description:**
Transitively rechecks targets based on triggers and the dependency map.

Returns a list (module id, path) tuples representing modules that contain
a target that needs to be reprocessed but that has not been parsed yet.

Processed targets should be appended to processed_targets (used in tests only,
to test the order of processing targets).

**Line:** 828

---

### `def find_targets_recursive(manager: BuildManager, graph: Graph, triggers: set[str], deps: dict[(str, set[str])], up_to_date_modules: set[str]) -> tuple[(dict[str, set[FineGrainedDeferredNode]], set[str], set[TypeInfo])]`

**Description:**
Find names of all targets that need to reprocessed, given some triggers.

Returns: A tuple containing a:
* Dictionary from module id to a set of stale targets.
* A set of module ids for unparsed modules with stale targets.

**Line:** 893

---

### `def reprocess_nodes(manager: BuildManager, graph: dict[(str, State)], module_id: str, nodeset: set[FineGrainedDeferredNode], deps: dict[(str, set[str])], processed_targets: list[str]) -> set[str]`

**Description:**
Reprocess a set of nodes within a single module.

Return fired triggers.

**Line:** 955

---

### `def find_symbol_tables_recursive(prefix: str, symbols: SymbolTable) -> dict[(str, SymbolTable)]`

**Description:**
Find all nested symbol tables.

Args:
prefix: Full name prefix (used for return value keys and to filter result so that
cross references to other modules aren't included)
symbols: Root symbol table

Returns a dictionary from full name to corresponding symbol table.

**Line:** 1052

---

### `def update_deps(module_id: str, nodes: list[FineGrainedDeferredNode], graph: dict[(str, State)], deps: dict[(str, set[str])], options: Options) -> None`

**Line:** 1071

---

### `def lookup_target(manager: BuildManager, target: str) -> tuple[(list[FineGrainedDeferredNode], TypeInfo | None)]`

**Description:**
Look up a target by fully-qualified name.

The first item in the return tuple is a list of deferred nodes that
needs to be reprocessed. If the target represents a TypeInfo corresponding
to a protocol, return it as a second item in the return tuple, otherwise None.

**Line:** 1092

---

### `def is_verbose(manager: BuildManager) -> bool`

**Line:** 1170

---

### `def target_from_node(module: str, node: FuncDef | MypyFile | OverloadedFuncDef) -> str | None`

**Description:**
Return the target name corresponding to a deferred node.

Args:
module: Must be module id of the module that defines 'node'

Returns the target name, or None if the node is not a valid target in the given
module (for example, if it's actually defined in another module).

**Line:** 1174

---

### `def refresh_suppressed_submodules(module: str, path: str | None, deps: dict[(str, set[str])], graph: Graph, fscache: FileSystemCache, refresh_file: Callable[([str, str], list[str])]) -> list[str] | None`

**Description:**
Look for submodules that are now suppressed in target package.

If a submodule a.b gets added, we need to mark it as suppressed
in modules that contain "from a import b". Previously we assumed
that 'a.b' is not a module but a regular name.

This is only relevant when following imports normally.

Args:
module: target package in which to look for submodules
path: path of the module
refresh_file: function that reads the AST of a module (returns error messages)

Return a list of errors from refresh_file() if it was called. If the
return value is None, we didn't call refresh_file().

**Line:** 1206

---

### `def extract_fnam_from_message(message: str) -> str | None`

**Line:** 1284

---

### `def extract_possible_fnam_from_message(message: str) -> str`

**Line:** 1291

---

### `def sort_messages_preserving_file_order(messages: list[str], prev_messages: list[str]) -> list[str]`

**Description:**
Sort messages so that the order of files is preserved.

An update generates messages so that the files can be in a fairly
arbitrary order.  Preserve the order of files to avoid messages
getting reshuffled continuously.  If there are messages in
additional files, sort them towards the end.

**Line:** 1296

---


## Module: venv2.libthon3.12.site-packages.mypy.sharedparse
**File:** `venv2/lib/python3.12/site-packages/mypy/sharedparse.py`

**Imports:**
- __future__.annotations
- typing.Final

**Functions:**

### `def special_function_elide_names(name: str) -> bool`

**Line:** 107

---

### `def argument_elide_name(name: str | None) -> bool`

**Line:** 111

---


## Module: venv2.libthon3.12.site-packages.mypy.solve
**File:** `venv2/lib/python3.12/site-packages/mypy/solve.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- mypy.constraints.Constraint
- mypy.constraints.SUBTYPE_OF
- mypy.constraints.SUPERTYPE_OF
- mypy.constraints.infer_constraints
- mypy.constraints.neg_op
- mypy.expandtype.expand_type
- mypy.graph_utils.prepare_sccs
- mypy.graph_utils.strongly_connected_components
- mypy.graph_utils.topsort
- mypy.join.join_types
- mypy.meet.meet_type_list
- mypy.meet.meet_types
- mypy.subtypes.is_subtype
- mypy.typeops.get_all_type_vars
- mypy.types.AnyType
- mypy.types.Instance
- mypy.types.NoneType
- mypy.types.ParamSpecType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeVarId
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.get_proper_type
- mypy.typestate.type_state
- typing.Iterable
- typing.Sequence
- typing_extensions.TypeAlias

**Functions:**

### `def solve_constraints(original_vars: Sequence[TypeVarLikeType], constraints: list[Constraint], strict: bool = True, allow_polymorphic: bool = False, skip_unsatisfied: bool = False) -> tuple[(list[Type | None], list[TypeVarLikeType])]`

**Description:**
Solve type constraints.

Return the best type(s) for type variables; each type can be None if the value of
the variable could not be solved.

If a variable has no constraints, if strict=True then arbitrarily
pick UninhabitedType as the value of the type variable. If strict=False, pick AnyType.
If allow_polymorphic=True, then use the full algorithm that can potentially return
free type variables in solutions (these require special care when applying). Otherwise,
use a simplified algorithm that just solves each type variable individually if possible.

The skip_unsatisfied flag matches the same one in applytype.apply_generic_arguments().

**Line:** 41

---

### `def solve_with_dependent(vars: list[TypeVarId], constraints: list[Constraint], original_vars: list[TypeVarId], originals: dict[(TypeVarId, TypeVarLikeType)]) -> tuple[(Solutions, list[TypeVarLikeType])]`

**Description:**
Solve set of constraints that may depend on each other, like T <: List[S].

The whole algorithm consists of five steps:
* Propagate via linear constraints and use secondary constraints to get transitive closure
* Find dependencies between type variables, group them in SCCs, and sort topologically
* Check that all SCC are intrinsically linear, we can't solve (express) T <: List[T]
* Variables in leaf SCCs that don't have constant bounds are free (choose one per SCC)
* Solve constraints iteratively starting from leafs, updating bounds after each step.

**Line:** 129

---

### `def solve_iteratively(batch: list[TypeVarId], graph: Graph, lowers: Bounds, uppers: Bounds) -> Solutions`

**Description:**
Solve transitive closure sequentially, updating upper/lower bounds after each step.

Transitive closure is represented as a linear graph plus lower/upper bounds for each
type variable, see transitive_closure() docstring for details.

We solve for type variables that appear in `batch`. If a bound is not constant (i.e. it
looks like T :> F[S, ...]), we substitute solutions found so far in the target F[S, ...]
after solving the batch.

Importantly, after solving each variable in a batch, we move it from linear graph to
upper/lower bounds, this way we can guarantee consistency of solutions (see comment below
for an example when this is important).

**Line:** 190

---

### `def solve_one(lowers: Iterable[Type], uppers: Iterable[Type]) -> Type | None`

**Description:**
Solve constraints by finding by using meets of upper bounds, and joins of lower bounds.

**Line:** 250

---

### `def choose_free(scc: list[TypeVarLikeType], original_vars: list[TypeVarId]) -> TypeVarLikeType | None`

**Description:**
Choose the best solution for an SCC containing only type variables.

This is needed to preserve e.g. the upper bound in a situation like this:
def dec(f: Callable[[T], S]) -> Callable[[T], S]: ...

@dec
def test(x: U) -> U: ...

where U <: A.

**Line:** 311

---

### `def is_trivial_bound(tp: ProperType, allow_tuple: bool = False) -> bool`

**Line:** 362

---

### `def find_linear(c: Constraint) -> tuple[(bool, TypeVarId | None)]`

**Description:**
Find out if this constraint represent a linear relationship, return target id if yes.

**Line:** 368

---

### `def transitive_closure(tvars: list[TypeVarId], constraints: list[Constraint]) -> tuple[(Graph, Bounds, Bounds)]`

**Description:**
Find transitive closure for given constraints on type variables.

Transitive closure gives maximal set of lower/upper bounds for each type variable,
such that we cannot deduce any further bounds by chaining other existing bounds.

The transitive closure is represented by:
* A set of lower and upper bounds for each type variable, where only constant and
non-linear terms are included in the bounds.
* A graph of linear constraints between type variables (represented as a set of pairs)
Such separation simplifies reasoning, and allows an efficient and simple incremental
transitive closure algorithm that we use here.

For example if we have initial constraints [T <: S, S <: U, U <: int], the transitive
closure is given by:
* {} <: T <: {int}
* {} <: S <: {int}
* {} <: U <: {int}
* {T <: S, S <: U, T <: U}

**Line:** 385

---

### `def add_secondary_constraints(cs: set[Constraint], lower: Type, upper: Type) -> None`

**Description:**
Add secondary constraints inferred between lower and upper (in place).

**Line:** 459

---

### `def compute_dependencies(tvars: list[TypeVarId], graph: Graph, lowers: Bounds, uppers: Bounds) -> dict[(TypeVarId, list[TypeVarId])]`

**Description:**
Compute dependencies between type variables induced by constraints.

If we have a constraint like T <: List[S], we say that T depends on S, since
we will need to solve for S first before we can solve for T.

**Line:** 473

---

### `def check_linear(scc: set[TypeVarId], lowers: Bounds, uppers: Bounds) -> bool`

**Description:**
Check there are only linear constraints between type variables in SCC.

Linear are constraints like T <: S (while T <: F[S] are non-linear).

**Line:** 497

---

### `def skip_reverse_union_constraints(cs: list[Constraint]) -> list[Constraint]`

**Description:**
Avoid ambiguities for constraints inferred from unions during polymorphic inference.

Polymorphic inference implicitly relies on assumption that a reverse of a linear constraint
is a linear constraint. This is however not true in presence of union types, for example
T :> Union[S, int] vs S <: T. Trying to solve such constraints would be detected ambiguous
as (T, S) form a non-linear SCC. However, simply removing the linear part results in a valid
solution T = Union[S, int], S = <free>.

TODO: a cleaner solution may be to avoid inferring such constraints in first place, but
this would require passing around a flag through all infer_constraints() calls.

**Line:** 510

---

### `def get_vars(target: Type, vars: list[TypeVarId]) -> set[TypeVarId]`

**Description:**
Find type variables for which we are solving in a target type.

**Line:** 532

---

### `def pre_validate_solutions(solutions: list[Type | None], original_vars: Sequence[TypeVarLikeType], constraints: list[Constraint]) -> list[Type | None]`

**Description:**
Check is each solution satisfies the upper bound of the corresponding type variable.

If it doesn't satisfy the bound, check if bound itself satisfies all constraints, and
if yes, use it instead as a fallback solution.

**Line:** 537

---


## Module: venv2.libthon3.12.site-packages.mypy.stats
**File:** `venv2/lib/python3.12/site-packages/mypy/stats.py`

**Imports:**
- __future__.annotations
- collections.Counter
- contextlib.contextmanager
- mypy.argmap.map_formals_to_actuals
- mypy.nodes
- mypy.nodes.AssignmentExpr
- mypy.nodes.AssignmentStmt
- mypy.nodes.BreakStmt
- mypy.nodes.BytesExpr
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.ComparisonExpr
- mypy.nodes.ComplexExpr
- mypy.nodes.ContinueStmt
- mypy.nodes.EllipsisExpr
- mypy.nodes.Expression
- mypy.nodes.ExpressionStmt
- mypy.nodes.FloatExpr
- mypy.nodes.FuncDef
- mypy.nodes.Import
- mypy.nodes.ImportAll
- mypy.nodes.ImportFrom
- mypy.nodes.IndexExpr
- mypy.nodes.IntExpr
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.Node
- mypy.nodes.OpExpr
- mypy.nodes.PassStmt
- mypy.nodes.RefExpr
- mypy.nodes.StrExpr
- mypy.nodes.TypeApplication
- mypy.nodes.UnaryExpr
- mypy.nodes.YieldFromExpr
- mypy.traverser.TraverserVisitor
- mypy.typeanal.collect_all_inner_types
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeQuery
- mypy.types.TypeVarType
- mypy.types.get_proper_type
- mypy.types.get_proper_types
- mypy.util.correct_relative_import
- os
- typing.Final
- typing.Iterator

**Functions:**

### `def dump_type_stats(tree: MypyFile, path: str, modules: dict[(str, MypyFile)], inferred: bool = False, typemap: dict[Expression, Type] | None = None) -> None`

**Line:** 415

---

### `def is_special_module(path: str) -> bool`

**Line:** 443

---

### `def is_imprecise(t: Type) -> bool`

**Line:** 447

---

### `def is_imprecise2(t: Type) -> bool`

**Line:** 459

---

### `def is_generic(t: Type) -> bool`

**Line:** 470

---

### `def is_complex(t: Type) -> bool`

**Line:** 475

---

### `def ensure_dir_exists(dir: str) -> None`

**Line:** 480

---

### `def is_special_form_any(t: AnyType) -> bool`

**Line:** 485

---

### `def get_original_any(t: AnyType) -> AnyType`

**Line:** 489

---


## Module: venv2.libthon3.12.site-packages.mypy.strconv
**File:** `venv2/lib/python3.12/site-packages/mypy/strconv.py`

**Imports:**
- __future__.annotations
- mypy.nodes
- mypy.options.Options
- mypy.patterns
- mypy.types
- mypy.types.Type
- mypy.types.TypeStrVisitor
- mypy.util.IdMapper
- mypy.util.short_type
- mypy.visitor.NodeVisitor
- os
- re
- typing.Any
- typing.Sequence
- typing.TYPE_CHECKING

**Functions:**

### `def dump_tagged(nodes: Sequence[object], tag: str | None, str_conv: StrConv) -> str`

**Description:**
Convert an array into a pretty-printed multiline string representation.

The format is
tag(
item1..
itemN)
Individual items are formatted like this:
- arrays are flattened
- pairs (str, array) are converted recursively, so that str is the tag
- other items are converted to strings and indented

**Line:** 600

---

### `def indent(s: str, n: int) -> str`

**Description:**
Indent all the lines in s (separated by newlines) by n spaces.

**Line:** 637

---


## Module: venv2.libthon3.12.site-packages.mypy.stubdoc
**File:** `venv2/lib/python3.12/site-packages/mypy/stubdoc.py`

**Imports:**
- __future__.annotations
- contextlib
- io
- keyword
- mypy.util
- re
- tokenize
- typing.Any
- typing.Final
- typing.MutableMapping
- typing.MutableSequence
- typing.NamedTuple
- typing.Sequence
- typing.Tuple
- typing_extensions.TypeAlias

**Functions:**

### `def is_valid_type(s: str) -> bool`

**Description:**
Try to determine whether a string might be a valid type annotation.

**Line:** 27

---

### `def infer_sig_from_docstring(docstr: str | None, name: str) -> list[FunctionSig] | None`

**Description:**
Convert function signature to list of FunctionSig

Look for function signatures of function in docstring. Signature is a string of
the format <function_name>(<signature>) -> <return type> or perhaps without
the return type.

Returns empty list, when no signature is found, one signature in typical case,
multiple signatures, if docstring specifies multiple signatures for overload functions.
Return None if the docstring is empty.

Arguments:
* docstr: docstring
* name: name of function for which signatures are to be found

**Line:** 322

---

### `def infer_arg_sig_from_anon_docstring(docstr: str) -> list[ArgSig]`

**Description:**
Convert signature in form of "(self: TestClass, arg0: str='ada')" to List[TypedArgList].

**Line:** 359

---

### `def infer_ret_type_sig_from_docstring(docstr: str, name: str) -> str | None`

**Description:**
Convert signature in form of "func(self: TestClass, arg0) -> int" to their return type.

**Line:** 367

---

### `def infer_ret_type_sig_from_anon_docstring(docstr: str) -> str | None`

**Description:**
Convert signature in form of "(self: TestClass, arg0) -> int" to their return type.

**Line:** 375

---

### `def parse_signature(sig: str) -> tuple[str, list[str], list[str]] | None`

**Description:**
Split function signature into its name, positional an optional arguments.

The expected format is "func_name(arg, opt_arg=False)". Return the name of function
and lists of positional and optional argument names.

**Line:** 380

---

### `def build_signature(positional: Sequence[str], optional: Sequence[str]) -> str`

**Description:**
Build function signature from lists of positional and optional argument names.

**Line:** 417

---

### `def parse_all_signatures(lines: Sequence[str]) -> tuple[(list[Sig], list[Sig])]`

**Description:**
Parse all signatures in a given reST document.

Return lists of found signatures for functions and classes.

**Line:** 432

---

### `def find_unique_signatures(sigs: Sequence[Sig]) -> list[Sig]`

**Description:**
Remove names with duplicate found signatures.

**Line:** 455

---

### `def infer_prop_type_from_docstring(docstr: str | None) -> str | None`

**Description:**
Check for Google/Numpy style docstring type annotation for a property.

The docstring has the format "<type>: <descriptions>".
In the type string, we allow the following characters:
* dot: because sometimes classes are annotated using full path
* brackets: to allow type hints like List[int]
* comma/space: things like Tuple[int, int]

**Line:** 468

---


## Module: venv2.libthon3.12.site-packages.mypy.stubgen
**File:** `venv2/lib/python3.12/site-packages/mypy/stubgen.py`

**Imports:**
- __future__.annotations
- argparse
- keyword
- mypy.build
- mypy.build.build
- mypy.errors.CompileError
- mypy.errors.Errors
- mypy.find_sources.InvalidSourceList
- mypy.find_sources.create_source_list
- mypy.mixedtraverser
- mypy.modulefinder.BuildSource
- mypy.modulefinder.FindModuleCache
- mypy.modulefinder.ModuleNotFoundReason
- mypy.modulefinder.SearchPaths
- mypy.modulefinder.default_lib_path
- mypy.moduleinspect.ModuleInspect
- mypy.moduleinspect.is_pyc_only
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.AssignmentStmt
- mypy.nodes.Block
- mypy.nodes.BytesExpr
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.ComparisonExpr
- mypy.nodes.ComplexExpr
- mypy.nodes.Decorator
- mypy.nodes.DictExpr
- mypy.nodes.EllipsisExpr
- mypy.nodes.Expression
- mypy.nodes.ExpressionStmt
- mypy.nodes.FloatExpr
- mypy.nodes.FuncBase
- mypy.nodes.FuncDef
- mypy.nodes.IS_ABSTRACT
- mypy.nodes.IfStmt
- mypy.nodes.Import
- mypy.nodes.ImportAll
- mypy.nodes.ImportFrom
- mypy.nodes.IndexExpr
- mypy.nodes.IntExpr
- mypy.nodes.ListExpr
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NOT_ABSTRACT
- mypy.nodes.NameExpr
- mypy.nodes.OpExpr
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.Statement
- mypy.nodes.StrExpr
- mypy.nodes.TempNode
- mypy.nodes.TupleExpr
- mypy.nodes.TypeInfo
- mypy.nodes.UnaryExpr
- mypy.nodes.Var
- mypy.options.Options
- mypy.parse
- mypy.stubdoc.ArgSig
- mypy.stubdoc.FunctionSig
- mypy.stubgenc.InspectionStubGenerator
- mypy.stubgenc.generate_stub_for_c_module
- mypy.stubutil.BaseStubGenerator
- mypy.stubutil.CantImport
- mypy.stubutil.ClassInfo
- mypy.stubutil.FunctionContext
- mypy.stubutil.common_dir_prefix
- mypy.stubutil.fail_missing
- mypy.stubutil.find_module_path_and_all_py3
- mypy.stubutil.generate_guarded
- mypy.stubutil.infer_method_arg_types
- mypy.stubutil.infer_method_ret_type
- mypy.stubutil.remove_misplaced_type_comments
- mypy.stubutil.report_missing
- mypy.stubutil.walk_packages
- mypy.traverser
- mypy.traverser.all_yield_expressions
- mypy.traverser.has_return_statement
- mypy.traverser.has_yield_expression
- mypy.traverser.has_yield_from_expression
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.OVERLOAD_NAMES
- mypy.types.TPDICT_NAMES
- mypy.types.TYPED_NAMEDTUPLE_NAMES
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.UnboundType
- mypy.types.get_proper_type
- mypy.util
- mypy.visitor.NodeVisitor
- os
- os.path
- sys
- traceback
- typing.Final
- typing.Iterable

**Functions:**

### `def find_defined_names(file: MypyFile) -> set[str]`

**Line:** 335

---

### `def find_referenced_names(file: MypyFile) -> set[str]`

**Line:** 359

---

### `def is_none_expr(expr: Expression) -> bool`

**Line:** 365

---

### `def find_method_names(defs: list[Statement]) -> set[str]`

**Line:** 1253

---

### `def find_self_initializers(fdef: FuncBase) -> list[tuple[(str, Expression)]]`

**Description:**
Find attribute initializers in a method.

Return a list of pairs (attribute name, r.h.s. expression).

**Line:** 1281

---

### `def get_qualified_name(o: Expression) -> str`

**Line:** 1291

---

### `def remove_blacklisted_modules(modules: list[StubSource]) -> list[StubSource]`

**Line:** 1300

---

### `def split_pyc_from_py(modules: list[StubSource]) -> tuple[(list[StubSource], list[StubSource])]`

**Line:** 1306

---

### `def is_blacklisted_path(path: str) -> bool`

**Line:** 1317

---

### `def normalize_path_separators(path: str) -> str`

**Line:** 1321

---

### `def collect_build_targets(options: Options, mypy_opts: MypyOptions) -> tuple[(list[StubSource], list[StubSource], list[StubSource])]`

**Description:**
Collect files for which we need to generate stubs.

Return list of py modules, pyc modules, and C modules.

**Line:** 1327

---

### `def find_module_paths_using_imports(modules: list[str], packages: list[str], verbose: bool, quiet: bool) -> tuple[(list[StubSource], list[StubSource])]`

**Description:**
Find path and runtime value of __all__ (if possible) for modules and packages.

This function uses runtime Python imports to get the information.

**Line:** 1359

---

### `def is_non_library_module(module: str) -> bool`

**Description:**
Does module look like a test module or a script?

**Line:** 1392

---

### `def translate_module_name(module: str, relative: int) -> tuple[(str, int)]`

**Line:** 1422

---

### `def find_module_paths_using_search(modules: list[str], packages: list[str], search_path: list[str], pyversion: tuple[(int, int)]) -> list[StubSource]`

**Description:**
Find sources for modules and packages requested.

This function just looks for source files at the file system level.
This is used if user passes --no-import, and will not find C modules.
Exit if some of the modules or packages can't be found.

**Line:** 1433

---

### `def mypy_options(stubgen_options: Options) -> MypyOptions`

**Description:**
Generate mypy options using the flag passed by user.

**Line:** 1466

---

### `def parse_source_file(mod: StubSource, mypy_options: MypyOptions) -> None`

**Description:**
Parse a source file.

On success, store AST in the corresponding attribute of the stub source.
If there are syntax errors, print them and exit.

**Line:** 1488

---

### `def generate_asts_for_modules(py_modules: list[StubSource], parse_only: bool, mypy_options: MypyOptions, verbose: bool) -> None`

**Description:**
Use mypy to parse (and optionally analyze) source files.

**Line:** 1510

---

### `def generate_stub_for_py_module(mod: StubSource, target: str, parse_only: bool = False, inspect: bool = False, include_private: bool = False, export_less: bool = False, include_docstrings: bool = False, doc_dir: str = '', all_modules: list[str]) -> None`

**Description:**
Use analysed (or just parsed) AST to generate type stub for single file.

If directory for target doesn't exist it will created. Existing stub
will be overwritten.

**Line:** 1535

---

### `def generate_stubs(options: Options) -> None`

**Description:**
Main entry point for the program.

**Line:** 1585

---

### `def parse_options(args: list[str]) -> Options`

**Line:** 1653

---

### `def main(args: list[str] | None = None) -> None`

**Line:** 1788

---


## Module: venv2.libthon3.12.site-packages.mypy.stubgenc
**File:** `venv2/lib/python3.12/site-packages/mypy/stubgenc.py`

**Imports:**
- __future__.annotations
- glob
- importlib
- inspect
- keyword
- mypy.fastparse.parse_type_comment
- mypy.moduleinspect.is_c_module
- mypy.stubdoc.ArgSig
- mypy.stubdoc.FunctionSig
- mypy.stubdoc.Sig
- mypy.stubdoc.find_unique_signatures
- mypy.stubdoc.infer_arg_sig_from_anon_docstring
- mypy.stubdoc.infer_prop_type_from_docstring
- mypy.stubdoc.infer_ret_type_sig_from_anon_docstring
- mypy.stubdoc.infer_ret_type_sig_from_docstring
- mypy.stubdoc.infer_sig_from_docstring
- mypy.stubdoc.parse_all_signatures
- mypy.stubutil.BaseStubGenerator
- mypy.stubutil.ClassInfo
- mypy.stubutil.FunctionContext
- mypy.stubutil.SignatureGenerator
- mypy.stubutil.infer_method_arg_types
- mypy.stubutil.infer_method_ret_type
- os.path
- types.FunctionType
- types.ModuleType
- typing.Any
- typing.Mapping

**Functions:**

### `def is_pybind11_overloaded_function_docstring(docstring: str, name: str) -> bool`

**Line:** 138

---

### `def generate_stub_for_c_module(module_name: str, target: str, known_modules: list[str], doc_dir: str = '', include_private: bool = False, export_less: bool = False, include_docstrings: bool = False) -> None`

**Description:**
Generate stub for C module.

Signature generators are called in order until a list of signatures is returned.  The order
is:
- signatures inferred from .rst documentation (if given)
- simple runtime introspection (looking for docstrings and attributes
with simple builtin types)
- fallback based special method names or "(*args, **kwargs)"

If directory for target doesn't exist it will be created. Existing stub
will be overwritten.

**Line:** 142

---

### `def method_name_sort_key(name: str) -> tuple[(int, str)]`

**Description:**
Sort methods in classes in a typical order.

I.e.: constructor, normal methods, special methods.

**Line:** 824

---

### `def is_pybind_skipped_attribute(attr: str) -> bool`

**Line:** 836

---

### `def infer_c_method_args(name: str, self_var: str = 'self', arg_names: list[str] | None = None) -> list[ArgSig]`

**Line:** 840

---


## Module: venv2.libthon3.12.site-packages.mypy.stubinfo
**File:** `venv2/lib/python3.12/site-packages/mypy/stubinfo.py`

**Imports:**
- __future__.annotations

**Functions:**

### `def is_legacy_bundled_package(prefix: str) -> bool`

**Line:** 4

---

### `def approved_stub_package_exists(prefix: str) -> bool`

**Line:** 8

---

### `def stub_distribution_name(prefix: str) -> str`

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.mypy.stubtest
**File:** `venv2/lib/python3.12/site-packages/mypy/stubtest.py`

**Imports:**
- __future__.annotations
- argparse
- collections.abc
- collections.defaultdict
- contextlib.redirect_stderr
- contextlib.redirect_stdout
- copy
- enum
- functools.singledispatch
- importlib
- importlib.machinery
- inspect
- mypy.build
- mypy.config_parser.parse_config_file
- mypy.evalexpr.UNKNOWN
- mypy.evalexpr.evaluate_expression
- mypy.modulefinder
- mypy.nodes
- mypy.options.Options
- mypy.state
- mypy.types
- mypy.util.FancyFormatter
- mypy.util.bytes_to_human_readable_repr
- mypy.util.is_dunder
- mypy.util.plural_s
- mypy.version
- os
- pathlib.Path
- pkgutil
- re
- symtable
- sys
- traceback
- types
- typing
- typing.AbstractSet
- typing.Any
- typing.Generic
- typing.Iterator
- typing.TypeVar
- typing.Union
- typing_extensions
- typing_extensions.get_origin
- typing_extensions.is_typeddict
- warnings

**Functions:**

### `def _style(message: str, **kwargs: Any) -> str`

**Description:**
Wrapper around mypy.util for fancy formatting.

**Line:** 61

---

### `def _truncate(message: str, length: int) -> str`

**Line:** 67

---

### `def silent_import_module(module_name: str) -> types.ModuleType`

**Line:** 180

---

### `def test_module(module_name: str) -> Iterator[Error]`

**Description:**
Tests a given module's stub against introspecting it at runtime.

Requires the stub to have been built already, accomplished by a call to ``build_stubs``.

:param module_name: The module to test

**Line:** 192

---

### `def verify(stub: MaybeMissing[nodes.Node], runtime: MaybeMissing[Any], object_path: list[str]) -> Iterator[Error]`

**Decorators:**
- `@singledispatch`

**Description:**
Entry point for comparing a stub to a runtime object.

We use single dispatch based on the type of ``stub``.

:param stub: The mypy node representing a part of the stub
:param runtime: The runtime object corresponding to ``stub``

**Line:** 249

---

### `def _verify_exported_names(object_path: list[str], stub: nodes.MypyFile, runtime_all_as_set: set[str]) -> Iterator[Error]`

**Line:** 263

---

### `def _get_imported_symbol_names(runtime: types.ModuleType) -> frozenset[str] | None`

**Description:**
Retrieve the names in the global namespace which are known to be imported.

1). Use inspect to retrieve the source code of the module
2). Use symtable to parse the source and retrieve names that are known to be imported
from other modules.

If either of the above steps fails, return `None`.

Note that if a set of names is returned,
it won't include names imported via `from foo import *` imports.

**Line:** 294

---

### `def verify_mypyfile(stub: nodes.MypyFile, runtime: MaybeMissing[types.ModuleType], object_path: list[str]) -> Iterator[Error]`

**Decorators:**
- `@verify.register(...)`

**Line:** 325

---

### `def _verify_final(stub: nodes.TypeInfo, runtime: type[Any], object_path: list[str]) -> Iterator[Error]`

**Line:** 406

---

### `def _verify_metaclass(stub: nodes.TypeInfo, runtime: type[Any], object_path: list[str], is_runtime_typeddict: bool) -> Iterator[Error]`

**Line:** 445

---

### `def verify_typeinfo(stub: nodes.TypeInfo, runtime: MaybeMissing[type[Any]], object_path: list[str]) -> Iterator[Error]`

**Decorators:**
- `@verify.register(...)`

**Line:** 484

---

### `def _static_lookup_runtime(object_path: list[str]) -> MaybeMissing[Any]`

**Line:** 548

---

### `def _verify_static_class_methods(stub: nodes.FuncBase, runtime: Any, static_runtime: MaybeMissing[Any], object_path: list[str]) -> Iterator[str]`

**Line:** 561

---

### `def _verify_arg_name(stub_arg: nodes.Argument, runtime_arg: inspect.Parameter, function_name: str) -> Iterator[str]`

**Description:**
Checks whether argument names match.

**Line:** 590

---

### `def _verify_arg_default_value(stub_arg: nodes.Argument, runtime_arg: inspect.Parameter) -> Iterator[str]`

**Description:**
Checks whether argument default values are compatible.

**Line:** 623

---

### `def maybe_strip_cls(name: str, args: list[nodes.Argument]) -> list[nodes.Argument]`

**Line:** 681

---

### `def _verify_signature(stub: Signature[nodes.Argument], runtime: Signature[inspect.Parameter], function_name: str) -> Iterator[str]`

**Line:** 854

---

### `def verify_funcitem(stub: nodes.FuncItem, runtime: MaybeMissing[Any], object_path: list[str]) -> Iterator[Error]`

**Decorators:**
- `@verify.register(...)`

**Line:** 960

---

### `def verify_none(stub: Missing, runtime: MaybeMissing[Any], object_path: list[str]) -> Iterator[Error]`

**Decorators:**
- `@verify.register(...)`

**Line:** 1022

---

### `def verify_var(stub: nodes.Var, runtime: MaybeMissing[Any], object_path: list[str]) -> Iterator[Error]`

**Decorators:**
- `@verify.register(...)`

**Line:** 1029

---

### `def verify_overloadedfuncdef(stub: nodes.OverloadedFuncDef, runtime: MaybeMissing[Any], object_path: list[str]) -> Iterator[Error]`

**Decorators:**
- `@verify.register(...)`

**Line:** 1066

---

### `def verify_typevarexpr(stub: nodes.TypeVarExpr, runtime: MaybeMissing[Any], object_path: list[str]) -> Iterator[Error]`

**Decorators:**
- `@verify.register(...)`

**Line:** 1129

---

### `def verify_paramspecexpr(stub: nodes.ParamSpecExpr, runtime: MaybeMissing[Any], object_path: list[str]) -> Iterator[Error]`

**Decorators:**
- `@verify.register(...)`

**Line:** 1145

---

### `def _verify_readonly_property(stub: nodes.Decorator, runtime: Any) -> Iterator[str]`

**Line:** 1161

---

### `def _verify_abstract_status(stub: nodes.FuncDef, runtime: Any) -> Iterator[str]`

**Line:** 1184

---

### `def _verify_final_method(stub: nodes.FuncDef, runtime: Any, static_runtime: MaybeMissing[Any]) -> Iterator[str]`

**Line:** 1193

---

### `def _resolve_funcitem_from_decorator(dec: nodes.OverloadPart) -> nodes.FuncItem | None`

**Description:**
Returns a FuncItem that corresponds to the output of the decorator.

Returns None if we can't figure out what that would be. For convenience, this function also
accepts FuncItems.

**Line:** 1204

---

### `def verify_decorator(stub: nodes.Decorator, runtime: MaybeMissing[Any], object_path: list[str]) -> Iterator[Error]`

**Decorators:**
- `@verify.register(...)`

**Line:** 1253

---

### `def verify_typealias(stub: nodes.TypeAlias, runtime: MaybeMissing[Any], object_path: list[str]) -> Iterator[Error]`

**Decorators:**
- `@verify.register(...)`

**Line:** 1272

---

### `def is_probably_private(name: str) -> bool`

**Line:** 1425

---

### `def is_probably_a_function(runtime: Any) -> bool`

**Line:** 1429

---

### `def is_read_only_property(runtime: object) -> bool`

**Line:** 1437

---

### `def safe_inspect_signature(runtime: Any) -> inspect.Signature | None`

**Line:** 1441

---

### `def is_subtype_helper(left: mypy.types.Type, right: mypy.types.Type) -> bool`

**Description:**
Checks whether ``left`` is a subtype of ``right``.

**Line:** 1452

---

### `def get_mypy_type_of_runtime_value(runtime: Any) -> mypy.types.Type | None`

**Description:**
Returns a mypy type object representing the type of ``runtime``.

Returns None if we can't find something that works.

**Line:** 1475

---

### `def build_stubs(modules: list[str], options: Options, find_submodules: bool = False) -> list[str]`

**Description:**
Uses mypy to construct stub objects for the given modules.

This sets global state that ``get_stub`` can access.

Returns all modules we might want to check. If ``find_submodules`` is False, this is equal
to ``modules``.

:param modules: List of modules to build stubs for.
:param options: Mypy options for finding and building stubs.
:param find_submodules: Whether to attempt to find submodules of the given modules as well.

**Line:** 1579

---

### `def get_stub(module: str) -> nodes.MypyFile | None`

**Description:**
Returns a stub object for the given module, if we've built one.

**Line:** 1640

---

### `def get_typeshed_stdlib_modules(custom_typeshed_dir: str | None, version_info: tuple[int, int] | None = None) -> set[str]`

**Description:**
Returns a list of stdlib modules in typeshed (for current Python version).

**Line:** 1645

---

### `def get_importable_stdlib_modules() -> set[str]`

**Description:**
Return all importable stdlib modules at runtime.

**Line:** 1679

---

### `def get_allowlist_entries(allowlist_file: str) -> Iterator[str]`

**Line:** 1758

---

### `def test_stubs(args: _Arguments, use_builtins_fixtures: bool = False) -> int`

**Description:**
This is stubtest! It's time to test the stubs!

**Line:** 1790

---

### `def parse_options(args: list[str]) -> _Arguments`

**Line:** 1910

---

### `def main() -> int`

**Line:** 1972

---


## Module: venv2.libthon3.12.site-packages.mypy.stubutil
**File:** `venv2/lib/python3.12/site-packages/mypy/stubutil.py`

**Imports:**
- __future__.annotations
- abc.abstractmethod
- collections.defaultdict
- contextlib.contextmanager
- mypy.modulefinder.ModuleNotFoundReason
- mypy.moduleinspect.InspectError
- mypy.moduleinspect.ModuleInspect
- mypy.options
- mypy.stubdoc.ArgSig
- mypy.stubdoc.FunctionSig
- mypy.types.AnyType
- mypy.types.NoneType
- mypy.types.Type
- mypy.types.TypeList
- mypy.types.TypeStrVisitor
- mypy.types.UnboundType
- mypy.types.UnionType
- mypy_extensions.mypyc_attr
- os.path
- re
- sys
- typing.Final
- typing.Iterable
- typing.Iterator
- typing.Mapping
- typing_extensions.overload

**Functions:**

### `def walk_packages(inspect: ModuleInspect, packages: list[str], verbose: bool = False) -> Iterator[str]`

**Description:**
Iterates through all packages and sub-packages in the given list.

This uses runtime imports (in another process) to find both Python and C modules.
For Python packages we simply pass the __path__ attribute to pkgutil.walk_packages() to
get the content of the package (all subpackages and modules).  However, packages in C
extensions do not have this attribute, so we have to roll out our own logic: recursively
find all modules imported in the package that have matching names.

**Line:** 32

---

### `def find_module_path_using_sys_path(module: str, sys_path: list[str]) -> str | None`

**Line:** 62

---

### `def find_module_path_and_all_py3(inspect: ModuleInspect, module: str, verbose: bool) -> tuple[str | None, list[str] | None] | None`

**Description:**
Find module and determine __all__ for a Python 3 module.

Return None if the module is a C or pyc-only module.
Return (module_path, __all__) if it is a Python module.
Raise CantImport if import failed.

**Line:** 75

---

### `def generate_guarded(mod: str, target: str, ignore_errors: bool = True, verbose: bool = False) -> Iterator[None]`

**Decorators:**
- `@contextmanager`

**Description:**
Ignore or report errors during stub generation.

Optionally report success.

**Line:** 104

---

### `def report_missing(mod: str, message: str | None = '', traceback: str = '') -> None`

**Line:** 126

---

### `def fail_missing(mod: str, reason: ModuleNotFoundReason) -> None`

**Line:** 132

---

### `def remove_misplaced_type_comments(source: bytes) -> bytes`

**Decorators:**
- `@overload`

**Line:** 143

---

### `def remove_misplaced_type_comments(source: str) -> str`

**Decorators:**
- `@overload`

**Line:** 148

---

### `def remove_misplaced_type_comments(source: str | bytes) -> str | bytes`

**Description:**
Remove comments from source that could be understood as misplaced type comments.

Normal comments may look like misplaced type comments, and since they cause blocking
parse errors, we want to avoid them.

**Line:** 152

---

### `def common_dir_prefix(paths: list[str]) -> str`

**Line:** 182

---

### `def infer_method_ret_type(name: str) -> str | None`

**Description:**
Infer return types for known special methods

**Line:** 314

---

### `def infer_method_arg_types(name: str, self_var: str = 'self', arg_names: list[str] | None = None) -> list[ArgSig] | None`

**Description:**
Infer argument types for known special methods

**Line:** 332

---


## Module: venv2.libthon3.12.site-packages.mypy.subtypes
**File:** `venv2/lib/python3.12/site-packages/mypy/subtypes.py`

**Imports:**
- __future__.annotations
- contextlib.contextmanager
- mypy.applytype
- mypy.constraints
- mypy.erasetype.erase_type
- mypy.expandtype.expand_self_type
- mypy.expandtype.expand_type_by_instance
- mypy.maptype.map_instance_to_supertype
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.CONTRAVARIANT
- mypy.nodes.COVARIANT
- mypy.nodes.Decorator
- mypy.nodes.FuncBase
- mypy.nodes.INVARIANT
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.options.Options
- mypy.solve
- mypy.state.state
- mypy.typeops
- mypy.typeops.bind_self
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.ErasedType
- mypy.types.FormalArgument
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.MYPYC_NATIVE_INT_NAMES
- mypy.types.NoneType
- mypy.types.NormalizedCallableType
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TUPLE_LIKE_INSTANCE_NAMES
- mypy.types.TYPED_NAMEDTUPLE_NAMES
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypeVisitor
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.find_unpack_in_list
- mypy.types.get_proper_type
- mypy.types.is_named_instance
- mypy.types.split_with_prefix_and_suffix
- mypy.types_utils.flatten_types
- mypy.typestate.SubtypeKind
- mypy.typestate.type_state
- mypy.typevars.fill_typevars_with_any
- typing.Any
- typing.Callable
- typing.Final
- typing.Iterator
- typing.List
- typing.TypeVar
- typing.cast
- typing_extensions.TypeAlias

**Functions:**

### `def is_subtype(left: Type, right: Type, subtype_context: SubtypeContext | None = None, ignore_type_params: bool = False, ignore_pos_arg_names: bool = False, ignore_declared_variance: bool = False, ignore_promotions: bool = False, ignore_uninhabited: bool = False, options: Options | None = None) -> bool`

**Description:**
Is 'left' subtype of 'right'?

Also consider Any to be a subtype of any type, and vice versa. This
recursively applies to components of composite types (List[int] is subtype
of List[Any], for example).

type_parameter_checker is used to check the type parameters (for example,
A with B in is_subtype(C[A], C[B]). The default checks for subtype relation
between the type arguments (e.g., A and B), taking the variance of the
type var into account.

**Line:** 114

---

### `def is_proper_subtype(left: Type, right: Type, subtype_context: SubtypeContext | None = None, ignore_promotions: bool = False, ignore_uninhabited: bool = False, erase_instances: bool = False, keep_erased_types: bool = False) -> bool`

**Description:**
Is left a proper subtype of right?

For proper subtypes, there's no need to rely on compatibility due to
Any types. Every usable type is a proper subtype of itself.

If erase_instances is True, erase left instance *after* mapping it to supertype
(this is useful for runtime isinstance() checks). If keep_erased_types is True,
do not consider ErasedType a subtype of all types (used by type inference against unions).

**Line:** 182

---

### `def is_equivalent(a: Type, b: Type, ignore_type_params: bool = False, ignore_pos_arg_names: bool = False, options: Options | None = None, subtype_context: SubtypeContext | None = None) -> bool`

**Line:** 227

---

### `def is_same_type(a: Type, b: Type, ignore_promotions: bool = True, subtype_context: SubtypeContext | None = None) -> bool`

**Description:**
Are these types proper subtypes of each other?

This means types may have different representation (e.g. an alias, or
a non-simplified union) but are semantically exchangeable in all contexts.

**Line:** 253

---

### `def _is_subtype(left: Type, right: Type, subtype_context: SubtypeContext, proper_subtype: bool) -> bool`

**Line:** 286

---

### `def check_type_parameter(left: Type, right: Type, variance: int, proper_subtype: bool, subtype_context: SubtypeContext) -> bool`

**Line:** 355

---

### `def pop_on_exit(stack: list[tuple[(T, T)]], left: T, right: T) -> Iterator[None]`

**Decorators:**
- `@contextmanager`

**Line:** 1077

---

### `def is_protocol_implementation(left: Instance, right: Instance, proper_subtype: bool = False, class_obj: bool = False, skip: list[str] | None = None, options: Options | None = None) -> bool`

**Description:**
Check whether 'left' implements the protocol 'right'.

If 'proper_subtype' is True, then check for a proper subtype.
Treat recursive protocols by using the 'assuming' structural subtype matrix
(in sparse representation, i.e. as a list of pairs (subtype, supertype)),
see also comment in nodes.TypeInfo. When we enter a check for classes
(A, P), defined as following::

class P(Protocol):
def f(self) -> P: ...
class A:
def f(self) -> A: ...

this results in A being a subtype of P without infinite recursion.
On every false result, we pop the assumption, thus avoiding an infinite recursion
as well.

**Line:** 1083

---

### `def find_member(name: str, itype: Instance, subtype: Type, is_operator: bool = False, class_obj: bool = False) -> Type | None`

**Description:**
Find the type of member by 'name' in 'itype's TypeInfo.

Find the member type after applying type arguments from 'itype', and binding
'self' to 'subtype'. Return None if member was not found.

**Line:** 1203

---

### `def get_member_flags(name: str, itype: Instance, class_obj: bool = False) -> set[int]`

**Description:**
Detect whether a member 'name' is settable, whether it is an
instance or class variable, and whether it is class or static method.

The flags are defined as following:
* IS_SETTABLE: whether this attribute can be set, not set for methods and
non-settable properties;
* IS_CLASSVAR: set if the variable is annotated as 'x: ClassVar[t]';
* IS_CLASS_OR_STATIC: set for methods decorated with @classmethod or
with @staticmethod.

**Line:** 1262

---

### `def find_node_type(node: Var | FuncBase, itype: Instance, subtype: Type, class_obj: bool = False) -> Type`

**Description:**
Find type of a variable or method 'node' (maybe also a decorated method).
Apply type arguments from 'itype', and bind 'self' to 'subtype'.

**Line:** 1317

---

### `def non_method_protocol_members(tp: TypeInfo) -> list[str]`

**Description:**
Find all non-callable members of a protocol.

**Line:** 1362

---

### `def is_callable_compatible(left: CallableType, right: CallableType, is_compat: Callable[([Type, Type], bool)], is_proper_subtype: bool, is_compat_return: Callable[[Type, Type], bool] | None = None, ignore_return: bool = False, ignore_pos_arg_names: bool = False, check_args_covariantly: bool = False, allow_partial_overlap: bool = False, strict_concatenate: bool = False, no_unify_none: bool = False) -> bool`

**Description:**
Is the left compatible with the right, using the provided compatibility check?

is_compat:
The check we want to run against the parameters.

is_compat_return:
The check we want to run against the return type.
If None, use the 'is_compat' check.

check_args_covariantly:
If true, check if the left's args is compatible with the right's
instead of the other way around (contravariantly).

This function is mostly used to check if the left is a subtype of the right which
is why the default is to check the args contravariantly. However, it's occasionally
useful to check the args using some other check, so we leave the variance
configurable.

For example, when checking the validity of overloads, it's useful to see if
the first overload alternative has more precise arguments then the second.
We would want to check the arguments covariantly in that case.

Note! The following two function calls are NOT equivalent:

is_callable_compatible(f, g, is_compat=is_subtype, check_args_covariantly=False)
is_callable_compatible(g, f, is_compat=is_subtype, check_args_covariantly=True)

The two calls are similar in that they both check the function arguments in
the same direction: they both run `is_subtype(argument_from_g, argument_from_f)`.

However, the two calls differ in which direction they check things like
keyword arguments. For example, suppose f and g are defined like so:

def f(x: int, *y: int) -> int: ...
def g(x: int) -> int: ...

In this case, the first call will succeed and the second will fail: f is a
valid stand-in for g but not vice-versa.

allow_partial_overlap:
By default this function returns True if and only if *all* calls to left are
also calls to right (with respect to the provided 'is_compat' function).

If this parameter is set to 'True', we return True if *there exists at least one*
call to left that's also a call to right.

In other words, we perform an existential check instead of a universal one;
we require left to only overlap with right instead of being a subset.

For example, suppose we set 'is_compat' to some subtype check and compare following:

f(x: float, y: str = "...", *args: bool) -> str
g(*args: int) -> str

This function would normally return 'False': f is not a subtype of g.
However, we would return True if this parameter is set to 'True': the two
calls are compatible if the user runs "f_or_g(3)". In the context of that
specific call, the two functions effectively have signatures of:

f2(float) -> str
g2(int) -> str

Here, f2 is a valid subtype of g2 so we return True.

Specifically, if this parameter is set this function will:

-   Ignore optional arguments on either the left or right that have no
corresponding match.
-   No longer mandate optional arguments on either side are also optional
on the other.
-   No longer mandate that if right has a *arg or **kwarg that left must also
have the same.

Note: when this argument is set to True, this function becomes "symmetric" --
the following calls are equivalent:

is_callable_compatible(f, g,
is_compat=some_check,
check_args_covariantly=False,
allow_partial_overlap=True)
is_callable_compatible(g, f,
is_compat=some_check,
check_args_covariantly=True,
allow_partial_overlap=True)

If the 'some_check' function is also symmetric, the two calls would be equivalent
whether or not we check the args covariantly.

**Line:** 1377

---

### `def are_trivial_parameters(param: Parameters | NormalizedCallableType) -> bool`

**Line:** 1549

---

### `def is_trivial_suffix(param: Parameters | NormalizedCallableType) -> bool`

**Line:** 1561

---

### `def are_parameters_compatible(left: Parameters | NormalizedCallableType, right: Parameters | NormalizedCallableType, is_compat: Callable[([Type, Type], bool)], is_proper_subtype: bool, ignore_pos_arg_names: bool = False, allow_partial_overlap: bool = False, strict_concatenate_check: bool = False) -> bool`

**Description:**
Helper function for is_callable_compatible, used for Parameter compatibility

**Line:** 1573

---

### `def are_args_compatible(left: FormalArgument, right: FormalArgument, is_compat: Callable[([Type, Type], bool)], ignore_pos_arg_names: bool, allow_partial_overlap: bool, allow_imprecise_kinds: bool = False) -> bool`

**Line:** 1759

---

### `def flip_compat_check(is_compat: Callable[([Type, Type], bool)]) -> Callable[([Type, Type], bool)]`

**Line:** 1812

---

### `def unify_generic_callable(type: NormalizedCallableType, target: NormalizedCallableType, ignore_return: bool, return_constraint_direction: int | None = None, no_unify_none: bool = False) -> NormalizedCallableType | None`

**Description:**
Try to unify a generic callable type with another callable type.

Return unified CallableType if successful; otherwise, return None.

**Line:** 1819

---

### `def try_restrict_literal_union(t: UnionType, s: Type) -> list[Type] | None`

**Description:**
Return the items of t, excluding any occurrence of s, if and only if
- t only contains simple literals
- s is a simple literal

Otherwise, returns None

**Line:** 1877

---

### `def restrict_subtype_away(t: Type, s: Type) -> Type`

**Description:**
Return t minus s for runtime type assertions.

If we can't determine a precise result, return a supertype of the
ideal result (just t is a valid result).

This is used for type inference of runtime type checks such as
isinstance(). Currently, this just removes elements of a union type.

**Line:** 1898

---

### `def covers_at_runtime(item: Type, supertype: Type) -> bool`

**Description:**
Will isinstance(item, supertype) always return True at runtime?

**Line:** 1923

---

### `def is_more_precise(left: Type, right: Type, ignore_promotions: bool = False) -> bool`

**Description:**
Check if left is a more precise type than right.

A left is a proper subtype of right, left is also more precise than
right. Also, if right is Any, left is more precise than right, for
any left.

**Line:** 1954

---


## Module: venv2.libthon3.12.site-packages.mypy.suggestions
**File:** `venv2/lib/python3.12/site-packages/mypy/suggestions.py`

**Imports:**
- __future__.annotations
- contextlib.contextmanager
- itertools
- json
- mypy.argmap.map_actuals_to_formals
- mypy.build.Graph
- mypy.build.State
- mypy.checkexpr.has_any_type
- mypy.find_sources.InvalidSourceList
- mypy.find_sources.SourceFinder
- mypy.join.join_type_list
- mypy.meet.meet_type_list
- mypy.modulefinder.PYTHON_EXTENSIONS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.ArgKind
- mypy.nodes.CallExpr
- mypy.nodes.Decorator
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.MypyFile
- mypy.nodes.RefExpr
- mypy.nodes.ReturnStmt
- mypy.nodes.SymbolNode
- mypy.nodes.SymbolTable
- mypy.nodes.TypeInfo
- mypy.nodes.reverse_builtin_aliases
- mypy.options.Options
- mypy.plugin.FunctionContext
- mypy.plugin.MethodContext
- mypy.plugin.Plugin
- mypy.server.update.FineGrainedBuildManager
- mypy.state.state
- mypy.traverser.TraverserVisitor
- mypy.typeops.make_simplified_union
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.NoneType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeOfAny
- mypy.types.TypeStrVisitor
- mypy.types.TypeTranslator
- mypy.types.TypeVarType
- mypy.types.TypedDictType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.get_proper_type
- mypy.types_utils.is_overlapping_none
- mypy.types_utils.remove_optional
- mypy.util.split_target
- os
- typing.Callable
- typing.Iterator
- typing.NamedTuple
- typing.TypeVar
- typing.cast
- typing_extensions.TypedDict

**Functions:**

### `def get_return_types(typemap: dict[(Expression, Type)], func: FuncDef) -> list[Type]`

**Description:**
Find all the types returned by return statements in func.

**Line:** 156

---

### `def get_arg_uses(typemap: dict[(Expression, Type)], func: FuncDef) -> list[list[Type]]`

**Description:**
Find all the types of arguments that each arg is passed to.

For example, given
def foo(x: int) -> None: ...
def bar(x: str) -> None: ...
def test(x, y):
foo(x)
bar(y)

this will return [[int], [str]].

**Line:** 196

---

### `def is_explicit_any(typ: AnyType) -> bool`

**Line:** 217

---

### `def is_implicit_any(typ: Type) -> bool`

**Line:** 227

---

### `def any_score_type(ut: Type, arg_pos: bool) -> float`

**Description:**
Generate a very made up number representing the Anyness of a type.

Higher is better, 1.0 is max

**Line:** 767

---

### `def any_score_callable(t: CallableType, is_method: bool, ignore_return: bool) -> float`

**Line:** 790

---

### `def is_tricky_callable(t: CallableType) -> bool`

**Description:**
Is t a callable that we need to put a ... in for syntax reasons?

**Line:** 803

---

### `def make_suggestion_anys(t: TType) -> TType`

**Description:**
Make all anys in the type as coming from the suggestion engine.

This keeps those Anys from influencing constraint generation,
which allows us to do better when refining types.

**Line:** 894

---

### `def generate_type_combinations(types: list[Type]) -> list[Type]`

**Description:**
Generate possible combinations of a list of types.

mypy essentially supports two different ways to do this: joining the types
and unioning the types. We try both.

**Line:** 914

---

### `def count_errors(msgs: list[str]) -> int`

**Line:** 928

---

### `def refine_type(ti: Type, si: Type) -> Type`

**Description:**
Refine `ti` by replacing Anys in it with information taken from `si`

This basically works by, when the types have the same structure,
traversing both of them in parallel and replacing Any on the left
with whatever the type on the right is. If the types don't have the
same structure (or aren't supported), the left type is chosen.

For example:
refine(Any, T) = T,  for all T
refine(float, int) = float
refine(List[Any], List[int]) = List[int]
refine(Dict[int, Any], Dict[Any, int]) = Dict[int, int]
refine(Tuple[int, Any], Tuple[Any, int]) = Tuple[int, int]

refine(Callable[[Any], Any], Callable[[int], int]) = Callable[[int], int]
refine(Callable[..., int], Callable[[int, float], Any]) = Callable[[int, float], int]

refine(Optional[Any], int) = Optional[int]
refine(Optional[Any], Optional[int]) = Optional[int]
refine(Optional[Any], Union[int, str]) = Optional[Union[int, str]]
refine(Optional[List[Any]], List[int]) = List[int]

**Line:** 932

---

### `def refine_union(t: UnionType, s: ProperType) -> Type`

**Description:**
Refine a union type based on another type.

This is done by refining every component of the union against the
right hand side type (or every component of its union if it is
one). If an element of the union is successfully refined, we drop it
from the union in favor of the refined versions.

**Line:** 985

---

### `def refine_callable(t: CallableType, s: CallableType) -> CallableType`

**Description:**
Refine a callable based on another.

See comments for refine_type.

**Line:** 1018

---

### `def dedup(old: list[T]) -> list[T]`

**Line:** 1041

---


## Module: venv2.libthon3.12.site-packages.mypy.test.data
**File:** `venv2/lib/python3.12/site-packages/mypy/test/data.py`

**Imports:**
- __future__.annotations
- abc.abstractmethod
- dataclasses.dataclass
- mypy.defaults
- mypy.test.config.PREFIX
- mypy.test.config.test_data_prefix
- mypy.test.config.test_temp_dir
- os
- os.path
- pathlib.Path
- posixpath
- pytest
- re
- shutil
- sys
- tempfile
- typing.Any
- typing.Final
- typing.Iterator
- typing.NamedTuple
- typing.NoReturn
- typing.Pattern
- typing.Union
- typing_extensions.TypeAlias

**Functions:**

### `def _file_arg_to_module(filename: str) -> str`

**Line:** 47

---

### `def parse_test_case(case: DataDrivenTestCase) -> None`

**Description:**
Parse and prepare a single case from suite with test case descriptions.

This method is part of the setup phase, just before the test case is run.

**Line:** 55

---

### `def module_from_path(path: str) -> str`

**Line:** 414

---

### `def parse_test_data(raw_data: str, name: str) -> list[TestItem]`

**Description:**
Parse a list of lines that represent a sequence of test items.

**Line:** 447

---

### `def strip_list(l: list[str]) -> list[str]`

**Description:**
Return a stripped copy of l.

Strip whitespace at the end of all lines, and strip all empty
lines from the end of the array.

**Line:** 492

---

### `def collapse_line_continuation(l: list[str]) -> list[str]`

**Line:** 510

---

### `def expand_variables(s: str) -> str`

**Line:** 523

---

### `def expand_errors(input: list[str], output: list[str], fnam: str) -> None`

**Description:**
Transform comments such as '# E: message' or
'# E:3: message' in input.

The result is lines like 'fnam:line: error: message'.

**Line:** 527

---

### `def fix_win_path(line: str) -> str`

**Description:**
Changes Windows paths to Linux paths in error messages.

E.g. foo\bar.py -> foo/bar.py.

**Line:** 556

---

### `def fix_cobertura_filename(line: str) -> str`

**Description:**
Changes filename paths to Linux paths in Cobertura output files.

E.g. filename="pkg\subpkg\a.py" -> filename="pkg/subpkg/a.py".

**Line:** 570

---

### `def pytest_addoption(parser: Any) -> None`

**Line:** 592

---

### `def pytest_configure(config: pytest.Config) -> None`

**Line:** 623

---

### `def pytest_pycollect_makeitem(collector: Any, name: str, obj: object) -> Any | None`

**Description:**
Called by pytest on each object in modules configured in conftest.py files.

collector is pytest.Collector, returns Optional[pytest.Class]

**Line:** 632

---

### `def split_test_cases(parent: DataFileCollector, suite: DataSuite, file: str) -> Iterator[DataDrivenTestCase]`

**Description:**
Iterate over raw test cases in file, at collection time, ignoring sub items.

The collection phase is slow, so any heavy processing should be deferred to after
uninteresting tests are filtered (when using -k PATTERN switch).

**Line:** 660

---

### `def add_test_name_suffix(name: str, suffix: str) -> str`

**Line:** 775

---

### `def is_incremental(testcase: DataDrivenTestCase) -> bool`

**Line:** 788

---

### `def has_stable_flags(testcase: DataDrivenTestCase) -> bool`

**Line:** 792

---


## Module: venv2.libthon3.12.site-packages.mypy.test.helpers
**File:** `venv2/lib/python3.12/site-packages/mypy/test/helpers.py`

**Imports:**
- __future__.annotations
- contextlib
- difflib
- mypy.api
- mypy.defaults
- mypy.main.process_options
- mypy.options.Options
- mypy.test.config.test_data_prefix
- mypy.test.config.test_temp_dir
- mypy.test.data.DataDrivenTestCase
- mypy.test.data.DeleteFile
- mypy.test.data.UpdateFile
- mypy.test.data.fix_cobertura_filename
- mypy.version
- os
- pathlib
- pytest
- re
- shutil
- sys
- time
- typing.Any
- typing.Callable
- typing.IO
- typing.Iterable
- typing.Iterator
- typing.Pattern
- unittest.TestCase

**Functions:**

### `def run_mypy(args: list[str]) -> None`

**Line:** 36

---

### `def diff_ranges(left: list[str], right: list[str]) -> tuple[(list[tuple[int, int]], list[tuple[int, int]])]`

**Line:** 47

---

### `def render_diff_range(ranges: list[tuple[(int, int)]], content: list[str], colour: str | None = None, output: IO[str] = sys.stderr, indent: int = 2) -> None`

**Line:** 72

---

### `def assert_string_arrays_equal(expected: list[str], actual: list[str], msg: str) -> None`

**Description:**
Assert that two string arrays are equal.

Display any differences in a human-readable form.

**Line:** 107

---

### `def assert_module_equivalence(name: str, expected: Iterable[str], actual: Iterable[str]) -> None`

**Line:** 142

---

### `def assert_target_equivalence(name: str, expected: list[str], actual: list[str]) -> None`

**Description:**
Compare actual and expected targets (order sensitive).

**Line:** 154

---

### `def show_align_message(s1: str, s2: str) -> None`

**Description:**
Align s1 and s2 so that the their first difference is highlighted.

For example, if s1 is 'foobar' and s2 is 'fobar', display the
following lines:

E: foobar
A: fobar
^

If s1 and s2 are long, only display a fragment of the strings around the
first difference. If s1 is very short, do nothing.

**Line:** 165

---

### `def clean_up(a: list[str]) -> list[str]`

**Description:**
Remove common directory prefix from all strings in a.

This uses a naive string replace; it seems to work well enough. Also
remove trailing carriage returns.

**Line:** 217

---

### `def local_sys_path_set() -> Iterator[None]`

**Decorators:**
- `@contextlib.contextmanager`

**Description:**
Temporary insert current directory into sys.path.

This can be used by test cases that do runtime imports, for example
by the stubgen tests.

**Line:** 241

---

### `def testfile_pyversion(path: str) -> tuple[(int, int)]`

**Line:** 256

---

### `def normalize_error_messages(messages: list[str]) -> list[str]`

**Description:**
Translate an array of error messages to use / as path separator.

**Line:** 271

---

### `def retry_on_error(func: Callable[([], Any)], max_wait: float = 1.0) -> None`

**Description:**
Retry callback with exponential backoff when it raises OSError.

If the function still generates an error after max_wait seconds, propagate
the exception.

This can be effective against random file system operation failures on
Windows.

**Line:** 280

---

### `def good_repr(obj: object) -> str`

**Line:** 303

---

### `def assert_equal(a: object, b: object, fmt: str = '{} != {}') -> None`

**Line:** 315

---

### `def typename(t: type) -> str`

**Line:** 321

---

### `def assert_type(typ: type, value: object) -> None`

**Line:** 328

---

### `def parse_options(program_text: str, testcase: DataDrivenTestCase, incremental_step: int) -> Options`

**Description:**
Parse comments like '# flags: --foo' in a test case.

**Line:** 334

---

### `def split_lines(*streams: bytes) -> list[str]`

**Description:**
Returns a single list of string lines from the byte streams in args.

**Line:** 372

---

### `def write_and_fudge_mtime(content: str, target_path: str) -> None`

**Line:** 377

---

### `def perform_file_operations(operations: list[UpdateFile | DeleteFile]) -> None`

**Line:** 398

---

### `def check_test_output_files(testcase: DataDrivenTestCase, step: int, strip_prefix: str = '') -> None`

**Line:** 415

---

### `def normalize_file_output(content: list[str], current_abs_path: str) -> list[str]`

**Description:**
Normalize file output for comparison.

**Line:** 457

---

### `def find_test_files(pattern: str, exclude: list[str] | None = None) -> list[str]`

**Line:** 471

---


## Module: venv2.libthon3.12.site-packages.mypy.test.meta._pytest
**File:** `venv2/lib/python3.12/site-packages/mypy/test/meta/_pytest.py`

**Imports:**
- dataclasses.dataclass
- mypy.test.config.test_data_prefix
- pathlib.Path
- shlex
- subprocess
- sys
- textwrap
- typing.Iterable
- uuid

**Functions:**

### `def dedent_docstring(s: str) -> str`

**Line:** 21

---

### `def run_pytest_data_suite(data_suite: str, data_file_prefix: str = 'check', pytest_node_prefix: str = 'mypy/test/testcheck.py::TypeCheckSuite', extra_args: Iterable[str], max_attempts: int) -> PytestResult`

**Description:**
Runs a suite of data test cases through pytest until either tests pass
or until a maximum number of attempts (needed for incremental tests).

:param data_suite: the actual "suite" i.e. the contents of a .test file

**Line:** 25

---


## Module: venv2.libthon3.12.site-packages.mypy.test.meta.test_parse_data
**File:** `venv2/lib/python3.12/site-packages/mypy/test/meta/test_parse_data.py`

**Imports:**
- mypy.test.helpers.Suite
- mypy.test.meta._pytest.PytestResult
- mypy.test.meta._pytest.run_pytest_data_suite

**Functions:**

### `def _run_pytest(data_suite: str) -> PytestResult`

**Line:** 9

---


## Module: venv2.libthon3.12.site-packages.mypy.test.meta.test_update_data
**File:** `venv2/lib/python3.12/site-packages/mypy/test/meta/test_update_data.py`

**Imports:**
- mypy.test.helpers.Suite
- mypy.test.meta._pytest.PytestResult
- mypy.test.meta._pytest.dedent_docstring
- mypy.test.meta._pytest.run_pytest_data_suite

**Functions:**

### `def _run_pytest_update_data(data_suite: str) -> PytestResult`

**Description:**
Runs a suite of data test cases through 'pytest --update-data' until either tests pass
or until a maximum number of attempts (needed for incremental tests).

**Line:** 10

---


## Module: venv2.libthon3.12.site-packages.mypy.test.test_find_sources
**File:** `venv2/lib/python3.12/site-packages/mypy/test/test_find_sources.py`

**Imports:**
- __future__.annotations
- mypy.find_sources.InvalidSourceList
- mypy.find_sources.SourceFinder
- mypy.find_sources.create_source_list
- mypy.fscache.FileSystemCache
- mypy.modulefinder.BuildSource
- mypy.options.Options
- os
- pytest
- shutil
- tempfile
- unittest

**Functions:**

### `def normalise_path(path: str) -> str`

**Line:** 37

---

### `def normalise_build_source_list(sources: list[BuildSource]) -> list[tuple[(str, str | None)]]`

**Line:** 43

---

### `def crawl(finder: SourceFinder, f: str) -> tuple[(str, str)]`

**Line:** 50

---

### `def find_sources_in_dir(finder: SourceFinder, f: str) -> list[tuple[(str, str | None)]]`

**Line:** 55

---

### `def find_sources(paths: list[str], options: Options, fscache: FileSystemCache) -> list[tuple[(str, str | None)]]`

**Line:** 59

---


## Module: venv2.libthon3.12.site-packages.mypy.test.testcmdline
**File:** `venv2/lib/python3.12/site-packages/mypy/test/testcmdline.py`

**Imports:**
- __future__.annotations
- lxml
- mypy.test.config.PREFIX
- mypy.test.config.test_temp_dir
- mypy.test.data.DataDrivenTestCase
- mypy.test.data.DataSuite
- mypy.test.helpers.assert_string_arrays_equal
- mypy.test.helpers.check_test_output_files
- mypy.test.helpers.normalize_error_messages
- os
- pytest
- re
- subprocess
- sys

**Functions:**

### `def test_python_cmdline(testcase: DataDrivenTestCase, step: int) -> None`

**Line:** 47

---

### `def parse_args(line: str) -> list[str]`

**Description:**
Parse the first line of the program for the command line.

This should have the form

# cmd: mypy <options>

For example:

# cmd: mypy pkg/

**Line:** 123

---

### `def parse_cwd(line: str) -> str | None`

**Description:**
Parse the second line of the program for the command line.

This should have the form

# cwd: <directory>

For example:

# cwd: main/subdir

**Line:** 140

---


## Module: venv2.libthon3.12.site-packages.mypy.test.testdaemon
**File:** `venv2/lib/python3.12/site-packages/mypy/test/testdaemon.py`

**Imports:**
- __future__.annotations
- mypy.dmypy_server.filter_out_missing_top_level_packages
- mypy.fscache.FileSystemCache
- mypy.modulefinder.SearchPaths
- mypy.test.config.PREFIX
- mypy.test.config.test_temp_dir
- mypy.test.data.DataDrivenTestCase
- mypy.test.data.DataSuite
- mypy.test.helpers.assert_string_arrays_equal
- mypy.test.helpers.normalize_error_messages
- os
- subprocess
- sys
- tempfile
- unittest

**Functions:**

### `def test_daemon(testcase: DataDrivenTestCase) -> None`

**Line:** 38

---

### `def parse_script(input: list[str]) -> list[list[str]]`

**Description:**
Parse testcase.input into steps.

Each command starts with a line starting with '$'.
The first line (less '$') is sent to the shell.
The remaining lines are expected output.

**Line:** 58

---

### `def run_cmd(input: str) -> tuple[(int, str)]`

**Line:** 79

---


## Module: venv2.libthon3.12.site-packages.mypy.test.testerrorstream
**File:** `venv2/lib/python3.12/site-packages/mypy/test/testerrorstream.py`

**Imports:**
- __future__.annotations
- mypy.build
- mypy.errors.CompileError
- mypy.modulefinder.BuildSource
- mypy.options.Options
- mypy.test.data.DataDrivenTestCase
- mypy.test.data.DataSuite
- mypy.test.helpers.assert_string_arrays_equal

**Functions:**

### `def test_error_stream(testcase: DataDrivenTestCase) -> None`

**Description:**
Perform a single error streaming test case.

The argument contains the description of the test case.

**Line:** 21

---


## Module: venv2.libthon3.12.site-packages.mypy.test.testfinegrained
**File:** `venv2/lib/python3.12/site-packages/mypy/test/testfinegrained.py`

**Imports:**
- __future__.annotations
- mypy.build
- mypy.config_parser.parse_config_file
- mypy.dmypy_server.Server
- mypy.dmypy_util.DEFAULT_STATUS_FILE
- mypy.errors.CompileError
- mypy.find_sources.create_source_list
- mypy.modulefinder.BuildSource
- mypy.options.Options
- mypy.server.mergecheck.check_consistency
- mypy.server.update.sort_messages_preserving_file_order
- mypy.test.config.test_temp_dir
- mypy.test.data.DataDrivenTestCase
- mypy.test.data.DataSuite
- mypy.test.data.DeleteFile
- mypy.test.data.UpdateFile
- mypy.test.helpers.assert_module_equivalence
- mypy.test.helpers.assert_string_arrays_equal
- mypy.test.helpers.assert_target_equivalence
- mypy.test.helpers.find_test_files
- mypy.test.helpers.parse_options
- mypy.test.helpers.perform_file_operations
- os
- pytest
- re
- typing.Any
- unittest

**Functions:**

### `def normalize_messages(messages: list[str]) -> list[str]`

**Line:** 370

---


## Module: venv2.libthon3.12.site-packages.mypy.test.testinfer
**File:** `venv2/lib/python3.12/site-packages/mypy/test/testinfer.py`

**Imports:**
- __future__.annotations
- mypy.argmap.map_actuals_to_formals
- mypy.checker.DisjointDict
- mypy.checker.group_comparison_operands
- mypy.literals.Key
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_OPT
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.ArgKind
- mypy.nodes.NameExpr
- mypy.test.helpers.Suite
- mypy.test.helpers.assert_equal
- mypy.test.typefixture.TypeFixture
- mypy.types.AnyType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny

**Functions:**

### `def expand_caller_kinds(kinds_or_names: list[ArgKind | str]) -> tuple[(list[ArgKind], list[str | None])]`

**Line:** 121

---

### `def expand_callee_kinds(kinds_and_names: list[ArgKind | tuple[ArgKind, str]]) -> tuple[(list[ArgKind], list[str | None])]`

**Line:** 136

---


## Module: venv2.libthon3.12.site-packages.mypy.test.testipc
**File:** `venv2/lib/python3.12/site-packages/mypy/test/testipc.py`

**Imports:**
- __future__.annotations
- multiprocessing.Process
- multiprocessing.Queue
- mypy.ipc.IPCClient
- mypy.ipc.IPCServer
- pytest
- sys
- time
- unittest.TestCase
- unittest.main

**Functions:**

### `def server(msg: str, q: Queue[str]) -> None`

**Line:** 15

---

### `def server_multi_message_echo(q: Queue[str]) -> None`

**Line:** 26

---


## Module: venv2.libthon3.12.site-packages.mypy.test.testparse
**File:** `venv2/lib/python3.12/site-packages/mypy/test/testparse.py`

**Imports:**
- __future__.annotations
- mypy.config_parser.parse_mypy_comments
- mypy.defaults
- mypy.errors.CompileError
- mypy.options.Options
- mypy.parse.parse
- mypy.test.data.DataDrivenTestCase
- mypy.test.data.DataSuite
- mypy.test.helpers.assert_string_arrays_equal
- mypy.test.helpers.find_test_files
- mypy.test.helpers.parse_options
- mypy.util.get_mypy_comments
- pytest.skip
- sys

**Functions:**

### `def test_parser(testcase: DataDrivenTestCase) -> None`

**Description:**
Perform a single parser test case.

The argument contains the description of the test case.

**Line:** 31

---

### `def test_parse_error(testcase: DataDrivenTestCase) -> None`

**Line:** 78

---


## Module: venv2.libthon3.12.site-packages.mypy.test.testpep561
**File:** `venv2/lib/python3.12/site-packages/mypy/test/testpep561.py`

**Imports:**
- __future__.annotations
- contextlib.contextmanager
- filelock
- mypy.api
- mypy.test.config.package_path
- mypy.test.config.pip_lock
- mypy.test.config.pip_timeout
- mypy.test.config.test_temp_dir
- mypy.test.data.DataDrivenTestCase
- mypy.test.data.DataSuite
- mypy.test.helpers.assert_string_arrays_equal
- mypy.test.helpers.perform_file_operations
- os
- re
- subprocess
- sys
- tempfile
- typing.Iterator

**Functions:**

### `def virtualenv(python_executable: str = sys.executable) -> Iterator[tuple[(str, str)]]`

**Decorators:**
- `@contextmanager`

**Description:**
Context manager that creates a virtualenv in a temporary directory

Returns the path to the created Python executable

**Line:** 31

---

### `def upgrade_pip(python_executable: str) -> None`

**Description:**
Install pip>=21.3.1. Required for editable installs with PEP 660.

**Line:** 49

---

### `def install_package(pkg: str, python_executable: str = sys.executable, editable: bool = False) -> None`

**Description:**
Install a package from test-data/packages/pkg/

**Line:** 71

---

### `def test_pep561(testcase: DataDrivenTestCase) -> None`

**Description:**
Test running mypy on files that depend on PEP 561 packages.

**Line:** 96

---

### `def parse_pkgs(comment: str) -> tuple[(list[str], list[str])]`

**Line:** 164

---

### `def parse_mypy_args(line: str) -> list[str]`

**Line:** 172

---

### `def test_mypy_path_is_respected() -> None`

**Line:** 179

---


## Module: venv2.libthon3.12.site-packages.mypy.test.testpythoneval
**File:** `venv2/lib/python3.12/site-packages/mypy/test/testpythoneval.py`

**Imports:**
- __future__.annotations
- mypy.api
- mypy.defaults.PYTHON3_VERSION
- mypy.test.config.test_temp_dir
- mypy.test.data.DataDrivenTestCase
- mypy.test.data.DataSuite
- mypy.test.helpers.assert_string_arrays_equal
- mypy.test.helpers.split_lines
- os
- os.path
- re
- subprocess
- sys
- tempfile.TemporaryDirectory

**Functions:**

### `def test_python_evaluation(testcase: DataDrivenTestCase, cache_dir: str) -> None`

**Description:**
Runs Mypy in a subprocess.

If this passes without errors, executes the script again with a given Python
version.

**Line:** 41

---

### `def adapt_output(testcase: DataDrivenTestCase) -> list[str]`

**Description:**
Translates the generic _program.py into the actual filename.

**Line:** 113

---


## Module: venv2.libthon3.12.site-packages.mypy.test.testsemanal
**File:** `venv2/lib/python3.12/site-packages/mypy/test/testsemanal.py`

**Imports:**
- __future__.annotations
- mypy.build
- mypy.defaults.PYTHON3_VERSION
- mypy.errors.CompileError
- mypy.modulefinder.BuildSource
- mypy.nodes.TypeInfo
- mypy.options.Options
- mypy.test.config.test_temp_dir
- mypy.test.data.DataDrivenTestCase
- mypy.test.data.DataSuite
- mypy.test.helpers.assert_string_arrays_equal
- mypy.test.helpers.find_test_files
- mypy.test.helpers.normalize_error_messages
- mypy.test.helpers.parse_options
- mypy.test.helpers.testfile_pyversion
- sys
- typing.Dict

**Functions:**

### `def get_semanal_options(program_text: str, testcase: DataDrivenTestCase) -> Options`

**Line:** 42

---

### `def test_semanal(testcase: DataDrivenTestCase) -> None`

**Description:**
Perform a semantic analysis test case.

The testcase argument contains a description of the test case
(inputs and output).

**Line:** 60

---

### `def test_semanal_error(testcase: DataDrivenTestCase) -> None`

**Description:**
Perform a test case.

**Line:** 105

---


## Module: venv2.libthon3.12.site-packages.mypy.test.teststubgen
**File:** `venv2/lib/python3.12/site-packages/mypy/test/teststubgen.py`

**Imports:**
- __future__.annotations
- argparse
- io
- mypy.errors.CompileError
- mypy.moduleinspect.InspectError
- mypy.moduleinspect.ModuleInspect
- mypy.stubdoc.ArgSig
- mypy.stubdoc.FunctionSig
- mypy.stubdoc.build_signature
- mypy.stubdoc.find_unique_signatures
- mypy.stubdoc.infer_arg_sig_from_anon_docstring
- mypy.stubdoc.infer_prop_type_from_docstring
- mypy.stubdoc.infer_sig_from_docstring
- mypy.stubdoc.is_valid_type
- mypy.stubdoc.parse_all_signatures
- mypy.stubdoc.parse_signature
- mypy.stubgen.Options
- mypy.stubgen.collect_build_targets
- mypy.stubgen.generate_stubs
- mypy.stubgen.is_blacklisted_path
- mypy.stubgen.is_non_library_module
- mypy.stubgen.mypy_options
- mypy.stubgen.parse_options
- mypy.stubgenc.InspectionStubGenerator
- mypy.stubgenc.infer_c_method_args
- mypy.stubutil.ClassInfo
- mypy.stubutil.common_dir_prefix
- mypy.stubutil.infer_method_ret_type
- mypy.stubutil.remove_misplaced_type_comments
- mypy.stubutil.walk_packages
- mypy.test.data.DataDrivenTestCase
- mypy.test.data.DataSuite
- mypy.test.helpers.assert_equal
- mypy.test.helpers.assert_string_arrays_equal
- mypy.test.helpers.local_sys_path_set
- os.path
- re
- shutil
- sys
- tempfile
- types.ModuleType
- typing.Any
- unittest

**Functions:**

### `def module_to_path(out_dir: str, module: str) -> str`

**Line:** 1403

---


## Module: venv2.libthon3.12.site-packages.mypy.test.teststubtest
**File:** `venv2/lib/python3.12/site-packages/mypy/test/teststubtest.py`

**Imports:**
- __future__.annotations
- contextlib
- inspect
- io
- mypy.stubtest
- mypy.stubtest.parse_options
- mypy.stubtest.test_stubs
- mypy.test.data.root_dir
- os
- re
- sys
- tempfile
- textwrap
- typing.Any
- typing.Callable
- typing.Iterator
- unittest

**Functions:**

### `def use_tmp_dir(mod_name: str) -> Iterator[str]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 20

---

### `def run_stubtest(stub: str, runtime: str, options: list[str], config_file: str | None = None) -> str`

**Line:** 145

---

### `def collect_cases(fn: Callable[(..., Iterator[Case])]) -> Callable[(..., None)]`

**Description:**
run_stubtest used to be slow, so we used this decorator to combine cases.

If you're reading this and bored, feel free to refactor this and make it more like
other mypy tests.

**Line:** 180

---

### `def remove_color_code(s: str) -> str`

**Line:** 2031

---


## Module: venv2.libthon3.12.site-packages.mypy.test.testtransform
**File:** `venv2/lib/python3.12/site-packages/mypy/test/testtransform.py`

**Imports:**
- __future__.annotations
- mypy.build
- mypy.errors.CompileError
- mypy.modulefinder.BuildSource
- mypy.test.config.test_temp_dir
- mypy.test.data.DataDrivenTestCase
- mypy.test.data.DataSuite
- mypy.test.helpers.assert_string_arrays_equal
- mypy.test.helpers.normalize_error_messages
- mypy.test.helpers.parse_options
- mypy.test.visitors.TypeAssertTransformVisitor

**Functions:**

### `def test_transform(testcase: DataDrivenTestCase) -> None`

**Description:**
Perform an identity transform test case.

**Line:** 32

---


## Module: venv2.libthon3.12.site-packages.mypy.test.testtypes
**File:** `venv2/lib/python3.12/site-packages/mypy/test/testtypes.py`

**Imports:**
- __future__.annotations
- mypy.erasetype.erase_type
- mypy.erasetype.remove_instance_last_known_values
- mypy.expandtype
- mypy.indirection.TypeIndirectionVisitor
- mypy.join.join_simple
- mypy.join.join_types
- mypy.meet.meet_types
- mypy.meet.narrow_declared_type
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_OPT
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.ArgKind
- mypy.nodes.CONTRAVARIANT
- mypy.nodes.COVARIANT
- mypy.nodes.CallExpr
- mypy.nodes.Expression
- mypy.nodes.INVARIANT
- mypy.nodes.NameExpr
- mypy.options.Options
- mypy.plugins.common.find_shallow_matching_overload_item
- mypy.state.state
- mypy.subtypes.is_more_precise
- mypy.subtypes.is_proper_subtype
- mypy.subtypes.is_same_type
- mypy.subtypes.is_subtype
- mypy.test.helpers.Suite
- mypy.test.helpers.assert_equal
- mypy.test.helpers.assert_type
- mypy.test.helpers.skip
- mypy.test.typefixture.InterfaceTypeFixture
- mypy.test.typefixture.TypeFixture
- mypy.typeops.false_only
- mypy.typeops.make_simplified_union
- mypy.typeops.true_only
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.TypeVarId
- mypy.types.TypeVarType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.get_proper_type
- mypy.types.has_recursive_types
- re
- unittest.TestCase
- unittest.skipUnless

**Functions:**

### `def make_call(*items: tuple[(str, str | None)]) -> CallExpr`

**Line:** 1524

---


## Module: venv2.libthon3.12.site-packages.mypy.test.update_data
**File:** `venv2/lib/python3.12/site-packages/mypy/test/update_data.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- mypy.test.data.DataDrivenTestCase
- mypy.test.data.DataFileCollector
- mypy.test.data.DataFileFix
- mypy.test.data.parse_test_data
- re
- typing.Iterator

**Functions:**

### `def update_testcase_output(testcase: DataDrivenTestCase, actual: list[str], incremental_step: int) -> None`

**Line:** 10

---

### `def _iter_fixes(testcase: DataDrivenTestCase, actual: list[str], incremental_step: int) -> Iterator[DataFileFix]`

**Line:** 21

---


## Module: venv2.libthon3.12.site-packages.mypy.test.visitors
**File:** `venv2/lib/python3.12/site-packages/mypy/test/visitors.py`

**Imports:**
- __future__.annotations
- mypy.nodes.AssignmentStmt
- mypy.nodes.CallExpr
- mypy.nodes.Expression
- mypy.nodes.IntExpr
- mypy.nodes.NameExpr
- mypy.nodes.Node
- mypy.nodes.TypeVarExpr
- mypy.traverser.TraverserVisitor
- mypy.treetransform.TransformVisitor
- mypy.types.Type

**Functions:**

### `def ignore_node(node: Expression) -> bool`

**Description:**
Return True if node is to be omitted from test case output.

**Line:** 41

---


## Module: venv2.libthon3.12.site-packages.mypy.traverser
**File:** `venv2/lib/python3.12/site-packages/mypy/traverser.py`

**Imports:**
- __future__.annotations
- mypy.nodes.AssertStmt
- mypy.nodes.AssertTypeExpr
- mypy.nodes.AssignmentExpr
- mypy.nodes.AssignmentStmt
- mypy.nodes.AwaitExpr
- mypy.nodes.Block
- mypy.nodes.BreakStmt
- mypy.nodes.BytesExpr
- mypy.nodes.CallExpr
- mypy.nodes.CastExpr
- mypy.nodes.ClassDef
- mypy.nodes.ComparisonExpr
- mypy.nodes.ComplexExpr
- mypy.nodes.ConditionalExpr
- mypy.nodes.ContinueStmt
- mypy.nodes.Decorator
- mypy.nodes.DelStmt
- mypy.nodes.DictExpr
- mypy.nodes.DictionaryComprehension
- mypy.nodes.EllipsisExpr
- mypy.nodes.EnumCallExpr
- mypy.nodes.Expression
- mypy.nodes.ExpressionStmt
- mypy.nodes.FloatExpr
- mypy.nodes.ForStmt
- mypy.nodes.FuncBase
- mypy.nodes.FuncDef
- mypy.nodes.FuncItem
- mypy.nodes.GeneratorExpr
- mypy.nodes.GlobalDecl
- mypy.nodes.IfStmt
- mypy.nodes.Import
- mypy.nodes.ImportAll
- mypy.nodes.ImportFrom
- mypy.nodes.IndexExpr
- mypy.nodes.IntExpr
- mypy.nodes.LambdaExpr
- mypy.nodes.ListComprehension
- mypy.nodes.ListExpr
- mypy.nodes.MatchStmt
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.NamedTupleExpr
- mypy.nodes.NewTypeExpr
- mypy.nodes.Node
- mypy.nodes.NonlocalDecl
- mypy.nodes.OpExpr
- mypy.nodes.OperatorAssignmentStmt
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.ParamSpecExpr
- mypy.nodes.PassStmt
- mypy.nodes.REVEAL_TYPE
- mypy.nodes.RaiseStmt
- mypy.nodes.ReturnStmt
- mypy.nodes.RevealExpr
- mypy.nodes.SetComprehension
- mypy.nodes.SetExpr
- mypy.nodes.SliceExpr
- mypy.nodes.StarExpr
- mypy.nodes.StrExpr
- mypy.nodes.SuperExpr
- mypy.nodes.TryStmt
- mypy.nodes.TupleExpr
- mypy.nodes.TypeAlias
- mypy.nodes.TypeAliasExpr
- mypy.nodes.TypeApplication
- mypy.nodes.TypeVarExpr
- mypy.nodes.TypeVarTupleExpr
- mypy.nodes.TypedDictExpr
- mypy.nodes.UnaryExpr
- mypy.nodes.WhileStmt
- mypy.nodes.WithStmt
- mypy.nodes.YieldExpr
- mypy.nodes.YieldFromExpr
- mypy.patterns.AsPattern
- mypy.patterns.ClassPattern
- mypy.patterns.MappingPattern
- mypy.patterns.OrPattern
- mypy.patterns.SequencePattern
- mypy.patterns.SingletonPattern
- mypy.patterns.StarredPattern
- mypy.patterns.ValuePattern
- mypy.visitor.NodeVisitor
- mypy_extensions.mypyc_attr
- mypy_extensions.trait

**Functions:**

### `def has_return_statement(fdef: FuncBase) -> bool`

**Description:**
Find if a function has a non-trivial return statement.

Plain 'return' and 'return None' don't count.

**Line:** 841

---

### `def has_yield_expression(fdef: FuncBase) -> bool`

**Line:** 871

---

### `def has_yield_from_expression(fdef: FuncBase) -> bool`

**Line:** 886

---

### `def has_await_expression(expr: Expression) -> bool`

**Line:** 901

---

### `def all_return_statements(node: Node) -> list[ReturnStmt]`

**Line:** 916

---

### `def all_yield_expressions(node: Node) -> list[tuple[(YieldExpr, bool)]]`

**Line:** 937

---

### `def all_yield_from_expressions(node: Node) -> list[tuple[(YieldFromExpr, bool)]]`

**Line:** 958

---


## Module: venv2.libthon3.12.site-packages.mypy.typeanal
**File:** `venv2/lib/python3.12/site-packages/mypy/typeanal.py`

**Imports:**
- __future__.annotations
- contextlib.contextmanager
- itertools
- mypy.errorcodes
- mypy.errorcodes.ErrorCode
- mypy.message_registry
- mypy.messages.MessageBuilder
- mypy.messages.format_type_bare
- mypy.messages.quote_type_string
- mypy.messages.wrong_type_arg_count
- mypy.nodes
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_NAMED_OPT
- mypy.nodes.ARG_OPT
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.ArgKind
- mypy.nodes.Context
- mypy.nodes.Decorator
- mypy.nodes.MypyFile
- mypy.nodes.ParamSpecExpr
- mypy.nodes.PlaceholderNode
- mypy.nodes.SYMBOL_FUNCBASE_TYPES
- mypy.nodes.SymbolTableNode
- mypy.nodes.TypeAlias
- mypy.nodes.TypeInfo
- mypy.nodes.TypeVarExpr
- mypy.nodes.TypeVarLikeExpr
- mypy.nodes.TypeVarTupleExpr
- mypy.nodes.Var
- mypy.nodes.check_arg_kinds
- mypy.nodes.check_arg_names
- mypy.nodes.get_nongen_builtins
- mypy.options.Options
- mypy.plugin.AnalyzeTypeContext
- mypy.plugin.Plugin
- mypy.plugin.TypeAnalyzerPluginInterface
- mypy.semanal_shared.SemanticAnalyzerCoreInterface
- mypy.semanal_shared.paramspec_args
- mypy.semanal_shared.paramspec_kwargs
- mypy.tvar_scope.TypeVarLikeScope
- mypy.types.ANNOTATED_TYPE_NAMES
- mypy.types.ANY_STRATEGY
- mypy.types.AnyType
- mypy.types.BoolTypeQuery
- mypy.types.CallableArgument
- mypy.types.CallableType
- mypy.types.DeletedType
- mypy.types.EllipsisType
- mypy.types.ErasedType
- mypy.types.FINAL_TYPE_NAMES
- mypy.types.Instance
- mypy.types.LITERAL_TYPE_NAMES
- mypy.types.LiteralType
- mypy.types.NEVER_NAMES
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ParamSpecFlavor
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.PlaceholderType
- mypy.types.ProperType
- mypy.types.RawExpressionType
- mypy.types.RequiredType
- mypy.types.SyntheticTypeVisitor
- mypy.types.TYPE_ALIAS_NAMES
- mypy.types.TrivialSyntheticTypeTranslator
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeList
- mypy.types.TypeOfAny
- mypy.types.TypeQuery
- mypy.types.TypeType
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypedDictType
- mypy.types.UnboundType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.callable_with_ellipsis
- mypy.types.find_unpack_in_list
- mypy.types.flatten_nested_tuples
- mypy.types.flatten_nested_unions
- mypy.types.get_proper_type
- mypy.types.has_type_vars
- mypy.types_utils.is_bad_type_type_item
- mypy.typevars.fill_typevars
- typing.Callable
- typing.Final
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Sequence
- typing.Tuple
- typing.TypeVar
- typing_extensions.Protocol

**Functions:**

### `def analyze_type_alias(type: Type, api: SemanticAnalyzerCoreInterface, tvar_scope: TypeVarLikeScope, plugin: Plugin, options: Options, is_typeshed_stub: bool, allow_placeholder: bool = False, in_dynamic_func: bool = False, global_scope: bool = True, allowed_alias_tvars: list[TypeVarLikeType] | None = None) -> tuple[(Type, set[str])]`

**Description:**
Analyze r.h.s. of a (potential) type alias definition.

If `node` is valid as a type alias rvalue, return the resulting type and a set of
full names of type aliases it depends on (directly or indirectly).
'node' must have been semantically analyzed.

**Line:** 125

---

### `def no_subscript_builtin_alias(name: str, propose_alt: bool = True) -> str`

**Line:** 160

---

### `def get_omitted_any(disallow_any: bool, fail: MsgCallback, note: MsgCallback, orig_type: Type, options: Options, fullname: str | None = None, unexpanded_type: Type | None = None) -> AnyType`

**Line:** 1783

---

### `def fix_type_var_tuple_argument(any_type: Type, t: Instance) -> None`

**Line:** 1840

---

### `def fix_instance(t: Instance, fail: MsgCallback, note: MsgCallback, disallow_any: bool, options: Options, use_generic_error: bool = False, unexpanded_type: Type | None = None) -> None`

**Description:**
Fix a malformed instance by replacing all type arguments with Any.

Also emit a suitable error if this is not due to implicit Any's.

**Line:** 1852

---

### `def instantiate_type_alias(node: TypeAlias, args: list[Type], fail: MsgCallback, no_args: bool, ctx: Context, options: Options, unexpanded_type: Type | None = None, disallow_any: bool = False, use_standard_error: bool = False, empty_tuple_index: bool = False) -> Type`

**Description:**
Create an instance of a (generic) type alias from alias node and type arguments.

We are following the rules outlined in TypeAlias docstring.
Here:
node: type alias node (definition)
args: type arguments (types to be substituted in place of type variables
when expanding the alias)
fail: error reporter callback
no_args: whether original definition used a bare generic `A = List`
ctx: context where expansion happens
unexpanded_type, disallow_any, use_standard_error: used to customize error messages

**Line:** 1883

---

### `def set_any_tvars(node: TypeAlias, newline: int, newcolumn: int, options: Options, from_error: bool = False, disallow_any: bool = False, special_form: bool = False, fail: MsgCallback | None = None, unexpanded_type: Type | None = None) -> TypeAliasType`

**Line:** 2011

---

### `def flatten_tvars(lists: list[list[T]]) -> list[T]`

**Line:** 2056

---

### `def detect_diverging_alias(node: TypeAlias, target: Type, lookup: Callable[([str, Context], SymbolTableNode | None)], scope: TypeVarLikeScope) -> bool`

**Description:**
This detects type aliases that will diverge during type checking.

For example F = Something[..., F[List[T]]]. At each expansion step this will produce
*new* type aliases: e.g. F[List[int]], F[List[List[int]]], etc. So we can't detect
recursion. It is a known problem in the literature, recursive aliases and generic types
don't always go well together. It looks like there is no known systematic solution yet.

# TODO: should we handle such aliases using type_recursion counter and some large limit?
They may be handy in rare cases, e.g. to express a union of non-mixed nested lists:
Nested = Union[T, Nested[List[T]]] ~> Union[T, List[T], List[List[T]], ...]

**Line:** 2162

---

### `def check_for_explicit_any(typ: Type | None, options: Options, is_typeshed_stub: bool, msg: MessageBuilder, context: Context) -> None`

**Line:** 2184

---

### `def has_explicit_any(t: Type) -> bool`

**Description:**
Whether this type is or type it contains is an Any coming from explicit type annotation

**Line:** 2195

---

### `def has_any_from_unimported_type(t: Type) -> bool`

**Description:**
Return true if this type is Any because an import was not followed.

If type t is such Any type or has type arguments that contain such Any type
this function will return true.

**Line:** 2214

---

### `def collect_all_inner_types(t: Type) -> list[Type]`

**Description:**
Return all types that `t` contains

**Line:** 2235

---

### `def make_optional_type(t: Type) -> Type`

**Description:**
Return the type corresponding to Optional[t].

Note that we can't use normal union simplification, since this function
is called during semantic analysis and simplification only works during
type checking.

**Line:** 2254

---

### `def validate_instance(t: Instance, fail: MsgCallback, empty_tuple_index: bool) -> bool`

**Description:**
Check if this is a well-formed instance with respect to argument count/positions.

**Line:** 2276

---

### `def find_self_type(typ: Type, lookup: Callable[([str], SymbolTableNode | None)]) -> bool`

**Line:** 2334

---

### `def unknown_unpack(t: Type) -> bool`

**Description:**
Check if a given type is an unpack of an unknown type.

Unfortunately, there is no robust way to distinguish forward references from
genuine undefined names here. But this worked well so far, although it looks
quite fragile.

**Line:** 2350

---


## Module: venv2.libthon3.12.site-packages.mypy.typeops
**File:** `venv2/lib/python3.12/site-packages/mypy/typeops.py`

**Imports:**
- __future__.annotations
- itertools
- mypy.checkmember.type_object_type
- mypy.copytype.copy_type
- mypy.expandtype.expand_type
- mypy.expandtype.expand_type_by_instance
- mypy.infer.infer_type_arguments
- mypy.join.join_type_list
- mypy.maptype.map_instance_to_supertype
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.Decorator
- mypy.nodes.Expression
- mypy.nodes.FuncBase
- mypy.nodes.FuncDef
- mypy.nodes.FuncItem
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.SYMBOL_FUNCBASE_TYPES
- mypy.nodes.StrExpr
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.state.state
- mypy.subtypes.find_member
- mypy.subtypes.is_equivalent
- mypy.subtypes.is_proper_subtype
- mypy.subtypes.is_subtype
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.ENUM_REMOVED_PROPS
- mypy.types.ExtraAttrs
- mypy.types.FormalArgument
- mypy.types.FunctionLike
- mypy.types.Instance
- mypy.types.LiteralType
- mypy.types.NoneType
- mypy.types.NormalizedCallableType
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.Parameters
- mypy.types.PartialType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeOfAny
- mypy.types.TypeQuery
- mypy.types.TypeType
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.TypedDictType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.flatten_nested_unions
- mypy.types.get_proper_type
- mypy.types.get_proper_types
- mypy.typevars.fill_typevars
- typing.Any
- typing.Iterable
- typing.List
- typing.Sequence
- typing.TypeVar
- typing.cast

**Functions:**

### `def is_recursive_pair(s: Type, t: Type) -> bool`

**Description:**
Is this a pair of recursive types?

There may be more cases, and we may be forced to use e.g. has_recursive_types()
here, but this function is called in very hot code, so we try to keep it simple
and return True only in cases we know may have problems.

**Line:** 68

---

### `def tuple_fallback(typ: TupleType) -> Instance`

**Description:**
Return fallback type for a tuple.

**Line:** 96

---

### `def get_self_type(func: CallableType, default_self: Instance | TupleType) -> Type | None`

**Line:** 122

---

### `def type_object_type_from_function(signature: FunctionLike, info: TypeInfo, def_info: TypeInfo, fallback: Instance, is_new: bool) -> FunctionLike`

**Line:** 131

---

### `def class_callable(init_type: CallableType, info: TypeInfo, type_type: Instance, special_sig: str | None, is_new: bool, orig_self_type: Type | None = None) -> CallableType`

**Description:**
Create a type object type based on the signature of __init__.

**Line:** 174

---

### `def map_type_from_supertype(typ: Type, sub_info: TypeInfo, super_info: TypeInfo) -> Type`

**Description:**
Map type variables in a type defined in a supertype context to be valid
in the subtype context. Assume that the result is unique; if more than
one type is possible, return one of the alternatives.

For example, assume

class D(Generic[S]): ...
class C(D[E[T]], Generic[T]): ...

Now S in the context of D would be mapped to E[T] in the context of C.

**Line:** 218

---

### `def supported_self_type(typ: ProperType, allow_callable: bool = True) -> bool`

**Description:**
Is this a supported kind of explicit self-types?

Currently, this means an X or Type[X], where X is an instance or
a type variable with an instance upper bound.

**Line:** 247

---

### `def bind_self(method: F, original_type: Type | None = None, is_classmethod: bool = False) -> F`

**Description:**
Return a copy of `method`, with the type of its first parameter (usually
self or cls) bound to original_type.

If the type of `self` is a generic type (T, or Type[T] for classmethods),
instantiate every occurrence of type with original_type in the rest of the
signature and in the return type.

original_type is the type of E in the expression E.copy(). It is None in
compatibility checks. In this case we treat it as the erasure of the
declared type of self.

This way we can express "the type of self". For example:

T = TypeVar('T', bound='A')
class A:
def copy(self: T) -> T: ...

class B(A): pass

b = B().copy()  # type: B

**Line:** 267

---

### `def erase_to_bound(t: Type) -> Type`

**Line:** 360

---

### `def callable_corresponding_argument(typ: NormalizedCallableType | Parameters, model: FormalArgument) -> FormalArgument | None`

**Description:**
Return the argument a function that corresponds to `model`

**Line:** 371

---

### `def simple_literal_type(t: ProperType | None) -> Instance | None`

**Description:**
Extract the underlying fallback Instance type for a simple Literal

**Line:** 401

---

### `def is_simple_literal(t: ProperType) -> bool`

**Line:** 410

---

### `def make_simplified_union(items: Sequence[Type], line: int = -1, column: int = -1, keep_erased: bool = False, contract_literals: bool = True) -> ProperType`

**Description:**
Build union type with redundant union items removed.

If only a single item remains, this may return a non-union type.

Examples:

* [int, str] -> Union[int, str]
* [int, object] -> object
* [int, int] -> int
* [int, Any] -> Union[int, Any] (Any types are not simplified away!)
* [Any, Any] -> Any
* [int, Union[bytes, str]] -> Union[int, bytes, str]

Note: This must NOT be used during semantic analysis, since TypeInfos may not
be fully initialized.

The keep_erased flag is used for type inference against union types
containing type variables. If set to True, keep all ErasedType items.

The contract_literals flag indicates whether we need to contract literal types
back into a sum type. Set it to False when called by try_expanding_sum_type_
to_union().

**Line:** 418

---

### `def _remove_redundant_union_items(items: list[Type], keep_erased: bool) -> list[Type]`

**Line:** 493

---

### `def _get_type_special_method_bool_ret_type(t: Type) -> Type | None`

**Line:** 572

---

### `def true_only(t: Type) -> ProperType`

**Description:**
Restricted version of t with only True-ish values

**Line:** 585

---

### `def false_only(t: Type) -> ProperType`

**Description:**
Restricted version of t with only False-ish values

**Line:** 613

---

### `def true_or_false(t: Type) -> ProperType`

**Description:**
Unrestricted version of t with both True-ish and False-ish values

**Line:** 646

---

### `def erase_def_to_union_or_bound(tdef: TypeVarLikeType) -> Type`

**Line:** 662

---

### `def erase_to_union_or_bound(typ: TypeVarType) -> ProperType`

**Line:** 672

---

### `def function_type(func: FuncBase, fallback: Instance) -> FunctionLike`

**Line:** 679

---

### `def callable_type(fdef: FuncItem, fallback: Instance, ret_type: Type | None = None) -> CallableType`

**Line:** 706

---

### `def try_getting_str_literals(expr: Expression, typ: Type) -> list[str] | None`

**Description:**
If the given expression or type corresponds to a string literal
or a union of string literals, returns a list of the underlying strings.
Otherwise, returns None.

Specifically, this function is guaranteed to return a list with
one or more strings if one of the following is true:

1. 'expr' is a StrExpr
2. 'typ' is a LiteralType containing a string
3. 'typ' is a UnionType containing only LiteralType of strings

**Line:** 733

---

### `def try_getting_str_literals_from_type(typ: Type) -> list[str] | None`

**Description:**
If the given expression or type corresponds to a string Literal
or a union of string Literals, returns a list of the underlying strings.
Otherwise, returns None.

For example, if we had the type 'Literal["foo", "bar"]' as input, this function
would return a list of strings ["foo", "bar"].

**Line:** 752

---

### `def try_getting_int_literals_from_type(typ: Type) -> list[int] | None`

**Description:**
If the given expression or type corresponds to an int Literal
or a union of int Literals, returns a list of the underlying ints.
Otherwise, returns None.

For example, if we had the type 'Literal[1, 2, 3]' as input, this function
would return a list of ints [1, 2, 3].

**Line:** 763

---

### `def try_getting_literals_from_type(typ: Type, target_literal_type: type[T], target_fullname: str) -> list[T] | None`

**Description:**
If the given expression or type corresponds to a Literal or
union of Literals where the underlying values correspond to the given
target type, returns a list of those underlying values. Otherwise,
returns None.

**Line:** 777

---

### `def is_literal_type_like(t: Type | None) -> bool`

**Description:**
Returns 'true' if the given type context is potentially either a LiteralType,
a Union of LiteralType, or something similar.

**Line:** 807

---

### `def is_singleton_type(typ: Type) -> bool`

**Description:**
Returns 'true' if this type is a "singleton type" -- if there exists
exactly only one runtime value associated with this type.

That is, given two values 'a' and 'b' that have the same type 't',
'is_singleton_type(t)' returns True if and only if the expression 'a is b' is
always true.

Currently, this returns True when given NoneTypes, enum LiteralTypes,
enum types with a single value and ... (Ellipses).

Note that other kinds of LiteralTypes cannot count as singleton types. For
example, suppose we do 'a = 100000 + 1' and 'b = 100001'. It is not guaranteed
that 'a is b' will always be true -- some implementations of Python will end up
constructing two distinct instances of 100001.

**Line:** 826

---

### `def try_expanding_sum_type_to_union(typ: Type, target_fullname: str) -> ProperType`

**Description:**
Attempts to recursively expand any enum Instances with the given target_fullname
into a Union of all of its component LiteralTypes.

For example, if we have:

class Color(Enum):
RED = 1
BLUE = 2
YELLOW = 3

class Status(Enum):
SUCCESS = 1
FAILURE = 2
UNKNOWN = 3

...and if we call `try_expanding_enum_to_union(Union[Color, Status], 'module.Color')`,
this function will return Literal[Color.RED, Color.BLUE, Color.YELLOW, Status].

**Line:** 846

---

### `def try_contracting_literals_in_union(types: Sequence[Type]) -> list[ProperType]`

**Description:**
Contracts any literal types back into a sum type if possible.

Will replace the first instance of the literal with the sum type and
remove all others.

If we call `try_contracting_union(Literal[Color.RED, Color.BLUE, Color.YELLOW])`,
this function will return Color.

We also treat `Literal[True, False]` as `bool`.

**Line:** 891

---

### `def coerce_to_literal(typ: Type) -> Type`

**Description:**
Recursively converts any Instances that have a last_known_value or are
instances of enum types with a single value into the corresponding LiteralType.

**Line:** 930

---

### `def get_type_vars(tp: Type) -> list[TypeVarType]`

**Line:** 949

---

### `def get_all_type_vars(tp: Type) -> list[TypeVarLikeType]`

**Line:** 953

---

### `def custom_special_method(typ: Type, name: str, check_all: bool = False) -> bool`

**Description:**
Does this type have a custom special method such as __format__() or __eq__()?

If check_all is True ensure all items of a union have a custom method, not just some.

**Line:** 979

---

### `def separate_union_literals(t: UnionType) -> tuple[(Sequence[LiteralType], Sequence[Type])]`

**Description:**
Separate literals from other members in a union type.

**Line:** 1007

---

### `def try_getting_instance_fallback(typ: Type) -> Instance | None`

**Description:**
Returns the Instance fallback for this type if one exists or None.

**Line:** 1022

---

### `def fixup_partial_type(typ: Type) -> Type`

**Description:**
Convert a partial type that we couldn't resolve into something concrete.

This means, for None we make it Optional[Any], and for anything else we
fill in all of the type arguments with Any.

**Line:** 1042

---

### `def get_protocol_member(left: Instance, member: str, class_obj: bool) -> ProperType | None`

**Line:** 1056

---


## Module: venv2.libthon3.12.site-packages.mypy.types
**File:** `venv2/lib/python3.12/site-packages/mypy/types.py`

**Imports:**
- __future__.annotations
- abc.abstractmethod
- mypy.bogus_type.Bogus
- mypy.expandtype.ExpandTypeVisitor
- mypy.nodes
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.ArgKind
- mypy.nodes.FakeInfo
- mypy.nodes.FuncDef
- mypy.nodes.INVARIANT
- mypy.nodes.SymbolNode
- mypy.options.Options
- mypy.state.state
- mypy.type_visitor.ALL_STRATEGY
- mypy.type_visitor.ANY_STRATEGY
- mypy.type_visitor.BoolTypeQuery
- mypy.type_visitor.SyntheticTypeVisitor
- mypy.type_visitor.TypeQuery
- mypy.type_visitor.TypeTranslator
- mypy.type_visitor.TypeVisitor
- mypy.typetraverser.TypeTraverserVisitor
- mypy.util.IdMapper
- sys
- typing.Any
- typing.ClassVar
- typing.Dict
- typing.Final
- typing.Iterable
- typing.NamedTuple
- typing.NewType
- typing.Sequence
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.Union
- typing.cast
- typing_extensions.Self
- typing_extensions.TypeAlias
- typing_extensions.TypeGuard
- typing_extensions.overload

**Functions:**

### `def deserialize_type(data: JsonDict | str) -> Type`

**Line:** 203

---

### `def get_proper_type(typ: None) -> None`

**Decorators:**
- `@overload`

**Line:** 3049

---

### `def get_proper_type(typ: Type) -> ProperType`

**Decorators:**
- `@overload`

**Line:** 3054

---

### `def get_proper_type(typ: Type | None) -> ProperType | None`

**Description:**
Get the expansion of a type alias type.

If the type is already a proper type, this is a no-op. Use this function
wherever a decision is made on a call like e.g. 'if isinstance(typ, UnionType): ...',
because 'typ' in this case may be an alias to union. Note: if after making the decision
on the isinstance() call you pass on the original type (and not one of its components)
it is recommended to *always* pass on the unexpanded alias.

**Line:** 3058

---

### `def get_proper_types(types: list[Type] | tuple[Type, ...]) -> list[ProperType]`

**Decorators:**
- `@overload`

**Line:** 3078

---

### `def get_proper_types(types: list[Type | None] | tuple[Type | None, ...]) -> list[ProperType | None]`

**Decorators:**
- `@overload`

**Line:** 3083

---

### `def get_proper_types(types: list[Type] | list[Type | None] | tuple[Type | None, ...]) -> list[ProperType] | list[ProperType | None]`

**Line:** 3089

---

### `def is_named_instance(t: Type, fullnames: str | tuple[str, ...]) -> TypeGuard[Instance]`

**Line:** 3453

---

### `def has_type_vars(typ: Type) -> bool`

**Description:**
Check if a type contains any type variables (recursively).

**Line:** 3488

---

### `def has_recursive_types(typ: Type) -> bool`

**Description:**
Check if a type contains any recursive aliases (recursively).

**Line:** 3505

---

### `def split_with_prefix_and_suffix(types: tuple[(Type, ...)], prefix: int, suffix: int) -> tuple[(tuple[Type, ...], tuple[Type, ...], tuple[Type, ...])]`

**Line:** 3511

---

### `def extend_args_for_prefix_and_suffix(types: tuple[(Type, ...)], prefix: int, suffix: int) -> tuple[(Type, ...)]`

**Description:**
Extend list of types by eating out from variadic tuple to satisfy prefix and suffix.

**Line:** 3522

---

### `def flatten_nested_unions(types: Sequence[Type], handle_type_alias_type: bool = True) -> list[Type]`

**Description:**
Flatten nested unions in a type list.

**Line:** 3550

---

### `def find_unpack_in_list(items: Sequence[Type]) -> int | None`

**Line:** 3576

---

### `def flatten_nested_tuples(types: Sequence[Type]) -> list[Type]`

**Description:**
Recursively flatten TupleTypes nested with Unpack.

For example this will transform
Tuple[A, Unpack[Tuple[B, Unpack[Tuple[C, D]]]]]
into
Tuple[A, B, C, D]

**Line:** 3590

---

### `def is_literal_type(typ: ProperType, fallback_fullname: str, value: LiteralValue) -> bool`

**Description:**
Check if this type is a LiteralType with the given fallback type and value.

**Line:** 3611

---

### `def callable_with_ellipsis(any_type: AnyType, ret_type: Type, fallback: Instance) -> CallableType`

**Description:**
Construct type Callable[..., ret_type].

**Line:** 3631

---

### `def remove_dups(types: list[T]) -> list[T]`

**Line:** 3643

---

### `def type_vars_as_args(type_vars: Sequence[TypeVarLikeType]) -> tuple[(Type, ...)]`

**Description:**
Represent type variables as they would appear in a type argument list.

**Line:** 3656

---


## Module: venv2.libthon3.12.site-packages.mypy.types_utils
**File:** `venv2/lib/python3.12/site-packages/mypy/types_utils.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.FuncItem
- mypy.nodes.TypeAlias
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ParamSpecType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeAliasType
- mypy.types.TypeType
- mypy.types.TypeVarType
- mypy.types.UnionType
- mypy.types.UnpackType
- mypy.types.flatten_nested_unions
- mypy.types.get_proper_type
- mypy.types.get_proper_types
- typing.Callable
- typing.Iterable
- typing.cast

**Functions:**

### `def flatten_types(types: Iterable[Type]) -> Iterable[Type]`

**Line:** 35

---

### `def strip_type(typ: Type) -> Type`

**Description:**
Make a copy of type without 'debugging info' (function name).

**Line:** 44

---

### `def is_invalid_recursive_alias(seen_nodes: set[TypeAlias], target: Type) -> bool`

**Description:**
Flag aliases like A = Union[int, A], T = tuple[int, *T] (and similar mutual aliases).

Such aliases don't make much sense, and cause problems in later phases.

**Line:** 56

---

### `def is_bad_type_type_item(item: Type) -> bool`

**Description:**
Prohibit types like Type[Type[...]].

Such types are explicitly prohibited by PEP 484. Also, they cause problems
with recursive types like T = Type[T], because internal representation of
TypeType item is normalized (i.e. always a proper type).

**Line:** 78

---

### `def is_union_with_any(tp: Type) -> bool`

**Description:**
Is this a union with Any or a plain Any type?

**Line:** 95

---

### `def is_generic_instance(tp: Type) -> bool`

**Line:** 105

---

### `def is_overlapping_none(t: Type) -> bool`

**Line:** 110

---

### `def remove_optional(typ: Type) -> Type`

**Line:** 117

---

### `def is_self_type_like(typ: Type, is_classmethod: bool) -> bool`

**Description:**
Does this look like a self-type annotation?

**Line:** 127

---

### `def store_argument_type(defn: FuncItem, i: int, typ: CallableType, named_type: Callable[([str, list[Type]], Instance)]) -> None`

**Line:** 137

---


## Module: venv2.libthon3.12.site-packages.mypy.typestate
**File:** `venv2/lib/python3.12/site-packages/mypy/typestate.py`

**Imports:**
- __future__.annotations
- mypy.nodes.TypeInfo
- mypy.server.trigger.make_trigger
- mypy.types.Instance
- mypy.types.Type
- mypy.types.TypeVarId
- mypy.types.get_proper_type
- typing.Dict
- typing.Final
- typing.Set
- typing.Tuple
- typing_extensions.TypeAlias

**Functions:**

### `def reset_global_state() -> None`

**Description:**
Reset most existing global state.

Currently most of it is in this module. Few exceptions are strict optional status
and functools.lru_cache.

**Line:** 315

---


## Module: venv2.libthon3.12.site-packages.mypy.typevars
**File:** `venv2/lib/python3.12/site-packages/mypy/typevars.py`

**Imports:**
- __future__.annotations
- mypy.erasetype.erase_typevars
- mypy.nodes.TypeInfo
- mypy.types.AnyType
- mypy.types.Instance
- mypy.types.ParamSpecType
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeVarLikeType
- mypy.types.TypeVarTupleType
- mypy.types.TypeVarType
- mypy.types.UnpackType

**Functions:**

### `def fill_typevars(typ: TypeInfo) -> Instance | TupleType`

**Description:**
For a non-generic type, return instance type representing the type.

For a generic G type with parameters T1, .., Tn, return G[T1, ..., Tn].

**Line:** 20

---

### `def fill_typevars_with_any(typ: TypeInfo) -> Instance | TupleType`

**Description:**
Apply a correct number of Any's as type arguments to a type.

**Line:** 65

---

### `def has_no_typevars(typ: Type) -> bool`

**Line:** 86

---


## Module: venv2.libthon3.12.site-packages.mypy.typevartuples
**File:** `venv2/lib/python3.12/site-packages/mypy/typevartuples.py`

**Imports:**
- __future__.annotations
- mypy.types.Instance
- mypy.types.ProperType
- mypy.types.Type
- mypy.types.UnpackType
- mypy.types.get_proper_type
- mypy.types.split_with_prefix_and_suffix
- typing.Sequence

**Functions:**

### `def split_with_instance(typ: Instance) -> tuple[(tuple[Type, ...], tuple[Type, ...], tuple[Type, ...])]`

**Line:** 17

---

### `def extract_unpack(types: Sequence[Type]) -> ProperType | None`

**Description:**
Given a list of types, extracts either a single type from an unpack, or returns None.

**Line:** 27

---


## Module: venv2.libthon3.12.site-packages.mypy.util
**File:** `venv2/lib/python3.12/site-packages/mypy/util.py`

**Imports:**
- __future__.annotations
- _curses
- ctypes
- curses
- hashlib
- importlib.resources
- inspect
- io
- os
- pathlib
- re
- shutil
- sys
- time
- typing.Callable
- typing.Container
- typing.Final
- typing.IO
- typing.Iterable
- typing.Sequence
- typing.Sized
- typing.TypeVar
- typing_extensions.Literal
- xml.sax.saxutils.escape

**Functions:**

### `def is_dunder(name: str, exclude_special: bool = False) -> bool`

**Description:**
Returns whether name is a dunder name.

Args:
exclude_special: Whether to return False for a couple special dunder methods.

**Line:** 59

---

### `def is_sunder(name: str) -> bool`

**Line:** 71

---

### `def split_module_names(mod_name: str) -> list[str]`

**Description:**
Return the module and all parent module names.

So, if `mod_name` is 'a.b.c', this function will return
['a.b.c', 'a.b', and 'a'].

**Line:** 75

---

### `def module_prefix(modules: Iterable[str], target: str) -> str | None`

**Line:** 88

---

### `def split_target(modules: Iterable[str], target: str) -> tuple[str, str] | None`

**Line:** 95

---

### `def short_type(obj: object) -> str`

**Description:**
Return the last component of the type name of an object.

If obj is None, return 'nil'. For example, if obj is 1, return 'int'.

**Line:** 107

---

### `def find_python_encoding(text: bytes) -> tuple[(str, int)]`

**Description:**
PEP-263 for detecting Python file encoding

**Line:** 118

---

### `def bytes_to_human_readable_repr(b: bytes) -> str`

**Description:**
Converts bytes into some human-readable representation. Unprintable
bytes such as the nul byte are escaped. For example:

>>> b = bytes([102, 111, 111, 10, 0])
>>> s = bytes_to_human_readable_repr(b)
>>> print(s)
foo
 
>>> print(repr(s))
'foo\n\x00'

**Line:** 133

---

### `def decode_python_encoding(source: bytes) -> str`

**Description:**
Read the Python file with while obeying PEP-263 encoding detection.

Returns the source as a string.

**Line:** 154

---

### `def read_py_file(path: str, read: Callable[([str], bytes)]) -> list[str] | None`

**Description:**
Try reading a Python file as list of source lines.

Return None if something goes wrong.

**Line:** 174

---

### `def trim_source_line(line: str, max_len: int, col: int, min_width: int) -> tuple[(str, int)]`

**Description:**
Trim a line of source code to fit into max_len.

Show 'min_width' characters on each side of 'col' (an error location). If either
start or end is trimmed, this is indicated by adding '...' there.
A typical result looks like this:
...some_variable = function_to_call(one_arg, other_arg) or...

Return the trimmed string and the column offset to to adjust error location.

**Line:** 191

---

### `def get_mypy_comments(source: str) -> list[tuple[(int, str)]]`

**Line:** 223

---

### `def write_junit_xml(dt: float, serious: bool, messages: list[str], path: str, version: str, platform: str) -> None`

**Line:** 261

---

### `def get_prefix(fullname: str) -> str`

**Description:**
Drop the final component of a qualified name (e.g. ('x.y' -> 'x').

**Line:** 306

---

### `def correct_relative_import(cur_mod_id: str, relative: int, target: str, is_cur_package_init_file: bool) -> tuple[(str, bool)]`

**Line:** 311

---

### `def get_class_descriptors(cls: type[object]) -> Sequence[str]`

**Line:** 329

---

### `def replace_object_state(new: object, old: object, copy_dict: bool = False, skip_slots: tuple[(str, ...)] = ()) -> None`

**Description:**
Copy state of old node to the new node.

This handles cases where there is __dict__ and/or attribute descriptors
(either from slots or because the type is defined in a C extension module).

Assume that both objects have the same __class__.

**Line:** 342

---

### `def is_sub_path(path1: str, path2: str) -> bool`

**Description:**
Given two paths, return if path1 is a sub-path of path2.

**Line:** 374

---

### `def hard_exit(status: int = 0) -> None`

**Description:**
Kill the current process without fully cleaning up.

This can be quite a bit faster than a normal exit() since objects are not freed.

**Line:** 379

---

### `def unmangle(name: str) -> str`

**Description:**
Remove internal suffixes from a short name.

**Line:** 389

---

### `def get_unique_redefinition_name(name: str, existing: Container[str]) -> str`

**Description:**
Get a simple redefinition name not present among existing.

For example, for name 'foo' we try 'foo-redefinition', 'foo-redefinition2',
'foo-redefinition3', etc. until we find one that is not in existing.

**Line:** 394

---

### `def check_python_version(program: str) -> None`

**Description:**
Report issues with the Python used to run mypy, dmypy, or stubgen

**Line:** 410

---

### `def count_stats(messages: list[str]) -> tuple[(int, int, int)]`

**Description:**
Count total number of errors, notes and error_files in message list.

**Line:** 420

---

### `def split_words(msg: str) -> list[str]`

**Description:**
Split line of text into words (but not within quoted groups).

**Line:** 428

---

### `def get_terminal_width() -> int`

**Description:**
Get current terminal width if possible, otherwise return the default one.

**Line:** 445

---

### `def soft_wrap(msg: str, max_len: int, first_offset: int, num_indent: int = 0) -> str`

**Description:**
Wrap a long error message into few lines.

Breaks will only happen between words, and never inside a quoted group
(to avoid breaking types such as "Union[int, str]"). The 'first_offset' is
the width before the start of first line.

Pad every next line with 'num_indent' spaces. Every line will be at most 'max_len'
characters, except if it is a single word or quoted group.

For example:
first_offset
------------------------
path/to/file: error: 58: Some very long error message
that needs to be split in separate lines.
"Long[Type, Names]" are never split.
^^^^--------------------------------------------------
num_indent           max_len

**Line:** 454

---

### `def hash_digest(data: bytes) -> str`

**Description:**
Compute a hash digest of some data.

We use a cryptographic hash because we want a low probability of
accidental collision, but we don't really care about any of the
cryptographic properties.

**Line:** 490

---

### `def parse_gray_color(cup: bytes) -> str`

**Description:**
Reproduce a gray color in ANSI escape sequence

**Line:** 502

---

### `def should_force_color() -> bool`

**Line:** 511

---

### `def is_typeshed_file(typeshed_dir: str | None, file: str) -> bool`

**Line:** 780

---

### `def is_stub_package_file(file: str) -> bool`

**Line:** 788

---

### `def unnamed_function(name: str | None) -> bool`

**Line:** 795

---

### `def time_spent_us(t0: int) -> int`

**Line:** 802

---

### `def plural_s(s: int | Sized) -> str`

**Line:** 806

---

### `def quote_docstring(docstr: str) -> str`

**Description:**
Returns docstring correctly encapsulated in a single or double quoted form.

**Line:** 814

---


## Module: venv2.libthon3.12.site-packages.mypy_extensions
**File:** `venv2/lib/python3.12/site-packages/mypy_extensions.py`

**Imports:**
- sys
- typing.Any
- typing.Dict
- typing._type_check
- warnings

**Functions:**

### `def _check_fails(cls, other)`

**Line:** 16

---

### `def _dict_new(cls, *args, **kwargs)`

**Line:** 26

---

### `def _typeddict_new(cls, _typename, _fields = None, **kwargs)`

**Line:** 30

---

### `def Arg(type = Any, name = None)`

**Description:**
A normal positional argument

**Line:** 122

---

### `def DefaultArg(type = Any, name = None)`

**Description:**
A positional argument with a default value

**Line:** 127

---

### `def NamedArg(type = Any, name = None)`

**Description:**
A keyword-only argument

**Line:** 132

---

### `def DefaultNamedArg(type = Any, name = None)`

**Description:**
A keyword-only argument with a default value

**Line:** 137

---

### `def VarArg(type = Any)`

**Description:**
A *args-style variadic positional argument

**Line:** 142

---

### `def KwArg(type = Any)`

**Description:**
A **kwargs-style variadic keyword argument

**Line:** 147

---

### `def trait(cls)`

**Line:** 157

---

### `def mypyc_attr(*attrs, **kwattrs)`

**Line:** 161

---

### `def _warn_deprecation(name: str, module_globals: Dict[(str, Any)]) -> Any`

**Line:** 232

---

### `def __getattr__(name: str) -> Any`

**Line:** 250

---


## Module: venv2.libthon3.12.site-packages.mypyc.__main__
**File:** `venv2/lib/python3.12/site-packages/mypyc/__main__.py`

**Imports:**
- __future__.annotations
- os
- os.path
- subprocess
- sys

**Functions:**

### `def main() -> None`

**Line:** 32

---


## Module: venv2.libthon3.12.site-packages.mypyc.analysis.attrdefined
**File:** `venv2/lib/python3.12/site-packages/mypyc/analysis/attrdefined.py`

**Imports:**
- __future__.annotations
- mypyc.analysis.dataflow.AnalysisResult
- mypyc.analysis.dataflow.BaseAnalysisVisitor
- mypyc.analysis.dataflow.CFG
- mypyc.analysis.dataflow.MAYBE_ANALYSIS
- mypyc.analysis.dataflow.get_cfg
- mypyc.analysis.dataflow.run_analysis
- mypyc.analysis.selfleaks.analyze_self_leaks
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.ops.Assign
- mypyc.ir.ops.AssignMulti
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Branch
- mypyc.ir.ops.Call
- mypyc.ir.ops.ControlOp
- mypyc.ir.ops.GetAttr
- mypyc.ir.ops.Register
- mypyc.ir.ops.RegisterOp
- mypyc.ir.ops.Return
- mypyc.ir.ops.SetAttr
- mypyc.ir.ops.SetMem
- mypyc.ir.ops.Unreachable
- mypyc.ir.rtypes.RInstance
- typing.Final
- typing.Set
- typing.Tuple

**Functions:**

### `def analyze_always_defined_attrs(class_irs: list[ClassIR]) -> None`

**Description:**
Find always defined attributes all classes of a compilation unit.

Also tag attribute initialization ops to not decref the previous
value (as this would read a NULL pointer and segfault).

Update the _always_initialized_attrs, _sometimes_initialized_attrs
and init_self_leak attributes in ClassIR instances.

This is the main entry point.

**Line:** 100

---

### `def analyze_always_defined_attrs_in_class(cl: ClassIR, seen: set[ClassIR]) -> None`

**Line:** 128

---

### `def find_always_defined_attributes(blocks: list[BasicBlock], self_reg: Register, all_attrs: set[str], maybe_defined: AnalysisResult[str], maybe_undefined: AnalysisResult[str], dirty: AnalysisResult[None]) -> set[str]`

**Description:**
Find attributes that are always initialized in some basic blocks.

The analysis results are expected to be up-to-date for the blocks.

Return a set of always defined attributes.

**Line:** 191

---

### `def find_sometimes_defined_attributes(blocks: list[BasicBlock], self_reg: Register, maybe_defined: AnalysisResult[str], dirty: AnalysisResult[None]) -> set[str]`

**Description:**
Find attributes that are sometimes initialized in some basic blocks.

**Line:** 241

---

### `def mark_attr_initialiation_ops(blocks: list[BasicBlock], self_reg: Register, maybe_defined: AnalysisResult[str], dirty: AnalysisResult[None]) -> None`

**Description:**
Tag all SetAttr ops in the basic blocks that initialize attributes.

Initialization ops assume that the previous attribute value is the error value,
so there's no need to decref or check for definedness.

**Line:** 263

---

### `def attributes_initialized_by_init_call(op: Call) -> set[str]`

**Description:**
Calculate attributes that are always initialized by a super().__init__ call.

**Line:** 285

---

### `def attributes_maybe_initialized_by_init_call(op: Call) -> set[str]`

**Description:**
Calculate attributes that may be initialized by a super().__init__ call.

**Line:** 293

---

### `def analyze_maybe_defined_attrs_in_init(blocks: list[BasicBlock], self_reg: Register, attrs_with_defaults: set[str], cfg: CFG) -> AnalysisResult[str]`

**Line:** 337

---

### `def analyze_maybe_undefined_attrs_in_init(blocks: list[BasicBlock], self_reg: Register, initial_undefined: set[str], cfg: CFG) -> AnalysisResult[str]`

**Line:** 386

---

### `def update_always_defined_attrs_using_subclasses(cl: ClassIR, seen: set[ClassIR]) -> None`

**Description:**
Remove attributes not defined in all subclasses from always defined attrs.

**Line:** 399

---

### `def detect_undefined_bitmap(cl: ClassIR, seen: set[ClassIR]) -> None`

**Line:** 416

---


## Module: venv2.libthon3.12.site-packages.mypyc.analysis.blockfreq
**File:** `venv2/lib/python3.12/site-packages/mypyc/analysis/blockfreq.py`

**Imports:**
- __future__.annotations
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Branch
- mypyc.ir.ops.Goto

**Functions:**

### `def frequently_executed_blocks(entry_point: BasicBlock) -> set[BasicBlock]`

**Line:** 15

---


## Module: venv2.libthon3.12.site-packages.mypyc.analysis.dataflow
**File:** `venv2/lib/python3.12/site-packages/mypyc/analysis/dataflow.py`

**Imports:**
- __future__.annotations
- abc.abstractmethod
- mypyc.ir.func_ir.all_values
- mypyc.ir.ops.Assign
- mypyc.ir.ops.AssignMulti
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Box
- mypyc.ir.ops.Branch
- mypyc.ir.ops.Call
- mypyc.ir.ops.CallC
- mypyc.ir.ops.Cast
- mypyc.ir.ops.ComparisonOp
- mypyc.ir.ops.ControlOp
- mypyc.ir.ops.Extend
- mypyc.ir.ops.Float
- mypyc.ir.ops.FloatComparisonOp
- mypyc.ir.ops.FloatNeg
- mypyc.ir.ops.FloatOp
- mypyc.ir.ops.GetAttr
- mypyc.ir.ops.GetElementPtr
- mypyc.ir.ops.Goto
- mypyc.ir.ops.InitStatic
- mypyc.ir.ops.IntOp
- mypyc.ir.ops.Integer
- mypyc.ir.ops.KeepAlive
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.LoadErrorValue
- mypyc.ir.ops.LoadGlobal
- mypyc.ir.ops.LoadLiteral
- mypyc.ir.ops.LoadMem
- mypyc.ir.ops.LoadStatic
- mypyc.ir.ops.MethodCall
- mypyc.ir.ops.Op
- mypyc.ir.ops.OpVisitor
- mypyc.ir.ops.RaiseStandardError
- mypyc.ir.ops.RegisterOp
- mypyc.ir.ops.Return
- mypyc.ir.ops.SetAttr
- mypyc.ir.ops.SetMem
- mypyc.ir.ops.Truncate
- mypyc.ir.ops.TupleGet
- mypyc.ir.ops.TupleSet
- mypyc.ir.ops.Unborrow
- mypyc.ir.ops.Unbox
- mypyc.ir.ops.Unreachable
- mypyc.ir.ops.Value
- typing.Dict
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.Set
- typing.Tuple
- typing.TypeVar

**Functions:**

### `def get_cfg(blocks: list[BasicBlock]) -> CFG`

**Description:**
Calculate basic block control-flow graph.

The result is a dictionary like this:

basic block index -> (successors blocks, predecesssor blocks)

**Line:** 79

---

### `def get_real_target(label: BasicBlock) -> BasicBlock`

**Line:** 122

---

### `def cleanup_cfg(blocks: list[BasicBlock]) -> None`

**Description:**
Cleanup the control flow graph.

This eliminates obviously dead basic blocks and eliminates blocks that contain
nothing but a single jump.

There is a lot more that could be done.

**Line:** 128

---

### `def analyze_maybe_defined_regs(blocks: list[BasicBlock], cfg: CFG, initial_defined: set[Value]) -> AnalysisResult[Value]`

**Description:**
Calculate potentially defined registers at each CFG location.

A register is defined if it has a value along some path from the initial location.

**Line:** 323

---

### `def analyze_must_defined_regs(blocks: list[BasicBlock], cfg: CFG, initial_defined: set[Value], regs: Iterable[Value], strict_errors: bool = False) -> AnalysisResult[Value]`

**Description:**
Calculate always defined registers at each CFG location.

This analysis can work before exception insertion, since it is a
sound assumption that registers defined in a block might not be
initialized in its error handler.

A register is defined if it has a value along all paths from the
initial location.

**Line:** 340

---

### `def analyze_borrowed_arguments(blocks: list[BasicBlock], cfg: CFG, borrowed: set[Value]) -> AnalysisResult[Value]`

**Description:**
Calculate arguments that can use references borrowed from the caller.

When assigning to an argument, it no longer is borrowed.

**Line:** 395

---

### `def analyze_undefined_regs(blocks: list[BasicBlock], cfg: CFG, initial_defined: set[Value]) -> AnalysisResult[Value]`

**Description:**
Calculate potentially undefined registers at each CFG location.

A register is undefined if there is some path from initial block
where it has an undefined value.

Function arguments are assumed to be always defined.

**Line:** 436

---

### `def non_trivial_sources(op: Op) -> set[Value]`

**Line:** 457

---

### `def analyze_live_regs(blocks: list[BasicBlock], cfg: CFG) -> AnalysisResult[Value]`

**Description:**
Calculate live registers at each CFG location.

A register is live at a location if it can be read along some CFG path starting
from the location.

**Line:** 495

---

### `def run_analysis(blocks: list[BasicBlock], cfg: CFG, gen_and_kill: OpVisitor[GenAndKill[T]], initial: set[T], kind: int, backward: bool, universe: set[T] | None = None) -> AnalysisResult[T]`

**Description:**
Run a general set-based data flow analysis.

Args:
blocks: All basic blocks
cfg: Control-flow graph for the code
gen_and_kill: Implementation of gen and kill functions for each op
initial: Value of analysis for the entry points (for a forward analysis) or the
exit points (for a backward analysis)
kind: MUST_ANALYSIS or MAYBE_ANALYSIS
backward: If False, the analysis is a forward analysis; it's backward otherwise
universe: For a must analysis, the set of all possible values. This is the starting
value for the work list algorithm, which will narrow this down until reaching a
fixed point. For a maybe analysis the iteration always starts from an empty set
and this argument is ignored.

Return analysis results: (before, after)

**Line:** 516

---


## Module: venv2.libthon3.12.site-packages.mypyc.analysis.ircheck
**File:** `venv2/lib/python3.12/site-packages/mypyc/analysis/ircheck.py`

**Imports:**
- __future__.annotations
- mypyc.ir.func_ir.FUNC_STATICMETHOD
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.ops.Assign
- mypyc.ir.ops.AssignMulti
- mypyc.ir.ops.BaseAssign
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Box
- mypyc.ir.ops.Branch
- mypyc.ir.ops.Call
- mypyc.ir.ops.CallC
- mypyc.ir.ops.Cast
- mypyc.ir.ops.ComparisonOp
- mypyc.ir.ops.ControlOp
- mypyc.ir.ops.DecRef
- mypyc.ir.ops.Extend
- mypyc.ir.ops.FloatComparisonOp
- mypyc.ir.ops.FloatNeg
- mypyc.ir.ops.FloatOp
- mypyc.ir.ops.GetAttr
- mypyc.ir.ops.GetElementPtr
- mypyc.ir.ops.Goto
- mypyc.ir.ops.IncRef
- mypyc.ir.ops.InitStatic
- mypyc.ir.ops.IntOp
- mypyc.ir.ops.Integer
- mypyc.ir.ops.KeepAlive
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.LoadErrorValue
- mypyc.ir.ops.LoadGlobal
- mypyc.ir.ops.LoadLiteral
- mypyc.ir.ops.LoadMem
- mypyc.ir.ops.LoadStatic
- mypyc.ir.ops.MethodCall
- mypyc.ir.ops.Op
- mypyc.ir.ops.OpVisitor
- mypyc.ir.ops.RaiseStandardError
- mypyc.ir.ops.Register
- mypyc.ir.ops.Return
- mypyc.ir.ops.SetAttr
- mypyc.ir.ops.SetMem
- mypyc.ir.ops.Truncate
- mypyc.ir.ops.TupleGet
- mypyc.ir.ops.TupleSet
- mypyc.ir.ops.Unborrow
- mypyc.ir.ops.Unbox
- mypyc.ir.ops.Unreachable
- mypyc.ir.ops.Value
- mypyc.ir.pprint.format_func
- mypyc.ir.rtypes.RArray
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.RPrimitive
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.RUnion
- mypyc.ir.rtypes.bytes_rprimitive
- mypyc.ir.rtypes.dict_rprimitive
- mypyc.ir.rtypes.int_rprimitive
- mypyc.ir.rtypes.is_float_rprimitive
- mypyc.ir.rtypes.is_object_rprimitive
- mypyc.ir.rtypes.list_rprimitive
- mypyc.ir.rtypes.range_rprimitive
- mypyc.ir.rtypes.set_rprimitive
- mypyc.ir.rtypes.str_rprimitive
- mypyc.ir.rtypes.tuple_rprimitive

**Functions:**

### `def check_func_ir(fn: FuncIR) -> list[FnError]`

**Description:**
Applies validations to a given function ir and returns a list of errors found.

**Line:** 86

---

### `def assert_func_ir_valid(fn: FuncIR) -> None`

**Line:** 121

---

### `def check_op_sources_valid(fn: FuncIR) -> list[FnError]`

**Line:** 130

---

### `def can_coerce_to(src: RType, dest: RType) -> bool`

**Description:**
Check if src can be assigned to dest_rtype.

Currently okay to have false positives.

**Line:** 182

---


## Module: venv2.libthon3.12.site-packages.mypyc.analysis.selfleaks
**File:** `venv2/lib/python3.12/site-packages/mypyc/analysis/selfleaks.py`

**Imports:**
- __future__.annotations
- mypyc.analysis.dataflow.AnalysisResult
- mypyc.analysis.dataflow.CFG
- mypyc.analysis.dataflow.MAYBE_ANALYSIS
- mypyc.analysis.dataflow.run_analysis
- mypyc.ir.ops.Assign
- mypyc.ir.ops.AssignMulti
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Box
- mypyc.ir.ops.Branch
- mypyc.ir.ops.Call
- mypyc.ir.ops.CallC
- mypyc.ir.ops.Cast
- mypyc.ir.ops.ComparisonOp
- mypyc.ir.ops.Extend
- mypyc.ir.ops.FloatComparisonOp
- mypyc.ir.ops.FloatNeg
- mypyc.ir.ops.FloatOp
- mypyc.ir.ops.GetAttr
- mypyc.ir.ops.GetElementPtr
- mypyc.ir.ops.Goto
- mypyc.ir.ops.InitStatic
- mypyc.ir.ops.IntOp
- mypyc.ir.ops.KeepAlive
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.LoadErrorValue
- mypyc.ir.ops.LoadGlobal
- mypyc.ir.ops.LoadLiteral
- mypyc.ir.ops.LoadMem
- mypyc.ir.ops.LoadStatic
- mypyc.ir.ops.MethodCall
- mypyc.ir.ops.OpVisitor
- mypyc.ir.ops.RaiseStandardError
- mypyc.ir.ops.Register
- mypyc.ir.ops.RegisterOp
- mypyc.ir.ops.Return
- mypyc.ir.ops.SetAttr
- mypyc.ir.ops.SetMem
- mypyc.ir.ops.Truncate
- mypyc.ir.ops.TupleGet
- mypyc.ir.ops.TupleSet
- mypyc.ir.ops.Unborrow
- mypyc.ir.ops.Unbox
- mypyc.ir.ops.Unreachable
- mypyc.ir.rtypes.RInstance
- typing.Set
- typing.Tuple

**Functions:**

### `def analyze_self_leaks(blocks: list[BasicBlock], self_reg: Register, cfg: CFG) -> AnalysisResult[None]`

**Line:** 197

---


## Module: venv2.libthon3.12.site-packages.mypyc.build
**File:** `venv2/lib/python3.12/site-packages/mypyc/build.py`

**Imports:**
- __future__.annotations
- distutils.ccompiler
- distutils.core
- distutils.core.Extension
- distutils.sysconfig
- hashlib
- mypy.build.BuildSource
- mypy.errors.CompileError
- mypy.fscache.FileSystemCache
- mypy.main.process_options
- mypy.options.Options
- mypy.util.write_junit_xml
- mypyc.codegen.emitmodule
- mypyc.common.RUNTIME_C_FILES
- mypyc.common.shared_lib_name
- mypyc.errors.Errors
- mypyc.ir.pprint.format_modules
- mypyc.namegen.exported_name
- mypyc.options.CompilerOptions
- os.path
- re
- setuptools
- setuptools.Extension
- sys
- time
- typing.Any
- typing.Dict
- typing.Iterable
- typing.NoReturn
- typing.TYPE_CHECKING
- typing.Union
- typing.cast
- typing_extensions.TypeAlias

**Functions:**

### `def get_extension() -> type[Extension]`

**Line:** 67

---

### `def setup_mypycify_vars() -> None`

**Description:**
Rewrite a bunch of config vars in pretty dubious ways.

**Line:** 85

---

### `def fail(message: str) -> NoReturn`

**Line:** 99

---

### `def emit_messages(options: Options, messages: list[str], dt: float, serious: bool = False) -> None`

**Line:** 104

---

### `def get_mypy_config(mypy_options: list[str], only_compile_paths: Iterable[str] | None, compiler_options: CompilerOptions, fscache: FileSystemCache | None) -> tuple[(list[BuildSource], list[BuildSource], Options)]`

**Description:**
Construct mypy BuildSources and Options from file and options lists

**Line:** 113

---

### `def generate_c_extension_shim(full_module_name: str, module_name: str, dir_name: str, group_name: str) -> str`

**Description:**
Create a C extension shim with a passthrough PyInit function.

Arguments:
full_module_name: the dotted full module name
module_name: the final component of the module name
dir_name: the directory to place source code
group_name: the name of the group

**Line:** 156

---

### `def group_name(modules: list[str]) -> str`

**Description:**
Produce a probably unique name for a group from a list of module names.

**Line:** 187

---

### `def include_dir() -> str`

**Description:**
Find the path of the lib-rt dir that needs to be included

**Line:** 197

---

### `def generate_c(sources: list[BuildSource], options: Options, groups: emitmodule.Groups, fscache: FileSystemCache, compiler_options: CompilerOptions) -> tuple[(list[list[tuple[str, str]]], str)]`

**Description:**
Drive the actual core compilation step.

The groups argument describes how modules are assigned to C
extension modules. See the comments on the Groups type in
mypyc.emitmodule for details.

Returns the C source code and (for debugging) the pretty printed IR.

**Line:** 202

---

### `def build_using_shared_lib(sources: list[BuildSource], group_name: str, cfiles: list[str], deps: list[str], build_dir: str, extra_compile_args: list[str]) -> list[Extension]`

**Description:**
Produce the list of extension modules when a shared library is needed.

This creates one shared library extension module that all of the
others import and then one shim extension module for each
module in the build, that simply calls an initialization function
in the shared library.

The shared library (which lib_name is the name of) is a python
extension module that exports the real initialization functions in
Capsules stored in module attributes.

**Line:** 251

---

### `def build_single_module(sources: list[BuildSource], cfiles: list[str], extra_compile_args: list[str]) -> list[Extension]`

**Description:**
Produce the list of extension modules for a standalone extension.

This contains just one module, since there is no need for a shared module.

**Line:** 299

---

### `def write_file(path: str, contents: str) -> None`

**Description:**
Write data into a file.

If the file already exists and has the same contents we
want to write, skip writing so as to preserve the mtime
and avoid triggering recompilation.

**Line:** 316

---

### `def construct_groups(sources: list[BuildSource], separate: bool | list[tuple[list[str], str | None]], use_shared_lib: bool) -> emitmodule.Groups`

**Description:**
Compute Groups given the input source list and separate configs.

separate is the user-specified configuration for how to assign
modules to compilation groups (see mypycify docstring for details).

This takes that and expands it into our internal representation of
group configuration, documented in mypyc.emitmodule's definition
of Group.

**Line:** 344

---

### `def get_header_deps(cfiles: list[tuple[(str, str)]]) -> list[str]`

**Description:**
Find all the headers used by a group of cfiles.

We do this by just regexping the source, which is a bit simpler than
properly plumbing the data through.

Arguments:
cfiles: A list of (file name, file contents) pairs.

**Line:** 383

---

### `def mypyc_build(paths: list[str], compiler_options: CompilerOptions, separate: bool | list[tuple[list[str], str | None]] = False, only_compile_paths: Iterable[str] | None = None, skip_cgen_input: Any | None = None, always_use_shared_lib: bool = False) -> tuple[(emitmodule.Groups, list[tuple[list[str], list[str]]])]`

**Description:**
Do the front and middle end of mypyc building, producing and writing out C source.

**Line:** 399

---

### `def mypycify(paths: list[str], only_compile_paths: Iterable[str] | None = None, verbose: bool = False, opt_level: str = '3', debug_level: str = '1', strip_asserts: bool = False, multi_file: bool = False, separate: bool | list[tuple[list[str], str | None]] = False, skip_cgen_input: Any | None = None, target_dir: str | None = None, include_runtime_files: bool | None = None) -> list[Extension]`

**Description:**
Main entry point to building using mypyc.

This produces a list of Extension objects that should be passed as the
ext_modules parameter to setup.

Arguments:
paths: A list of file paths to build. It may also contain mypy options.
only_compile_paths: If not None, an iterable of paths that are to be
the only modules compiled, even if other modules
appear in the mypy command line given to paths.
(These modules must still be passed to paths.)

verbose: Should mypyc be more verbose. Defaults to false.

opt_level: The optimization level, as a string. Defaults to '3' (meaning '-O3').
debug_level: The debug level, as a string. Defaults to '1' (meaning '-g1').
strip_asserts: Should asserts be stripped from the generated code.

multi_file: Should each Python module be compiled into its own C source file.
This can reduce compile time and memory requirements at the likely
cost of runtime performance of compiled code. Defaults to false.
separate: Should compiled modules be placed in separate extension modules.
If False, all modules are placed in a single shared library.
If True, every module is placed in its own library.
Otherwise separate should be a list of
(file name list, optional shared library name) pairs specifying
groups of files that should be placed in the same shared library
(while all other modules will be placed in its own library).

Each group can be compiled independently, which can
speed up compilation, but calls between groups can
be slower than calls within a group and can't be
inlined.
target_dir: The directory to write C output files. Defaults to 'build'.
include_runtime_files: If not None, whether the mypyc runtime library
should be directly #include'd instead of linked
separately in order to reduce compiler invocations.
Defaults to False in multi_file mode, True otherwise.

**Line:** 453

---


## Module: venv2.libthon3.12.site-packages.mypyc.codegen.cstring
**File:** `venv2/lib/python3.12/site-packages/mypyc/codegen/cstring.py`

**Imports:**
- __future__.annotations
- string
- typing.Final

**Functions:**

### `def encode_bytes_as_c_string(b: bytes) -> str`

**Description:**
Produce contents of a C string literal for a byte string, without quotes.

**Line:** 43

---

### `def c_string_initializer(value: bytes) -> str`

**Description:**
Create initializer for a C char[]/ char * variable from a string.

For example, if value if b'foo', the result would be '"foo"'.

**Line:** 49

---


## Module: venv2.libthon3.12.site-packages.mypyc.codegen.emit
**File:** `venv2/lib/python3.12/site-packages/mypyc/codegen/emit.py`

**Imports:**
- __future__.annotations
- mypyc.codegen.literals.Literals
- mypyc.common.ATTR_PREFIX
- mypyc.common.BITMAP_BITS
- mypyc.common.FAST_ISINSTANCE_MAX_SUBCLASSES
- mypyc.common.NATIVE_PREFIX
- mypyc.common.REG_PREFIX
- mypyc.common.STATIC_PREFIX
- mypyc.common.TYPE_PREFIX
- mypyc.common.use_vectorcall
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.class_ir.all_concrete_classes
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.RPrimitive
- mypyc.ir.rtypes.RTuple
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.RUnion
- mypyc.ir.rtypes.int_rprimitive
- mypyc.ir.rtypes.is_bit_rprimitive
- mypyc.ir.rtypes.is_bool_rprimitive
- mypyc.ir.rtypes.is_bytes_rprimitive
- mypyc.ir.rtypes.is_dict_rprimitive
- mypyc.ir.rtypes.is_fixed_width_rtype
- mypyc.ir.rtypes.is_float_rprimitive
- mypyc.ir.rtypes.is_int16_rprimitive
- mypyc.ir.rtypes.is_int32_rprimitive
- mypyc.ir.rtypes.is_int64_rprimitive
- mypyc.ir.rtypes.is_int_rprimitive
- mypyc.ir.rtypes.is_list_rprimitive
- mypyc.ir.rtypes.is_none_rprimitive
- mypyc.ir.rtypes.is_object_rprimitive
- mypyc.ir.rtypes.is_optional_type
- mypyc.ir.rtypes.is_range_rprimitive
- mypyc.ir.rtypes.is_set_rprimitive
- mypyc.ir.rtypes.is_short_int_rprimitive
- mypyc.ir.rtypes.is_str_rprimitive
- mypyc.ir.rtypes.is_tuple_rprimitive
- mypyc.ir.rtypes.is_uint8_rprimitive
- mypyc.ir.rtypes.object_rprimitive
- mypyc.ir.rtypes.optional_value_type
- mypyc.namegen.NameGenerator
- mypyc.namegen.exported_name
- mypyc.sametype.is_same_type
- pprint
- sys
- textwrap
- typing.Callable
- typing.Final

**Functions:**

### `def c_array_initializer(components: list[str], indented: bool = False) -> str`

**Description:**
Construct an initializer for a C array variable.

Components are C expressions valid in an initializer.

For example, if components are ["1", "2"], the result
would be "{1, 2}", which can be used like this:

int a[] = {1, 2};

If the result is long, split it into multiple lines.

**Line:** 1164

---


## Module: venv2.libthon3.12.site-packages.mypyc.codegen.emitclass
**File:** `venv2/lib/python3.12/site-packages/mypyc/codegen/emitclass.py`

**Imports:**
- __future__.annotations
- mypyc.codegen.emit.Emitter
- mypyc.codegen.emit.HeaderDeclaration
- mypyc.codegen.emit.ReturnHandler
- mypyc.codegen.emitfunc.native_function_header
- mypyc.codegen.emitwrapper.generate_bin_op_wrapper
- mypyc.codegen.emitwrapper.generate_bool_wrapper
- mypyc.codegen.emitwrapper.generate_contains_wrapper
- mypyc.codegen.emitwrapper.generate_dunder_wrapper
- mypyc.codegen.emitwrapper.generate_get_wrapper
- mypyc.codegen.emitwrapper.generate_hash_wrapper
- mypyc.codegen.emitwrapper.generate_ipow_wrapper
- mypyc.codegen.emitwrapper.generate_len_wrapper
- mypyc.codegen.emitwrapper.generate_richcompare_wrapper
- mypyc.codegen.emitwrapper.generate_set_del_item_wrapper
- mypyc.common.BITMAP_BITS
- mypyc.common.BITMAP_TYPE
- mypyc.common.NATIVE_PREFIX
- mypyc.common.PREFIX
- mypyc.common.REG_PREFIX
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.class_ir.VTableEntries
- mypyc.ir.func_ir.FUNC_CLASSMETHOD
- mypyc.ir.func_ir.FUNC_STATICMETHOD
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.rtypes.RTuple
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.object_rprimitive
- mypyc.namegen.NameGenerator
- mypyc.sametype.is_same_type
- typing.Callable
- typing.Mapping
- typing.Tuple

**Functions:**

### `def native_slot(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str`

**Line:** 29

---

### `def wrapper_slot(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str`

**Line:** 33

---

### `def generate_call_wrapper(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str`

**Line:** 138

---

### `def slot_key(attr: str) -> str`

**Description:**
Map dunder method name to sort key.

Sort reverse operator methods and __delitem__ after others ('x' > '_').

**Line:** 147

---

### `def generate_slots(cl: ClassIR, table: SlotTable, emitter: Emitter) -> dict[(str, str)]`

**Line:** 157

---

### `def generate_class_type_decl(cl: ClassIR, c_emitter: Emitter, external_emitter: Emitter, emitter: Emitter) -> None`

**Line:** 176

---

### `def generate_class(cl: ClassIR, module: str, emitter: Emitter) -> None`

**Description:**
Generate C code for a class.

This is the main entry point to the module.

**Line:** 197

---

### `def getter_name(cl: ClassIR, attribute: str, names: NameGenerator) -> str`

**Line:** 372

---

### `def setter_name(cl: ClassIR, attribute: str, names: NameGenerator) -> str`

**Line:** 376

---

### `def generate_object_struct(cl: ClassIR, emitter: Emitter) -> None`

**Line:** 380

---

### `def generate_vtables(base: ClassIR, vtable_setup_name: str, vtable_name: str, emitter: Emitter, shadow: bool) -> str`

**Description:**
Emit the vtables and vtable setup functions for a class.

This includes both the primary vtable and any trait implementation vtables.
The trait vtables go before the main vtable, and have the following layout:
{
CPyType_T1,         // pointer to type object
C_T1_trait_vtable,  // pointer to array of method pointers
C_T1_offset_table,  // pointer to array of attribute offsets
CPyType_T2,
C_T2_trait_vtable,
C_T2_offset_table,
...
}
The method implementations are calculated at the end of IR pass, attribute
offsets are {offsetof(native__C, _x1), offsetof(native__C, _y1), ...}.

To account for both dynamic loading and dynamic class creation,
vtables are populated dynamically at class creation time, so we
emit empty array definitions to store the vtables and a function to
populate them.

If shadow is True, generate "shadow vtables" that point to the
shadow glue methods (which should dispatch via the Python C-API).

Returns the expression to use to refer to the vtable, which might be
different than the name, if there are trait vtables.

**Line:** 412

---

### `def generate_offset_table(trait_offset_table_name: str, emitter: Emitter, trait: ClassIR, cl: ClassIR) -> None`

**Description:**
Generate attribute offset row of a trait vtable.

**Line:** 498

---

### `def generate_vtable(entries: VTableEntries, vtable_name: str, emitter: Emitter, subtables: list[tuple[(ClassIR, str, str)]], shadow: bool) -> None`

**Line:** 514

---

### `def generate_setup_for_class(cl: ClassIR, func_name: str, defaults_fn: FuncIR | None, vtable_name: str, shadow_vtable_name: str | None, emitter: Emitter) -> None`

**Description:**
Generate a native function that allocates an instance of a class.

**Line:** 549

---

### `def generate_constructor_for_class(cl: ClassIR, fn: FuncDecl, init_fn: FuncIR | None, setup_name: str, vtable_name: str, emitter: Emitter) -> None`

**Description:**
Generate a native function that allocates and initializes an instance of a class.

**Line:** 606

---

### `def generate_init_for_class(cl: ClassIR, init_fn: FuncIR, emitter: Emitter) -> str`

**Description:**
Generate an init function suitable for use as tp_init.

tp_init needs to be a function that returns an int, and our
__init__ methods return a PyObject. Translate NULL to -1,
everything else to 0.

**Line:** 648

---

### `def generate_new_for_class(cl: ClassIR, func_name: str, vtable_name: str, setup_name: str, init_fn: FuncIR | None, emitter: Emitter) -> None`

**Line:** 673

---

### `def generate_new_for_trait(cl: ClassIR, func_name: str, emitter: Emitter) -> None`

**Line:** 710

---

### `def generate_traverse_for_class(cl: ClassIR, func_name: str, emitter: Emitter) -> None`

**Description:**
Emit function that performs cycle GC traversal of an instance.

**Line:** 726

---

### `def generate_clear_for_class(cl: ClassIR, func_name: str, emitter: Emitter) -> None`

**Line:** 752

---

### `def generate_dealloc_for_class(cl: ClassIR, dealloc_func_name: str, clear_func_name: str, emitter: Emitter) -> None`

**Line:** 775

---

### `def generate_methods_table(cl: ClassIR, name: str, emitter: Emitter) -> None`

**Line:** 790

---

### `def generate_side_table_for_class(cl: ClassIR, name: str, type: str, slots: dict[(str, str)], emitter: Emitter) -> str | None`

**Line:** 816

---

### `def generate_getseter_declarations(cl: ClassIR, emitter: Emitter) -> None`

**Line:** 827

---

### `def generate_getseters_table(cl: ClassIR, name: str, emitter: Emitter) -> None`

**Line:** 865

---

### `def generate_getseters(cl: ClassIR, emitter: Emitter) -> None`

**Line:** 896

---

### `def generate_getter(cl: ClassIR, attr: str, rtype: RType, emitter: Emitter) -> None`

**Line:** 917

---

### `def generate_setter(cl: ClassIR, attr: str, rtype: RType, emitter: Emitter) -> None`

**Line:** 945

---

### `def generate_readonly_getter(cl: ClassIR, attr: str, rtype: RType, func_ir: FuncIR, emitter: Emitter) -> None`

**Line:** 1002

---

### `def generate_property_setter(cl: ClassIR, attr: str, arg_type: RType, func_ir: FuncIR, emitter: Emitter) -> None`

**Line:** 1028

---

### `def has_managed_dict(cl: ClassIR, emitter: Emitter) -> bool`

**Description:**
Should the class get the Py_TPFLAGS_MANAGED_DICT flag?

**Line:** 1051

---


## Module: venv2.libthon3.12.site-packages.mypyc.codegen.emitfunc
**File:** `venv2/lib/python3.12/site-packages/mypyc/codegen/emitfunc.py`

**Imports:**
- __future__.annotations
- mypyc.analysis.blockfreq.frequently_executed_blocks
- mypyc.codegen.emit.DEBUG_ERRORS
- mypyc.codegen.emit.Emitter
- mypyc.codegen.emit.TracebackAndGotoHandler
- mypyc.codegen.emit.c_array_initializer
- mypyc.common.MODULE_PREFIX
- mypyc.common.NATIVE_PREFIX
- mypyc.common.REG_PREFIX
- mypyc.common.STATIC_PREFIX
- mypyc.common.TYPE_PREFIX
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.func_ir.FUNC_CLASSMETHOD
- mypyc.ir.func_ir.FUNC_STATICMETHOD
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.func_ir.all_values
- mypyc.ir.ops.Assign
- mypyc.ir.ops.AssignMulti
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Box
- mypyc.ir.ops.Branch
- mypyc.ir.ops.Call
- mypyc.ir.ops.CallC
- mypyc.ir.ops.Cast
- mypyc.ir.ops.ComparisonOp
- mypyc.ir.ops.ControlOp
- mypyc.ir.ops.DecRef
- mypyc.ir.ops.ERR_FALSE
- mypyc.ir.ops.Extend
- mypyc.ir.ops.Float
- mypyc.ir.ops.FloatComparisonOp
- mypyc.ir.ops.FloatNeg
- mypyc.ir.ops.FloatOp
- mypyc.ir.ops.GetAttr
- mypyc.ir.ops.GetElementPtr
- mypyc.ir.ops.Goto
- mypyc.ir.ops.IncRef
- mypyc.ir.ops.InitStatic
- mypyc.ir.ops.IntOp
- mypyc.ir.ops.Integer
- mypyc.ir.ops.KeepAlive
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.LoadErrorValue
- mypyc.ir.ops.LoadGlobal
- mypyc.ir.ops.LoadLiteral
- mypyc.ir.ops.LoadMem
- mypyc.ir.ops.LoadStatic
- mypyc.ir.ops.MethodCall
- mypyc.ir.ops.NAMESPACE_MODULE
- mypyc.ir.ops.NAMESPACE_STATIC
- mypyc.ir.ops.NAMESPACE_TYPE
- mypyc.ir.ops.Op
- mypyc.ir.ops.OpVisitor
- mypyc.ir.ops.RaiseStandardError
- mypyc.ir.ops.Register
- mypyc.ir.ops.Return
- mypyc.ir.ops.SetAttr
- mypyc.ir.ops.SetMem
- mypyc.ir.ops.Truncate
- mypyc.ir.ops.TupleGet
- mypyc.ir.ops.TupleSet
- mypyc.ir.ops.Unborrow
- mypyc.ir.ops.Unbox
- mypyc.ir.ops.Unreachable
- mypyc.ir.ops.Value
- mypyc.ir.pprint.generate_names_for_ir
- mypyc.ir.rtypes.RArray
- mypyc.ir.rtypes.RStruct
- mypyc.ir.rtypes.RTuple
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.is_int32_rprimitive
- mypyc.ir.rtypes.is_int64_rprimitive
- mypyc.ir.rtypes.is_int_rprimitive
- mypyc.ir.rtypes.is_pointer_rprimitive
- mypyc.ir.rtypes.is_tagged
- typing.Final

**Functions:**

### `def native_function_type(fn: FuncIR, emitter: Emitter) -> str`

**Line:** 77

---

### `def native_function_header(fn: FuncDecl, emitter: Emitter) -> str`

**Line:** 83

---

### `def generate_native_function(fn: FuncIR, emitter: Emitter, source_path: str, module_name: str) -> None`

**Line:** 95

---


## Module: venv2.libthon3.12.site-packages.mypyc.codegen.emitmodule
**File:** `venv2/lib/python3.12/site-packages/mypyc/codegen/emitmodule.py`

**Imports:**
- __future__.annotations
- json
- mypy.build.BuildResult
- mypy.build.BuildSource
- mypy.build.State
- mypy.build.build
- mypy.build.compute_hash
- mypy.build.create_metastore
- mypy.build.get_cache_names
- mypy.build.sorted_components
- mypy.errors.CompileError
- mypy.fscache.FileSystemCache
- mypy.nodes.MypyFile
- mypy.options.Options
- mypy.plugin.Plugin
- mypy.plugin.ReportConfigContext
- mypy.util.hash_digest
- mypyc.codegen.cstring.c_string_initializer
- mypyc.codegen.emit.Emitter
- mypyc.codegen.emit.EmitterContext
- mypyc.codegen.emit.HeaderDeclaration
- mypyc.codegen.emit.c_array_initializer
- mypyc.codegen.emitclass.generate_class
- mypyc.codegen.emitclass.generate_class_type_decl
- mypyc.codegen.emitfunc.generate_native_function
- mypyc.codegen.emitfunc.native_function_header
- mypyc.codegen.emitwrapper.generate_legacy_wrapper_function
- mypyc.codegen.emitwrapper.generate_wrapper_function
- mypyc.codegen.emitwrapper.legacy_wrapper_function_header
- mypyc.codegen.emitwrapper.wrapper_function_header
- mypyc.codegen.literals.Literals
- mypyc.common.MODULE_PREFIX
- mypyc.common.PREFIX
- mypyc.common.RUNTIME_C_FILES
- mypyc.common.TOP_LEVEL_NAME
- mypyc.common.shared_lib_name
- mypyc.common.short_id_from_name
- mypyc.common.use_vectorcall
- mypyc.errors.Errors
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.module_ir.ModuleIR
- mypyc.ir.module_ir.ModuleIRs
- mypyc.ir.module_ir.deserialize_modules
- mypyc.ir.ops.DeserMaps
- mypyc.ir.ops.LoadLiteral
- mypyc.ir.rtypes.RType
- mypyc.irbuild.main.build_ir
- mypyc.irbuild.mapper.Mapper
- mypyc.irbuild.prepare.load_type_map
- mypyc.namegen.NameGenerator
- mypyc.namegen.exported_name
- mypyc.options.CompilerOptions
- mypyc.transform.exceptions.insert_exception_handling
- mypyc.transform.refcount.insert_ref_count_opcodes
- mypyc.transform.uninit.insert_uninit_checks
- os
- typing.Iterable
- typing.List
- typing.Optional
- typing.Tuple
- typing.TypeVar

**Functions:**

### `def parse_and_typecheck(sources: list[BuildSource], options: Options, compiler_options: CompilerOptions, groups: Groups, fscache: FileSystemCache | None = None, alt_lib_path: str | None = None) -> BuildResult`

**Line:** 177

---

### `def compile_scc_to_ir(scc: list[MypyFile], result: BuildResult, mapper: Mapper, compiler_options: CompilerOptions, errors: Errors) -> ModuleIRs`

**Description:**
Compile an SCC into ModuleIRs.

Any modules that this SCC depends on must have either compiled or
loaded from a cache into mapper.

Arguments:
scc: The list of MypyFiles to compile
result: The BuildResult from the mypy front-end
mapper: The Mapper object mapping mypy ASTs to class and func IRs
compiler_options: The compilation options
errors: Where to report any errors encountered

Returns the IR of the modules.

**Line:** 198

---

### `def compile_modules_to_ir(result: BuildResult, mapper: Mapper, compiler_options: CompilerOptions, errors: Errors) -> ModuleIRs`

**Description:**
Compile a collection of modules into ModuleIRs.

The modules to compile are specified as part of mapper's group_map.

Returns the IR of the modules.

**Line:** 244

---

### `def compile_ir_to_c(groups: Groups, modules: ModuleIRs, result: BuildResult, mapper: Mapper, compiler_options: CompilerOptions) -> dict[(str | None, list[tuple[str, str]])]`

**Description:**
Compile a collection of ModuleIRs to C source text.

Returns a dictionary mapping group names to a list of (file name,
file text) pairs.

**Line:** 274

---

### `def get_ir_cache_name(id: str, path: str, options: Options) -> str`

**Line:** 314

---

### `def get_state_ir_cache_name(state: State) -> str`

**Line:** 319

---

### `def write_cache(modules: ModuleIRs, result: BuildResult, group_map: dict[(str, str | None)], ctext: dict[(str | None, list[tuple[str, str]])]) -> None`

**Description:**
Write out the cache information for modules.

Each module has the following cache information written (which is
in addition to the cache information written by mypy itself):
* A serialized version of its mypyc IR, minus the bodies of
functions. This allows code that depends on it to use
these serialized data structures when compiling against it
instead of needing to recompile it. (Compiling against a
module requires access to both its mypy and mypyc data
structures.)
* The hash of the mypy metadata cache file for the module.
This is used to ensure that the mypyc cache and the mypy
cache are in sync and refer to the same version of the code.
This is particularly important if mypyc crashes/errors/is
stopped after mypy has written its cache but before mypyc has.
* The hashes of all of the source file outputs for the group
the module is in. This is so that the module will be
recompiled if the source outputs are missing.

**Line:** 323

---

### `def load_scc_from_cache(scc: list[MypyFile], result: BuildResult, mapper: Mapper, ctx: DeserMaps) -> ModuleIRs`

**Description:**
Load IR for an SCC of modules from the cache.

Arguments and return are as compile_scc_to_ir.

**Line:** 376

---

### `def compile_modules_to_c(result: BuildResult, compiler_options: CompilerOptions, errors: Errors, groups: Groups) -> tuple[(ModuleIRs, list[FileContents])]`

**Description:**
Compile Python module(s) to the source of Python C extension modules.

This generates the source code for the "shared library" module
for each group. The shim modules are generated in mypyc.build.
Each shared library module provides, for each module in its group,
a PyCapsule containing an initialization function.
Additionally, it provides a capsule containing an export table of
pointers to all of the group's functions and static variables.

Arguments:
result: The BuildResult from the mypy front-end
compiler_options: The compilation options
errors: Where to report any errors encountered
groups: The groups that we are compiling. See documentation of Groups type above.

Returns the IR of the modules and a list containing the generated files for each group.

**Line:** 394

---

### `def generate_function_declaration(fn: FuncIR, emitter: Emitter) -> None`

**Line:** 433

---

### `def pointerize(decl: str, name: str) -> str`

**Description:**
Given a C decl and its name, modify it to be a declaration to a pointer.

**Line:** 448

---

### `def group_dir(group_name: str) -> str`

**Description:**
Given a group name, return the relative directory path for it.

**Line:** 459

---

### `def sort_classes(classes: list[tuple[(str, ClassIR)]]) -> list[tuple[(str, ClassIR)]]`

**Line:** 1062

---

### `def toposort(deps: dict[(T, set[T])]) -> list[T]`

**Description:**
Topologically sort a dict from item to dependencies.

This runs in O(V + E).

**Line:** 1079

---

### `def is_fastcall_supported(fn: FuncIR, capi_version: tuple[(int, int)]) -> bool`

**Line:** 1103

---

### `def collect_literals(fn: FuncIR, literals: Literals) -> None`

**Description:**
Store all Python literal object refs in fn.

Collecting literals must happen only after we have the final IR.
This way we won't include literals that have been optimized away.

**Line:** 1113

---

### `def c_string_array_initializer(components: list[bytes]) -> str`

**Line:** 1125

---


## Module: venv2.libthon3.12.site-packages.mypyc.codegen.emitwrapper
**File:** `venv2/lib/python3.12/site-packages/mypyc/codegen/emitwrapper.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_NAMED_OPT
- mypy.nodes.ARG_OPT
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.ArgKind
- mypy.operators.op_methods_to_symbols
- mypy.operators.reverse_op_method_names
- mypy.operators.reverse_op_methods
- mypyc.codegen.emit.AssignHandler
- mypyc.codegen.emit.Emitter
- mypyc.codegen.emit.ErrorHandler
- mypyc.codegen.emit.GotoHandler
- mypyc.codegen.emit.ReturnHandler
- mypyc.common.BITMAP_BITS
- mypyc.common.BITMAP_TYPE
- mypyc.common.DUNDER_PREFIX
- mypyc.common.NATIVE_PREFIX
- mypyc.common.PREFIX
- mypyc.common.bitmap_name
- mypyc.common.use_vectorcall
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.func_ir.FUNC_STATICMETHOD
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.func_ir.RuntimeArg
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.is_bool_rprimitive
- mypyc.ir.rtypes.is_int_rprimitive
- mypyc.ir.rtypes.is_object_rprimitive
- mypyc.ir.rtypes.object_rprimitive
- mypyc.namegen.NameGenerator
- typing.Sequence

**Functions:**

### `def wrapper_function_header(fn: FuncIR, names: NameGenerator) -> str`

**Description:**
Return header of a vectorcall wrapper function.

See comment above for a summary of the arguments.

**Line:** 60

---

### `def generate_traceback_code(fn: FuncIR, emitter: Emitter, source_path: str, module_name: str) -> str`

**Line:** 71

---

### `def make_arg_groups(args: list[RuntimeArg]) -> dict[(ArgKind, list[RuntimeArg])]`

**Description:**
Group arguments by kind.

**Line:** 89

---

### `def reorder_arg_groups(groups: dict[(ArgKind, list[RuntimeArg])]) -> list[RuntimeArg]`

**Description:**
Reorder argument groups to match their order in a format string.

**Line:** 94

---

### `def make_static_kwlist(args: list[RuntimeArg]) -> str`

**Line:** 99

---

### `def make_format_string(func_name: str | None, groups: dict[(ArgKind, list[RuntimeArg])]) -> str`

**Description:**
Return a format string that specifies the accepted arguments.

The format string is an extended subset of what is supported by
PyArg_ParseTupleAndKeywords(). Only the type 'O' is used, and we
also support some extensions:

- Required keyword-only arguments are introduced after '@'
- If the function receives *args or **kwargs, we add a '%' prefix

Each group requires the previous groups' delimiters to be present
first.

These are used by both vectorcall and legacy wrapper functions.

**Line:** 104

---

### `def generate_wrapper_function(fn: FuncIR, emitter: Emitter, source_path: str, module_name: str) -> None`

**Description:**
Generate a CPython-compatible vectorcall wrapper for a native function.

In particular, this handles unboxing the arguments, calling the native function, and
then boxing the return value.

**Line:** 134

---

### `def legacy_wrapper_function_header(fn: FuncIR, names: NameGenerator) -> str`

**Line:** 221

---

### `def generate_legacy_wrapper_function(fn: FuncIR, emitter: Emitter, source_path: str, module_name: str) -> None`

**Description:**
Generates a CPython-compatible legacy wrapper for a native function.

In particular, this handles unboxing the arguments, calling the native function, and
then boxing the return value.

**Line:** 227

---

### `def generate_dunder_wrapper(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str`

**Description:**
Generates a wrapper for native __dunder__ methods to be able to fit into the mapping
protocol slot. This specifically means that the arguments are taken as *PyObjects and returned
as *PyObjects.

**Line:** 290

---

### `def generate_ipow_wrapper(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str`

**Description:**
Generate a wrapper for native __ipow__.

Since __ipow__ fills a ternary slot, but almost no one defines __ipow__ to take three
arguments, the wrapper needs to tweaked to force it to accept three arguments.

**Line:** 304

---

### `def generate_bin_op_wrapper(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str`

**Description:**
Generates a wrapper for a native binary dunder method.

The same wrapper that handles the forward method (e.g. __add__) also handles
the corresponding reverse method (e.g. __radd__), if defined.

Both arguments and the return value are PyObject *.

**Line:** 330

---

### `def generate_bin_op_forward_only_wrapper(fn: FuncIR, emitter: Emitter, gen: WrapperGenerator) -> None`

**Line:** 362

---

### `def generate_bin_op_reverse_only_wrapper(fn: FuncIR, emitter: Emitter, gen: WrapperGenerator) -> None`

**Line:** 389

---

### `def generate_bin_op_both_wrappers(cl: ClassIR, fn: FuncIR, fn_rev: FuncIR, emitter: Emitter, gen: WrapperGenerator) -> None`

**Line:** 403

---

### `def generate_bin_op_reverse_dunder_call(fn: FuncIR, emitter: Emitter, rmethod: str) -> None`

**Line:** 451

---

### `def handle_third_pow_argument(fn: FuncIR, emitter: Emitter, gen: WrapperGenerator, if_unsupported: list[str]) -> None`

**Line:** 468

---

### `def generate_richcompare_wrapper(cl: ClassIR, emitter: Emitter) -> str | None`

**Description:**
Generates a wrapper for richcompare dunder methods.

**Line:** 502

---

### `def generate_get_wrapper(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str`

**Description:**
Generates a wrapper for native __get__ methods.

**Line:** 532

---

### `def generate_hash_wrapper(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str`

**Description:**
Generates a wrapper for native __hash__ methods.

**Line:** 547

---

### `def generate_len_wrapper(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str`

**Description:**
Generates a wrapper for native __len__ methods.

**Line:** 574

---

### `def generate_bool_wrapper(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str`

**Description:**
Generates a wrapper for native __bool__ methods.

**Line:** 599

---

### `def generate_del_item_wrapper(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str`

**Description:**
Generates a wrapper for native __delitem__.

This is only called from a combined __delitem__/__setitem__ wrapper.

**Line:** 619

---

### `def generate_set_del_item_wrapper(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str`

**Description:**
Generates a wrapper for native __setitem__ method (also works for __delitem__).

This is used with the mapping protocol slot. Arguments are taken as *PyObjects and we
return a negative C int on error.

Create a separate wrapper function for __delitem__ as needed and have the
__setitem__ wrapper call it if the value is NULL. Return the name
of the outer (__setitem__) wrapper.

**Line:** 631

---

### `def generate_set_del_item_wrapper_inner(fn: FuncIR, emitter: Emitter, args: Sequence[RuntimeArg]) -> None`

**Line:** 701

---

### `def generate_contains_wrapper(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str`

**Description:**
Generates a wrapper for a native __contains__ method.

**Line:** 720

---

### `def generate_wrapper_core(fn: FuncIR, emitter: Emitter, optional_args: list[RuntimeArg] | None = None, arg_names: list[str] | None = None, cleanups: list[str] | None = None, traceback_code: str | None = None) -> None`

**Description:**
Generates the core part of a wrapper function for a native function.

This expects each argument as a PyObject * named obj_{arg} as a precondition.
It converts the PyObject *s to the necessary types, checking and unboxing if necessary,
makes the call, then boxes the result if necessary and returns it.

**Line:** 745

---

### `def generate_arg_check(name: str, typ: RType, emitter: Emitter, error: ErrorHandler | None = None, optional: bool = False, raise_exception: bool = True, bitmap_arg_index: int = 0) -> None`

**Description:**
Insert a runtime check for argument and unbox if necessary.

The object is named PyObject *obj_{}. This is expected to generate
a value of name arg_{} (unboxed if necessary). For each primitive a runtime
check ensures the correct type.

**Line:** 773

---


## Module: venv2.libthon3.12.site-packages.mypyc.codegen.literals
**File:** `venv2/lib/python3.12/site-packages/mypyc/codegen/literals.py`

**Imports:**
- __future__.annotations
- typing.Final
- typing.FrozenSet
- typing.Tuple
- typing.Union
- typing_extensions.TypeGuard

**Functions:**

### `def _is_literal_value(obj: object) -> TypeGuard[LiteralValue]`

**Line:** 13

---

### `def _encode_str_values(values: dict[(str, int)]) -> list[bytes]`

**Line:** 175

---

### `def _encode_bytes_values(values: dict[(bytes, int)]) -> list[bytes]`

**Line:** 196

---

### `def format_int(n: int) -> bytes`

**Description:**
Format an integer using a variable-length binary encoding.

**Line:** 217

---

### `def format_str_literal(s: str) -> bytes`

**Line:** 232

---

### `def _encode_int_values(values: dict[(int, int)]) -> list[bytes]`

**Description:**
Encode int values into C strings.

Values are stored in base 10 and separated by 0 bytes.

**Line:** 237

---

### `def float_to_c(x: float) -> str`

**Description:**
Return C literal representation of a float value.

**Line:** 261

---

### `def _encode_float_values(values: dict[(float, int)]) -> list[str]`

**Description:**
Encode float values into a C array values.

The result contains the number of values followed by individual values.

**Line:** 273

---

### `def _encode_complex_values(values: dict[(complex, int)]) -> list[str]`

**Description:**
Encode float values into a C array values.

The result contains the number of values followed by pairs of doubles
representing complex numbers.

**Line:** 288

---


## Module: venv2.libthon3.12.site-packages.mypyc.common
**File:** `venv2/lib/python3.12/site-packages/mypyc/common.py`

**Imports:**
- __future__.annotations
- mypy.util.unnamed_function
- sys
- sysconfig
- typing.Any
- typing.Dict
- typing.Final

**Functions:**

### `def shared_lib_name(group_name: str) -> str`

**Description:**
Given a group name, return the actual name of its extension module.

(This just adds a suffix to the final component.)

**Line:** 87

---

### `def short_name(name: str) -> str`

**Line:** 95

---

### `def use_vectorcall(capi_version: tuple[(int, int)]) -> bool`

**Line:** 101

---

### `def use_method_vectorcall(capi_version: tuple[(int, int)]) -> bool`

**Line:** 106

---

### `def get_id_from_name(name: str, fullname: str, line: int) -> str`

**Description:**
Create a unique id for a function.

This creates an id that is unique for any given function definition, so that it can be used as
a dictionary key. This is usually the fullname of the function, but this is different in that
it handles the case where the function is named '_', in which case multiple different functions
could have the same name.

**Line:** 111

---

### `def short_id_from_name(func_name: str, shortname: str, line: int | None) -> str`

**Line:** 124

---

### `def bitmap_name(index: int) -> str`

**Line:** 133

---


## Module: venv2.libthon3.12.site-packages.mypyc.crash
**File:** `venv2/lib/python3.12/site-packages/mypyc/crash.py`

**Imports:**
- __future__.annotations
- contextlib.contextmanager
- sys
- traceback
- typing.Iterator
- typing.NoReturn

**Functions:**

### `def catch_errors(module_path: str, line: int) -> Iterator[None]`

**Decorators:**
- `@contextmanager`

**Line:** 10

---

### `def crash_report(module_path: str, line: int) -> NoReturn`

**Line:** 17

---


## Module: venv2.libthon3.12.site-packages.mypyc.ir.class_ir
**File:** `venv2/lib/python3.12/site-packages/mypyc/ir/class_ir.py`

**Imports:**
- __future__.annotations
- mypyc.common.JsonDict
- mypyc.common.PROPSET_PREFIX
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.func_ir.FuncSignature
- mypyc.ir.ops.DeserMaps
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.deserialize_type
- mypyc.namegen.NameGenerator
- mypyc.namegen.exported_name
- typing.List
- typing.NamedTuple

**Functions:**

### `def serialize_vtable_entry(entry: VTableMethod) -> JsonDict`

**Line:** 463

---

### `def serialize_vtable(vtable: VTableEntries) -> list[JsonDict]`

**Line:** 473

---

### `def deserialize_vtable_entry(data: JsonDict, ctx: DeserMaps) -> VTableMethod`

**Line:** 477

---

### `def deserialize_vtable(data: list[JsonDict], ctx: DeserMaps) -> VTableEntries`

**Line:** 488

---

### `def all_concrete_classes(class_ir: ClassIR) -> list[ClassIR] | None`

**Description:**
Return all concrete classes among the class itself and its subclasses.

**Line:** 492

---


## Module: venv2.libthon3.12.site-packages.mypyc.ir.func_ir
**File:** `venv2/lib/python3.12/site-packages/mypyc/ir/func_ir.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ARG_POS
- mypy.nodes.ArgKind
- mypy.nodes.Block
- mypy.nodes.FuncDef
- mypyc.common.BITMAP_BITS
- mypyc.common.JsonDict
- mypyc.common.bitmap_name
- mypyc.common.get_id_from_name
- mypyc.common.short_id_from_name
- mypyc.ir.ops.Assign
- mypyc.ir.ops.AssignMulti
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.ControlOp
- mypyc.ir.ops.DeserMaps
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.Register
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.bitmap_rprimitive
- mypyc.ir.rtypes.deserialize_type
- mypyc.namegen.NameGenerator
- typing.Final
- typing.Sequence

**Functions:**

### `def num_bitmap_args(args: tuple[(RuntimeArg, ...)]) -> int`

**Line:** 112

---

### `def all_values(args: list[Register], blocks: list[BasicBlock]) -> list[Value]`

**Description:**
Return the set of all values that may be initialized in the blocks.

This omits registers that are only read.

**Line:** 316

---

### `def all_values_full(args: list[Register], blocks: list[BasicBlock]) -> list[Value]`

**Description:**
Return set of all values that are initialized or accessed.

**Line:** 347

---


## Module: venv2.libthon3.12.site-packages.mypyc.ir.module_ir
**File:** `venv2/lib/python3.12/site-packages/mypyc/ir/module_ir.py`

**Imports:**
- __future__.annotations
- mypyc.common.JsonDict
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.ops.DeserMaps
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.deserialize_type
- typing.Dict

**Functions:**

### `def deserialize_modules(data: dict[(str, JsonDict)], ctx: DeserMaps) -> dict[(str, ModuleIR)]`

**Description:**
Deserialize a collection of modules.

The modules can contain dependencies on each other.

Arguments:
data: A dict containing the modules to deserialize.
ctx: The deserialization maps to use and to populate.
They are populated with information from the deserialized
modules and as a precondition must have been populated by
deserializing any dependencies of the modules being deserialized
(outside of dependencies between the modules themselves).

Returns a map containing the deserialized modules.

**Line:** 51

---


## Module: venv2.libthon3.12.site-packages.mypyc.ir.pprint
**File:** `venv2/lib/python3.12/site-packages/mypyc/ir/pprint.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- mypyc.common.short_name
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.func_ir.all_values_full
- mypyc.ir.module_ir.ModuleIRs
- mypyc.ir.ops.Assign
- mypyc.ir.ops.AssignMulti
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Box
- mypyc.ir.ops.Branch
- mypyc.ir.ops.Call
- mypyc.ir.ops.CallC
- mypyc.ir.ops.Cast
- mypyc.ir.ops.ComparisonOp
- mypyc.ir.ops.ControlOp
- mypyc.ir.ops.DecRef
- mypyc.ir.ops.ERR_NEVER
- mypyc.ir.ops.Extend
- mypyc.ir.ops.Float
- mypyc.ir.ops.FloatComparisonOp
- mypyc.ir.ops.FloatNeg
- mypyc.ir.ops.FloatOp
- mypyc.ir.ops.GetAttr
- mypyc.ir.ops.GetElementPtr
- mypyc.ir.ops.Goto
- mypyc.ir.ops.IncRef
- mypyc.ir.ops.InitStatic
- mypyc.ir.ops.IntOp
- mypyc.ir.ops.Integer
- mypyc.ir.ops.KeepAlive
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.LoadErrorValue
- mypyc.ir.ops.LoadGlobal
- mypyc.ir.ops.LoadLiteral
- mypyc.ir.ops.LoadMem
- mypyc.ir.ops.LoadStatic
- mypyc.ir.ops.MethodCall
- mypyc.ir.ops.Op
- mypyc.ir.ops.OpVisitor
- mypyc.ir.ops.RaiseStandardError
- mypyc.ir.ops.Register
- mypyc.ir.ops.Return
- mypyc.ir.ops.SetAttr
- mypyc.ir.ops.SetMem
- mypyc.ir.ops.Truncate
- mypyc.ir.ops.TupleGet
- mypyc.ir.ops.TupleSet
- mypyc.ir.ops.Unborrow
- mypyc.ir.ops.Unbox
- mypyc.ir.ops.Unreachable
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.is_bool_rprimitive
- mypyc.ir.rtypes.is_int_rprimitive
- typing.Any
- typing.Final
- typing.Sequence
- typing.Union

**Functions:**

### `def format_registers(func_ir: FuncIR, names: dict[(Value, str)]) -> list[str]`

**Line:** 348

---

### `def format_blocks(blocks: list[BasicBlock], names: dict[(Value, str)], source_to_error: dict[(ErrorSource, list[str])]) -> list[str]`

**Description:**
Format a list of IR basic blocks into a human-readable form.

**Line:** 363

---

### `def format_func(fn: FuncIR, errors: Sequence[tuple[(ErrorSource, str)]] = ()) -> list[str]`

**Line:** 414

---

### `def format_modules(modules: ModuleIRs) -> list[str]`

**Line:** 433

---

### `def generate_names_for_ir(args: list[Register], blocks: list[BasicBlock]) -> dict[(Value, str)]`

**Description:**
Generate unique names for IR values.

Give names such as 'r5' to temp values in IR which are useful when
pretty-printing or generating C. Ensure generated names are unique.

**Line:** 442

---


## Module: venv2.libthon3.12.site-packages.mypyc.ir.rtypes
**File:** `venv2/lib/python3.12/site-packages/mypyc/ir/rtypes.py`

**Imports:**
- __future__.annotations
- abc.abstractmethod
- mypyc.common.IS_32_BIT_PLATFORM
- mypyc.common.JsonDict
- mypyc.common.PLATFORM_SIZE
- mypyc.common.short_name
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.ops.DeserMaps
- mypyc.namegen.NameGenerator
- typing.ClassVar
- typing.Final
- typing.Generic
- typing.TYPE_CHECKING
- typing.TypeVar
- typing_extensions.TypeGuard

**Functions:**

### `def deserialize_type(data: JsonDict | str, ctx: DeserMaps) -> RType`

**Description:**
Deserialize a JSON-serialized RType.

Arguments:
data: The decoded JSON of the serialized type
ctx: The deserialization maps to use

**Line:** 82

---

### `def is_tagged(rtype: RType) -> bool`

**Line:** 460

---

### `def is_int_rprimitive(rtype: RType) -> bool`

**Line:** 464

---

### `def is_short_int_rprimitive(rtype: RType) -> bool`

**Line:** 468

---

### `def is_int16_rprimitive(rtype: RType) -> TypeGuard[RPrimitive]`

**Line:** 472

---

### `def is_int32_rprimitive(rtype: RType) -> TypeGuard[RPrimitive]`

**Line:** 476

---

### `def is_int64_rprimitive(rtype: RType) -> bool`

**Line:** 482

---

### `def is_fixed_width_rtype(rtype: RType) -> TypeGuard[RPrimitive]`

**Line:** 488

---

### `def is_uint8_rprimitive(rtype: RType) -> TypeGuard[RPrimitive]`

**Line:** 497

---

### `def is_uint32_rprimitive(rtype: RType) -> bool`

**Line:** 501

---

### `def is_uint64_rprimitive(rtype: RType) -> bool`

**Line:** 505

---

### `def is_c_py_ssize_t_rprimitive(rtype: RType) -> bool`

**Line:** 509

---

### `def is_pointer_rprimitive(rtype: RType) -> bool`

**Line:** 513

---

### `def is_float_rprimitive(rtype: RType) -> bool`

**Line:** 517

---

### `def is_bool_rprimitive(rtype: RType) -> bool`

**Line:** 521

---

### `def is_bit_rprimitive(rtype: RType) -> bool`

**Line:** 525

---

### `def is_object_rprimitive(rtype: RType) -> bool`

**Line:** 529

---

### `def is_none_rprimitive(rtype: RType) -> bool`

**Line:** 533

---

### `def is_list_rprimitive(rtype: RType) -> bool`

**Line:** 537

---

### `def is_dict_rprimitive(rtype: RType) -> bool`

**Line:** 541

---

### `def is_set_rprimitive(rtype: RType) -> bool`

**Line:** 545

---

### `def is_str_rprimitive(rtype: RType) -> bool`

**Line:** 549

---

### `def is_bytes_rprimitive(rtype: RType) -> bool`

**Line:** 553

---

### `def is_tuple_rprimitive(rtype: RType) -> bool`

**Line:** 557

---

### `def is_range_rprimitive(rtype: RType) -> bool`

**Line:** 561

---

### `def is_sequence_rprimitive(rtype: RType) -> bool`

**Line:** 565

---

### `def compute_rtype_alignment(typ: RType) -> int`

**Description:**
Compute alignment of a given type based on platform alignment rule

**Line:** 679

---

### `def compute_rtype_size(typ: RType) -> int`

**Description:**
Compute unaligned size of rtype

**Line:** 701

---

### `def compute_aligned_offsets_and_size(types: list[RType]) -> tuple[(list[int], int)]`

**Description:**
Compute offsets and total size of a list of types after alignment

Note that the types argument are types of values that are stored
sequentially with platform default alignment.

**Line:** 721

---

### `def flatten_nested_unions(types: list[RType]) -> list[RType]`

**Line:** 909

---

### `def optional_value_type(rtype: RType) -> RType | None`

**Description:**
If rtype is the union of none_rprimitive and another type X, return X.

Otherwise return None.

**Line:** 922

---

### `def is_optional_type(rtype: RType) -> bool`

**Description:**
Is rtype an optional type with exactly two union items?

**Line:** 935

---

### `def check_native_int_range(rtype: RPrimitive, n: int) -> bool`

**Description:**
Is n within the range of a native, fixed-width int type?

Assume the type is a fixed-width int type.

**Line:** 1029

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.ast_helpers
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/ast_helpers.py`

**Imports:**
- __future__.annotations
- mypy.nodes.BytesExpr
- mypy.nodes.ComparisonExpr
- mypy.nodes.Expression
- mypy.nodes.FloatExpr
- mypy.nodes.IntExpr
- mypy.nodes.LDEF
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.OpExpr
- mypy.nodes.StrExpr
- mypy.nodes.UnaryExpr
- mypy.nodes.Var
- mypyc.ir.ops.BasicBlock
- mypyc.ir.rtypes.is_fixed_width_rtype
- mypyc.ir.rtypes.is_tagged
- mypyc.irbuild.builder.IRBuilder
- mypyc.irbuild.constant_fold.constant_fold_expr

**Functions:**

### `def process_conditional(self: IRBuilder, e: Expression, true: BasicBlock, false: BasicBlock) -> None`

**Line:** 29

---

### `def maybe_process_conditional_comparison(self: IRBuilder, e: Expression, true: BasicBlock, false: BasicBlock) -> bool`

**Description:**
Transform simple tagged integer comparisons in a conditional context.

Return True if the operation is supported (and was transformed). Otherwise,
do nothing and return False.

Args:
e: Arbitrary expression
true: Branch target if comparison is true
false: Branch target if comparison is false

**Line:** 56

---

### `def is_borrow_friendly_expr(self: IRBuilder, expr: Expression) -> bool`

**Description:**
Can the result of the expression borrowed temporarily?

Borrowing means keeping a reference without incrementing the reference count.

**Line:** 100

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.builder
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/builder.py`

**Imports:**
- __future__.annotations
- contextlib.contextmanager
- mypy.build.Graph
- mypy.join.join_types
- mypy.maptype.map_instance_to_supertype
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_POS
- mypy.nodes.ArgKind
- mypy.nodes.CallExpr
- mypy.nodes.Decorator
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.GDEF
- mypy.nodes.IndexExpr
- mypy.nodes.IntExpr
- mypy.nodes.LDEF
- mypy.nodes.Lvalue
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.OpExpr
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.RefExpr
- mypy.nodes.StarExpr
- mypy.nodes.Statement
- mypy.nodes.SymbolNode
- mypy.nodes.TupleExpr
- mypy.nodes.TypeAlias
- mypy.nodes.TypeInfo
- mypy.nodes.UnaryExpr
- mypy.nodes.Var
- mypy.types.AnyType
- mypy.types.DeletedType
- mypy.types.Instance
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypedDictType
- mypy.types.UninhabitedType
- mypy.types.UnionType
- mypy.types.get_proper_type
- mypy.util.split_target
- mypy.visitor.ExpressionVisitor
- mypy.visitor.StatementVisitor
- mypyc.common.BITMAP_BITS
- mypyc.common.SELF_NAME
- mypyc.common.TEMP_ATTR_NAME
- mypyc.crash.catch_errors
- mypyc.errors.Errors
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.class_ir.NonExtClassInfo
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.func_ir.FuncSignature
- mypyc.ir.func_ir.INVALID_FUNC_DEF
- mypyc.ir.func_ir.RuntimeArg
- mypyc.ir.ops.Assign
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Branch
- mypyc.ir.ops.ComparisonOp
- mypyc.ir.ops.GetAttr
- mypyc.ir.ops.InitStatic
- mypyc.ir.ops.IntOp
- mypyc.ir.ops.Integer
- mypyc.ir.ops.LoadStatic
- mypyc.ir.ops.NAMESPACE_MODULE
- mypyc.ir.ops.Op
- mypyc.ir.ops.RaiseStandardError
- mypyc.ir.ops.Register
- mypyc.ir.ops.SetAttr
- mypyc.ir.ops.TupleGet
- mypyc.ir.ops.Unreachable
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.RTuple
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.RUnion
- mypyc.ir.rtypes.bitmap_rprimitive
- mypyc.ir.rtypes.c_pyssize_t_rprimitive
- mypyc.ir.rtypes.dict_rprimitive
- mypyc.ir.rtypes.int_rprimitive
- mypyc.ir.rtypes.is_float_rprimitive
- mypyc.ir.rtypes.is_list_rprimitive
- mypyc.ir.rtypes.is_none_rprimitive
- mypyc.ir.rtypes.is_object_rprimitive
- mypyc.ir.rtypes.is_tagged
- mypyc.ir.rtypes.is_tuple_rprimitive
- mypyc.ir.rtypes.none_rprimitive
- mypyc.ir.rtypes.object_rprimitive
- mypyc.ir.rtypes.str_rprimitive
- mypyc.irbuild.context.FuncInfo
- mypyc.irbuild.context.ImplicitClass
- mypyc.irbuild.ll_builder.LowLevelIRBuilder
- mypyc.irbuild.mapper.Mapper
- mypyc.irbuild.nonlocalcontrol.BaseNonlocalControl
- mypyc.irbuild.nonlocalcontrol.GeneratorNonlocalControl
- mypyc.irbuild.nonlocalcontrol.LoopNonlocalControl
- mypyc.irbuild.nonlocalcontrol.NonlocalControl
- mypyc.irbuild.prebuildvisitor.PreBuildVisitor
- mypyc.irbuild.prepare.RegisterImplInfo
- mypyc.irbuild.targets.AssignmentTarget
- mypyc.irbuild.targets.AssignmentTargetAttr
- mypyc.irbuild.targets.AssignmentTargetIndex
- mypyc.irbuild.targets.AssignmentTargetRegister
- mypyc.irbuild.targets.AssignmentTargetTuple
- mypyc.irbuild.util.bytes_from_str
- mypyc.irbuild.util.is_constant
- mypyc.options.CompilerOptions
- mypyc.primitives.dict_ops.dict_get_item_op
- mypyc.primitives.dict_ops.dict_set_item_op
- mypyc.primitives.generic_ops.iter_op
- mypyc.primitives.generic_ops.next_op
- mypyc.primitives.generic_ops.py_setattr_op
- mypyc.primitives.list_ops.list_get_item_unsafe_op
- mypyc.primitives.list_ops.list_pop_last
- mypyc.primitives.list_ops.to_list
- mypyc.primitives.misc_ops.check_unpack_count_op
- mypyc.primitives.misc_ops.get_module_dict_op
- mypyc.primitives.misc_ops.import_op
- mypyc.primitives.registry.CFunctionDescription
- mypyc.primitives.registry.function_ops
- typing.Any
- typing.Callable
- typing.Final
- typing.Iterator
- typing.Sequence
- typing.Union
- typing_extensions.overload

**Functions:**

### `def gen_arg_defaults(builder: IRBuilder) -> None`

**Description:**
Generate blocks for arguments that have default values.

If the passed value is an error value, then assign the default
value to the argument.

**Line:** 1339

---

### `def remangle_redefinition_name(name: str) -> str`

**Description:**
Remangle names produced by mypy when allow-redefinition is used and a name
is used with multiple types within a single block.

We only need to do this for locals, because the name is used as the name of the register;
for globals, the name itself is stored in a register for the purpose of doing dict
lookups.

**Line:** 1382

---

### `def get_call_target_fullname(ref: RefExpr) -> str`

**Line:** 1393

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.callable_class
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/callable_class.py`

**Imports:**
- __future__.annotations
- mypyc.common.ENV_ATTR_NAME
- mypyc.common.SELF_NAME
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.func_ir.FuncSignature
- mypyc.ir.func_ir.RuntimeArg
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Call
- mypyc.ir.ops.Register
- mypyc.ir.ops.Return
- mypyc.ir.ops.SetAttr
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.object_rprimitive
- mypyc.irbuild.builder.IRBuilder
- mypyc.irbuild.context.FuncInfo
- mypyc.irbuild.context.ImplicitClass
- mypyc.primitives.misc_ops.method_new_op

**Functions:**

### `def setup_callable_class(builder: IRBuilder) -> None`

**Description:**
Generate an (incomplete) callable class representing a function.

This can be a nested function or a function within a non-extension
class.  Also set up the 'self' variable for that class.

This takes the most recently visited function and returns a
ClassIR to represent that function. Each callable class contains
an environment attribute which points to another ClassIR
representing the environment class where some of its variables can
be accessed.

Note that some methods, such as '__call__', are not yet
created here. Use additional functions, such as
add_call_to_callable_class(), to add them.

Return a newly constructed ClassIR representing the callable
class for the nested function.

**Line:** 19

---

### `def add_call_to_callable_class(builder: IRBuilder, args: list[Register], blocks: list[BasicBlock], sig: FuncSignature, fn_info: FuncInfo) -> FuncIR`

**Description:**
Generate a '__call__' method for a callable class representing a nested function.

This takes the blocks and signature associated with a function
definition and uses those to build the '__call__' method of a
given callable class, used to represent that function.

**Line:** 81

---

### `def add_get_to_callable_class(builder: IRBuilder, fn_info: FuncInfo) -> None`

**Description:**
Generate the '__get__' method for a callable class.

**Line:** 108

---

### `def instantiate_callable_class(builder: IRBuilder, fn_info: FuncInfo) -> Value`

**Description:**
Create an instance of a callable class for a function.

Calls to the function will actually call this instance.

Note that fn_info refers to the function being assigned, whereas
builder.fn_info refers to the function encapsulating the function
being turned into a callable class.

**Line:** 139

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.classdef
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/classdef.py`

**Imports:**
- __future__.annotations
- abc.abstractmethod
- mypy.nodes.AssignmentStmt
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.Decorator
- mypy.nodes.ExpressionStmt
- mypy.nodes.FuncDef
- mypy.nodes.Lvalue
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.PassStmt
- mypy.nodes.RefExpr
- mypy.nodes.StrExpr
- mypy.nodes.TempNode
- mypy.nodes.TypeInfo
- mypy.nodes.is_class_var
- mypy.types.ENUM_REMOVED_PROPS
- mypy.types.Instance
- mypy.types.UnboundType
- mypy.types.get_proper_type
- mypyc.common.PROPSET_PREFIX
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.class_ir.NonExtClassInfo
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncSignature
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Branch
- mypyc.ir.ops.Call
- mypyc.ir.ops.InitStatic
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.LoadErrorValue
- mypyc.ir.ops.LoadStatic
- mypyc.ir.ops.MethodCall
- mypyc.ir.ops.NAMESPACE_TYPE
- mypyc.ir.ops.Register
- mypyc.ir.ops.Return
- mypyc.ir.ops.SetAttr
- mypyc.ir.ops.TupleSet
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.bool_rprimitive
- mypyc.ir.rtypes.dict_rprimitive
- mypyc.ir.rtypes.is_none_rprimitive
- mypyc.ir.rtypes.is_object_rprimitive
- mypyc.ir.rtypes.is_optional_type
- mypyc.ir.rtypes.object_rprimitive
- mypyc.irbuild.builder.IRBuilder
- mypyc.irbuild.function.gen_property_getter_ir
- mypyc.irbuild.function.gen_property_setter_ir
- mypyc.irbuild.function.handle_ext_method
- mypyc.irbuild.function.handle_non_ext_method
- mypyc.irbuild.function.load_type
- mypyc.irbuild.util.dataclass_type
- mypyc.irbuild.util.get_func_def
- mypyc.irbuild.util.is_constant
- mypyc.irbuild.util.is_dataclass_decorator
- mypyc.primitives.dict_ops.dict_new_op
- mypyc.primitives.dict_ops.dict_set_item_op
- mypyc.primitives.generic_ops.py_hasattr_op
- mypyc.primitives.generic_ops.py_setattr_op
- mypyc.primitives.misc_ops.dataclass_sleight_of_hand
- mypyc.primitives.misc_ops.not_implemented_op
- mypyc.primitives.misc_ops.py_calc_meta_op
- mypyc.primitives.misc_ops.pytype_from_template_op
- mypyc.primitives.misc_ops.type_object_op
- typing.Callable
- typing.Final
- typing_extensions

**Functions:**

### `def transform_class_def(builder: IRBuilder, cdef: ClassDef) -> None`

**Description:**
Create IR for a class definition.

This can generate both extension (native) and non-extension
classes.  These are generated in very different ways. In the
latter case we construct a Python type object at runtime by doing
the equivalent of "type(name, bases, dict)" in IR. Extension
classes are defined via C structs that are generated later in
mypyc.codegen.emitclass.

This is the main entry point to this module.

**Line:** 76

---

### `def allocate_class(builder: IRBuilder, cdef: ClassDef) -> Value`

**Line:** 405

---

### `def populate_non_ext_bases(builder: IRBuilder, cdef: ClassDef) -> Value`

**Description:**
Create base class tuple of a non-extension class.

The tuple is passed to the metaclass constructor.

**Line:** 464

---

### `def find_non_ext_metaclass(builder: IRBuilder, cdef: ClassDef, bases: Value) -> Value`

**Description:**
Find the metaclass of a class from its defs and bases.

**Line:** 533

---

### `def setup_non_ext_dict(builder: IRBuilder, cdef: ClassDef, metaclass: Value, bases: Value) -> Value`

**Description:**
Initialize the class dictionary for a non-extension class.

This class dictionary is passed to the metaclass constructor.

**Line:** 554

---

### `def add_non_ext_class_attr_ann(builder: IRBuilder, non_ext: NonExtClassInfo, lvalue: NameExpr, stmt: AssignmentStmt, get_type_info: Callable[[AssignmentStmt], TypeInfo | None] | None = None) -> None`

**Description:**
Add a class attribute to __annotations__ of a non-extension class.

**Line:** 586

---

### `def add_non_ext_class_attr(builder: IRBuilder, non_ext: NonExtClassInfo, lvalue: NameExpr, stmt: AssignmentStmt, cdef: ClassDef, attr_to_cache: list[tuple[(Lvalue, RType)]]) -> None`

**Description:**
Add a class attribute to __dict__ of a non-extension class.

**Line:** 623

---

### `def find_attr_initializers(builder: IRBuilder, cdef: ClassDef, skip: Callable[[str, AssignmentStmt], bool] | None = None) -> tuple[(set[str], list[AssignmentStmt])]`

**Description:**
Find initializers of attributes in a class body.

If provided, the skip arg should be a callable which will return whether
to skip generating a default for an attribute.  It will be passed the name of
the attribute and the corresponding AssignmentStmt.

**Line:** 649

---

### `def generate_attr_defaults_init(builder: IRBuilder, cdef: ClassDef, default_assignments: list[AssignmentStmt]) -> None`

**Description:**
Generate an initialization method for default attr values (from class vars).

**Line:** 706

---

### `def check_deletable_declaration(builder: IRBuilder, cl: ClassIR, line: int) -> None`

**Line:** 733

---

### `def create_ne_from_eq(builder: IRBuilder, cdef: ClassDef) -> None`

**Description:**
Create a "__ne__" method from a "__eq__" method (if only latter exists).

**Line:** 753

---

### `def gen_glue_ne_method(builder: IRBuilder, cls: ClassIR, line: int) -> None`

**Description:**
Generate a "__ne__" method from a "__eq__" method.

**Line:** 760

---

### `def load_non_ext_class(builder: IRBuilder, ir: ClassIR, non_ext: NonExtClassInfo, line: int) -> Value`

**Line:** 788

---

### `def load_decorated_class(builder: IRBuilder, cdef: ClassDef, type_obj: Value) -> Value`

**Description:**
Apply class decorators to create a decorated (non-extension) class object.

Given a decorated ClassDef and a register containing a
non-extension representation of the ClassDef created via the type
constructor, applies the corresponding decorator functions on that
decorated ClassDef and returns a register containing the decorated
ClassDef.

**Line:** 801

---

### `def cache_class_attrs(builder: IRBuilder, attrs_to_cache: list[tuple[(Lvalue, RType)]], cdef: ClassDef) -> None`

**Description:**
Add class attributes to be cached to the global cache.

**Line:** 819

---

### `def create_mypyc_attrs_tuple(builder: IRBuilder, ir: ClassIR, line: int) -> Value`

**Line:** 830

---

### `def add_dunders_to_non_ext_dict(builder: IRBuilder, non_ext: NonExtClassInfo, line: int, add_annotations: bool = True) -> None`

**Line:** 838

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.constant_fold
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/constant_fold.py`

**Imports:**
- __future__.annotations
- mypy.constant_fold.constant_fold_binary_op
- mypy.constant_fold.constant_fold_unary_op
- mypy.nodes.BytesExpr
- mypy.nodes.ComplexExpr
- mypy.nodes.Expression
- mypy.nodes.FloatExpr
- mypy.nodes.IntExpr
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.OpExpr
- mypy.nodes.StrExpr
- mypy.nodes.UnaryExpr
- mypy.nodes.Var
- mypyc.irbuild.builder.IRBuilder
- mypyc.irbuild.util.bytes_from_str
- typing.Final
- typing.Union

**Functions:**

### `def constant_fold_expr(builder: IRBuilder, expr: Expression) -> ConstantValue | None`

**Description:**
Return the constant value of an expression for supported operations.

Return None otherwise.

**Line:** 37

---

### `def constant_fold_binary_op_extended(op: str, left: ConstantValue, right: ConstantValue) -> ConstantValue | None`

**Description:**
Like mypy's constant_fold_binary_op(), but includes bytes support.

mypy cannot use constant folded bytes easily so it's simpler to only support them in mypyc.

**Line:** 78

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.env_class
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/env_class.py`

**Imports:**
- __future__.annotations
- mypy.nodes.Argument
- mypy.nodes.FuncDef
- mypy.nodes.SymbolNode
- mypy.nodes.Var
- mypyc.common.BITMAP_BITS
- mypyc.common.ENV_ATTR_NAME
- mypyc.common.SELF_NAME
- mypyc.common.bitmap_name
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.ops.Call
- mypyc.ir.ops.GetAttr
- mypyc.ir.ops.SetAttr
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.bitmap_rprimitive
- mypyc.ir.rtypes.object_rprimitive
- mypyc.irbuild.builder.IRBuilder
- mypyc.irbuild.builder.SymbolTarget
- mypyc.irbuild.context.FuncInfo
- mypyc.irbuild.context.GeneratorClass
- mypyc.irbuild.context.ImplicitClass
- mypyc.irbuild.targets.AssignmentTargetAttr

**Functions:**

### `def setup_env_class(builder: IRBuilder) -> ClassIR`

**Description:**
Generate a class representing a function environment.

Note that the variables in the function environment are not
actually populated here. This is because when the environment
class is generated, the function environment has not yet been
visited. This behavior is allowed so that when the compiler visits
nested functions, it can use the returned ClassIR instance to
figure out free variables it needs to access.  The remaining
attributes of the environment class are populated when the
environment registers are loaded.

Return a ClassIR representing an environment for a function
containing a nested function.

**Line:** 30

---

### `def finalize_env_class(builder: IRBuilder) -> None`

**Description:**
Generate, instantiate, and set up the environment of an environment class.

**Line:** 59

---

### `def instantiate_env_class(builder: IRBuilder) -> Value`

**Description:**
Assign an environment class to a register named after the given function definition.

**Line:** 72

---

### `def load_env_registers(builder: IRBuilder) -> None`

**Description:**
Load the registers for the current FuncItem being visited.

Adds the arguments of the FuncItem to the environment. If the
FuncItem is nested inside of another function, then this also
loads all of the outer environments of the FuncItem into registers
so that they can be used when accessing free variables.

**Line:** 94

---

### `def load_outer_env(builder: IRBuilder, base: Value, outer_env: dict[(SymbolNode, SymbolTarget)]) -> Value`

**Description:**
Load the environment class for a given base into a register.

Additionally, iterates through all of the SymbolNode and
AssignmentTarget instances of the environment at the given index's
symtable, and adds those instances to the environment of the
current environment. This is done so that the current environment
can access outer environment variables without having to reload
all of the environment registers.

Returns the register where the environment class was loaded.

**Line:** 114

---

### `def load_outer_envs(builder: IRBuilder, base: ImplicitClass) -> None`

**Line:** 139

---

### `def num_bitmap_args(builder: IRBuilder, args: list[Argument]) -> int`

**Line:** 162

---

### `def add_args_to_env(builder: IRBuilder, local: bool = True, base: FuncInfo | ImplicitClass | None = None, reassign: bool = True) -> None`

**Line:** 171

---

### `def setup_func_for_recursive_call(builder: IRBuilder, fdef: FuncDef, base: ImplicitClass) -> None`

**Description:**
Enable calling a nested function (with a callable class) recursively.

Adds the instance of the callable class representing the given
FuncDef to a register in the environment so that the function can
be called recursively. Note that this needs to be done only for
nested functions.

**Line:** 194

---

### `def is_free_variable(builder: IRBuilder, symbol: SymbolNode) -> bool`

**Line:** 221

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.expression
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/expression.py`

**Imports:**
- __future__.annotations
- math
- mypy.nodes.ARG_POS
- mypy.nodes.AssertTypeExpr
- mypy.nodes.AssignmentExpr
- mypy.nodes.BytesExpr
- mypy.nodes.CallExpr
- mypy.nodes.CastExpr
- mypy.nodes.ComparisonExpr
- mypy.nodes.ComplexExpr
- mypy.nodes.ConditionalExpr
- mypy.nodes.DictExpr
- mypy.nodes.DictionaryComprehension
- mypy.nodes.EllipsisExpr
- mypy.nodes.Expression
- mypy.nodes.FloatExpr
- mypy.nodes.GeneratorExpr
- mypy.nodes.IndexExpr
- mypy.nodes.IntExpr
- mypy.nodes.LDEF
- mypy.nodes.ListComprehension
- mypy.nodes.ListExpr
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.OpExpr
- mypy.nodes.RefExpr
- mypy.nodes.SetComprehension
- mypy.nodes.SetExpr
- mypy.nodes.SliceExpr
- mypy.nodes.StarExpr
- mypy.nodes.StrExpr
- mypy.nodes.SuperExpr
- mypy.nodes.TupleExpr
- mypy.nodes.TypeApplication
- mypy.nodes.TypeInfo
- mypy.nodes.UnaryExpr
- mypy.nodes.Var
- mypy.types.Instance
- mypy.types.ProperType
- mypy.types.TupleType
- mypy.types.TypeType
- mypy.types.get_proper_type
- mypyc.common.MAX_SHORT_INT
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.func_ir.FUNC_CLASSMETHOD
- mypyc.ir.func_ir.FUNC_STATICMETHOD
- mypyc.ir.ops.Assign
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.ComparisonOp
- mypyc.ir.ops.Integer
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.LoadLiteral
- mypyc.ir.ops.RaiseStandardError
- mypyc.ir.ops.Register
- mypyc.ir.ops.TupleGet
- mypyc.ir.ops.TupleSet
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RTuple
- mypyc.ir.rtypes.bool_rprimitive
- mypyc.ir.rtypes.int_rprimitive
- mypyc.ir.rtypes.is_fixed_width_rtype
- mypyc.ir.rtypes.is_int_rprimitive
- mypyc.ir.rtypes.is_list_rprimitive
- mypyc.ir.rtypes.is_none_rprimitive
- mypyc.ir.rtypes.object_rprimitive
- mypyc.ir.rtypes.set_rprimitive
- mypyc.irbuild.ast_helpers.is_borrow_friendly_expr
- mypyc.irbuild.ast_helpers.process_conditional
- mypyc.irbuild.builder.IRBuilder
- mypyc.irbuild.builder.int_borrow_friendly_op
- mypyc.irbuild.constant_fold.constant_fold_expr
- mypyc.irbuild.for_helpers.comprehension_helper
- mypyc.irbuild.for_helpers.translate_list_comprehension
- mypyc.irbuild.for_helpers.translate_set_comprehension
- mypyc.irbuild.format_str_tokenizer.convert_format_expr_to_bytes
- mypyc.irbuild.format_str_tokenizer.convert_format_expr_to_str
- mypyc.irbuild.format_str_tokenizer.join_formatted_bytes
- mypyc.irbuild.format_str_tokenizer.join_formatted_strings
- mypyc.irbuild.format_str_tokenizer.tokenizer_printf_style
- mypyc.irbuild.specialize.apply_function_specialization
- mypyc.irbuild.specialize.apply_method_specialization
- mypyc.primitives.bytes_ops.bytes_slice_op
- mypyc.primitives.dict_ops.dict_get_item_op
- mypyc.primitives.dict_ops.dict_new_op
- mypyc.primitives.dict_ops.dict_set_item_op
- mypyc.primitives.generic_ops.iter_op
- mypyc.primitives.int_ops.int_comparison_op_mapping
- mypyc.primitives.list_ops.list_append_op
- mypyc.primitives.list_ops.list_extend_op
- mypyc.primitives.list_ops.list_slice_op
- mypyc.primitives.misc_ops.ellipsis_op
- mypyc.primitives.misc_ops.get_module_dict_op
- mypyc.primitives.misc_ops.new_slice_op
- mypyc.primitives.misc_ops.type_op
- mypyc.primitives.registry.CFunctionDescription
- mypyc.primitives.registry.builtin_names
- mypyc.primitives.set_ops.set_add_op
- mypyc.primitives.set_ops.set_in_op
- mypyc.primitives.set_ops.set_update_op
- mypyc.primitives.str_ops.str_slice_op
- mypyc.primitives.tuple_ops.list_tuple_op
- mypyc.primitives.tuple_ops.tuple_slice_op
- typing.Callable
- typing.Sequence

**Functions:**

### `def transform_name_expr(builder: IRBuilder, expr: NameExpr) -> Value`

**Line:** 108

---

### `def transform_member_expr(builder: IRBuilder, expr: MemberExpr) -> Value`

**Line:** 187

---

### `def check_instance_attribute_access_through_class(builder: IRBuilder, expr: MemberExpr, typ: ProperType | None) -> None`

**Description:**
Report error if accessing an instance attribute through class object.

**Line:** 223

---

### `def transform_super_expr(builder: IRBuilder, o: SuperExpr) -> Value`

**Line:** 255

---

### `def transform_call_expr(builder: IRBuilder, expr: CallExpr) -> Value`

**Line:** 281

---

### `def translate_call(builder: IRBuilder, expr: CallExpr, callee: Expression) -> Value`

**Line:** 312

---

### `def translate_refexpr_call(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value`

**Description:**
Translate a non-method call.

**Line:** 326

---

### `def translate_method_call(builder: IRBuilder, expr: CallExpr, callee: MemberExpr) -> Value`

**Description:**
Generate IR for an arbitrary call of form e.m(...).

This can also deal with calls to module-level functions.

**Line:** 334

---

### `def call_classmethod(builder: IRBuilder, ir: ClassIR, expr: CallExpr, callee: MemberExpr) -> Value`

**Line:** 392

---

### `def translate_super_method_call(builder: IRBuilder, expr: CallExpr, callee: SuperExpr) -> Value`

**Line:** 418

---

### `def translate_cast_expr(builder: IRBuilder, expr: CastExpr) -> Value`

**Line:** 484

---

### `def transform_unary_expr(builder: IRBuilder, expr: UnaryExpr) -> Value`

**Line:** 493

---

### `def transform_op_expr(builder: IRBuilder, expr: OpExpr) -> Value`

**Line:** 501

---

### `def try_optimize_int_floor_divide(expr: OpExpr) -> OpExpr`

**Description:**
Replace // with a power of two with a right shift, if possible.

**Line:** 537

---

### `def transform_index_expr(builder: IRBuilder, expr: IndexExpr) -> Value`

**Line:** 548

---

### `def try_constant_fold(builder: IRBuilder, expr: Expression) -> Value | None`

**Description:**
Return the constant value of an expression if possible.

Return None otherwise.

**Line:** 570

---

### `def try_gen_slice_op(builder: IRBuilder, base: Value, index: SliceExpr) -> Value | None`

**Description:**
Generate specialized slice op for some index expressions.

Return None if a specialized op isn't available.

This supports obj[x:y], obj[:x], and obj[x:] for a few types.

**Line:** 581

---

### `def transform_conditional_expr(builder: IRBuilder, expr: ConditionalExpr) -> Value`

**Line:** 619

---

### `def set_literal_values(builder: IRBuilder, items: Sequence[Expression]) -> list[object] | None`

**Line:** 644

---

### `def precompute_set_literal(builder: IRBuilder, s: SetExpr) -> Value | None`

**Description:**
Try to pre-compute a frozenset literal during module initialization.

Return None if it's not possible.

Supported items:
- Anything supported by irbuild.constant_fold.constant_fold_expr()
- None, True, and False
- Tuple literals with only items listed above

**Line:** 670

---

### `def transform_comparison_expr(builder: IRBuilder, e: ComparisonExpr) -> Value`

**Line:** 687

---

### `def translate_is_none(builder: IRBuilder, expr: Expression, negated: bool) -> Value`

**Line:** 802

---

### `def transform_basic_comparison(builder: IRBuilder, op: str, left: Value, right: Value, line: int) -> Value`

**Line:** 807

---

### `def translate_printf_style_formatting(builder: IRBuilder, format_expr: StrExpr | BytesExpr, rhs: Expression) -> Value | None`

**Line:** 857

---

### `def transform_int_expr(builder: IRBuilder, expr: IntExpr) -> Value`

**Line:** 889

---

### `def transform_float_expr(builder: IRBuilder, expr: FloatExpr) -> Value`

**Line:** 893

---

### `def transform_complex_expr(builder: IRBuilder, expr: ComplexExpr) -> Value`

**Line:** 897

---

### `def transform_str_expr(builder: IRBuilder, expr: StrExpr) -> Value`

**Line:** 901

---

### `def transform_bytes_expr(builder: IRBuilder, expr: BytesExpr) -> Value`

**Line:** 905

---

### `def transform_ellipsis(builder: IRBuilder, o: EllipsisExpr) -> Value`

**Line:** 909

---

### `def transform_list_expr(builder: IRBuilder, expr: ListExpr) -> Value`

**Line:** 916

---

### `def _visit_list_display(builder: IRBuilder, items: list[Expression], line: int) -> Value`

**Line:** 920

---

### `def transform_tuple_expr(builder: IRBuilder, expr: TupleExpr) -> Value`

**Line:** 926

---

### `def _visit_tuple_display(builder: IRBuilder, expr: TupleExpr) -> Value`

**Description:**
Create a list, then turn it into a tuple.

**Line:** 948

---

### `def transform_dict_expr(builder: IRBuilder, expr: DictExpr) -> Value`

**Description:**
First accepts all keys and values, then makes a dict out of them.

**Line:** 954

---

### `def transform_set_expr(builder: IRBuilder, expr: SetExpr) -> Value`

**Line:** 965

---

### `def _visit_display(builder: IRBuilder, items: list[Expression], constructor_op: Callable[([list[Value], int], Value)], append_op: CFunctionDescription, extend_op: CFunctionDescription, line: int, is_list: bool) -> Value`

**Line:** 971

---

### `def transform_list_comprehension(builder: IRBuilder, o: ListComprehension) -> Value`

**Line:** 1008

---

### `def transform_set_comprehension(builder: IRBuilder, o: SetComprehension) -> Value`

**Line:** 1012

---

### `def transform_dictionary_comprehension(builder: IRBuilder, o: DictionaryComprehension) -> Value`

**Line:** 1016

---

### `def transform_slice_expr(builder: IRBuilder, expr: SliceExpr) -> Value`

**Line:** 1032

---

### `def transform_generator_expr(builder: IRBuilder, o: GeneratorExpr) -> Value`

**Line:** 1043

---

### `def transform_assignment_expr(builder: IRBuilder, o: AssignmentExpr) -> Value`

**Line:** 1048

---

### `def transform_math_literal(builder: IRBuilder, fullname: str) -> Value | None`

**Line:** 1055

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.for_helpers
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/for_helpers.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ARG_POS
- mypy.nodes.CallExpr
- mypy.nodes.Expression
- mypy.nodes.GeneratorExpr
- mypy.nodes.Lvalue
- mypy.nodes.MemberExpr
- mypy.nodes.RefExpr
- mypy.nodes.SetExpr
- mypy.nodes.TupleExpr
- mypy.nodes.TypeAlias
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Branch
- mypyc.ir.ops.IntOp
- mypyc.ir.ops.Integer
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.LoadMem
- mypyc.ir.ops.Register
- mypyc.ir.ops.TupleGet
- mypyc.ir.ops.TupleSet
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RTuple
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.bool_rprimitive
- mypyc.ir.rtypes.int_rprimitive
- mypyc.ir.rtypes.is_dict_rprimitive
- mypyc.ir.rtypes.is_fixed_width_rtype
- mypyc.ir.rtypes.is_list_rprimitive
- mypyc.ir.rtypes.is_sequence_rprimitive
- mypyc.ir.rtypes.is_short_int_rprimitive
- mypyc.ir.rtypes.is_str_rprimitive
- mypyc.ir.rtypes.is_tuple_rprimitive
- mypyc.ir.rtypes.pointer_rprimitive
- mypyc.ir.rtypes.short_int_rprimitive
- mypyc.irbuild.builder.IRBuilder
- mypyc.irbuild.expression.precompute_set_literal
- mypyc.irbuild.statement.emit_await
- mypyc.irbuild.statement.transform_try_except
- mypyc.irbuild.targets.AssignmentTarget
- mypyc.irbuild.targets.AssignmentTargetTuple
- mypyc.primitives.dict_ops.dict_check_size_op
- mypyc.primitives.dict_ops.dict_item_iter_op
- mypyc.primitives.dict_ops.dict_key_iter_op
- mypyc.primitives.dict_ops.dict_next_item_op
- mypyc.primitives.dict_ops.dict_next_key_op
- mypyc.primitives.dict_ops.dict_next_value_op
- mypyc.primitives.dict_ops.dict_value_iter_op
- mypyc.primitives.exc_ops.no_err_occurred_op
- mypyc.primitives.generic_ops.aiter_op
- mypyc.primitives.generic_ops.anext_op
- mypyc.primitives.generic_ops.iter_op
- mypyc.primitives.generic_ops.next_op
- mypyc.primitives.list_ops.list_append_op
- mypyc.primitives.list_ops.list_get_item_unsafe_op
- mypyc.primitives.list_ops.new_list_set_item_op
- mypyc.primitives.misc_ops.stop_async_iteration_op
- mypyc.primitives.registry.CFunctionDescription
- mypyc.primitives.set_ops.set_add_op
- typing.Callable
- typing.ClassVar

**Functions:**

### `def for_loop_helper(builder: IRBuilder, index: Lvalue, expr: Expression, body_insts: GenFunc, else_insts: GenFunc | None, is_async: bool, line: int) -> None`

**Description:**
Generate IR for a loop.

Args:
index: the loop index Lvalue
expr: the expression to iterate over
body_insts: a function that generates the body of the loop
else_insts: a function that generates the else block instructions

**Line:** 72

---

### `def for_loop_helper_with_index(builder: IRBuilder, index: Lvalue, expr: Expression, expr_reg: Value, body_insts: Callable[([Value], None)], line: int) -> None`

**Description:**
Generate IR for a sequence iteration.

This function only works for sequence type. Compared to for_loop_helper,
it would feed iteration index to body_insts.

Args:
index: the loop index Lvalue
expr: the expression to iterate over
body_insts: a function that generates the body of the loop.
It needs a index as parameter.

**Line:** 134

---

### `def sequence_from_generator_preallocate_helper(builder: IRBuilder, gen: GeneratorExpr, empty_op_llbuilder: Callable[([Value, int], Value)], set_item_op: CFunctionDescription) -> Value | None`

**Description:**
Generate a new tuple or list from a simple generator expression.

Currently we only optimize for simplest generator expression, which means that
there is no condition list in the generator and only one original sequence with
one index is allowed.

e.g.  (1) tuple(f(x) for x in a_list/a_tuple)
(2) list(f(x) for x in a_list/a_tuple)
(3) [f(x) for x in a_list/a_tuple]
RTuple as an original sequence is not supported yet.

Args:
empty_op_llbuilder: A function that can generate an empty sequence op when
passed in length. See `new_list_op_with_length` and `new_tuple_op_with_length`
for detailed implementation.
set_item_op: A primitive that can modify an arbitrary position of a sequence.
The op should have three arguments:
- Self
- Target position
- New Value
See `new_list_set_item_op` and `new_tuple_set_item_op` for detailed
implementation.

**Line:** 183

---

### `def translate_list_comprehension(builder: IRBuilder, gen: GeneratorExpr) -> Value`

**Line:** 231

---

### `def translate_set_comprehension(builder: IRBuilder, gen: GeneratorExpr) -> Value`

**Line:** 254

---

### `def comprehension_helper(builder: IRBuilder, loop_params: list[tuple[(Lvalue, Expression, list[Expression], bool)]], gen_inner_stmts: Callable[([], None)], line: int) -> None`

**Description:**
Helper function for list comprehensions.

Args:
loop_params: a list of (index, expr, [conditions]) tuples defining nested loops:
- "index" is the Lvalue indexing that loop;
- "expr" is the expression for the object to be iterated over;
- "conditions" is a list of conditions, evaluated in order with short-circuiting,
that must all be true for the loop body to be executed
gen_inner_stmts: function to generate the IR for the body of the innermost loop

**Line:** 266

---

### `def is_range_ref(expr: RefExpr) -> bool`

**Line:** 333

---

### `def make_for_loop_generator(builder: IRBuilder, index: Lvalue, expr: Expression, body_block: BasicBlock, loop_exit: BasicBlock, line: int, is_async: bool = False, nested: bool = False) -> ForGenerator`

**Description:**
Return helper object for generating a for loop over an iterable.

If "nested" is True, this is a nested iterator such as "e" in "enumerate(e)".

**Line:** 341

---

### `def unsafe_index(builder: IRBuilder, target: Value, index: Value, line: int) -> Value`

**Description:**
Emit a potentially unsafe index into a target.

**Line:** 661

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.format_str_tokenizer
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/format_str_tokenizer.py`

**Imports:**
- __future__.annotations
- enum.Enum
- enum.unique
- mypy.checkstrformat.ConversionSpecifier
- mypy.checkstrformat.parse_conversion_specifiers
- mypy.checkstrformat.parse_format_value
- mypy.errors.Errors
- mypy.messages.MessageBuilder
- mypy.nodes.Context
- mypy.nodes.Expression
- mypy.options.Options
- mypyc.ir.ops.Integer
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.c_pyssize_t_rprimitive
- mypyc.ir.rtypes.is_bytes_rprimitive
- mypyc.ir.rtypes.is_int_rprimitive
- mypyc.ir.rtypes.is_short_int_rprimitive
- mypyc.ir.rtypes.is_str_rprimitive
- mypyc.irbuild.builder.IRBuilder
- mypyc.primitives.bytes_ops.bytes_build_op
- mypyc.primitives.int_ops.int_to_str_op
- mypyc.primitives.str_ops.str_build_op
- mypyc.primitives.str_ops.str_op
- typing.Final

**Functions:**

### `def generate_format_ops(specifiers: list[ConversionSpecifier]) -> list[FormatOp] | None`

**Description:**
Convert ConversionSpecifier to FormatOp.

Different ConversionSpecifiers may share a same FormatOp.

**Line:** 47

---

### `def tokenizer_printf_style(format_str: str) -> tuple[list[str], list[FormatOp]] | None`

**Description:**
Tokenize a printf-style format string using regex.

Return:
A list of string literals and a list of FormatOps.

**Line:** 69

---

### `def tokenizer_format_call(format_str: str) -> tuple[list[str], list[FormatOp]] | None`

**Description:**
Tokenize a str.format() format string.

The core function parse_format_value() is shared with mypy.
With these specifiers, we then parse the literal substrings
of the original format string and convert `ConversionSpecifier`
to `FormatOp`.

Return:
A list of string literals and a list of FormatOps. The literals
are interleaved with FormatOps and the length of returned literals
should be exactly one more than FormatOps.
Return None if it cannot parse the string.

**Line:** 96

---

### `def convert_format_expr_to_str(builder: IRBuilder, format_ops: list[FormatOp], exprs: list[Expression], line: int) -> list[Value] | None`

**Description:**
Convert expressions into string literal objects with the guidance
of FormatOps. Return None when fails.

**Line:** 134

---

### `def join_formatted_strings(builder: IRBuilder, literals: list[str] | None, substitutions: list[Value], line: int) -> Value`

**Description:**
Merge the list of literals and the list of substitutions
alternatively using 'str_build_op'.

`substitutions` is the result value of formatting conversions.

If the `literals` is set to None, we simply join the substitutions;
Otherwise, the `literals` is the literal substrings of the original
format string and its length should be exactly one more than
substitutions.

For example:
(1)    'This is a %s and the value is %d'
-> literals: ['This is a ', ' and the value is', '']
(2)    '{} and the value is {}'
-> literals: ['', ' and the value is', '']

**Line:** 163

---

### `def convert_format_expr_to_bytes(builder: IRBuilder, format_ops: list[FormatOp], exprs: list[Expression], line: int) -> list[Value] | None`

**Description:**
Convert expressions into bytes literal objects with the guidance
of FormatOps. Return None when fails.

**Line:** 206

---

### `def join_formatted_bytes(builder: IRBuilder, literals: list[str], substitutions: list[Value], line: int) -> Value`

**Description:**
Merge the list of literals and the list of substitutions
alternatively using 'bytes_build_op'.

**Line:** 229

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.function
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/function.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- mypy.nodes.ArgKind
- mypy.nodes.ClassDef
- mypy.nodes.Decorator
- mypy.nodes.FuncBase
- mypy.nodes.FuncDef
- mypy.nodes.FuncItem
- mypy.nodes.LambdaExpr
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.SymbolNode
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.types.CallableType
- mypy.types.get_proper_type
- mypyc.common.LAMBDA_NAME
- mypyc.common.PROPSET_PREFIX
- mypyc.common.SELF_NAME
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.class_ir.NonExtClassInfo
- mypyc.ir.func_ir.FUNC_CLASSMETHOD
- mypyc.ir.func_ir.FUNC_NORMAL
- mypyc.ir.func_ir.FUNC_STATICMETHOD
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.func_ir.FuncSignature
- mypyc.ir.func_ir.RuntimeArg
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.GetAttr
- mypyc.ir.ops.InitStatic
- mypyc.ir.ops.Integer
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.LoadLiteral
- mypyc.ir.ops.Register
- mypyc.ir.ops.Return
- mypyc.ir.ops.SetAttr
- mypyc.ir.ops.Unbox
- mypyc.ir.ops.Unreachable
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.bool_rprimitive
- mypyc.ir.rtypes.dict_rprimitive
- mypyc.ir.rtypes.int_rprimitive
- mypyc.ir.rtypes.object_rprimitive
- mypyc.irbuild.builder.IRBuilder
- mypyc.irbuild.builder.SymbolTarget
- mypyc.irbuild.builder.gen_arg_defaults
- mypyc.irbuild.callable_class.add_call_to_callable_class
- mypyc.irbuild.callable_class.add_get_to_callable_class
- mypyc.irbuild.callable_class.instantiate_callable_class
- mypyc.irbuild.callable_class.setup_callable_class
- mypyc.irbuild.context.FuncInfo
- mypyc.irbuild.context.ImplicitClass
- mypyc.irbuild.env_class.finalize_env_class
- mypyc.irbuild.env_class.load_env_registers
- mypyc.irbuild.env_class.load_outer_envs
- mypyc.irbuild.env_class.setup_env_class
- mypyc.irbuild.env_class.setup_func_for_recursive_call
- mypyc.irbuild.generator.add_methods_to_generator_class
- mypyc.irbuild.generator.add_raise_exception_blocks_to_generator_class
- mypyc.irbuild.generator.create_switch_for_generator_class
- mypyc.irbuild.generator.gen_generator_func
- mypyc.irbuild.generator.populate_switch_for_generator_class
- mypyc.irbuild.generator.setup_env_for_generator_class
- mypyc.irbuild.targets.AssignmentTarget
- mypyc.irbuild.util.is_constant
- mypyc.primitives.dict_ops.dict_get_method_with_none
- mypyc.primitives.dict_ops.dict_new_op
- mypyc.primitives.dict_ops.dict_set_item_op
- mypyc.primitives.generic_ops.py_setattr_op
- mypyc.primitives.misc_ops.register_function
- mypyc.primitives.registry.builtin_names
- mypyc.sametype.is_same_method_signature
- mypyc.sametype.is_same_type
- typing.NamedTuple
- typing.Sequence

**Functions:**

### `def transform_func_def(builder: IRBuilder, fdef: FuncDef) -> None`

**Line:** 98

---

### `def transform_overloaded_func_def(builder: IRBuilder, o: OverloadedFuncDef) -> None`

**Line:** 109

---

### `def transform_decorator(builder: IRBuilder, dec: Decorator) -> None`

**Line:** 115

---

### `def transform_lambda_expr(builder: IRBuilder, expr: LambdaExpr) -> Value`

**Line:** 147

---

### `def gen_func_item(builder: IRBuilder, fitem: FuncItem, name: str, sig: FuncSignature, cdef: ClassDef | None = None) -> tuple[(FuncIR, Value | None)]`

**Description:**
Generate and return the FuncIR for a given FuncDef.

If the given FuncItem is a nested function, then we generate a
callable class representing the function and use that instead of
the actual function. if the given FuncItem contains a nested
function, then we generate an environment class so that inner
nested functions can access the environment of the given FuncDef.

Consider the following nested function:

def a() -> None:
def b() -> None:
def c() -> None:
return None
return None
return None

The classes generated would look something like the following.

has pointer to        +-------+
+-------------------------->  | a_env |
|                             +-------+
|                                 ^
|                                 | has pointer to
+-------+     associated with     +-------+
| b_obj |   ------------------->  | b_env |
+-------+                         +-------+
^
|
+-------+         has pointer to      |
| c_obj |   --------------------------+
+-------+

**Line:** 173

---

### `def has_nested_func_self_reference(builder: IRBuilder, fitem: FuncItem) -> bool`

**Description:**
Does a nested function contain a self-reference in its body?

If a nested function only has references in the surrounding function,
we don't need to add it to the environment.

**Line:** 356

---

### `def gen_func_ir(builder: IRBuilder, args: list[Register], blocks: list[BasicBlock], sig: FuncSignature, fn_info: FuncInfo, cdef: ClassDef | None, is_singledispatch_main_func: bool = False) -> tuple[(FuncIR, Value | None)]`

**Description:**
Generate the FuncIR for a function.

This takes the basic blocks and function info of a particular
function and returns the IR. If the function is nested,
also returns the register containing the instance of the
corresponding callable class.

**Line:** 370

---

### `def handle_ext_method(builder: IRBuilder, cdef: ClassDef, fdef: FuncDef) -> None`

**Line:** 415

---

### `def handle_non_ext_method(builder: IRBuilder, non_ext: NonExtClassInfo, cdef: ClassDef, fdef: FuncDef) -> None`

**Line:** 479

---

### `def calculate_arg_defaults(builder: IRBuilder, fn_info: FuncInfo, func_reg: Value | None, symtable: dict[(SymbolNode, SymbolTarget)]) -> None`

**Description:**
Calculate default argument values and store them.

They are stored in statics for top level functions and in
the function objects for nested functions (while constants are
still stored computed on demand).

**Line:** 509

---

### `def gen_func_ns(builder: IRBuilder) -> str`

**Description:**
Generate a namespace for a nested function using its outer function names.

**Line:** 536

---

### `def load_decorated_func(builder: IRBuilder, fdef: FuncDef, orig_func_reg: Value) -> Value`

**Description:**
Apply decorators to a function.

Given a decorated FuncDef and an instance of the callable class
representing that FuncDef, apply the corresponding decorator
functions on that decorated FuncDef and return the decorated
function.

**Line:** 545

---

### `def is_decorated(builder: IRBuilder, fdef: FuncDef) -> bool`

**Line:** 567

---

### `def gen_glue(builder: IRBuilder, base_sig: FuncSignature, target: FuncIR, cls: ClassIR, base: ClassIR, fdef: FuncItem, do_py_ops: bool = False) -> FuncIR`

**Description:**
Generate glue methods that mediate between different method types in subclasses.

Works on both properties and methods. See gen_glue_methods below
for more details.

If do_py_ops is True, then the glue methods should use generic
C API operations instead of direct calls, to enable generating
"shadow" glue methods that work with interpreted subclasses.

**Line:** 571

---

### `def get_args(builder: IRBuilder, rt_args: Sequence[RuntimeArg], line: int) -> ArgInfo`

**Line:** 602

---

### `def gen_glue_method(builder: IRBuilder, base_sig: FuncSignature, target: FuncIR, cls: ClassIR, base: ClassIR, line: int, do_pycall: bool) -> FuncIR`

**Description:**
Generate glue methods that mediate between different method types in subclasses.

For example, if we have:

class A:
def f(builder: IRBuilder, x: int) -> object: ...

then it is totally permissible to have a subclass

class B(A):
def f(builder: IRBuilder, x: object) -> int: ...

since '(object) -> int' is a subtype of '(int) -> object' by the usual
contra/co-variant function subtyping rules.

The trickiness here is that int and object have different
runtime representations in mypyc, so A.f and B.f have
different signatures at the native C level. To deal with this,
we need to generate glue methods that mediate between the
different versions by coercing the arguments and return
values.

If do_pycall is True, then make the call using the C API
instead of a native call.

**Line:** 617

---

### `def check_native_override(builder: IRBuilder, base_sig: FuncSignature, sub_sig: FuncSignature, line: int) -> None`

**Description:**
Report an error if an override changes signature in unsupported ways.

Glue methods can work around many signature changes but not all of them.

**Line:** 711

---

### `def gen_glue_property(builder: IRBuilder, sig: FuncSignature, target: FuncIR, cls: ClassIR, base: ClassIR, line: int, do_pygetattr: bool) -> FuncIR`

**Description:**
Generate glue methods for properties that mediate between different subclass types.

Similarly to methods, properties of derived types can be covariantly subtyped. Thus,
properties also require glue. However, this only requires the return type to change.
Further, instead of a method call, an attribute get is performed.

If do_pygetattr is True, then get the attribute using the Python C
API instead of a native call.

**Line:** 740

---

### `def get_func_target(builder: IRBuilder, fdef: FuncDef) -> AssignmentTarget`

**Description:**
Given a FuncDef, return the target for the instance of its callable class.

If the function was not already defined somewhere, then define it
and add it to the current environment.

**Line:** 784

---

### `def load_type(builder: IRBuilder, typ: TypeInfo, line: int) -> Value`

**Line:** 800

---

### `def load_func(builder: IRBuilder, func_name: str, fullname: str | None, line: int) -> Value`

**Line:** 813

---

### `def generate_singledispatch_dispatch_function(builder: IRBuilder, main_singledispatch_function_name: str, fitem: FuncDef) -> None`

**Line:** 829

---

### `def gen_calls_to_correct_impl(builder: IRBuilder, impl_to_use: Value, arg_info: ArgInfo, fitem: FuncDef, line: int) -> None`

**Line:** 864

---

### `def gen_dispatch_func_ir(builder: IRBuilder, fitem: FuncDef, main_func_name: str, dispatch_name: str, sig: FuncSignature) -> tuple[(FuncIR, Value)]`

**Description:**
Create a dispatch function (a function that checks the first argument type and dispatches
to the correct implementation)

**Line:** 913

---

### `def generate_dispatch_glue_native_function(builder: IRBuilder, fitem: FuncDef, callable_class_decl: FuncDecl, dispatch_name: str) -> FuncIR`

**Line:** 941

---

### `def generate_singledispatch_callable_class_ctor(builder: IRBuilder) -> None`

**Description:**
Create an __init__ that sets registry and dispatch_cache to empty dicts

**Line:** 960

---

### `def add_register_method_to_callable_class(builder: IRBuilder, fn_info: FuncInfo) -> None`

**Line:** 975

---

### `def load_singledispatch_registry(builder: IRBuilder, dispatch_func_obj: Value, line: int) -> Value`

**Line:** 984

---

### `def singledispatch_main_func_name(orig_name: str) -> str`

**Line:** 988

---

### `def get_registry_identifier(fitem: FuncDef) -> str`

**Line:** 992

---

### `def maybe_insert_into_registry_dict(builder: IRBuilder, fitem: FuncDef) -> None`

**Line:** 996

---

### `def get_native_impl_ids(builder: IRBuilder, singledispatch_func: FuncDef) -> dict[(FuncDef, int)]`

**Description:**
Return a dict of registered implementation to native implementation ID for all
implementations

**Line:** 1045

---

### `def gen_property_getter_ir(builder: IRBuilder, func_decl: FuncDecl, cdef: ClassDef, is_trait: bool) -> FuncIR`

**Description:**
Generate an implicit trivial property getter for an attribute.

These are used if an attribute can also be accessed as a property.

**Line:** 1053

---

### `def gen_property_setter_ir(builder: IRBuilder, func_decl: FuncDecl, cdef: ClassDef, is_trait: bool) -> FuncIR`

**Description:**
Generate an implicit trivial property setter for an attribute.

These are used if an attribute can also be accessed as a property.

**Line:** 1072

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.generator
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/generator.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ARG_OPT
- mypy.nodes.Var
- mypyc.common.ENV_ATTR_NAME
- mypyc.common.NEXT_LABEL_ATTR_NAME
- mypyc.common.SELF_NAME
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.func_ir.FuncSignature
- mypyc.ir.func_ir.RuntimeArg
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Branch
- mypyc.ir.ops.Call
- mypyc.ir.ops.Goto
- mypyc.ir.ops.Integer
- mypyc.ir.ops.MethodCall
- mypyc.ir.ops.NO_TRACEBACK_LINE_NO
- mypyc.ir.ops.RaiseStandardError
- mypyc.ir.ops.Register
- mypyc.ir.ops.Return
- mypyc.ir.ops.SetAttr
- mypyc.ir.ops.TupleSet
- mypyc.ir.ops.Unreachable
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.int_rprimitive
- mypyc.ir.rtypes.object_rprimitive
- mypyc.irbuild.builder.IRBuilder
- mypyc.irbuild.builder.gen_arg_defaults
- mypyc.irbuild.context.FuncInfo
- mypyc.irbuild.context.GeneratorClass
- mypyc.irbuild.env_class.add_args_to_env
- mypyc.irbuild.env_class.finalize_env_class
- mypyc.irbuild.env_class.load_env_registers
- mypyc.irbuild.env_class.load_outer_env
- mypyc.irbuild.nonlocalcontrol.ExceptNonlocalControl
- mypyc.primitives.exc_ops.error_catch_op
- mypyc.primitives.exc_ops.exc_matches_op
- mypyc.primitives.exc_ops.raise_exception_with_tb_op
- mypyc.primitives.exc_ops.reraise_exception_op
- mypyc.primitives.exc_ops.restore_exc_info_op

**Functions:**

### `def gen_generator_func(builder: IRBuilder) -> None`

**Line:** 52

---

### `def instantiate_generator_class(builder: IRBuilder) -> Value`

**Line:** 60

---

### `def setup_generator_class(builder: IRBuilder) -> ClassIR`

**Line:** 83

---

### `def create_switch_for_generator_class(builder: IRBuilder) -> None`

**Line:** 95

---

### `def populate_switch_for_generator_class(builder: IRBuilder) -> None`

**Line:** 102

---

### `def add_raise_exception_blocks_to_generator_class(builder: IRBuilder, line: int) -> None`

**Description:**
Add error handling blocks to a generator class.

Generates blocks to check if error flags are set while calling the
helper method for generator functions, and raises an exception if
those flags are set.

**Line:** 117

---

### `def add_methods_to_generator_class(builder: IRBuilder, fn_info: FuncInfo, sig: FuncSignature, arg_regs: list[Register], blocks: list[BasicBlock], is_coroutine: bool) -> None`

**Line:** 140

---

### `def add_helper_to_generator_class(builder: IRBuilder, arg_regs: list[Register], blocks: list[BasicBlock], sig: FuncSignature, fn_info: FuncInfo) -> FuncDecl`

**Description:**
Generates a helper method for a generator class, called by '__next__' and 'throw'.

**Line:** 158

---

### `def add_iter_to_generator_class(builder: IRBuilder, fn_info: FuncInfo) -> None`

**Description:**
Generates the '__iter__' method for a generator class.

**Line:** 187

---

### `def add_next_to_generator_class(builder: IRBuilder, fn_info: FuncInfo, fn_decl: FuncDecl, sig: FuncSignature) -> None`

**Description:**
Generates the '__next__' method for a generator class.

**Line:** 193

---

### `def add_send_to_generator_class(builder: IRBuilder, fn_info: FuncInfo, fn_decl: FuncDecl, sig: FuncSignature) -> None`

**Description:**
Generates the 'send' method for a generator class.

**Line:** 210

---

### `def add_throw_to_generator_class(builder: IRBuilder, fn_info: FuncInfo, fn_decl: FuncDecl, sig: FuncSignature) -> None`

**Description:**
Generates the 'throw' method for a generator class.

**Line:** 228

---

### `def add_close_to_generator_class(builder: IRBuilder, fn_info: FuncInfo) -> None`

**Description:**
Generates the '__close__' method for a generator class.

**Line:** 255

---

### `def add_await_to_generator_class(builder: IRBuilder, fn_info: FuncInfo) -> None`

**Description:**
Generates the '__await__' method for a generator class.

**Line:** 309

---

### `def setup_env_for_generator_class(builder: IRBuilder) -> None`

**Description:**
Populates the environment for a generator class.

**Line:** 315

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.ll_builder
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/ll_builder.py`

**Imports:**
- __future__.annotations
- mypy.argmap.map_actuals_to_formals
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.ArgKind
- mypy.operators.op_methods
- mypy.types.AnyType
- mypy.types.TypeOfAny
- mypyc.common.BITMAP_BITS
- mypyc.common.FAST_ISINSTANCE_MAX_SUBCLASSES
- mypyc.common.MAX_LITERAL_SHORT_INT
- mypyc.common.MAX_SHORT_INT
- mypyc.common.MIN_LITERAL_SHORT_INT
- mypyc.common.MIN_SHORT_INT
- mypyc.common.PLATFORM_SIZE
- mypyc.common.use_method_vectorcall
- mypyc.common.use_vectorcall
- mypyc.errors.Errors
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.class_ir.all_concrete_classes
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncSignature
- mypyc.ir.ops.Assign
- mypyc.ir.ops.AssignMulti
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Box
- mypyc.ir.ops.Branch
- mypyc.ir.ops.Call
- mypyc.ir.ops.CallC
- mypyc.ir.ops.Cast
- mypyc.ir.ops.ComparisonOp
- mypyc.ir.ops.ERR_FALSE
- mypyc.ir.ops.ERR_NEVER
- mypyc.ir.ops.Extend
- mypyc.ir.ops.Float
- mypyc.ir.ops.FloatComparisonOp
- mypyc.ir.ops.FloatNeg
- mypyc.ir.ops.FloatOp
- mypyc.ir.ops.GetAttr
- mypyc.ir.ops.GetElementPtr
- mypyc.ir.ops.Goto
- mypyc.ir.ops.IntOp
- mypyc.ir.ops.Integer
- mypyc.ir.ops.KeepAlive
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.LoadErrorValue
- mypyc.ir.ops.LoadLiteral
- mypyc.ir.ops.LoadMem
- mypyc.ir.ops.LoadStatic
- mypyc.ir.ops.MethodCall
- mypyc.ir.ops.NAMESPACE_MODULE
- mypyc.ir.ops.NAMESPACE_STATIC
- mypyc.ir.ops.NAMESPACE_TYPE
- mypyc.ir.ops.Op
- mypyc.ir.ops.RaiseStandardError
- mypyc.ir.ops.Register
- mypyc.ir.ops.SetMem
- mypyc.ir.ops.Truncate
- mypyc.ir.ops.TupleGet
- mypyc.ir.ops.TupleSet
- mypyc.ir.ops.Unbox
- mypyc.ir.ops.Unreachable
- mypyc.ir.ops.Value
- mypyc.ir.ops.float_comparison_op_to_id
- mypyc.ir.ops.float_op_to_id
- mypyc.ir.ops.int_op_to_id
- mypyc.ir.rtypes.PyListObject
- mypyc.ir.rtypes.PyObject
- mypyc.ir.rtypes.PySetObject
- mypyc.ir.rtypes.PyVarObject
- mypyc.ir.rtypes.RArray
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.RPrimitive
- mypyc.ir.rtypes.RTuple
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.RUnion
- mypyc.ir.rtypes.bit_rprimitive
- mypyc.ir.rtypes.bitmap_rprimitive
- mypyc.ir.rtypes.bool_rprimitive
- mypyc.ir.rtypes.bytes_rprimitive
- mypyc.ir.rtypes.c_int_rprimitive
- mypyc.ir.rtypes.c_pointer_rprimitive
- mypyc.ir.rtypes.c_pyssize_t_rprimitive
- mypyc.ir.rtypes.c_size_t_rprimitive
- mypyc.ir.rtypes.check_native_int_range
- mypyc.ir.rtypes.dict_rprimitive
- mypyc.ir.rtypes.float_rprimitive
- mypyc.ir.rtypes.int_rprimitive
- mypyc.ir.rtypes.is_bit_rprimitive
- mypyc.ir.rtypes.is_bool_rprimitive
- mypyc.ir.rtypes.is_bytes_rprimitive
- mypyc.ir.rtypes.is_dict_rprimitive
- mypyc.ir.rtypes.is_fixed_width_rtype
- mypyc.ir.rtypes.is_float_rprimitive
- mypyc.ir.rtypes.is_int16_rprimitive
- mypyc.ir.rtypes.is_int32_rprimitive
- mypyc.ir.rtypes.is_int64_rprimitive
- mypyc.ir.rtypes.is_int_rprimitive
- mypyc.ir.rtypes.is_list_rprimitive
- mypyc.ir.rtypes.is_none_rprimitive
- mypyc.ir.rtypes.is_set_rprimitive
- mypyc.ir.rtypes.is_short_int_rprimitive
- mypyc.ir.rtypes.is_str_rprimitive
- mypyc.ir.rtypes.is_tagged
- mypyc.ir.rtypes.is_tuple_rprimitive
- mypyc.ir.rtypes.is_uint8_rprimitive
- mypyc.ir.rtypes.list_rprimitive
- mypyc.ir.rtypes.none_rprimitive
- mypyc.ir.rtypes.object_pointer_rprimitive
- mypyc.ir.rtypes.object_rprimitive
- mypyc.ir.rtypes.optional_value_type
- mypyc.ir.rtypes.pointer_rprimitive
- mypyc.ir.rtypes.short_int_rprimitive
- mypyc.ir.rtypes.str_rprimitive
- mypyc.irbuild.mapper.Mapper
- mypyc.irbuild.util.concrete_arg_kind
- mypyc.options.CompilerOptions
- mypyc.primitives.bytes_ops.bytes_compare
- mypyc.primitives.dict_ops.dict_build_op
- mypyc.primitives.dict_ops.dict_new_op
- mypyc.primitives.dict_ops.dict_ssize_t_size_op
- mypyc.primitives.dict_ops.dict_update_in_display_op
- mypyc.primitives.exc_ops.err_occurred_op
- mypyc.primitives.exc_ops.keep_propagating_op
- mypyc.primitives.float_ops.copysign_op
- mypyc.primitives.float_ops.int_to_float_op
- mypyc.primitives.generic_ops.generic_len_op
- mypyc.primitives.generic_ops.generic_ssize_t_len_op
- mypyc.primitives.generic_ops.py_call_op
- mypyc.primitives.generic_ops.py_call_with_kwargs_op
- mypyc.primitives.generic_ops.py_getattr_op
- mypyc.primitives.generic_ops.py_method_call_op
- mypyc.primitives.generic_ops.py_vectorcall_method_op
- mypyc.primitives.generic_ops.py_vectorcall_op
- mypyc.primitives.int_ops.int16_divide_op
- mypyc.primitives.int_ops.int16_mod_op
- mypyc.primitives.int_ops.int16_overflow
- mypyc.primitives.int_ops.int32_divide_op
- mypyc.primitives.int_ops.int32_mod_op
- mypyc.primitives.int_ops.int32_overflow
- mypyc.primitives.int_ops.int64_divide_op
- mypyc.primitives.int_ops.int64_mod_op
- mypyc.primitives.int_ops.int64_to_int_op
- mypyc.primitives.int_ops.int_comparison_op_mapping
- mypyc.primitives.int_ops.int_to_int32_op
- mypyc.primitives.int_ops.int_to_int64_op
- mypyc.primitives.int_ops.ssize_t_to_int_op
- mypyc.primitives.int_ops.uint8_overflow
- mypyc.primitives.list_ops.list_build_op
- mypyc.primitives.list_ops.list_extend_op
- mypyc.primitives.list_ops.new_list_op
- mypyc.primitives.misc_ops.bool_op
- mypyc.primitives.misc_ops.fast_isinstance_op
- mypyc.primitives.misc_ops.none_object_op
- mypyc.primitives.registry.CFunctionDescription
- mypyc.primitives.registry.ERR_NEG_INT
- mypyc.primitives.registry.binary_ops
- mypyc.primitives.registry.method_call_ops
- mypyc.primitives.registry.unary_ops
- mypyc.primitives.set_ops.new_set_op
- mypyc.primitives.str_ops.str_check_if_true
- mypyc.primitives.str_ops.str_ssize_t_size_op
- mypyc.primitives.str_ops.unicode_compare
- mypyc.primitives.tuple_ops.list_tuple_op
- mypyc.primitives.tuple_ops.new_tuple_op
- mypyc.primitives.tuple_ops.new_tuple_with_length_op
- mypyc.rt_subtype.is_runtime_subtype
- mypyc.sametype.is_same_type
- mypyc.subtype.is_subtype
- typing.Callable
- typing.Final
- typing.Optional
- typing.Sequence
- typing.Tuple

**Functions:**

### `def num_positional_args(arg_values: list[Value], arg_kinds: list[ArgKind] | None) -> int`

**Line:** 2400

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.main
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/main.py`

**Imports:**
- __future__.annotations
- mypy.build.Graph
- mypy.nodes.ClassDef
- mypy.nodes.Expression
- mypy.nodes.MypyFile
- mypy.state.state
- mypy.types.Type
- mypyc.analysis.attrdefined.analyze_always_defined_attrs
- mypyc.common.TOP_LEVEL_NAME
- mypyc.errors.Errors
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.func_ir.FuncSignature
- mypyc.ir.module_ir.ModuleIR
- mypyc.ir.module_ir.ModuleIRs
- mypyc.ir.rtypes.none_rprimitive
- mypyc.irbuild.builder.IRBuilder
- mypyc.irbuild.mapper.Mapper
- mypyc.irbuild.prebuildvisitor.PreBuildVisitor
- mypyc.irbuild.prepare.build_type_map
- mypyc.irbuild.prepare.find_singledispatch_register_impls
- mypyc.irbuild.visitor.IRBuilderVisitor
- mypyc.irbuild.vtable.compute_vtable
- mypyc.options.CompilerOptions
- typing.Any
- typing.Callable
- typing.TypeVar
- typing.cast

**Functions:**

### `def build_ir(modules: list[MypyFile], graph: Graph, types: dict[(Expression, Type)], mapper: Mapper, options: CompilerOptions, errors: Errors) -> ModuleIRs`

**Decorators:**
- `@strict_optional_dec`

**Description:**
Build basic IR for a set of modules that have been type-checked by mypy.

The returned IR is not complete and requires additional
transformations, such as the insertion of refcount handling.

**Line:** 52

---

### `def transform_mypy_file(builder: IRBuilder, mypyfile: MypyFile) -> None`

**Description:**
Generate IR for a single module.

**Line:** 116

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.match
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/match.py`

**Imports:**
- contextlib.contextmanager
- mypy.nodes.MatchStmt
- mypy.nodes.NameExpr
- mypy.nodes.TypeInfo
- mypy.patterns.AsPattern
- mypy.patterns.ClassPattern
- mypy.patterns.MappingPattern
- mypy.patterns.OrPattern
- mypy.patterns.Pattern
- mypy.patterns.SequencePattern
- mypy.patterns.SingletonPattern
- mypy.patterns.StarredPattern
- mypy.patterns.ValuePattern
- mypy.traverser.TraverserVisitor
- mypy.types.Instance
- mypy.types.TupleType
- mypy.types.get_proper_type
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.object_rprimitive
- mypyc.irbuild.builder.IRBuilder
- mypyc.primitives.dict_ops.dict_copy
- mypyc.primitives.dict_ops.dict_del_item
- mypyc.primitives.dict_ops.mapping_has_key
- mypyc.primitives.dict_ops.supports_mapping_protocol
- mypyc.primitives.generic_ops.generic_ssize_t_len_op
- mypyc.primitives.list_ops.sequence_get_item
- mypyc.primitives.list_ops.sequence_get_slice
- mypyc.primitives.list_ops.supports_sequence_protocol
- mypyc.primitives.misc_ops.fast_isinstance_op
- mypyc.primitives.misc_ops.slow_isinstance_op
- typing.Generator
- typing.List
- typing.Optional
- typing.Tuple

**Functions:**

### `def prep_sequence_pattern(seq_pattern: SequencePattern) -> Tuple[(Optional[int], Optional[NameExpr], List[Pattern])]`

**Line:** 340

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.prepare
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/prepare.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- mypy.build.Graph
- mypy.nodes.ARG_STAR
- mypy.nodes.ARG_STAR2
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.Decorator
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.MemberExpr
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.RefExpr
- mypy.nodes.SymbolNode
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.semanal.refers_to_fullname
- mypy.traverser.TraverserVisitor
- mypy.types.Instance
- mypy.types.Type
- mypy.types.get_proper_type
- mypyc.common.PROPSET_PREFIX
- mypyc.common.get_id_from_name
- mypyc.crash.catch_errors
- mypyc.errors.Errors
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.func_ir.FUNC_CLASSMETHOD
- mypyc.ir.func_ir.FUNC_NORMAL
- mypyc.ir.func_ir.FUNC_STATICMETHOD
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncSignature
- mypyc.ir.func_ir.RuntimeArg
- mypyc.ir.ops.DeserMaps
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.dict_rprimitive
- mypyc.ir.rtypes.none_rprimitive
- mypyc.ir.rtypes.tuple_rprimitive
- mypyc.irbuild.mapper.Mapper
- mypyc.irbuild.util.get_func_def
- mypyc.irbuild.util.get_mypyc_attrs
- mypyc.irbuild.util.is_dataclass
- mypyc.irbuild.util.is_extension_class
- mypyc.irbuild.util.is_trait
- mypyc.options.CompilerOptions
- mypyc.sametype.is_same_type
- typing.Iterable
- typing.NamedTuple
- typing.Tuple

**Functions:**

### `def build_type_map(mapper: Mapper, modules: list[MypyFile], graph: Graph, types: dict[(Expression, Type)], options: CompilerOptions, errors: Errors) -> None`

**Line:** 66

---

### `def is_from_module(node: SymbolNode, module: MypyFile) -> bool`

**Line:** 135

---

### `def load_type_map(mapper: Mapper, modules: list[MypyFile], deser_ctx: DeserMaps) -> None`

**Description:**
Populate a Mapper with deserialized IR from a list of modules.

**Line:** 139

---

### `def get_module_func_defs(module: MypyFile) -> Iterable[FuncDef]`

**Description:**
Collect all of the (non-method) functions declared in a module.

**Line:** 154

---

### `def prepare_func_def(module_name: str, class_name: str | None, fdef: FuncDef, mapper: Mapper) -> FuncDecl`

**Line:** 166

---

### `def prepare_method_def(ir: ClassIR, module_name: str, cdef: ClassDef, mapper: Mapper, node: FuncDef | Decorator) -> None`

**Line:** 179

---

### `def is_valid_multipart_property_def(prop: OverloadedFuncDef) -> bool`

**Line:** 206

---

### `def can_subclass_builtin(builtin_base: str) -> bool`

**Line:** 224

---

### `def prepare_class_def(path: str, module_name: str, cdef: ClassDef, errors: Errors, mapper: Mapper) -> None`

**Description:**
Populate the interface-level information in a class IR.

This includes attribute and method declarations, and the MRO, among other things, but
method bodies are generated in a later pass.

**Line:** 239

---

### `def prepare_methods_and_attributes(cdef: ClassDef, ir: ClassIR, path: str, module_name: str, errors: Errors, mapper: Mapper) -> None`

**Description:**
Populate attribute and method declarations.

**Line:** 318

---

### `def prepare_implicit_property_accessors(info: TypeInfo, ir: ClassIR, module_name: str, mapper: Mapper) -> None`

**Line:** 360

---

### `def add_property_methods_for_attribute_if_needed(info: TypeInfo, ir: ClassIR, attr_name: str, attr_rtype: RType, module_name: str, mapper: Mapper) -> None`

**Description:**
Add getter and/or setter for attribute if defined as property in a base class.

Only add declarations. The body IR will be synthesized later during irbuild.

**Line:** 379

---

### `def add_getter_declaration(ir: ClassIR, attr_name: str, attr_rtype: RType, module_name: str) -> None`

**Line:** 410

---

### `def add_setter_declaration(ir: ClassIR, attr_name: str, attr_rtype: RType, module_name: str) -> None`

**Line:** 422

---

### `def prepare_init_method(cdef: ClassDef, ir: ClassIR, module_name: str, mapper: Mapper) -> None`

**Line:** 435

---

### `def prepare_non_ext_class_def(path: str, module_name: str, cdef: ClassDef, errors: Errors, mapper: Mapper) -> None`

**Line:** 465

---

### `def find_singledispatch_register_impls(modules: list[MypyFile], errors: Errors) -> SingledispatchInfo`

**Line:** 499

---

### `def get_singledispatch_register_call_info(decorator: Expression, func: FuncDef) -> RegisteredImpl | None`

**Line:** 570

---

### `def registered_impl_from_possible_register_call(expr: MemberExpr, dispatch_type: TypeInfo) -> RegisteredImpl | None`

**Line:** 602

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.specialize
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/specialize.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_POS
- mypy.nodes.CallExpr
- mypy.nodes.DictExpr
- mypy.nodes.Expression
- mypy.nodes.GeneratorExpr
- mypy.nodes.IntExpr
- mypy.nodes.ListExpr
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.RefExpr
- mypy.nodes.StrExpr
- mypy.nodes.TupleExpr
- mypy.types.AnyType
- mypy.types.TypeOfAny
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Extend
- mypyc.ir.ops.Integer
- mypyc.ir.ops.RaiseStandardError
- mypyc.ir.ops.Register
- mypyc.ir.ops.Truncate
- mypyc.ir.ops.Unreachable
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.RPrimitive
- mypyc.ir.rtypes.RTuple
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.bool_rprimitive
- mypyc.ir.rtypes.c_int_rprimitive
- mypyc.ir.rtypes.dict_rprimitive
- mypyc.ir.rtypes.int16_rprimitive
- mypyc.ir.rtypes.int32_rprimitive
- mypyc.ir.rtypes.int64_rprimitive
- mypyc.ir.rtypes.int_rprimitive
- mypyc.ir.rtypes.is_bool_rprimitive
- mypyc.ir.rtypes.is_dict_rprimitive
- mypyc.ir.rtypes.is_fixed_width_rtype
- mypyc.ir.rtypes.is_float_rprimitive
- mypyc.ir.rtypes.is_int16_rprimitive
- mypyc.ir.rtypes.is_int32_rprimitive
- mypyc.ir.rtypes.is_int64_rprimitive
- mypyc.ir.rtypes.is_int_rprimitive
- mypyc.ir.rtypes.is_list_rprimitive
- mypyc.ir.rtypes.is_uint8_rprimitive
- mypyc.ir.rtypes.list_rprimitive
- mypyc.ir.rtypes.set_rprimitive
- mypyc.ir.rtypes.str_rprimitive
- mypyc.ir.rtypes.uint8_rprimitive
- mypyc.irbuild.builder.IRBuilder
- mypyc.irbuild.for_helpers.comprehension_helper
- mypyc.irbuild.for_helpers.sequence_from_generator_preallocate_helper
- mypyc.irbuild.for_helpers.translate_list_comprehension
- mypyc.irbuild.for_helpers.translate_set_comprehension
- mypyc.irbuild.format_str_tokenizer.FormatOp
- mypyc.irbuild.format_str_tokenizer.convert_format_expr_to_str
- mypyc.irbuild.format_str_tokenizer.join_formatted_strings
- mypyc.irbuild.format_str_tokenizer.tokenizer_format_call
- mypyc.primitives.dict_ops.dict_items_op
- mypyc.primitives.dict_ops.dict_keys_op
- mypyc.primitives.dict_ops.dict_setdefault_spec_init_op
- mypyc.primitives.dict_ops.dict_values_op
- mypyc.primitives.list_ops.new_list_set_item_op
- mypyc.primitives.tuple_ops.new_tuple_set_item_op
- typing.Callable
- typing.Optional

**Functions:**

### `def _apply_specialization(builder: IRBuilder, expr: CallExpr, callee: RefExpr, name: str | None, typ: RType | None = None) -> Value | None`

**Line:** 110

---

### `def apply_function_specialization(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Description:**
Invoke the Specializer callback for a function if one has been registered

**Line:** 126

---

### `def apply_method_specialization(builder: IRBuilder, expr: CallExpr, callee: MemberExpr, typ: RType | None = None) -> Value | None`

**Description:**
Invoke the Specializer callback for a method if one has been registered

**Line:** 133

---

### `def specialize_function(name: str, typ: RType | None = None) -> Callable[([Specializer], Specializer)]`

**Description:**
Decorator to register a function as being a specializer.

There may exist multiple specializers for one function. When
translating method calls, the earlier appended specializer has
higher priority.

**Line:** 141

---

### `def translate_globals(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Line:** 159

---

### `def translate_builtins_with_unary_dunder(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`

**Description:**
Specialize calls on native classes that implement the associated dunder.

E.g. i64(x) gets specialized to x.__int__() if x is a native instance.

**Line:** 173

---

### `def translate_len(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Line:** 196

---

### `def dict_methods_fast_path(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Description:**
Specialize a common case when list() is called on a dictionary
view method call.

For example:
foo = list(bar.keys())

**Line:** 216

---

### `def translate_list_from_generator_call(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Description:**
Special case for simplest list comprehension.

For example:
list(f(x) for x in some_list/some_tuple/some_str)
'translate_list_comprehension()' would take care of other cases
if this fails.

**Line:** 247

---

### `def translate_tuple_from_generator_call(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Description:**
Special case for simplest tuple creation from a generator.

For example:
tuple(f(x) for x in some_list/some_tuple/some_str)
'translate_safe_generator_call()' would take care of other cases
if this fails.

**Line:** 272

---

### `def translate_set_from_generator_call(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Description:**
Special case for set creation from a generator.

For example:
set(f(...) for ... in iterator/nested_generators...)

**Line:** 297

---

### `def faster_min_max(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`
- `@specialize_function(...)`

**Line:** 316

---

### `def translate_safe_generator_call(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`

**Description:**
Special cases for things that consume iterators where we know we
can safely compile a generator into a list.

**Line:** 353

---

### `def translate_any_call(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Line:** 390

---

### `def translate_all_call(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Line:** 401

---

### `def any_all_helper(builder: IRBuilder, gen: GeneratorExpr, initial_value: Callable[([], Value)], modify: Callable[([Value], Value)], new_value: Callable[([], Value)]) -> Value`

**Line:** 417

---

### `def translate_sum_call(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Line:** 444

---

### `def translate_dataclasses_field_call(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`
- `@specialize_function(...)`

**Description:**
Special case for 'dataclasses.field', 'attr.attrib', and 'attr.Factory'
function calls because the results of such calls are type-checked
by mypy using the types of the arguments to their respective
functions, resulting in attempted coercions by mypyc that throw a
runtime error.

**Line:** 486

---

### `def translate_next_call(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Description:**
Special case for calling next() on a generator expression, an
idiom that shows up some in mypy.

For example, next(x for x in l if x.id == 12, None) will
generate code that searches l for an element where x.id == 12
and produce the first such object, or None if no such element
exists.

**Line:** 500

---

### `def translate_isinstance(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Description:**
Special case for builtins.isinstance.

Prevent coercions on the thing we are checking the instance of -
there is no need to coerce something to a new type before checking
what type it is, and the coercion could lead to bugs.

**Line:** 544

---

### `def translate_dict_setdefault(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Description:**
Special case for 'dict.setdefault' which would only construct
default empty collection when needed.

The dict_setdefault_spec_init_op checks whether the dict contains
the key and would construct the empty collection only once.

For example, this specializer works for the following cases:
d.setdefault(key, set()).add(value)
d.setdefault(key, []).append(value)
d.setdefault(key, {})[inner_key] = inner_val

**Line:** 570

---

### `def translate_str_format(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Line:** 616

---

### `def translate_fstring(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Description:**
Special case for f-string, which is translated into str.join()
in mypy AST.

This specializer optimizes simplest f-strings which don't contain
any format operation.

**Line:** 636

---

### `def translate_i64(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Line:** 686

---

### `def translate_i32(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Line:** 706

---

### `def translate_i16(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Line:** 730

---

### `def translate_u8(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Line:** 751

---

### `def truncate_literal(value: Value, rtype: RPrimitive) -> Value`

**Description:**
If value is an integer literal value, truncate it to given native int rtype.

For example, truncate 256 into 0 if rtype is u8.

**Line:** 772

---

### `def translate_int(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Line:** 789

---

### `def translate_bool(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Line:** 805

---

### `def translate_float(builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Value | None`

**Decorators:**
- `@specialize_function(...)`

**Line:** 814

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.statement
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/statement.py`

**Imports:**
- __future__.annotations
- importlib.util
- match.MatchVisitor
- mypy.nodes.AssertStmt
- mypy.nodes.AssignmentStmt
- mypy.nodes.AwaitExpr
- mypy.nodes.Block
- mypy.nodes.BreakStmt
- mypy.nodes.ContinueStmt
- mypy.nodes.DelStmt
- mypy.nodes.Expression
- mypy.nodes.ExpressionStmt
- mypy.nodes.ForStmt
- mypy.nodes.IfStmt
- mypy.nodes.Import
- mypy.nodes.ImportAll
- mypy.nodes.ImportFrom
- mypy.nodes.ListExpr
- mypy.nodes.Lvalue
- mypy.nodes.MatchStmt
- mypy.nodes.OperatorAssignmentStmt
- mypy.nodes.RaiseStmt
- mypy.nodes.ReturnStmt
- mypy.nodes.StarExpr
- mypy.nodes.StrExpr
- mypy.nodes.TempNode
- mypy.nodes.TryStmt
- mypy.nodes.TupleExpr
- mypy.nodes.WhileStmt
- mypy.nodes.WithStmt
- mypy.nodes.YieldExpr
- mypy.nodes.YieldFromExpr
- mypyc.ir.ops.Assign
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Branch
- mypyc.ir.ops.InitStatic
- mypyc.ir.ops.Integer
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.LoadErrorValue
- mypyc.ir.ops.LoadLiteral
- mypyc.ir.ops.LoadStatic
- mypyc.ir.ops.MethodCall
- mypyc.ir.ops.NAMESPACE_MODULE
- mypyc.ir.ops.NO_TRACEBACK_LINE_NO
- mypyc.ir.ops.RaiseStandardError
- mypyc.ir.ops.Register
- mypyc.ir.ops.Return
- mypyc.ir.ops.TupleGet
- mypyc.ir.ops.Unborrow
- mypyc.ir.ops.Unreachable
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.RTuple
- mypyc.ir.rtypes.c_pyssize_t_rprimitive
- mypyc.ir.rtypes.exc_rtuple
- mypyc.ir.rtypes.is_tagged
- mypyc.ir.rtypes.none_rprimitive
- mypyc.ir.rtypes.object_pointer_rprimitive
- mypyc.ir.rtypes.object_rprimitive
- mypyc.irbuild.ast_helpers.is_borrow_friendly_expr
- mypyc.irbuild.ast_helpers.process_conditional
- mypyc.irbuild.builder.IRBuilder
- mypyc.irbuild.builder.int_borrow_friendly_op
- mypyc.irbuild.for_helpers.for_loop_helper
- mypyc.irbuild.generator.add_raise_exception_blocks_to_generator_class
- mypyc.irbuild.nonlocalcontrol.ExceptNonlocalControl
- mypyc.irbuild.nonlocalcontrol.FinallyNonlocalControl
- mypyc.irbuild.nonlocalcontrol.TryFinallyNonlocalControl
- mypyc.irbuild.targets.AssignmentTarget
- mypyc.irbuild.targets.AssignmentTargetAttr
- mypyc.irbuild.targets.AssignmentTargetIndex
- mypyc.irbuild.targets.AssignmentTargetRegister
- mypyc.irbuild.targets.AssignmentTargetTuple
- mypyc.primitives.exc_ops.error_catch_op
- mypyc.primitives.exc_ops.exc_matches_op
- mypyc.primitives.exc_ops.get_exc_info_op
- mypyc.primitives.exc_ops.get_exc_value_op
- mypyc.primitives.exc_ops.keep_propagating_op
- mypyc.primitives.exc_ops.raise_exception_op
- mypyc.primitives.exc_ops.reraise_exception_op
- mypyc.primitives.exc_ops.restore_exc_info_op
- mypyc.primitives.generic_ops.iter_op
- mypyc.primitives.generic_ops.next_raw_op
- mypyc.primitives.generic_ops.py_delattr_op
- mypyc.primitives.misc_ops.check_stop_op
- mypyc.primitives.misc_ops.coro_op
- mypyc.primitives.misc_ops.import_from_many_op
- mypyc.primitives.misc_ops.import_many_op
- mypyc.primitives.misc_ops.send_op
- mypyc.primitives.misc_ops.type_op
- mypyc.primitives.misc_ops.yield_from_except_op
- typing.Callable
- typing.Sequence

**Functions:**

### `def transform_block(builder: IRBuilder, block: Block) -> None`

**Line:** 119

---

### `def transform_expression_stmt(builder: IRBuilder, stmt: ExpressionStmt) -> None`

**Line:** 140

---

### `def transform_return_stmt(builder: IRBuilder, stmt: ReturnStmt) -> None`

**Line:** 150

---

### `def transform_assignment_stmt(builder: IRBuilder, stmt: AssignmentStmt) -> None`

**Line:** 159

---

### `def is_simple_lvalue(expr: Expression) -> bool`

**Line:** 222

---

### `def transform_operator_assignment_stmt(builder: IRBuilder, stmt: OperatorAssignmentStmt) -> None`

**Description:**
Operator assignment statement such as x += 1

**Line:** 226

---

### `def import_globals_id_and_name(module_id: str, as_name: str | None) -> tuple[(str, str)]`

**Description:**
Compute names for updating the globals dict with the appropriate module.

* For 'import foo.bar as baz' we add 'foo.bar' with the name 'baz'
* For 'import foo.bar' we add 'foo' with the name 'foo'

Typically we then ignore these entries and access things directly
via the module static, but we will use the globals version for
modules that mypy couldn't find, since it doesn't analyze module
references from those properly.

**Line:** 251

---

### `def transform_import(builder: IRBuilder, node: Import) -> None`

**Line:** 270

---

### `def transform_import_from(builder: IRBuilder, node: ImportFrom) -> None`

**Line:** 340

---

### `def transform_import_all(builder: IRBuilder, node: ImportAll) -> None`

**Line:** 374

---

### `def transform_if_stmt(builder: IRBuilder, stmt: IfStmt) -> None`

**Line:** 380

---

### `def transform_while_stmt(builder: IRBuilder, s: WhileStmt) -> None`

**Line:** 398

---

### `def transform_for_stmt(builder: IRBuilder, s: ForStmt) -> None`

**Line:** 423

---

### `def transform_break_stmt(builder: IRBuilder, node: BreakStmt) -> None`

**Line:** 436

---

### `def transform_continue_stmt(builder: IRBuilder, node: ContinueStmt) -> None`

**Line:** 440

---

### `def transform_raise_stmt(builder: IRBuilder, s: RaiseStmt) -> None`

**Line:** 444

---

### `def transform_try_except(builder: IRBuilder, body: GenFunc, handlers: Sequence[tuple[(tuple[ValueGenFunc, int] | None, Expression | None, GenFunc)]], else_body: GenFunc | None, line: int) -> None`

**Description:**
Generalized try/except/else handling that takes functions to gen the bodies.

The point of this is to also be able to support with.

**Line:** 455

---

### `def transform_try_except_stmt(builder: IRBuilder, t: TryStmt) -> None`

**Line:** 540

---

### `def try_finally_try(builder: IRBuilder, err_handler: BasicBlock, return_entry: BasicBlock, main_entry: BasicBlock, try_body: GenFunc) -> Register | AssignmentTarget | None`

**Line:** 559

---

### `def try_finally_entry_blocks(builder: IRBuilder, err_handler: BasicBlock, return_entry: BasicBlock, main_entry: BasicBlock, finally_block: BasicBlock, ret_reg: Register | AssignmentTarget | None) -> Value`

**Line:** 580

---

### `def try_finally_body(builder: IRBuilder, finally_block: BasicBlock, finally_body: GenFunc, old_exc: Value) -> tuple[(BasicBlock, FinallyNonlocalControl)]`

**Line:** 610

---

### `def try_finally_resolve_control(builder: IRBuilder, cleanup_block: BasicBlock, finally_control: FinallyNonlocalControl, old_exc: Value, ret_reg: Register | AssignmentTarget | None) -> BasicBlock`

**Description:**
Resolve the control flow out of a finally block.

This means returning if there was a return, propagating
exceptions, break/continue (soon), or just continuing on.

**Line:** 625

---

### `def transform_try_finally_stmt(builder: IRBuilder, try_body: GenFunc, finally_body: GenFunc) -> None`

**Description:**
Generalized try/finally handling that takes functions to gen the bodies.

The point of this is to also be able to support with.

**Line:** 669

---

### `def transform_try_stmt(builder: IRBuilder, t: TryStmt) -> None`

**Line:** 706

---

### `def get_sys_exc_info(builder: IRBuilder) -> list[Value]`

**Line:** 729

---

### `def transform_with(builder: IRBuilder, expr: Expression, target: Lvalue | None, body: GenFunc, is_async: bool, line: int) -> None`

**Line:** 734

---

### `def transform_with_stmt(builder: IRBuilder, o: WithStmt) -> None`

**Line:** 818

---

### `def transform_assert_stmt(builder: IRBuilder, a: AssertStmt) -> None`

**Line:** 831

---

### `def transform_del_stmt(builder: IRBuilder, o: DelStmt) -> None`

**Line:** 854

---

### `def transform_del_item(builder: IRBuilder, target: AssignmentTarget, line: int) -> None`

**Line:** 858

---

### `def emit_yield(builder: IRBuilder, val: Value, line: int) -> Value`

**Line:** 891

---

### `def emit_yield_from_or_await(builder: IRBuilder, val: Value, line: int, is_await: bool) -> Value`

**Line:** 911

---

### `def emit_await(builder: IRBuilder, val: Value, line: int) -> Value`

**Line:** 993

---

### `def transform_yield_expr(builder: IRBuilder, expr: YieldExpr) -> Value`

**Line:** 997

---

### `def transform_yield_from_expr(builder: IRBuilder, o: YieldFromExpr) -> Value`

**Line:** 1008

---

### `def transform_await_expr(builder: IRBuilder, o: AwaitExpr) -> Value`

**Line:** 1012

---

### `def transform_match_stmt(builder: IRBuilder, m: MatchStmt) -> None`

**Line:** 1016

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.util
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/util.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_NAMED_OPT
- mypy.nodes.ARG_OPT
- mypy.nodes.ARG_POS
- mypy.nodes.ArgKind
- mypy.nodes.BytesExpr
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.Decorator
- mypy.nodes.Expression
- mypy.nodes.FloatExpr
- mypy.nodes.FuncDef
- mypy.nodes.GDEF
- mypy.nodes.IntExpr
- mypy.nodes.NameExpr
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.RefExpr
- mypy.nodes.StrExpr
- mypy.nodes.TupleExpr
- mypy.nodes.UnaryExpr
- mypy.nodes.Var
- typing.Any

**Functions:**

### `def is_trait_decorator(d: Expression) -> bool`

**Line:** 34

---

### `def is_trait(cdef: ClassDef) -> bool`

**Line:** 38

---

### `def dataclass_decorator_type(d: Expression) -> str | None`

**Line:** 42

---

### `def is_dataclass_decorator(d: Expression) -> bool`

**Line:** 62

---

### `def is_dataclass(cdef: ClassDef) -> bool`

**Line:** 66

---

### `def dataclass_type(cdef: ClassDef) -> str | None`

**Line:** 70

---

### `def get_mypyc_attr_literal(e: Expression) -> Any`

**Description:**
Convert an expression from a mypyc_attr decorator to a value.

Supports a pretty limited range.

**Line:** 78

---

### `def get_mypyc_attr_call(d: Expression) -> CallExpr | None`

**Description:**
Check if an expression is a call to mypyc_attr and return it if so.

**Line:** 93

---

### `def get_mypyc_attrs(stmt: ClassDef | Decorator) -> dict[(str, Any)]`

**Description:**
Collect all the mypyc_attr attributes on a class definition or a function.

**Line:** 104

---

### `def is_extension_class(cdef: ClassDef) -> bool`

**Line:** 120

---

### `def get_func_def(op: FuncDef | Decorator | OverloadedFuncDef) -> FuncDef`

**Line:** 139

---

### `def concrete_arg_kind(kind: ArgKind) -> ArgKind`

**Description:**
Find the concrete version of an arg kind that is being passed.

**Line:** 148

---

### `def is_constant(e: Expression) -> bool`

**Description:**
Check whether we allow an expression to appear as a default value.

We don't currently properly support storing the evaluated
values for default arguments and default attribute values, so
we restrict what expressions we allow.  We allow literals of
primitives types, None, and references to Final global
variables.

**Line:** 158

---

### `def bytes_from_str(value: str) -> bytes`

**Description:**
Convert a string representing bytes into actual bytes.

This is needed because the literal characters of BytesExpr (the
characters inside b'') are stored in BytesExpr.value, whose type is
'str' not 'bytes'.

**Line:** 182

---


## Module: venv2.libthon3.12.site-packages.mypyc.irbuild.vtable
**File:** `venv2/lib/python3.12/site-packages/mypyc/irbuild/vtable.py`

**Imports:**
- __future__.annotations
- itertools
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.class_ir.VTableEntries
- mypyc.ir.class_ir.VTableMethod
- mypyc.sametype.is_same_method_signature

**Functions:**

### `def compute_vtable(cls: ClassIR) -> None`

**Description:**
Compute the vtable structure for a class.

**Line:** 11

---

### `def specialize_parent_vtable(cls: ClassIR, parent: ClassIR) -> VTableEntries`

**Description:**
Generate the part of a vtable corresponding to a parent class or trait

**Line:** 57

---


## Module: venv2.libthon3.12.site-packages.mypyc.namegen
**File:** `venv2/lib/python3.12/site-packages/mypyc/namegen.py`

**Imports:**
- __future__.annotations
- typing.Iterable

**Functions:**

### `def exported_name(fullname: str) -> str`

**Description:**
Return a C name usable for an exported definition.

This is like private_name(), but the output only depends on the
'fullname' argument, so the names are distinct across multiple
builds.

**Line:** 83

---

### `def make_module_translation_map(names: list[str]) -> dict[(str, str)]`

**Line:** 94

---

### `def candidate_suffixes(fullname: str) -> list[str]`

**Line:** 110

---


## Module: venv2.libthon3.12.site-packages.mypyc.primitives.int_ops
**File:** `venv2/lib/python3.12/site-packages/mypyc/primitives/int_ops.py`

**Imports:**
- __future__.annotations
- mypyc.ir.ops.ComparisonOp
- mypyc.ir.ops.ERR_ALWAYS
- mypyc.ir.ops.ERR_MAGIC
- mypyc.ir.ops.ERR_MAGIC_OVERLAPPING
- mypyc.ir.ops.ERR_NEVER
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.bit_rprimitive
- mypyc.ir.rtypes.bool_rprimitive
- mypyc.ir.rtypes.c_pyssize_t_rprimitive
- mypyc.ir.rtypes.float_rprimitive
- mypyc.ir.rtypes.int16_rprimitive
- mypyc.ir.rtypes.int32_rprimitive
- mypyc.ir.rtypes.int64_rprimitive
- mypyc.ir.rtypes.int_rprimitive
- mypyc.ir.rtypes.object_rprimitive
- mypyc.ir.rtypes.str_rprimitive
- mypyc.ir.rtypes.void_rtype
- mypyc.primitives.registry.CFunctionDescription
- mypyc.primitives.registry.binary_op
- mypyc.primitives.registry.custom_op
- mypyc.primitives.registry.function_op
- mypyc.primitives.registry.load_address_op
- mypyc.primitives.registry.unary_op
- typing.NamedTuple

**Functions:**

### `def int_binary_op(name: str, c_function_name: str, return_type: RType = int_rprimitive, error_kind: int = ERR_NEVER) -> None`

**Line:** 104

---

### `def int_unary_op(name: str, c_function_name: str) -> CFunctionDescription`

**Line:** 155

---


## Module: venv2.libthon3.12.site-packages.mypyc.primitives.registry
**File:** `venv2/lib/python3.12/site-packages/mypyc/primitives/registry.py`

**Imports:**
- __future__.annotations
- mypyc.ir.ops.StealsDescription
- mypyc.ir.rtypes.RType
- mypyc.primitives.bytes_ops
- mypyc.primitives.dict_ops
- mypyc.primitives.float_ops
- mypyc.primitives.int_ops
- mypyc.primitives.list_ops
- mypyc.primitives.misc_ops
- mypyc.primitives.str_ops
- mypyc.primitives.tuple_ops
- typing.Final
- typing.NamedTuple

**Functions:**

### `def method_op(name: str, arg_types: list[RType], return_type: RType, c_function_name: str, error_kind: int, var_arg_type: RType | None = None, truncated_type: RType | None = None, ordering: list[int] | None = None, extra_int_constants: list[tuple[(int, RType)]] = [], steals: StealsDescription = False, is_borrowed: bool = False, priority: int = 1) -> CFunctionDescription`

**Description:**
Define a c function call op that replaces a method call.

This will be automatically generated by matching against the AST.

Args:
name: short name of the method (for example, 'append')
arg_types: argument types; the receiver is always the first argument
return_type: type of the return value. Use void_rtype to represent void.
c_function_name: name of the C function to call
error_kind: how errors are represented in the result (one of ERR_*)
var_arg_type: type of all variable arguments
truncated_type: type to truncated to(See Truncate for info)
if it's defined both return_type and it should be non-referenced
integer types or bool type
ordering: optional ordering of the arguments, if defined,
reorders the arguments accordingly.
should never be used together with var_arg_type.
all the other arguments(such as arg_types) are in the order
accepted by the python syntax(before reordering)
extra_int_constants: optional extra integer constants as the last arguments to a C call
steals: description of arguments that this steals (ref count wise)
is_borrowed: if True, returned value is borrowed (no need to decrease refcount)
priority: if multiple ops match, the one with the highest priority is picked

**Line:** 87

---

### `def function_op(name: str, arg_types: list[RType], return_type: RType, c_function_name: str, error_kind: int, var_arg_type: RType | None = None, truncated_type: RType | None = None, ordering: list[int] | None = None, extra_int_constants: list[tuple[(int, RType)]] = [], steals: StealsDescription = False, is_borrowed: bool = False, priority: int = 1) -> CFunctionDescription`

**Description:**
Define a c function call op that replaces a function call.

This will be automatically generated by matching against the AST.

Most arguments are similar to method_op().

Args:
name: full name of the function
arg_types: positional argument types for which this applies

**Line:** 144

---

### `def binary_op(name: str, arg_types: list[RType], return_type: RType, c_function_name: str, error_kind: int, var_arg_type: RType | None = None, truncated_type: RType | None = None, ordering: list[int] | None = None, extra_int_constants: list[tuple[(int, RType)]] = [], steals: StealsDescription = False, is_borrowed: bool = False, priority: int = 1) -> CFunctionDescription`

**Description:**
Define a c function call op for a binary operation.

This will be automatically generated by matching against the AST.

Most arguments are similar to method_op(), but exactly two argument types
are expected.

**Line:** 187

---

### `def custom_op(arg_types: list[RType], return_type: RType, c_function_name: str, error_kind: int, var_arg_type: RType | None = None, truncated_type: RType | None = None, ordering: list[int] | None = None, extra_int_constants: list[tuple[(int, RType)]] = [], steals: StealsDescription = False, is_borrowed: bool = False) -> CFunctionDescription`

**Description:**
Create a one-off CallC op that can't be automatically generated from the AST.

Most arguments are similar to method_op().

**Line:** 227

---

### `def unary_op(name: str, arg_type: RType, return_type: RType, c_function_name: str, error_kind: int, truncated_type: RType | None = None, ordering: list[int] | None = None, extra_int_constants: list[tuple[(int, RType)]] = [], steals: StealsDescription = False, is_borrowed: bool = False, priority: int = 1) -> CFunctionDescription`

**Description:**
Define a c function call op for an unary operation.

This will be automatically generated by matching against the AST.

Most arguments are similar to method_op(), but exactly one argument type
is expected.

**Line:** 259

---

### `def load_address_op(name: str, type: RType, src: str) -> LoadAddressDescription`

**Line:** 298

---


## Module: venv2.libthon3.12.site-packages.mypyc.rt_subtype
**File:** `venv2/lib/python3.12/site-packages/mypyc/rt_subtype.py`

**Imports:**
- __future__.annotations
- mypyc.ir.rtypes.RArray
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.RPrimitive
- mypyc.ir.rtypes.RStruct
- mypyc.ir.rtypes.RTuple
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.RTypeVisitor
- mypyc.ir.rtypes.RUnion
- mypyc.ir.rtypes.RVoid
- mypyc.ir.rtypes.is_bit_rprimitive
- mypyc.ir.rtypes.is_bool_rprimitive
- mypyc.ir.rtypes.is_int_rprimitive
- mypyc.ir.rtypes.is_short_int_rprimitive
- mypyc.subtype.is_subtype

**Functions:**

### `def is_runtime_subtype(left: RType, right: RType) -> bool`

**Line:** 36

---


## Module: venv2.libthon3.12.site-packages.mypyc.sametype
**File:** `venv2/lib/python3.12/site-packages/mypyc/sametype.py`

**Imports:**
- __future__.annotations
- mypyc.ir.func_ir.FuncSignature
- mypyc.ir.rtypes.RArray
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.RPrimitive
- mypyc.ir.rtypes.RStruct
- mypyc.ir.rtypes.RTuple
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.RTypeVisitor
- mypyc.ir.rtypes.RUnion
- mypyc.ir.rtypes.RVoid

**Functions:**

### `def is_same_type(a: RType, b: RType) -> bool`

**Line:** 19

---

### `def is_same_signature(a: FuncSignature, b: FuncSignature) -> bool`

**Line:** 23

---

### `def is_same_method_signature(a: FuncSignature, b: FuncSignature) -> bool`

**Line:** 33

---


## Module: venv2.libthon3.12.site-packages.mypyc.subtype
**File:** `venv2/lib/python3.12/site-packages/mypyc/subtype.py`

**Imports:**
- __future__.annotations
- mypyc.ir.rtypes.RArray
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.RPrimitive
- mypyc.ir.rtypes.RStruct
- mypyc.ir.rtypes.RTuple
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.RTypeVisitor
- mypyc.ir.rtypes.RUnion
- mypyc.ir.rtypes.RVoid
- mypyc.ir.rtypes.is_bit_rprimitive
- mypyc.ir.rtypes.is_bool_rprimitive
- mypyc.ir.rtypes.is_fixed_width_rtype
- mypyc.ir.rtypes.is_int_rprimitive
- mypyc.ir.rtypes.is_object_rprimitive
- mypyc.ir.rtypes.is_short_int_rprimitive
- mypyc.ir.rtypes.is_tagged
- mypyc.ir.rtypes.is_tuple_rprimitive

**Functions:**

### `def is_subtype(left: RType, right: RType) -> bool`

**Line:** 26

---


## Module: venv2.libthon3.12.site-packages.mypyc.test-data.driver.driver
**File:** `venv2/lib/python3.12/site-packages/mypyc/test-data/driver/driver.py`

**Imports:**
- native
- re
- sys
- traceback.format_tb
- traceback.print_exception

**Functions:**

### `def extract_line(tb)`

**Line:** 27

---


## Module: venv2.libthon3.12.site-packages.mypyc.test-data.fixtures.ir
**File:** `venv2/lib/python3.12/site-packages/mypyc/test-data/fixtures/ir.py`

**Imports:**
- _typeshed
- typing.Any
- typing.Callable
- typing.Dict
- typing.FrozenSet
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.Optional
- typing.Protocol
- typing.Sequence
- typing.Set
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.overload

**Functions:**

### `def any(i: Iterable[T]) -> bool`

**Line:** 326

---

### `def all(i: Iterable[T]) -> bool`

**Line:** 327

---

### `def sum(i: Iterable[T]) -> int`

**Line:** 328

---

### `def reversed(object: Sequence[T]) -> Iterator[T]`

**Line:** 329

---

### `def id(o: object) -> int`

**Line:** 330

---

### `def len(o: object) -> int`

**Line:** 332

---

### `def print(*object) -> None`

**Line:** 333

---

### `def isinstance(x: object, t: object) -> bool`

**Line:** 334

---

### `def iter(i: Iterable[T]) -> Iterator[T]`

**Line:** 335

---

### `def next(i: Iterator[T]) -> T`

**Decorators:**
- `@overload`

**Line:** 337

---

### `def next(i: Iterator[T], default: T) -> T`

**Decorators:**
- `@overload`

**Line:** 339

---

### `def hash(o: object) -> int`

**Line:** 340

---

### `def globals() -> Dict[(str, Any)]`

**Line:** 341

---

### `def getattr(obj: object, name: str, default: Any = None) -> Any`

**Line:** 342

---

### `def setattr(obj: object, name: str, value: Any) -> None`

**Line:** 343

---

### `def enumerate(x: Iterable[T]) -> Iterator[Tuple[(int, T)]]`

**Line:** 344

---

### `def zip(x: Iterable[T], y: Iterable[S]) -> Iterator[Tuple[(T, S)]]`

**Decorators:**
- `@overload`

**Line:** 346

---

### `def zip(x: Iterable[T], y: Iterable[S], z: Iterable[V]) -> Iterator[Tuple[(T, S, V)]]`

**Decorators:**
- `@overload`

**Line:** 348

---

### `def eval(e: str) -> Any`

**Line:** 349

---

### `def abs(x: __SupportsAbs[T]) -> T`

**Line:** 350

---

### `def divmod(x: __SupportsDivMod[(T_contra, T_co)], y: T_contra) -> T_co`

**Decorators:**
- `@overload`

**Line:** 352

---

### `def divmod(x: T_contra, y: __SupportsRDivMod[(T_contra, T_co)]) -> T_co`

**Decorators:**
- `@overload`

**Line:** 354

---

### `def pow(base: __SupportsPow2[(T_contra, T_co)], exp: T_contra, mod: None = None) -> T_co`

**Decorators:**
- `@overload`

**Line:** 356

---

### `def pow(base: __SupportsPow3NoneOnly[(T_contra, T_co)], exp: T_contra, mod: None = None) -> T_co`

**Decorators:**
- `@overload`

**Line:** 358

---

### `def pow(base: __SupportsPow3[(T_contra, _M, T_co)], exp: T_contra, mod: _M) -> T_co`

**Decorators:**
- `@overload`

**Line:** 360

---

### `def exit() -> None`

**Line:** 361

---

### `def min(x: T, y: T) -> T`

**Line:** 362

---

### `def max(x: T, y: T) -> T`

**Line:** 363

---

### `def repr(o: object) -> str`

**Line:** 364

---

### `def ascii(o: object) -> str`

**Line:** 365

---

### `def ord(o: object) -> int`

**Line:** 366

---

### `def chr(i: int) -> str`

**Line:** 367

---


## Module: venv2.libthon3.12.site-packages.mypyc.test-data.fixtures.testutil
**File:** `venv2/lib/python3.12/site-packages/mypyc/test-data/fixtures/testutil.py`

**Imports:**
- collections.abc.Iterator
- contextlib.contextmanager
- math
- typing.Any
- typing.Awaitable
- typing.Callable
- typing.Final
- typing.Generator
- typing.Iterator
- typing.List
- typing.Optional
- typing.Sequence
- typing.Tuple
- typing.TypeVar
- typing.Union

**Functions:**

### `def assertRaises(typ: type, msg: str = '') -> Iterator[None]`

**Decorators:**
- `@contextmanager`

**Line:** 44

---

### `def assertDomainError() -> Any`

**Line:** 53

---

### `def assertMathRangeError() -> Any`

**Line:** 56

---

### `def run_generator(gen: Generator[(T, V, U)], inputs: Optional[List[V]] = None, p: bool = False) -> Tuple[(Sequence[T], Union[U, str])]`

**Line:** 63

---

### `def make_python_function(f: F) -> F`

**Line:** 100

---


## Module: venv2.libthon3.12.site-packages.mypyc.test.test_ircheck
**File:** `venv2/lib/python3.12/site-packages/mypyc/test/test_ircheck.py`

**Imports:**
- __future__.annotations
- mypyc.analysis.ircheck.FnError
- mypyc.analysis.ircheck.can_coerce_to
- mypyc.analysis.ircheck.check_func_ir
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.func_ir.FuncSignature
- mypyc.ir.ops.Assign
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Goto
- mypyc.ir.ops.Integer
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.LoadLiteral
- mypyc.ir.ops.Op
- mypyc.ir.ops.Register
- mypyc.ir.ops.Return
- mypyc.ir.pprint.format_func
- mypyc.ir.rtypes.RInstance
- mypyc.ir.rtypes.RType
- mypyc.ir.rtypes.RUnion
- mypyc.ir.rtypes.bytes_rprimitive
- mypyc.ir.rtypes.int32_rprimitive
- mypyc.ir.rtypes.int64_rprimitive
- mypyc.ir.rtypes.none_rprimitive
- mypyc.ir.rtypes.object_rprimitive
- mypyc.ir.rtypes.pointer_rprimitive
- mypyc.ir.rtypes.str_rprimitive
- unittest

**Functions:**

### `def assert_has_error(fn: FuncIR, error: FnError) -> None`

**Line:** 34

---

### `def assert_no_errors(fn: FuncIR) -> None`

**Line:** 39

---


## Module: venv2.libthon3.12.site-packages.mypyc.test.test_pprint
**File:** `venv2/lib/python3.12/site-packages/mypyc/test/test_pprint.py`

**Imports:**
- __future__.annotations
- mypyc.ir.ops.Assign
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.IntOp
- mypyc.ir.ops.Integer
- mypyc.ir.ops.Op
- mypyc.ir.ops.Register
- mypyc.ir.ops.Unreachable
- mypyc.ir.pprint.generate_names_for_ir
- mypyc.ir.rtypes.int_rprimitive
- unittest

**Functions:**

### `def register(name: str) -> Register`

**Line:** 10

---

### `def make_block(ops: list[Op]) -> BasicBlock`

**Line:** 14

---


## Module: venv2.libthon3.12.site-packages.mypyc.test.test_run
**File:** `venv2/lib/python3.12/site-packages/mypyc/test/test_run.py`

**Imports:**
- __future__.annotations
- ast
- contextlib
- glob
- mypy.build
- mypy.errors.CompileError
- mypy.options.Options
- mypy.options.TYPE_VAR_TUPLE
- mypy.options.UNPACK
- mypy.test.config.test_temp_dir
- mypy.test.data.DataDrivenTestCase
- mypy.test.helpers.assert_module_equivalence
- mypy.test.helpers.perform_file_operations
- mypyc.build.construct_groups
- mypyc.codegen.emitmodule
- mypyc.errors.Errors
- mypyc.options.CompilerOptions
- mypyc.test.test_serialization.check_serialization_roundtrip
- mypyc.test.testutil.ICODE_GEN_BUILTINS
- mypyc.test.testutil.MypycDataSuite
- mypyc.test.testutil.TESTUTIL_PATH
- mypyc.test.testutil.assert_test_output
- mypyc.test.testutil.fudge_dir_mtimes
- mypyc.test.testutil.show_c
- mypyc.test.testutil.use_custom_builtins
- os.path
- re
- shutil
- subprocess
- sys
- time
- typing.Any
- typing.Iterator

**Functions:**

### `def run_setup(script_name: str, script_args: list[str]) -> bool`

**Description:**
Run a setup script in a somewhat controlled environment.

This is adapted from code in distutils and our goal here is that is
faster to not need to spin up a python interpreter to run it.

We had to fork it because the real run_setup swallows errors
and KeyboardInterrupt with no way to recover them (!).
The real version has some extra features that we removed since
we weren't using them.

Returns whether the setup succeeded.

**Line:** 88

---

### `def chdir_manager(target: str) -> Iterator[None]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 124

---

### `def fix_native_line_number(message: str, fnam: str, delta: int) -> str`

**Description:**
Update code locations in test case output to point to the .test file.

The description of the test case is written to native.py, and line numbers
in test case output often are relative to native.py. This translates the
line numbers to be relative to the .test file that contains the test case
description, and also updates the file name to the .test file name.

Args:
message: message to update
fnam: path of the .test file
delta: line number of the beginning of the test case in the .test file

Returns updated message (or original message if we couldn't find anything).

**Line:** 405

---


## Module: venv2.libthon3.12.site-packages.mypyc.test.test_serialization
**File:** `venv2/lib/python3.12/site-packages/mypyc/test/test_serialization.py`

**Imports:**
- __future__.annotations
- collections.abc.Iterable
- mypyc.ir.class_ir.ClassIR
- mypyc.ir.func_ir.FuncDecl
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.func_ir.FuncSignature
- mypyc.ir.module_ir.ModuleIR
- mypyc.ir.module_ir.deserialize_modules
- mypyc.ir.ops.DeserMaps
- mypyc.ir.rtypes.RType
- mypyc.sametype.is_same_signature
- mypyc.sametype.is_same_type
- typing.Any

**Functions:**

### `def get_dict(x: Any) -> dict[(str, Any)]`

**Line:** 19

---

### `def get_function_dict(x: FuncIR) -> dict[(str, Any)]`

**Description:**
Get a dict of function attributes safe to compare across serialization

**Line:** 26

---

### `def assert_blobs_same(x: Any, y: Any, trail: tuple[(Any, ...)]) -> None`

**Description:**
Compare two blobs of IR as best we can.

FuncDecls, FuncIRs, and ClassIRs are compared by fullname to avoid
infinite recursion.
(More detailed comparisons should be done manually.)

Types and signatures are compared using mypyc.sametype.

Containers are compared recursively.

Anything else is compared with ==.

The `trail` argument is used in error messages.

**Line:** 34

---

### `def assert_modules_same(ir1: ModuleIR, ir2: ModuleIR) -> None`

**Description:**
Assert that two module IRs are the same (*).

* Or rather, as much as we care about preserving across
serialization.  We drop the actual IR bodies of functions but try
to preserve everything else.

**Line:** 76

---

### `def check_serialization_roundtrip(irs: dict[(str, ModuleIR)]) -> None`

**Description:**
Check that we can serialize modules out and deserialize them to the same thing.

**Line:** 99

---


## Module: venv2.libthon3.12.site-packages.mypyc.test.testutil
**File:** `venv2/lib/python3.12/site-packages/mypyc/test/testutil.py`

**Imports:**
- __future__.annotations
- contextlib
- mypy.build
- mypy.errors.CompileError
- mypy.options.Options
- mypy.test.config.test_temp_dir
- mypy.test.data.DataDrivenTestCase
- mypy.test.data.DataSuite
- mypy.test.helpers.assert_string_arrays_equal
- mypyc.analysis.ircheck.assert_func_ir_valid
- mypyc.common.IS_32_BIT_PLATFORM
- mypyc.common.PLATFORM_SIZE
- mypyc.errors.Errors
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.module_ir.ModuleIR
- mypyc.irbuild.main.build_ir
- mypyc.irbuild.mapper.Mapper
- mypyc.options.CompilerOptions
- mypyc.test.config.test_data_prefix
- os
- os.path
- re
- shutil
- typing.Callable
- typing.Iterator

**Functions:**

### `def builtins_wrapper(func: Callable[([DataDrivenTestCase], None)], path: str) -> Callable[([DataDrivenTestCase], None)]`

**Description:**
Decorate a function that implements a data-driven test case to copy an
alternative builtins module implementation in place before performing the
test case. Clean up after executing the test case.

**Line:** 40

---

### `def use_custom_builtins(builtins_path: str, testcase: DataDrivenTestCase) -> Iterator[None]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 51

---

### `def perform_test(func: Callable[([DataDrivenTestCase], None)], builtins_path: str, testcase: DataDrivenTestCase) -> None`

**Line:** 71

---

### `def build_ir_for_single_file(input_lines: list[str], compiler_options: CompilerOptions | None = None) -> list[FuncIR]`

**Line:** 92

---

### `def build_ir_for_single_file2(input_lines: list[str], compiler_options: CompilerOptions | None = None) -> ModuleIR`

**Line:** 98

---

### `def update_testcase_output(testcase: DataDrivenTestCase, output: list[str]) -> None`

**Line:** 142

---

### `def assert_test_output(testcase: DataDrivenTestCase, actual: list[str], message: str, expected: list[str] | None = None, formatted: list[str] | None = None) -> None`

**Line:** 170

---

### `def get_func_names(expected: list[str]) -> list[str]`

**Line:** 188

---

### `def remove_comment_lines(a: list[str]) -> list[str]`

**Description:**
Return a copy of array with comments removed.

Lines starting with '--' (but not with '---') are removed.

**Line:** 197

---

### `def print_with_line_numbers(s: str) -> None`

**Line:** 211

---

### `def heading(text: str) -> None`

**Line:** 217

---

### `def show_c(cfiles: list[list[tuple[(str, str)]]]) -> None`

**Line:** 221

---

### `def fudge_dir_mtimes(dir: str, delta: int) -> None`

**Line:** 230

---

### `def replace_word_size(text: list[str]) -> list[str]`

**Description:**
Replace WORDSIZE with platform specific word sizes

**Line:** 238

---

### `def infer_ir_build_options_from_test_name(name: str) -> CompilerOptions | None`

**Description:**
Look for magic substrings in test case name to set compiler options.

Return None if the test case should be skipped (always pass).

Supported naming conventions:

*_64bit*:
Run test case only on 64-bit platforms
*_32bit*:
Run test caseonly on 32-bit platforms
*_python3_8* (or for any Python version):
Use Python 3.8+ C API features (default: lowest supported version)
*StripAssert*:
Don't generate code for assert statements

**Line:** 254

---


## Module: venv2.libthon3.12.site-packages.mypyc.transform.exceptions
**File:** `venv2/lib/python3.12/site-packages/mypyc/transform/exceptions.py`

**Imports:**
- __future__.annotations
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Branch
- mypyc.ir.ops.CallC
- mypyc.ir.ops.ComparisonOp
- mypyc.ir.ops.ERR_ALWAYS
- mypyc.ir.ops.ERR_FALSE
- mypyc.ir.ops.ERR_MAGIC
- mypyc.ir.ops.ERR_MAGIC_OVERLAPPING
- mypyc.ir.ops.ERR_NEVER
- mypyc.ir.ops.Float
- mypyc.ir.ops.GetAttr
- mypyc.ir.ops.Integer
- mypyc.ir.ops.LoadErrorValue
- mypyc.ir.ops.NO_TRACEBACK_LINE_NO
- mypyc.ir.ops.Op
- mypyc.ir.ops.RegisterOp
- mypyc.ir.ops.Return
- mypyc.ir.ops.SetAttr
- mypyc.ir.ops.TupleGet
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.RTuple
- mypyc.ir.rtypes.bool_rprimitive
- mypyc.ir.rtypes.is_float_rprimitive
- mypyc.primitives.exc_ops.err_occurred_op
- mypyc.primitives.registry.CFunctionDescription

**Functions:**

### `def insert_exception_handling(ir: FuncIR) -> None`

**Line:** 42

---

### `def add_default_handler_block(ir: FuncIR) -> BasicBlock`

**Line:** 55

---

### `def split_blocks_at_errors(blocks: list[BasicBlock], default_error_handler: BasicBlock, func_name: str | None) -> list[BasicBlock]`

**Line:** 64

---

### `def primitive_call(desc: CFunctionDescription, args: list[Value], line: int) -> CallC`

**Line:** 140

---

### `def adjust_error_kinds(block: BasicBlock) -> None`

**Description:**
Infer more precise error_kind attributes for ops.

We have access here to more information than what was available
when the IR was initially built.

**Line:** 152

---

### `def insert_overlapping_error_value_check(ops: list[Op], target: Value) -> ComparisonOp`

**Description:**
Append to ops to check for an overlapping error value.

**Line:** 167

---


## Module: venv2.libthon3.12.site-packages.mypyc.transform.refcount
**File:** `venv2/lib/python3.12/site-packages/mypyc/transform/refcount.py`

**Imports:**
- __future__.annotations
- mypyc.analysis.dataflow.AnalysisDict
- mypyc.analysis.dataflow.analyze_borrowed_arguments
- mypyc.analysis.dataflow.analyze_live_regs
- mypyc.analysis.dataflow.analyze_must_defined_regs
- mypyc.analysis.dataflow.cleanup_cfg
- mypyc.analysis.dataflow.get_cfg
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.func_ir.all_values
- mypyc.ir.ops.Assign
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Branch
- mypyc.ir.ops.ControlOp
- mypyc.ir.ops.DecRef
- mypyc.ir.ops.Goto
- mypyc.ir.ops.IncRef
- mypyc.ir.ops.Integer
- mypyc.ir.ops.KeepAlive
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.Op
- mypyc.ir.ops.Register
- mypyc.ir.ops.RegisterOp
- mypyc.ir.ops.Value
- typing.Dict
- typing.Iterable
- typing.Tuple

**Functions:**

### `def insert_ref_count_opcodes(ir: FuncIR) -> None`

**Description:**
Insert reference count inc/dec opcodes to a function.

This is the entry point to this module.

**Line:** 58

---

### `def is_maybe_undefined(post_must_defined: set[Value], src: Value) -> bool`

**Line:** 90

---

### `def maybe_append_dec_ref(ops: list[Op], dest: Value, defined: AnalysisDict[Value], key: tuple[(BasicBlock, int)]) -> None`

**Line:** 94

---

### `def maybe_append_inc_ref(ops: list[Op], dest: Value) -> None`

**Line:** 101

---

### `def transform_block(block: BasicBlock, pre_live: AnalysisDict[Value], post_live: AnalysisDict[Value], pre_borrow: AnalysisDict[Value], post_must_defined: AnalysisDict[Value]) -> None`

**Line:** 106

---

### `def insert_branch_inc_and_decrefs(block: BasicBlock, cache: BlockCache, blocks: list[BasicBlock], pre_live: AnalysisDict[Value], pre_borrow: AnalysisDict[Value], post_borrow: AnalysisDict[Value], post_must_defined: AnalysisDict[Value], ordering: dict[(Value, int)]) -> None`

**Description:**
Insert inc_refs and/or dec_refs after a branch/goto.

Add dec_refs for registers that become dead after a branch.
Add inc_refs for registers that become unborrowed after a branch or goto.

Branches are special as the true and false targets may have a different
live and borrowed register sets. Add new blocks before the true/false target
blocks that tweak reference counts.

Example where we need to add an inc_ref:

def f(a: int) -> None
if a:
a = 1
return a  # a is borrowed if condition is false and unborrowed if true

**Line:** 157

---

### `def after_branch_decrefs(label: BasicBlock, pre_live: AnalysisDict[Value], source_defined: set[Value], source_borrowed: set[Value], source_live_regs: set[Value], ordering: dict[(Value, int)], omitted: Iterable[Value]) -> tuple[(tuple[Value, bool], ...)]`

**Line:** 207

---

### `def after_branch_increfs(label: BasicBlock, pre_live: AnalysisDict[Value], pre_borrow: AnalysisDict[Value], source_borrowed: set[Value], ordering: dict[(Value, int)]) -> tuple[(Value, ...)]`

**Line:** 227

---

### `def add_block(decs: Decs, incs: Incs, cache: BlockCache, blocks: list[BasicBlock], label: BasicBlock) -> BasicBlock`

**Line:** 244

---

### `def make_value_ordering(ir: FuncIR) -> dict[(Value, int)]`

**Description:**
Create a ordering of values that allows them to be sorted.

This omits registers that are only ever read.

**Line:** 263

---


## Module: venv2.libthon3.12.site-packages.mypyc.transform.uninit
**File:** `venv2/lib/python3.12/site-packages/mypyc/transform/uninit.py`

**Imports:**
- __future__.annotations
- mypyc.analysis.dataflow.AnalysisDict
- mypyc.analysis.dataflow.analyze_must_defined_regs
- mypyc.analysis.dataflow.cleanup_cfg
- mypyc.analysis.dataflow.get_cfg
- mypyc.common.BITMAP_BITS
- mypyc.ir.func_ir.FuncIR
- mypyc.ir.func_ir.all_values
- mypyc.ir.ops.Assign
- mypyc.ir.ops.BasicBlock
- mypyc.ir.ops.Branch
- mypyc.ir.ops.ComparisonOp
- mypyc.ir.ops.IntOp
- mypyc.ir.ops.Integer
- mypyc.ir.ops.LoadAddress
- mypyc.ir.ops.LoadErrorValue
- mypyc.ir.ops.Op
- mypyc.ir.ops.RaiseStandardError
- mypyc.ir.ops.Register
- mypyc.ir.ops.Unreachable
- mypyc.ir.ops.Value
- mypyc.ir.rtypes.bitmap_rprimitive

**Functions:**

### `def insert_uninit_checks(ir: FuncIR) -> None`

**Line:** 26

---

### `def split_blocks_at_uninits(blocks: list[BasicBlock], pre_must_defined: AnalysisDict[Value]) -> list[BasicBlock]`

**Line:** 39

---

### `def check_for_uninit_using_bitmap(ops: list[Op], src: Register, bitmap_registers: list[Register], bitmap_backed: list[Register], error_block: BasicBlock, ok_block: BasicBlock, line: int) -> None`

**Description:**
Check if src is defined using a bitmap.

Modifies ops, bitmap_registers and bitmap_backed.

**Line:** 128

---

### `def update_register_assignments_to_set_bitmap(blocks: list[BasicBlock], bitmap_registers: list[Register], bitmap_backed: list[Register]) -> None`

**Description:**
Update some assignments to registers to also set a bit in a bitmap.

The bitmaps are used to track if a local variable has been assigned to.

Modifies blocks.

**Line:** 162

---


## Module: venv2.libthon3.12.site-packages.mypyinfo
**File:** `venv2/lib/python3.12/site-packages/mypy/pyinfo.py`

**Imports:**
- __future__.annotations
- os
- site
- sys
- sysconfig
- types

**Functions:**

### `def getsitepackages() -> list[str]`

**Line:** 28

---

### `def getsyspath() -> list[str]`

**Line:** 40

---

### `def getsearchdirs() -> tuple[(list[str], list[str])]`

**Line:** 69

---


## Module: venv2.libthon3.12.site-packages.ordered_set.__init__
**File:** `venv2/lib/python3.12/site-packages/ordered_set/__init__.py`

**Imports:**
- itertools
- typing.AbstractSet
- typing.Any
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.MutableSet
- typing.Sequence
- typing.Set
- typing.TypeVar
- typing.Union
- typing.overload

**Functions:**

### `def _is_atomic(obj: Any) -> bool`

**Description:**
Returns True for objects which are iterable but should not be iterated in
the context of indexing an OrderedSet.

When we index by an iterable, usually that means we're being asked to look
up a list of things.

However, in the case of the .index() method, we shouldn't handle strings
and tuples like other iterables. They're not sequences of things to look
up, they're the single, atomic thing we're trying to find.

As an example, oset.index('hello') should give the index of 'hello' in an
OrderedSet of strings. It shouldn't give the indexes of each individual
character.

**Line:** 36

---


## Module: venv2.libthon3.12.site-packages.packaging._manylinux
**File:** `venv2/lib/python3.12/site-packages/packaging/_manylinux.py`

**Imports:**
- __future__.annotations
- _elffile.EIClass
- _elffile.EIData
- _elffile.ELFFile
- _elffile.EMachine
- _manylinux
- collections
- contextlib
- ctypes
- functools
- os
- re
- sys
- typing.Generator
- typing.Iterator
- typing.NamedTuple
- typing.Sequence
- warnings

**Functions:**

### `def _parse_elf(path: str) -> Generator[(ELFFile | None, None, None)]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 22

---

### `def _is_linux_armhf(executable: str) -> bool`

**Line:** 30

---

### `def _is_linux_i686(executable: str) -> bool`

**Line:** 45

---

### `def _have_compatible_abi(executable: str, archs: Sequence[str]) -> bool`

**Line:** 55

---

### `def _glibc_version_string_confstr() -> str | None`

**Description:**
Primary implementation of glibc_version_string using os.confstr.

**Line:** 85

---

### `def _glibc_version_string_ctypes() -> str | None`

**Description:**
Fallback implementation of glibc_version_string using ctypes.

**Line:** 104

---

### `def _glibc_version_string() -> str | None`

**Description:**
Returns glibc version string, or None if not using glibc.

**Line:** 148

---

### `def _parse_glibc_version(version_str: str) -> tuple[(int, int)]`

**Description:**
Parse glibc version.

We use a regexp instead of str.split because we want to discard any
random junk that might come after the minor version -- this might happen
in patched/forked versions of glibc (e.g. Linaro's version of glibc
uses version strings like "2.20-2014.11"). See gh-3588.

**Line:** 153

---

### `def _get_glibc_version() -> tuple[(int, int)]`

**Decorators:**
- `@functools.lru_cache`

**Line:** 173

---

### `def _is_compatible(arch: str, version: _GLibCVersion) -> bool`

**Line:** 181

---

### `def platform_tags(archs: Sequence[str]) -> Iterator[str]`

**Description:**
Generate manylinux tags compatible to the current platform.

:param archs: Sequence of compatible architectures.
The first one shall be the closest to the actual architecture and be the part of
platform tag after the ``linux_`` prefix, e.g. ``x86_64``.
The ``linux_`` prefix is assumed as a prerequisite for the current platform to
be manylinux-compatible.

:returns: An iterator of compatible manylinux tags.

**Line:** 217

---


## Module: venv2.libthon3.12.site-packages.packaging._musllinux
**File:** `venv2/lib/python3.12/site-packages/packaging/_musllinux.py`

**Imports:**
- __future__.annotations
- _elffile.ELFFile
- functools
- re
- subprocess
- sys
- sysconfig
- typing.Iterator
- typing.NamedTuple
- typing.Sequence

**Functions:**

### `def _parse_musl_version(output: str) -> _MuslVersion | None`

**Line:** 23

---

### `def _get_musl_version(executable: str) -> _MuslVersion | None`

**Decorators:**
- `@functools.lru_cache`

**Description:**
Detect currently-running musl runtime version.

This is done by checking the specified executable's dynamic linking
information, and invoking the loader to parse its output for a version
string. If the loader is musl, the output would be something like::

musl libc (x86_64)
Version 1.2.2
Dynamic Program Loader

**Line:** 34

---

### `def platform_tags(archs: Sequence[str]) -> Iterator[str]`

**Description:**
Generate musllinux tags compatible to the current platform.

:param archs: Sequence of compatible architectures.
The first one shall be the closest to the actual architecture and be the part of
platform tag after the ``linux_`` prefix, e.g. ``x86_64``.
The ``linux_`` prefix is assumed as a prerequisite for the current platform to
be musllinux-compatible.

:returns: An iterator of compatible musllinux tags.

**Line:** 56

---


## Module: venv2.libthon3.12.site-packages.packaging._parser
**File:** `venv2/lib/python3.12/site-packages/packaging/_parser.py`

**Imports:**
- __future__.annotations
- _tokenizer.DEFAULT_RULES
- _tokenizer.Tokenizer
- ast
- typing.NamedTuple
- typing.Sequence
- typing.Tuple
- typing.Union

**Functions:**

### `def parse_requirement(source: str) -> ParsedRequirement`

**Line:** 61

---

### `def _parse_requirement(tokenizer: Tokenizer) -> ParsedRequirement`

**Description:**
requirement = WS? IDENTIFIER WS? extras WS? requirement_details

**Line:** 65

---

### `def _parse_requirement_details(tokenizer: Tokenizer) -> tuple[(str, str, MarkerList | None)]`

**Description:**
requirement_details = AT URL (WS requirement_marker?)?
| specifier WS? (requirement_marker)?

**Line:** 86

---

### `def _parse_requirement_marker(tokenizer: Tokenizer, span_start: int, after: str) -> MarkerList`

**Description:**
requirement_marker = SEMICOLON marker WS?

**Line:** 137

---

### `def _parse_extras(tokenizer: Tokenizer) -> list[str]`

**Description:**
extras = (LEFT_BRACKET wsp* extras_list? wsp* RIGHT_BRACKET)?

**Line:** 157

---

### `def _parse_extras_list(tokenizer: Tokenizer) -> list[str]`

**Description:**
extras_list = identifier (wsp* ',' wsp* identifier)*

**Line:** 176

---

### `def _parse_specifier(tokenizer: Tokenizer) -> str`

**Description:**
specifier = LEFT_PARENTHESIS WS? version_many WS? RIGHT_PARENTHESIS
| WS? version_many WS?

**Line:** 203

---

### `def _parse_version_many(tokenizer: Tokenizer) -> str`

**Description:**
version_many = (SPECIFIER (WS? COMMA WS? SPECIFIER)*)?

**Line:** 220

---

### `def parse_marker(source: str) -> MarkerList`

**Line:** 252

---

### `def _parse_full_marker(tokenizer: Tokenizer) -> MarkerList`

**Line:** 256

---

### `def _parse_marker(tokenizer: Tokenizer) -> MarkerList`

**Description:**
marker = marker_atom (BOOLOP marker_atom)+

**Line:** 262

---

### `def _parse_marker_atom(tokenizer: Tokenizer) -> MarkerAtom`

**Description:**
marker_atom = WS? LEFT_PARENTHESIS WS? marker WS? RIGHT_PARENTHESIS WS?
| WS? marker_item WS?

**Line:** 274

---

### `def _parse_marker_item(tokenizer: Tokenizer) -> MarkerItem`

**Description:**
marker_item = WS? marker_var WS? marker_op WS? marker_var WS?

**Line:** 296

---

### `def _parse_marker_var(tokenizer: Tokenizer) -> MarkerVar`

**Description:**
marker_var = VARIABLE | QUOTED_STRING

**Line:** 310

---

### `def process_env_var(env_var: str) -> Variable`

**Line:** 324

---

### `def process_python_str(python_str: str) -> Value`

**Line:** 331

---

### `def _parse_marker_op(tokenizer: Tokenizer) -> Op`

**Description:**
marker_op = IN | NOT IN | OP

**Line:** 336

---


## Module: venv2.libthon3.12.site-packages.packaging.licenses.__init__
**File:** `venv2/lib/python3.12/site-packages/packaging/licenses/__init__.py`

**Imports:**
- __future__.annotations
- packaging.licenses._spdx.EXCEPTIONS
- packaging.licenses._spdx.LICENSES
- re
- typing.NewType
- typing.cast

**Functions:**

### `def canonicalize_license_expression(raw_license_expression: str) -> NormalizedLicenseExpression`

**Line:** 60

---


## Module: venv2.libthon3.12.site-packages.packaging.markers
**File:** `venv2/lib/python3.12/site-packages/packaging/markers.py`

**Imports:**
- __future__.annotations
- _parser.MarkerAtom
- _parser.MarkerList
- _parser.Op
- _parser.Value
- _parser.Variable
- _parser.parse_marker
- _tokenizer.ParserSyntaxError
- operator
- os
- platform
- specifiers.InvalidSpecifier
- specifiers.Specifier
- sys
- typing.AbstractSet
- typing.Any
- typing.Callable
- typing.Literal
- typing.TypedDict
- typing.Union
- typing.cast
- utils.canonicalize_name

**Functions:**

### `def _normalize_extra_values(results: Any) -> Any`

**Description:**
Normalize extra values.

**Line:** 124

---

### `def _format_marker(marker: list[str] | MarkerAtom | str, first: bool | None = True) -> str`

**Line:** 140

---

### `def _eval_op(lhs: str, op: Op, rhs: str | AbstractSet[str]) -> bool`

**Line:** 180

---

### `def _normalize(lhs: str, rhs: str | AbstractSet[str], key: str) -> tuple[(str, str | AbstractSet[str])]`

**Line:** 196

---

### `def _evaluate_markers(markers: MarkerList, environment: dict[(str, str | AbstractSet[str])]) -> bool`

**Line:** 216

---

### `def format_full_version(info: sys._version_info) -> str`

**Line:** 248

---

### `def default_environment() -> Environment`

**Line:** 256

---

### `def _repair_python_full_version(env: dict[(str, str | AbstractSet[str])]) -> dict[(str, str | AbstractSet[str])]`

**Description:**
Work around platform.python_version() returning something that is not PEP 440
compliant for non-tagged Python builds.

**Line:** 352

---


## Module: venv2.libthon3.12.site-packages.packaging.metadata
**File:** `venv2/lib/python3.12/site-packages/packaging/metadata.py`

**Imports:**
- __future__.annotations
- email.feedparser
- email.header
- email.message
- email.parser
- email.policy
- licenses.NormalizedLicenseExpression
- pathlib
- sys
- typing
- typing.Any
- typing.Callable
- typing.Generic
- typing.Literal
- typing.TypedDict
- typing.cast

**Functions:**

### `def _parse_keywords(data: str) -> list[str]`

**Description:**
Split a string of comma-separated keywords into a list of keywords.

**Line:** 175

---

### `def _parse_project_urls(data: list[str]) -> dict[(str, str)]`

**Description:**
Parse a list of label/URL string pairings separated by a comma.

**Line:** 180

---

### `def _get_payload(msg: email.message.Message, source: bytes | str) -> str`

**Description:**
Get the body of the message.

**Line:** 220

---

### `def parse_email(data: bytes | str) -> tuple[(RawMetadata, dict[str, list[str]])]`

**Description:**
Parse a distribution's metadata stored as email headers (e.g. from ``METADATA``).

This function returns a two-item tuple of dicts. The first dict is of
recognized fields from the core metadata specification. Fields that can be
parsed and translated into Python's built-in types are converted
appropriately. All other fields are left as-is. Fields that are allowed to
appear multiple times are stored as lists.

The second dict contains all other fields from the metadata. This includes
any unrecognized fields. It also includes any fields which are expected to
be parsed into a built-in type but were not formatted appropriately. Finally,
any fields that are expected to appear only once but are repeated are
included in this dict.

**Line:** 286

---


## Module: venv2.libthon3.12.site-packages.packaging.specifiers
**File:** `venv2/lib/python3.12/site-packages/packaging/specifiers.py`

**Imports:**
- __future__.annotations
- abc
- itertools
- re
- typing.Callable
- typing.Iterable
- typing.Iterator
- typing.TypeVar
- typing.Union
- utils.canonicalize_version
- version.Version

**Functions:**

### `def _coerce_version(version: UnparsedVersion) -> Version`

**Line:** 26

---

### `def _version_split(version: str) -> list[str]`

**Description:**
Split version into components.

The split components are intended for version comparison. The logic does
not attempt to retain the original version string, so joining the
components back with :func:`_version_join` may not produce the original
version string.

**Line:** 630

---

### `def _version_join(components: list[str]) -> str`

**Description:**
Join split version components into a version string.

This function assumes the input came from :func:`_version_split`, where the
first component must be the epoch (either empty or numeric), and all other
components numeric.

**Line:** 652

---

### `def _is_not_suffix(segment: str) -> bool`

**Line:** 663

---

### `def _pad_version(left: list[str], right: list[str]) -> tuple[(list[str], list[str])]`

**Line:** 669

---


## Module: venv2.libthon3.12.site-packages.packaging.tags
**File:** `venv2/lib/python3.12/site-packages/packaging/tags.py`

**Imports:**
- __future__.annotations
- importlib.machinery.EXTENSION_SUFFIXES
- logging
- platform
- re
- struct
- subprocess
- sys
- sysconfig
- typing.Iterable
- typing.Iterator
- typing.Sequence
- typing.Tuple
- typing.cast

**Functions:**

### `def parse_tag(tag: str) -> frozenset[Tag]`

**Description:**
Parses the provided tag (e.g. `py3-none-any`) into a frozenset of Tag instances.

Returning a set is required due to the possibility that the tag is a
compressed tag set.

**Line:** 96

---

### `def _get_config_var(name: str, warn: bool = False) -> int | str | None`

**Line:** 112

---

### `def _normalize_string(string: str) -> str`

**Line:** 121

---

### `def _is_threaded_cpython(abis: list[str]) -> bool`

**Description:**
Determine if the ABI corresponds to a threaded (`--disable-gil`) build.

The threaded builds are indicated by a "t" in the abiflags.

**Line:** 125

---

### `def _abi3_applies(python_version: PythonVersion, threading: bool) -> bool`

**Description:**
Determine if the Python version supports abi3.

PEP 384 was first implemented in Python 3.2. The threaded (`--disable-gil`)
builds do not support abi3.

**Line:** 141

---

### `def _cpython_abis(py_version: PythonVersion, warn: bool = False) -> list[str]`

**Line:** 151

---

### `def cpython_tags(python_version: PythonVersion | None = None, abis: Iterable[str] | None = None, platforms: Iterable[str] | None = None, warn: bool = False) -> Iterator[Tag]`

**Description:**
Yields the tags for a CPython interpreter.

The tags consist of:
- cp<python_version>-<abi>-<platform>
- cp<python_version>-abi3-<platform>
- cp<python_version>-none-<platform>
- cp<less than python_version>-abi3-<platform>  # Older Python versions down to 3.2.

If python_version only specifies a major version then user-provided ABIs and
the 'none' ABItag will be used.

If 'abi3' or 'none' are specified in 'abis' then they will be yielded at
their normal position and not at the beginning.

**Line:** 184

---

### `def _generic_abi() -> list[str]`

**Description:**
Return the ABI tag based on EXT_SUFFIX.

**Line:** 243

---

### `def generic_tags(interpreter: str | None = None, abis: Iterable[str] | None = None, platforms: Iterable[str] | None = None, warn: bool = False) -> Iterator[Tag]`

**Description:**
Yields the tags for a generic interpreter.

The tags consist of:
- <interpreter>-<abi>-<platform>

The "none" ABI will be added if it was not explicitly provided.

**Line:** 284

---

### `def _py_interpreter_range(py_version: PythonVersion) -> Iterator[str]`

**Description:**
Yields Python versions in descending order.

After the latest version, the major-only version will be yielded, and then
all previous versions of that major version.

**Line:** 315

---

### `def compatible_tags(python_version: PythonVersion | None = None, interpreter: str | None = None, platforms: Iterable[str] | None = None) -> Iterator[Tag]`

**Description:**
Yields the sequence of tags that are compatible with a specific version of Python.

The tags consist of:
- py*-none-<platform>
- <interpreter>-none-any  # ... if `interpreter` is provided.
- py*-none-any

**Line:** 330

---

### `def _mac_arch(arch: str, is_32bit: bool = _32_BIT_INTERPRETER) -> str`

**Line:** 355

---

### `def _mac_binary_formats(version: AppleVersion, cpu_arch: str) -> list[str]`

**Line:** 365

---

### `def mac_platforms(version: AppleVersion | None = None, arch: str | None = None) -> Iterator[str]`

**Description:**
Yields the platform tags for a macOS system.

The `version` parameter is a two-item tuple specifying the macOS version to
generate platform tags for. The `arch` parameter is the CPU architecture to
generate platform tags for. Both parameters default to the appropriate value
for the current system.

**Line:** 397

---

### `def ios_platforms(version: AppleVersion | None = None, multiarch: str | None = None) -> Iterator[str]`

**Description:**
Yields the platform tags for an iOS system.

:param version: A two-item tuple specifying the iOS version to generate
platform tags for. Defaults to the current iOS version.
:param multiarch: The CPU architecture+ABI to generate platform tags for -
(the value used by `sys.implementation._multiarch` e.g.,
`arm64_iphoneos` or `x84_64_iphonesimulator`). Defaults to the current
multiarch value.

**Line:** 476

---

### `def android_platforms(api_level: int | None = None, abi: str | None = None) -> Iterator[str]`

**Description:**
Yields the :attr:`~Tag.platform` tags for Android. If this function is invoked on
non-Android platforms, the ``api_level`` and ``abi`` arguments are required.

:param int api_level: The maximum `API level
<https://developer.android.com/tools/releases/platforms>`__ to return. Defaults
to the current system's version, as returned by ``platform.android_ver``.
:param str abi: The `Android ABI <https://developer.android.com/ndk/guides/abis>`__,
e.g. ``arm64_v8a``. Defaults to the current system's ABI , as returned by
``sysconfig.get_platform``. Hyphens and periods will be replaced with
underscores.

**Line:** 533

---

### `def _linux_platforms(is_32bit: bool = _32_BIT_INTERPRETER) -> Iterator[str]`

**Line:** 570

---

### `def _generic_platforms() -> Iterator[str]`

**Line:** 589

---

### `def platform_tags() -> Iterator[str]`

**Description:**
Provides the platform tags for this installation.

**Line:** 593

---

### `def interpreter_name() -> str`

**Description:**
Returns the name of the running interpreter.

Some implementations have a reserved, two-letter abbreviation which will
be returned when appropriate.

**Line:** 609

---

### `def interpreter_version(warn: bool = False) -> str`

**Description:**
Returns the version of the running interpreter.

**Line:** 620

---

### `def _version_nodot(version: PythonVersion) -> str`

**Line:** 632

---

### `def sys_tags(warn: bool = False) -> Iterator[Tag]`

**Description:**
Returns the sequence of tag triples for the running interpreter.

The order of the sequence corresponds to priority order for the
interpreter, from most to least important.

**Line:** 636

---


## Module: venv2.libthon3.12.site-packages.packaging.utils
**File:** `venv2/lib/python3.12/site-packages/packaging/utils.py`

**Imports:**
- __future__.annotations
- functools
- re
- tags.Tag
- tags.parse_tag
- typing.NewType
- typing.Tuple
- typing.Union
- typing.cast
- version.InvalidVersion
- version.Version
- version._TrimmedRelease

**Functions:**

### `def canonicalize_name(name: str, validate: bool = False) -> NormalizedName`

**Line:** 46

---

### `def is_normalized_name(name: str) -> bool`

**Line:** 54

---

### `def canonicalize_version(version: Version | str, strip_trailing_zero: bool = True) -> str`

**Decorators:**
- `@functools.singledispatch`

**Description:**
Return a canonical form of a version as a string.

>>> canonicalize_version('1.0.1')
'1.0.1'

Per PEP 625, versions may have multiple canonical forms, differing
only by trailing zeros.

>>> canonicalize_version('1.0.0')
'1'
>>> canonicalize_version('1.0.0', strip_trailing_zero=False)
'1.0.0'

Invalid versions are returned unaltered.

>>> canonicalize_version('foo bar baz')
'foo bar baz'

**Line:** 59

---

### `def _(version: str, strip_trailing_zero: bool = True) -> str`

**Decorators:**
- `@canonicalize_version.register`

**Line:** 85

---

### `def parse_wheel_filename(filename: str) -> tuple[(NormalizedName, Version, BuildTag, frozenset[Tag])]`

**Line:** 94

---

### `def parse_sdist_filename(filename: str) -> tuple[(NormalizedName, Version)]`

**Line:** 137

---


## Module: venv2.libthon3.12.site-packages.packaging.version
**File:** `venv2/lib/python3.12/site-packages/packaging/version.py`

**Imports:**
- __future__.annotations
- _structures.Infinity
- _structures.InfinityType
- _structures.NegativeInfinity
- _structures.NegativeInfinityType
- itertools
- re
- typing.Any
- typing.Callable
- typing.NamedTuple
- typing.SupportsInt
- typing.Tuple
- typing.Union

**Functions:**

### `def parse(version: str) -> Version`

**Description:**
Parse the given version string.

>>> parse('1.0.dev1')
<Version('1.0.dev1')>

:param version: The version string to parse.
:raises InvalidVersion: When the version string is not a valid version.

**Line:** 47

---

### `def _parse_letter_version(letter: str | None, number: str | bytes | SupportsInt | None) -> tuple[str, int] | None`

**Line:** 471

---

### `def _parse_local_version(local: str | None) -> LocalType | None`

**Description:**
Takes a string like abc.1.twelve and turns it into ("abc", 1, "twelve").

**Line:** 511

---

### `def _cmpkey(epoch: int, release: tuple[(int, ...)], pre: tuple[str, int] | None, post: tuple[str, int] | None, dev: tuple[str, int] | None, local: LocalType | None) -> CmpKey`

**Line:** 523

---


## Module: venv2.libthon3.12.site-packages.pathspec.util
**File:** `venv2/lib/python3.12/site-packages/pathspec/util.py`

**Imports:**
- collections.abc.Collection
- collections.abc.Iterable
- dataclasses.dataclass
- os
- os.PathLike
- os.path
- pathlib
- pattern.Pattern
- posixpath
- stat
- sys
- typing.Any
- typing.AnyStr
- typing.Callable
- typing.Collection
- typing.Dict
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Optional
- typing.Sequence
- typing.Set
- typing.Tuple
- typing.TypeVar
- typing.Union
- warnings

**Functions:**

### `def append_dir_sep(path: pathlib.Path) -> str`

**Description:**
Appends the path separator to the path if the path is a directory.
This can be used to aid in distinguishing between directories and
files on the file-system by relying on the presence of a trailing path
separator.

*path* (:class:`pathlib.Path`) is the path to use.

Returns the path (:class:`str`).

**Line:** 68

---

### `def check_match_file(patterns: Iterable[Tuple[(int, Pattern)]], file: str) -> Tuple[(Optional[bool], Optional[int])]`

**Description:**
Check the file against the patterns.

*patterns* (:class:`~collections.abc.Iterable`) yields each indexed pattern
(:class:`tuple`) which contains the pattern index (:class:`int`) and actual
pattern (:class:`~pathspec.pattern.Pattern`).

*file* (:class:`str`) is the normalized file path to be matched
against *patterns*.

Returns a :class:`tuple` containing whether to include *file* (:class:`bool`
or :data:`None`), and the index of the last matched pattern (:class:`int` or
:data:`None`).

**Line:** 86

---

### `def detailed_match_files(patterns: Iterable[Pattern], files: Iterable[str], all_matches: Optional[bool] = None) -> Dict[(str, 'MatchDetail')]`

**Description:**
Matches the files to the patterns, and returns which patterns matched
the files.

*patterns* (:class:`~collections.abc.Iterable` of :class:`~pathspec.pattern.Pattern`)
contains the patterns to use.

*files* (:class:`~collections.abc.Iterable` of :class:`str`) contains
the normalized file paths to be matched against *patterns*.

*all_matches* (:class:`bool` or :data:`None`) is whether to return all
matches patterns (:data:`True`), or only the last matched pattern
(:data:`False`). Default is :data:`None` for :data:`False`.

Returns the matched files (:class:`dict`) which maps each matched file
(:class:`str`) to the patterns that matched in order (:class:`.MatchDetail`).

**Line:** 114

---

### `def _filter_check_patterns(patterns: Iterable[Pattern]) -> List[Tuple[(int, Pattern)]]`

**Description:**
Filters out null-patterns.

*patterns* (:class:`Iterable` of :class:`.Pattern`) contains the
patterns.

Returns a :class:`list` containing each indexed pattern (:class:`tuple`) which
contains the pattern index (:class:`int`) and the actual pattern
(:class:`~pathspec.pattern.Pattern`).

**Line:** 160

---

### `def _is_iterable(value: Any) -> bool`

**Description:**
Check whether the value is an iterable (excludes strings).

*value* is the value to check,

Returns whether *value* is a iterable (:class:`bool`).

**Line:** 180

---

### `def iter_tree_entries(root: StrPath, on_error: Optional[Callable[([OSError], None)]] = None, follow_links: Optional[bool] = None) -> Iterator['TreeEntry']`

**Description:**
Walks the specified directory for all files and directories.

*root* (:class:`str` or :class:`os.PathLike`) is the root directory to
search.

*on_error* (:class:`~collections.abc.Callable` or :data:`None`)
optionally is the error handler for file-system exceptions. It will be
called with the exception (:exc:`OSError`). Reraise the exception to
abort the walk. Default is :data:`None` to ignore file-system
exceptions.

*follow_links* (:class:`bool` or :data:`None`) optionally is whether
to walk symbolic links that resolve to directories. Default is
:data:`None` for :data:`True`.

Raises :exc:`RecursionError` if recursion is detected.

Returns an :class:`~collections.abc.Iterator` yielding each file or
directory entry (:class:`.TreeEntry`) relative to *root*.

**Line:** 191

---

### `def _iter_tree_entries_next(root_full: str, dir_rel: str, memo: Dict[(str, str)], on_error: Callable[([OSError], None)], follow_links: bool) -> Iterator['TreeEntry']`

**Description:**
Scan the directory for all descendant files.

*root_full* (:class:`str`) the absolute path to the root directory.

*dir_rel* (:class:`str`) the path to the directory to scan relative to
*root_full*.

*memo* (:class:`dict`) keeps track of ancestor directories
encountered. Maps each ancestor real path (:class:`str`) to relative
path (:class:`str`).

*on_error* (:class:`~collections.abc.Callable` or :data:`None`)
optionally is the error handler for file-system exceptions.

*follow_links* (:class:`bool`) is whether to walk symbolic links that
resolve to directories.

Yields each entry (:class:`.TreeEntry`).

**Line:** 226

---

### `def iter_tree_files(root: StrPath, on_error: Optional[Callable[([OSError], None)]] = None, follow_links: Optional[bool] = None) -> Iterator[str]`

**Description:**
Walks the specified directory for all files.

*root* (:class:`str` or :class:`os.PathLike`) is the root directory to
search for files.

*on_error* (:class:`~collections.abc.Callable` or :data:`None`)
optionally is the error handler for file-system exceptions. It will be
called with the exception (:exc:`OSError`). Reraise the exception to
abort the walk. Default is :data:`None` to ignore file-system
exceptions.

*follow_links* (:class:`bool` or :data:`None`) optionally is whether
to walk symbolic links that resolve to directories. Default is
:data:`None` for :data:`True`.

Raises :exc:`RecursionError` if recursion is detected.

Returns an :class:`~collections.abc.Iterator` yielding the path to
each file (:class:`str`) relative to *root*.

**Line:** 307

---

### `def iter_tree(root, on_error = None, follow_links = None)`

**Description:**
DEPRECATED: The :func:`.iter_tree` function is an alias for the
:func:`.iter_tree_files` function.

**Line:** 338

---

### `def lookup_pattern(name: str) -> Callable[([AnyStr], Pattern)]`

**Description:**
Lookups a registered pattern factory by name.

*name* (:class:`str`) is the name of the pattern factory.

Returns the registered pattern factory (:class:`~collections.abc.Callable`).
If no pattern factory is registered, raises :exc:`KeyError`.

**Line:** 349

---

### `def match_file(patterns: Iterable[Pattern], file: str) -> bool`

**Description:**
Matches the file to the patterns.

*patterns* (:class:`~collections.abc.Iterable` of :class:`~pathspec.pattern.Pattern`)
contains the patterns to use.

*file* (:class:`str`) is the normalized file path to be matched
against *patterns*.

Returns :data:`True` if *file* matched; otherwise, :data:`False`.

**Line:** 361

---

### `def match_files(patterns: Iterable[Pattern], files: Iterable[str]) -> Set[str]`

**Description:**
DEPRECATED: This is an old function no longer used. Use the
:func:`~pathspec.util.match_file` function with a loop for better results.

Matches the files to the patterns.

*patterns* (:class:`~collections.abc.Iterable` of :class:`~pathspec.pattern.Pattern`)
contains the patterns to use.

*files* (:class:`~collections.abc.Iterable` of :class:`str`) contains
the normalized file paths to be matched against *patterns*.

Returns the matched files (:class:`set` of :class:`str`).

**Line:** 381

---

### `def normalize_file(file: StrPath, separators: Optional[Collection[str]] = None) -> str`

**Description:**
Normalizes the file path to use the POSIX path separator (i.e.,
``"/"``), and make the paths relative (remove leading ``"/"``).

*file* (:class:`str` or :class:`os.PathLike`) is the file path.

*separators* (:class:`~collections.abc.Collection` of :class:`str`; or
``None``) optionally contains the path separators to normalize.
This does not need to include the POSIX path separator (``"/"``),
but including it will not affect the results. Default is ``None``
for ``NORMALIZE_PATH_SEPS``. To prevent normalization, pass an
empty container (e.g., an empty tuple ``()``).

Returns the normalized file path (:class:`str`).

**Line:** 414

---

### `def normalize_files(files: Iterable[StrPath], separators: Optional[Collection[str]] = None) -> Dict[(str, List[StrPath])]`

**Description:**
DEPRECATED: This function is no longer used. Use the :func:`.normalize_file`
function with a loop for better results.

Normalizes the file paths to use the POSIX path separator.

*files* (:class:`~collections.abc.Iterable` of :class:`str` or
:class:`os.PathLike`) contains the file paths to be normalized.

*separators* (:class:`~collections.abc.Collection` of :class:`str`; or
:data:`None`) optionally contains the path separators to normalize.
See :func:`normalize_file` for more information.

Returns a :class:`dict` mapping each normalized file path (:class:`str`)
to the original file paths (:class:`list` of :class:`str` or
:class:`os.PathLike`).

**Line:** 454

---

### `def register_pattern(name: str, pattern_factory: Callable[([AnyStr], Pattern)], override: Optional[bool] = None) -> None`

**Description:**
Registers the specified pattern factory.

*name* (:class:`str`) is the name to register the pattern factory
under.

*pattern_factory* (:class:`~collections.abc.Callable`) is used to
compile patterns. It must accept an uncompiled pattern (:class:`str`)
and return the compiled pattern (:class:`.Pattern`).

*override* (:class:`bool` or :data:`None`) optionally is whether to
allow overriding an already registered pattern under the same name
(:data:`True`), instead of raising an :exc:`AlreadyRegisteredError`
(:data:`False`). Default is :data:`None` for :data:`False`.

**Line:** 491

---


## Module: venv2.libthon3.12.site-packages.pip.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/__init__.py`

**Imports:**
- pip._internal.utils.entrypoints._wrapper
- typing.List
- typing.Optional

**Functions:**

### `def main(args: Optional[List[str]] = None) -> int`

**Description:**
This is an internal API only meant for use by pip's own console scripts.

For additional details, see https://github.com/pypa/pip/issues/7498.

**Line:** 6

---


## Module: venv2.libthon3.12.site-packages.pip.__pip-runner__
**File:** `venv2/lib/python3.12/site-packages/pip/__pip-runner__.py`

**Imports:**
- importlib.machinery.PathFinder
- os.path.dirname
- runpy
- sys

**Functions:**

### `def version_str(version)`

**Line:** 15

---


## Module: venv2.libthon3.12.site-packages.pip._internal.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/__init__.py`

**Imports:**
- pip._internal.utils._log
- pip._internal.utils.entrypoints._wrapper
- typing.List
- typing.Optional

**Functions:**

### `def main(args: Optional[List[str]] = None) -> int`

**Description:**
This is preserved for old console scripts that may still be referencing
it.

For additional details, see https://github.com/pypa/pip/issues/7498.

**Line:** 10

---


## Module: venv2.libthon3.12.site-packages.pip._internal.build_env
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/build_env.py`

**Imports:**
- collections.OrderedDict
- logging
- os
- pathlib
- pip.__file__
- pip._internal.cli.spinners.open_spinner
- pip._internal.index.package_finder.PackageFinder
- pip._internal.locations.get_platlib
- pip._internal.locations.get_purelib
- pip._internal.locations.get_scheme
- pip._internal.metadata.get_default_environment
- pip._internal.metadata.get_environment
- pip._internal.utils.logging.VERBOSE
- pip._internal.utils.packaging.get_requirement
- pip._internal.utils.subprocess.call_subprocess
- pip._internal.utils.temp_dir.TempDirectory
- pip._internal.utils.temp_dir.tempdir_kinds
- pip._vendor.packaging.version.Version
- site
- sys
- textwrap
- types.TracebackType
- typing.Iterable
- typing.List
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.Union

**Functions:**

### `def _dedup(a: str, b: str) -> Union[(Tuple[str], Tuple[str, str])]`

**Line:** 30

---

### `def get_runnable_pip() -> str`

**Description:**
Get a file to pass to a Python executable, to run the currently-running pip.

This is used to run a pip subprocess, for installing requirements into the build
environment.

**Line:** 43

---

### `def _get_system_sitepackages() -> Set[str]`

**Description:**
Get system site packages

Usually from site.getsitepackages,
but fallback on `get_purelib()/get_platlib()` if unavailable
(e.g. in a virtualenv created by virtualenv<20)

Returns normalized set of strings.

**Line:** 59

---


## Module: venv2.libthon3.12.site-packages.pip._internal.cache
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/cache.py`

**Imports:**
- hashlib
- json
- logging
- os
- pathlib.Path
- pip._internal.exceptions.InvalidWheelFilename
- pip._internal.models.direct_url.DirectUrl
- pip._internal.models.link.Link
- pip._internal.models.wheel.Wheel
- pip._internal.utils.temp_dir.TempDirectory
- pip._internal.utils.temp_dir.tempdir_kinds
- pip._internal.utils.urls.path_to_url
- pip._vendor.packaging.tags.Tag
- pip._vendor.packaging.tags.interpreter_name
- pip._vendor.packaging.tags.interpreter_version
- pip._vendor.packaging.utils.canonicalize_name
- typing.Any
- typing.Dict
- typing.List
- typing.Optional

**Functions:**

### `def _hash_dict(d: Dict[(str, str)]) -> str`

**Description:**
Return a stable sha224 of a dictionary.

**Line:** 25

---


## Module: venv2.libthon3.12.site-packages.pip._internal.cli.autocompletion
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/cli/autocompletion.py`

**Imports:**
- itertools.chain
- optparse
- os
- pip._internal.cli.main_parser.create_main_parser
- pip._internal.commands.commands_dict
- pip._internal.commands.create_command
- pip._internal.metadata.get_default_environment
- sys
- typing.Any
- typing.Iterable
- typing.List
- typing.Optional

**Functions:**

### `def autocomplete() -> None`

**Description:**
Entry Point for completion of main and subcommand options.

**Line:** 14

---

### `def get_path_completion_type(cwords: List[str], cword: int, opts: Iterable[Any]) -> Optional[str]`

**Description:**
Get the type of path completion (``file``, ``dir``, ``path`` or None)

:param cwords: same as the environmental variable ``COMP_WORDS``
:param cword: same as the environmental variable ``COMP_CWORD``
:param opts: The available options to check
:return: path completion type (``file``, ``dir``, ``path`` or None)

**Line:** 123

---

### `def auto_complete_paths(current: str, completion_type: str) -> Iterable[str]`

**Description:**
If ``completion_type`` is ``file`` or ``path``, list all regular files
and directories starting with ``current``; otherwise only list directories
starting with ``current``.

:param current: The word to be completed
:param completion_type: path completion type(``file``, ``path`` or ``dir``)
:return: A generator of regular files and/or directories

**Line:** 147

---


## Module: venv2.libthon3.12.site-packages.pip._internal.cli.cmdoptions
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/cli/cmdoptions.py`

**Imports:**
- functools.partial
- importlib.util
- logging
- optparse.Option
- optparse.OptionGroup
- optparse.OptionParser
- optparse.SUPPRESS_HELP
- optparse.Values
- os
- pathlib
- pip._internal.cli.parser.ConfigOptionParser
- pip._internal.exceptions.CommandError
- pip._internal.locations.USER_CACHE_DIR
- pip._internal.locations.get_src_prefix
- pip._internal.models.format_control.FormatControl
- pip._internal.models.index.PyPI
- pip._internal.models.target_python.TargetPython
- pip._internal.utils.hashes.STRONG_HASHES
- pip._internal.utils.misc.strtobool
- pip._vendor.packaging.utils.canonicalize_name
- textwrap
- textwrap.dedent
- typing.Any
- typing.Callable
- typing.Dict
- typing.Optional
- typing.Tuple

**Functions:**

### `def raise_option_error(parser: OptionParser, option: Option, msg: str) -> None`

**Description:**
Raise an option parsing error using parser.error().

Args:
parser: an OptionParser instance.
option: an Option instance.
msg: the error text.

**Line:** 37

---

### `def make_option_group(group: Dict[(str, Any)], parser: ConfigOptionParser) -> OptionGroup`

**Description:**
Return an OptionGroup object
group  -- assumed to be dict with 'name' and 'options' keys
parser -- an optparse Parser

**Line:** 51

---

### `def check_dist_restriction(options: Values, check_target: bool = False) -> None`

**Description:**
Function for determining if custom platform options are allowed.

:param options: The OptionParser options.
:param check_target: Whether or not to check if --target is being used.

**Line:** 63

---

### `def _path_option_check(option: Option, opt: str, value: str) -> str`

**Line:** 103

---

### `def _package_name_option_check(option: Option, opt: str, value: str) -> str`

**Line:** 107

---

### `def exists_action() -> Option`

**Line:** 309

---

### `def extra_index_url() -> Option`

**Line:** 364

---

### `def find_links() -> Option`

**Line:** 387

---

### `def trusted_host() -> Option`

**Line:** 403

---

### `def constraints() -> Option`

**Line:** 415

---

### `def requirements() -> Option`

**Line:** 428

---

### `def editable() -> Option`

**Line:** 441

---

### `def _handle_src(option: Option, opt_str: str, value: str, parser: OptionParser) -> None`

**Line:** 456

---

### `def _get_format_control(values: Values, option: Option) -> Any`

**Description:**
Get a format_control object.

**Line:** 479

---

### `def _handle_no_binary(option: Option, opt_str: str, value: str, parser: OptionParser) -> None`

**Line:** 484

---

### `def _handle_only_binary(option: Option, opt_str: str, value: str, parser: OptionParser) -> None`

**Line:** 495

---

### `def no_binary() -> Option`

**Line:** 506

---

### `def only_binary() -> Option`

**Line:** 524

---

### `def _convert_python_version(value: str) -> Tuple[(Tuple[int, ...], Optional[str])]`

**Description:**
Convert a version string like "3", "37", or "3.7.3" into a tuple of ints.

:return: A 2-tuple (version_info, error_msg), where `error_msg` is
non-None if and only if there was a parsing error.

**Line:** 558

---

### `def _handle_python_version(option: Option, opt_str: str, value: str, parser: OptionParser) -> None`

**Description:**
Handle a provided --python-version value.

**Line:** 587

---

### `def add_target_python_options(cmd_opts: OptionGroup) -> None`

**Line:** 656

---

### `def make_target_python(options: Values) -> TargetPython`

**Line:** 663

---

### `def prefer_binary() -> Option`

**Line:** 674

---

### `def _handle_no_cache_dir(option: Option, opt: str, value: str, parser: OptionParser) -> None`

**Description:**
Process a value provided for the --no-cache-dir option.

This is an optparse.Option callback for the --no-cache-dir option.

**Line:** 698

---

### `def _handle_dependency_group(option: Option, opt: str, value: str, parser: OptionParser) -> None`

**Description:**
Process a value provided for the --group option.

Splits on the rightmost ":", and validates that the path (if present) ends
in `pyproject.toml`. Defaults the path to `pyproject.toml` when one is not given.

`:` cannot appear in dependency group names, so this is a safe and simple parse.

This is an optparse.Option callback for the dependency_groups option.

**Line:** 747

---

### `def _handle_no_use_pep517(option: Option, opt: str, value: str, parser: OptionParser) -> None`

**Description:**
Process a value provided for the --no-use-pep517 option.

This is an optparse.Option callback for the no_use_pep517 option.

**Line:** 815

---

### `def _handle_config_settings(option: Option, opt_str: str, value: str, parser: OptionParser) -> None`

**Line:** 871

---

### `def _handle_merge_hash(option: Option, opt_str: str, value: str, parser: OptionParser) -> None`

**Description:**
Given a value spelled "algo:digest", append the digest to a list
pointed to in a dict by the algo name.

**Line:** 968

---

### `def check_list_path_option(options: Values) -> None`

**Line:** 1029

---


## Module: venv2.libthon3.12.site-packages.pip._internal.cli.index_command
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/cli/index_command.py`

**Imports:**
- functools.lru_cache
- logging
- optparse.Values
- os
- pip._internal.cli.base_command.Command
- pip._internal.cli.command_context.CommandContextMixIn
- pip._internal.network.session.PipSession
- pip._internal.self_outdated_check.pip_self_version_check
- pip._vendor.certifi
- pip._vendor.truststore
- ssl
- ssl.SSLContext
- sys
- typing.List
- typing.Optional
- typing.TYPE_CHECKING

**Functions:**

### `def _create_truststore_ssl_context() -> Optional['SSLContext']`

**Decorators:**
- `@lru_cache`

**Line:** 30

---

### `def _pip_self_version_check(session: 'PipSession', options: Values) -> None`

**Line:** 137

---


## Module: venv2.libthon3.12.site-packages.pip._internal.cli.main
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/cli/main.py`

**Imports:**
- locale
- logging
- os
- pip._internal.cli.autocompletion.autocomplete
- pip._internal.cli.main_parser.parse_command
- pip._internal.commands.create_command
- pip._internal.exceptions.PipError
- pip._internal.utils.deprecation
- sys
- typing.List
- typing.Optional
- warnings

**Functions:**

### `def main(args: Optional[List[str]] = None) -> int`

**Line:** 46

---


## Module: venv2.libthon3.12.site-packages.pip._internal.cli.main_parser
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/cli/main_parser.py`

**Imports:**
- os
- pip._internal.build_env.get_runnable_pip
- pip._internal.cli.cmdoptions
- pip._internal.cli.parser.ConfigOptionParser
- pip._internal.cli.parser.UpdatingDefaultsHelpFormatter
- pip._internal.commands.commands_dict
- pip._internal.commands.get_similar_commands
- pip._internal.exceptions.CommandError
- pip._internal.utils.misc.get_pip_version
- pip._internal.utils.misc.get_prog
- subprocess
- sys
- typing.List
- typing.Optional
- typing.Tuple

**Functions:**

### `def create_main_parser() -> ConfigOptionParser`

**Description:**
Creates and returns the main parser for pip's CLI

**Line:** 18

---

### `def identify_python_interpreter(python: str) -> Optional[str]`

**Line:** 49

---

### `def parse_command(args: List[str]) -> Tuple[(str, List[str])]`

**Line:** 68

---


## Module: venv2.libthon3.12.site-packages.pip._internal.cli.progress_bars
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/cli/progress_bars.py`

**Imports:**
- functools
- pip._internal.cli.spinners.RateLimiter
- pip._internal.req.req_install.InstallRequirement
- pip._internal.utils.logging.get_console
- pip._internal.utils.logging.get_indentation
- pip._vendor.rich.progress.BarColumn
- pip._vendor.rich.progress.DownloadColumn
- pip._vendor.rich.progress.FileSizeColumn
- pip._vendor.rich.progress.MofNCompleteColumn
- pip._vendor.rich.progress.Progress
- pip._vendor.rich.progress.ProgressColumn
- pip._vendor.rich.progress.SpinnerColumn
- pip._vendor.rich.progress.TextColumn
- pip._vendor.rich.progress.TimeElapsedColumn
- pip._vendor.rich.progress.TimeRemainingColumn
- pip._vendor.rich.progress.TransferSpeedColumn
- sys
- typing.Callable
- typing.Generator
- typing.Iterable
- typing.Iterator
- typing.Optional
- typing.Tuple
- typing.TypeVar

**Functions:**

### `def _rich_download_progress_bar(iterable: Iterable[bytes], bar_type: str, size: Optional[int], initial_progress: Optional[int] = None) -> Generator[(bytes, None, None)]`

**Line:** 27

---

### `def _rich_install_progress_bar(iterable: Iterable[InstallRequirement], total: int) -> Iterator[InstallRequirement]`

**Line:** 66

---

### `def _raw_progress_bar(iterable: Iterable[bytes], size: Optional[int], initial_progress: Optional[int] = None) -> Generator[(bytes, None, None)]`

**Line:** 88

---

### `def get_download_progress_renderer(bar_type: str, size: Optional[int] = None, initial_progress: Optional[int] = None) -> ProgressRenderer[bytes]`

**Description:**
Get an object that can be used to render the download progress.

Returns a callable, that takes an iterable to "wrap".

**Line:** 111

---

### `def get_install_progress_renderer(bar_type: str, total: int) -> ProgressRenderer[InstallRequirement]`

**Description:**
Get an object that can be used to render the install progress.
Returns a callable, that takes an iterable to "wrap".

**Line:** 135

---


## Module: venv2.libthon3.12.site-packages.pip._internal.cli.req_command
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/cli/req_command.py`

**Imports:**
- functools.partial
- logging
- optparse.Values
- pip._internal.cache.WheelCache
- pip._internal.cli.cmdoptions
- pip._internal.cli.index_command.IndexGroupCommand
- pip._internal.cli.index_command.SessionCommandMixin
- pip._internal.exceptions.CommandError
- pip._internal.exceptions.PreviousBuildDirError
- pip._internal.index.collector.LinkCollector
- pip._internal.index.package_finder.PackageFinder
- pip._internal.models.selection_prefs.SelectionPreferences
- pip._internal.models.target_python.TargetPython
- pip._internal.network.session.PipSession
- pip._internal.operations.build.build_tracker.BuildTracker
- pip._internal.operations.prepare.RequirementPreparer
- pip._internal.req.constructors.install_req_from_editable
- pip._internal.req.constructors.install_req_from_line
- pip._internal.req.constructors.install_req_from_parsed_requirement
- pip._internal.req.constructors.install_req_from_req_string
- pip._internal.req.req_dependency_group.parse_dependency_groups
- pip._internal.req.req_file.parse_requirements
- pip._internal.req.req_install.InstallRequirement
- pip._internal.resolution.base.BaseResolver
- pip._internal.resolution.legacy.resolver
- pip._internal.resolution.resolvelib.resolver
- pip._internal.utils.temp_dir.TempDirectory
- pip._internal.utils.temp_dir.TempDirectoryTypeRegistry
- pip._internal.utils.temp_dir.tempdir_kinds
- typing.Any
- typing.List
- typing.Optional
- typing.Tuple

**Functions:**

### `def with_cleanup(func: Any) -> Any`

**Description:**
Decorator for common logic related to managing temporary
directories.

**Line:** 51

---


## Module: venv2.libthon3.12.site-packages.pip._internal.cli.spinners
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/cli/spinners.py`

**Imports:**
- contextlib
- itertools
- logging
- pip._internal.utils.compat.WINDOWS
- pip._internal.utils.logging.get_indentation
- sys
- time
- typing.Generator
- typing.IO
- typing.Optional

**Functions:**

### `def open_spinner(message: str) -> Generator[(SpinnerInterface, None, None)]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 116

---

### `def hidden_cursor(file: IO[str]) -> Generator[(None, None, None)]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 144

---


## Module: venv2.libthon3.12.site-packages.pip._internal.commands.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/commands/__init__.py`

**Imports:**
- collections.namedtuple
- difflib.get_close_matches
- importlib
- pip._internal.cli.base_command.Command
- typing.Any
- typing.Dict
- typing.Optional

**Functions:**

### `def create_command(name: str, **kwargs: Any) -> Command`

**Description:**
Create an instance of the Command class with the given name.

**Line:** 114

---

### `def get_similar_commands(name: str) -> Optional[str]`

**Description:**
Command name auto-correct.

**Line:** 126

---


## Module: venv2.libthon3.12.site-packages.pip._internal.commands.debug
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/commands/debug.py`

**Imports:**
- locale
- logging
- optparse.Values
- os
- pip._internal.cli.base_command.Command
- pip._internal.cli.cmdoptions
- pip._internal.cli.cmdoptions.make_target_python
- pip._internal.cli.status_codes.SUCCESS
- pip._internal.configuration.Configuration
- pip._internal.metadata.get_environment
- pip._internal.utils.compat.open_text_resource
- pip._internal.utils.logging.indent_log
- pip._internal.utils.misc.get_pip_version
- pip._vendor
- pip._vendor.certifi.where
- pip._vendor.packaging.version.parse
- sys
- types.ModuleType
- typing.Any
- typing.Dict
- typing.List
- typing.Optional

**Functions:**

### `def show_value(name: str, value: Any) -> None`

**Line:** 26

---

### `def show_sys_implementation() -> None`

**Line:** 30

---

### `def create_vendor_txt_map() -> Dict[(str, str)]`

**Line:** 37

---

### `def get_module_from_module_name(module_name: str) -> Optional[ModuleType]`

**Line:** 49

---

### `def get_vendor_version_from_module(module_name: str) -> Optional[str]`

**Line:** 67

---

### `def show_actual_vendor_versions(vendor_txt_versions: Dict[(str, str)]) -> None`

**Description:**
Log the actual version and print extra info if there is
a conflict or if the actual version could not be imported.

**Line:** 82

---

### `def show_vendor_versions() -> None`

**Line:** 103

---

### `def show_tags(options: Values) -> None`

**Line:** 111

---

### `def ca_bundle_info(config: Configuration) -> str`

**Line:** 141

---


## Module: venv2.libthon3.12.site-packages.pip._internal.commands.freeze
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/commands/freeze.py`

**Imports:**
- optparse.Values
- pip._internal.cli.base_command.Command
- pip._internal.cli.cmdoptions
- pip._internal.cli.status_codes.SUCCESS
- pip._internal.operations.freeze.freeze
- pip._internal.utils.compat.stdlib_pkgs
- sys
- typing.AbstractSet
- typing.List

**Functions:**

### `def _should_suppress_build_backends() -> bool`

**Line:** 12

---

### `def _dev_pkgs() -> AbstractSet[str]`

**Line:** 16

---


## Module: venv2.libthon3.12.site-packages.pip._internal.commands.hash
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/commands/hash.py`

**Imports:**
- hashlib
- logging
- optparse.Values
- pip._internal.cli.base_command.Command
- pip._internal.cli.status_codes.ERROR
- pip._internal.cli.status_codes.SUCCESS
- pip._internal.utils.hashes.FAVORITE_HASH
- pip._internal.utils.hashes.STRONG_HASHES
- pip._internal.utils.misc.read_chunks
- pip._internal.utils.misc.write_output
- sys
- typing.List

**Functions:**

### `def _hash_of_file(path: str, algorithm: str) -> str`

**Description:**
Return the hash digest of a file.

**Line:** 53

---


## Module: venv2.libthon3.12.site-packages.pip._internal.commands.install
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/commands/install.py`

**Imports:**
- errno
- json
- operator
- optparse.SUPPRESS_HELP
- optparse.Values
- os
- pip._internal.cache.WheelCache
- pip._internal.cli.cmdoptions
- pip._internal.cli.cmdoptions.make_target_python
- pip._internal.cli.req_command.RequirementCommand
- pip._internal.cli.req_command.with_cleanup
- pip._internal.cli.status_codes.ERROR
- pip._internal.cli.status_codes.SUCCESS
- pip._internal.exceptions.CommandError
- pip._internal.exceptions.InstallationError
- pip._internal.locations.get_scheme
- pip._internal.metadata.get_environment
- pip._internal.models.installation_report.InstallationReport
- pip._internal.operations.build.build_tracker.get_build_tracker
- pip._internal.operations.check.ConflictDetails
- pip._internal.operations.check.check_install_conflicts
- pip._internal.req.install_given_reqs
- pip._internal.req.req_install.InstallRequirement
- pip._internal.req.req_install.check_legacy_setup_py_options
- pip._internal.self_outdated_check
- pip._internal.utils.compat.WINDOWS
- pip._internal.utils.filesystem.test_writable_dir
- pip._internal.utils.logging.getLogger
- pip._internal.utils.misc.check_externally_managed
- pip._internal.utils.misc.ensure_dir
- pip._internal.utils.misc.get_pip_version
- pip._internal.utils.misc.protect_pip_from_modification_on_windows
- pip._internal.utils.misc.warn_if_run_as_root
- pip._internal.utils.misc.write_output
- pip._internal.utils.temp_dir.TempDirectory
- pip._internal.utils.virtualenv.running_under_virtualenv
- pip._internal.utils.virtualenv.virtualenv_no_global
- pip._internal.wheel_builder.build
- pip._internal.wheel_builder.should_build_for_install_command
- pip._vendor.packaging.utils.canonicalize_name
- pip._vendor.requests.exceptions.InvalidProxyURL
- pip._vendor.rich.print_json
- shutil
- site
- typing.List
- typing.Optional

**Functions:**

### `def get_lib_location_guesses(user: bool = False, home: Optional[str] = None, root: Optional[str] = None, isolated: bool = False, prefix: Optional[str] = None) -> List[str]`

**Line:** 646

---

### `def site_packages_writable(root: Optional[str], isolated: bool) -> bool`

**Line:** 664

---

### `def decide_user_install(use_user_site: Optional[bool], prefix_path: Optional[str] = None, target_dir: Optional[str] = None, root_path: Optional[str] = None, isolated_mode: bool = False) -> bool`

**Description:**
Determine whether to do a user install based on the input options.

If use_user_site is False, no additional checks are done.
If use_user_site is True, it is checked for compatibility with other
options.
If use_user_site is None, the default behaviour depends on the environment,
which is provided by the other arguments.

**Line:** 671

---

### `def create_os_error_message(error: OSError, show_traceback: bool, using_user_site: bool) -> str`

**Description:**
Format an error message for an OSError

It may occur anytime during the execution of the install command.

**Line:** 732

---


## Module: venv2.libthon3.12.site-packages.pip._internal.commands.list
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/commands/list.py`

**Imports:**
- email.parser.Parser
- json
- logging
- optparse.Values
- pip._internal.cli.cmdoptions
- pip._internal.cli.index_command.IndexGroupCommand
- pip._internal.cli.status_codes.SUCCESS
- pip._internal.exceptions.CommandError
- pip._internal.index.collector.LinkCollector
- pip._internal.index.package_finder.PackageFinder
- pip._internal.metadata.BaseDistribution
- pip._internal.metadata.get_environment
- pip._internal.models.selection_prefs.SelectionPreferences
- pip._internal.network.session.PipSession
- pip._internal.utils.compat.stdlib_pkgs
- pip._internal.utils.misc.tabulate
- pip._internal.utils.misc.write_output
- pip._vendor.packaging.utils.canonicalize_name
- pip._vendor.packaging.version.Version
- typing.Generator
- typing.List
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.cast

**Functions:**

### `def format_for_columns(pkgs: '_ProcessedDists', options: Values) -> Tuple[(List[List[str]], List[str])]`

**Description:**
Convert the package data into something usable
by output_package_listing_columns.

**Line:** 314

---

### `def format_for_json(packages: '_ProcessedDists', options: Values) -> str`

**Line:** 374

---


## Module: venv2.libthon3.12.site-packages.pip._internal.commands.search
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/commands/search.py`

**Imports:**
- collections.OrderedDict
- logging
- optparse.Values
- pip._internal.cli.base_command.Command
- pip._internal.cli.req_command.SessionCommandMixin
- pip._internal.cli.status_codes.NO_MATCHES_FOUND
- pip._internal.cli.status_codes.SUCCESS
- pip._internal.exceptions.CommandError
- pip._internal.metadata.base.BaseDistribution
- pip._internal.metadata.get_default_environment
- pip._internal.models.index.PyPI
- pip._internal.network.xmlrpc.PipXmlrpcTransport
- pip._internal.utils.logging.indent_log
- pip._internal.utils.misc.write_output
- pip._vendor.packaging.version.parse
- shutil
- sys
- textwrap
- typing.Dict
- typing.List
- typing.Optional
- typing.TypedDict
- xmlrpc.client

**Functions:**

### `def transform_hits(hits: List[Dict[(str, str)]]) -> List['TransformedHit']`

**Description:**
The list from pypi is really a list of versions. We want a list of
packages with the list of versions stored inline. This converts the
list from pypi into one we can use.

**Line:** 86

---

### `def print_dist_installation_info(latest: str, dist: Optional[BaseDistribution]) -> None`

**Line:** 114

---

### `def get_installed_distribution(name: str) -> Optional[BaseDistribution]`

**Line:** 131

---

### `def print_results(hits: List['TransformedHit'], name_column_width: Optional[int] = None, terminal_width: Optional[int] = None) -> None`

**Line:** 136

---

### `def highest_version(versions: List[str]) -> str`

**Line:** 175

---


## Module: venv2.libthon3.12.site-packages.pip._internal.commands.show
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/commands/show.py`

**Imports:**
- logging
- optparse.Values
- pip._internal.cli.base_command.Command
- pip._internal.cli.status_codes.ERROR
- pip._internal.cli.status_codes.SUCCESS
- pip._internal.metadata.BaseDistribution
- pip._internal.metadata.get_default_environment
- pip._internal.utils.misc.write_output
- pip._vendor.packaging.requirements.InvalidRequirement
- pip._vendor.packaging.utils.canonicalize_name
- string
- typing.Generator
- typing.Iterable
- typing.Iterator
- typing.List
- typing.NamedTuple
- typing.Optional

**Functions:**

### `def normalize_project_url_label(label: str) -> str`

**Line:** 17

---

### `def search_packages_info(query: List[str]) -> Generator[(_PackageInfo, None, None)]`

**Description:**
Gather details from installed distributions. Print distribution name,
version, location, and installed files. Installed files requires a
pip generated 'installed-files.txt' in the distributions '.egg-info'
directory.

**Line:** 82

---

### `def print_results(distributions: Iterable[_PackageInfo], list_files: bool, verbose: bool) -> bool`

**Description:**
Print the information from installed distributions found.

**Line:** 175

---


## Module: venv2.libthon3.12.site-packages.pip._internal.configuration
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/configuration.py`

**Imports:**
- configparser
- locale
- os
- pip._internal.exceptions.ConfigurationError
- pip._internal.exceptions.ConfigurationFileCouldNotBeLoaded
- pip._internal.utils.appdirs
- pip._internal.utils.compat.WINDOWS
- pip._internal.utils.logging.getLogger
- pip._internal.utils.misc.ensure_dir
- pip._internal.utils.misc.enum
- sys
- typing.Any
- typing.Dict
- typing.Iterable
- typing.List
- typing.NewType
- typing.Optional
- typing.Tuple

**Functions:**

### `def _normalize_name(name: str) -> str`

**Description:**
Make a name consistent regardless of source (environment or file)

**Line:** 50

---

### `def _disassemble_key(name: str) -> List[str]`

**Line:** 58

---

### `def get_configuration_files() -> Dict[(Kind, List[str])]`

**Line:** 68

---


## Module: venv2.libthon3.12.site-packages.pip._internal.distributions.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/distributions/__init__.py`

**Imports:**
- pip._internal.distributions.base.AbstractDistribution
- pip._internal.distributions.sdist.SourceDistribution
- pip._internal.distributions.wheel.WheelDistribution
- pip._internal.req.req_install.InstallRequirement

**Functions:**

### `def make_distribution_for_install_requirement(install_req: InstallRequirement) -> AbstractDistribution`

**Description:**
Returns a Distribution for the given InstallRequirement

**Line:** 7

---


## Module: venv2.libthon3.12.site-packages.pip._internal.exceptions
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/exceptions.py`

**Imports:**
- configparser
- contextlib
- hashlib._Hash
- itertools.chain
- itertools.groupby
- itertools.repeat
- locale
- logging
- pathlib
- pip._internal.metadata.BaseDistribution
- pip._internal.models.link.Link
- pip._internal.req.req_install.InstallRequirement
- pip._internal.utils._log.VERBOSE
- pip._internal.utils.hashes.FAVORITE_HASH
- pip._internal.utils.misc.format_size
- pip._vendor.packaging.requirements.InvalidRequirement
- pip._vendor.packaging.version.InvalidVersion
- pip._vendor.requests.models.Request
- pip._vendor.requests.models.Response
- pip._vendor.rich.console.Console
- pip._vendor.rich.console.ConsoleOptions
- pip._vendor.rich.console.RenderResult
- pip._vendor.rich.markup.escape
- pip._vendor.rich.text.Text
- re
- sys
- typing.Dict
- typing.Iterator
- typing.List
- typing.Literal
- typing.Optional
- typing.TYPE_CHECKING
- typing.Union

**Functions:**

### `def _is_kebab_case(s: str) -> bool`

**Line:** 39

---

### `def _prefix_with_indent(s: Union[(Text, str)], console: Console, prefix: str, indent: str) -> Text`

**Line:** 43

---


## Module: venv2.libthon3.12.site-packages.pip._internal.index.collector
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/index/collector.py`

**Imports:**
- collections
- dataclasses.dataclass
- email.message
- functools
- html.parser.HTMLParser
- itertools
- json
- logging
- optparse.Values
- os
- pip._internal.exceptions.NetworkConnectionError
- pip._internal.models.link.Link
- pip._internal.models.search_scope.SearchScope
- pip._internal.network.session.PipSession
- pip._internal.network.utils.raise_for_status
- pip._internal.utils.filetypes.is_archive_file
- pip._internal.utils.misc.redact_auth_from_url
- pip._internal.vcs.vcs
- pip._vendor.requests
- pip._vendor.requests.Response
- pip._vendor.requests.exceptions.RetryError
- pip._vendor.requests.exceptions.SSLError
- sources.CandidatesFromPage
- sources.LinkSource
- sources.build_source
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.List
- typing.MutableMapping
- typing.NamedTuple
- typing.Optional
- typing.Protocol
- typing.Sequence
- typing.Tuple
- typing.Union
- urllib.parse
- urllib.request

**Functions:**

### `def _match_vcs_scheme(url: str) -> Optional[str]`

**Description:**
Look for VCS schemes in the URL.

Returns the matched VCS scheme, or None if there's no match.

**Line:** 51

---

### `def _ensure_api_header(response: Response) -> None`

**Description:**
Check the Content-Type header to ensure the response contains a Simple
API Response.

Raises `_NotAPIContent` if the content type is not a valid content-type.

**Line:** 69

---

### `def _ensure_api_response(url: str, session: PipSession) -> None`

**Description:**
Send a HEAD request to the URL, and ensure the response contains a simple
API Response.

Raises `_NotHTTP` if the URL is not available for a HEAD request, or
`_NotAPIContent` if the content type is not a valid content type.

**Line:** 95

---

### `def _get_simple_response(url: str, session: PipSession) -> Response`

**Description:**
Access an Simple API response with GET, and return the response.

This consists of three parts:

1. If the URL looks suspiciously like an archive, send a HEAD first to
check the Content-Type is HTML or Simple API, to avoid downloading a
large file. Raise `_NotHTTP` if the content type cannot be determined, or
`_NotAPIContent` if it is not HTML or a Simple API.
2. Actually perform the request. Raise HTTP exceptions on network failures.
3. Check the Content-Type header to make sure we got a Simple API response,
and raise `_NotAPIContent` otherwise.

**Line:** 113

---

### `def _get_encoding_from_headers(headers: ResponseHeaders) -> Optional[str]`

**Description:**
Determine if we have any encoding information in our headers.

**Line:** 176

---

### `def with_cached_index_content(fn: ParseLinks) -> ParseLinks`

**Description:**
Given a function that parses an Iterable[Link] from an IndexContent, cache the
function's result (keyed by CacheablePageContent), unless the IndexContent
`page` has `page.cache_link_parsing == False`.

**Line:** 203

---

### `def parse_links(page: 'IndexContent') -> Iterable[Link]`

**Decorators:**
- `@with_cached_index_content`

**Description:**
Parse a Simple API's Index Content, and yield its anchor elements as Link objects.

**Line:** 224

---

### `def _handle_get_simple_fail(link: Link, reason: Union[(str, Exception)], meth: Optional[Callable[(..., None)]] = None) -> None`

**Line:** 301

---

### `def _make_index_content(response: Response, cache_link_parsing: bool = True) -> IndexContent`

**Line:** 311

---

### `def _get_index_content(link: Link, session: PipSession) -> Optional['IndexContent']`

**Line:** 324

---


## Module: venv2.libthon3.12.site-packages.pip._internal.index.package_finder
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/index/package_finder.py`

**Imports:**
- dataclasses.dataclass
- enum
- functools
- itertools
- logging
- pip._internal.exceptions.BestVersionAlreadyInstalled
- pip._internal.exceptions.DistributionNotFound
- pip._internal.exceptions.InvalidWheelFilename
- pip._internal.exceptions.UnsupportedWheel
- pip._internal.index.collector.LinkCollector
- pip._internal.index.collector.parse_links
- pip._internal.models.candidate.InstallationCandidate
- pip._internal.models.format_control.FormatControl
- pip._internal.models.link.Link
- pip._internal.models.search_scope.SearchScope
- pip._internal.models.selection_prefs.SelectionPreferences
- pip._internal.models.target_python.TargetPython
- pip._internal.models.wheel.Wheel
- pip._internal.req.InstallRequirement
- pip._internal.utils._log.getLogger
- pip._internal.utils.filetypes.WHEEL_EXTENSION
- pip._internal.utils.hashes.Hashes
- pip._internal.utils.logging.indent_log
- pip._internal.utils.misc.build_netloc
- pip._internal.utils.packaging.check_requires_python
- pip._internal.utils.unpacking.SUPPORTED_EXTENSIONS
- pip._vendor.packaging.specifiers
- pip._vendor.packaging.tags.Tag
- pip._vendor.packaging.utils.canonicalize_name
- pip._vendor.packaging.version.InvalidVersion
- pip._vendor.packaging.version._BaseVersion
- pip._vendor.packaging.version.parse
- pip._vendor.typing_extensions.TypeGuard
- re
- typing.Dict
- typing.FrozenSet
- typing.Iterable
- typing.List
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union

**Functions:**

### `def _check_link_requires_python(link: Link, version_info: Tuple[(int, int, int)], ignore_requires_python: bool = False) -> bool`

**Description:**
Return whether the given Python version is compatible with a link's
"Requires-Python" value.

:param version_info: A 3-tuple of ints representing the Python
major-minor-micro version to check.
:param ignore_requires_python: Whether to ignore the "Requires-Python"
value if the given Python version isn't compatible.

**Line:** 62

---

### `def filter_unallowed_hashes(candidates: List[InstallationCandidate], hashes: Optional[Hashes], project_name: str) -> List[InstallationCandidate]`

**Description:**
Filter out candidates whose hashes aren't allowed, and return a new
list of candidates.

If at least one candidate has an allowed hash, then all candidates with
either an allowed hash or no hash specified are returned.  Otherwise,
the given candidates are returned.

Including the candidates with no hash specified when there is a match
allows a warning to be logged if there is a more preferred candidate
with no hash specified.  Returning all candidates in the case of no
matches lets pip report the hash of the candidate that would otherwise
have been installed (e.g. permitting the user to more easily update
their requirements file with the desired hash).

**Line:** 262

---

### `def _find_name_version_sep(fragment: str, canonical_name: str) -> int`

**Description:**
Find the separator's index based on the package's canonical name.

:param fragment: A <package>+<version> filename "fragment" (stem) or
egg fragment.
:param canonical_name: The package's canonical name.

This function is needed since the canonicalized name does not necessarily
have the same length as the egg info's name part. An example::

>>> fragment = 'foo__bar-1.0'
>>> canonical_name = 'foo-bar'
>>> _find_name_version_sep(fragment, canonical_name)
8

**Line:** 1009

---

### `def _extract_version_from_fragment(fragment: str, canonical_name: str) -> Optional[str]`

**Description:**
Parse the version string from a <package>+<version> filename
"fragment" (stem) or egg fragment.

:param fragment: The string to parse. E.g. foo-2.1
:param canonical_name: The canonicalized name of the package this
belongs to.

**Line:** 1035

---


## Module: venv2.libthon3.12.site-packages.pip._internal.index.sources
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/index/sources.py`

**Imports:**
- collections.defaultdict
- logging
- mimetypes
- os
- pip._internal.models.candidate.InstallationCandidate
- pip._internal.models.link.Link
- pip._internal.utils.urls.path_to_url
- pip._internal.utils.urls.url_to_path
- pip._internal.vcs.is_url
- pip._vendor.packaging.utils.InvalidSdistFilename
- pip._vendor.packaging.utils.InvalidWheelFilename
- pip._vendor.packaging.utils.canonicalize_name
- pip._vendor.packaging.utils.parse_sdist_filename
- pip._vendor.packaging.utils.parse_wheel_filename
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.List
- typing.Optional
- typing.Tuple

**Functions:**

### `def _is_html_file(file_url: str) -> bool`

**Line:** 43

---

### `def build_source(location: str, candidates_from_page: CandidatesFromPage, page_validator: PageValidator, expand_dir: bool, cache_link_parsing: bool, project_name: str) -> Tuple[(Optional[str], Optional[LinkSource])]`

**Line:** 225

---


## Module: venv2.libthon3.12.site-packages.pip._internal.locations.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/locations/__init__.py`

**Imports:**
- base.USER_CACHE_DIR
- base.get_major_minor_version
- base.get_src_prefix
- base.is_osx_framework
- base.site_packages
- base.user_site
- distutils.command.install.INSTALL_SCHEMES
- distutils.command.install.install
- distutils.dist.Distribution
- functools
- logging
- os
- pathlib
- pip._internal.models.scheme.SCHEME_KEYS
- pip._internal.models.scheme.Scheme
- pip._internal.utils.compat.WINDOWS
- pip._internal.utils.deprecation.deprecated
- pip._internal.utils.virtualenv.running_under_virtualenv
- sys
- sysconfig
- typing.Any
- typing.Dict
- typing.Optional

**Functions:**

### `def _should_use_sysconfig() -> bool`

**Description:**
This function determines the value of _USE_SYSCONFIG.

By default, pip uses sysconfig on Python 3.10+.
But Python distributors can override this decision by setting:
sysconfig._PIP_USE_SYSCONFIG = True / False
Rationale in https://github.com/pypa/pip/issues/10647

This is a function for testability, but should be constant during any one
run.

**Line:** 46

---

### `def _looks_like_bpo_44860() -> bool`

**Description:**
The resolution to bpo-44860 will change this incorrect platlib.

See <https://bugs.python.org/issue44860>.

**Line:** 76

---

### `def _looks_like_red_hat_patched_platlib_purelib(scheme: Dict[(str, str)]) -> bool`

**Line:** 90

---

### `def _looks_like_red_hat_lib() -> bool`

**Decorators:**
- `@functools.lru_cache(...)`

**Description:**
Red Hat patches platlib in unix_prefix and unix_home, but not purelib.

This is the only way I can see to tell a Red Hat-patched Python.

**Line:** 101

---

### `def _looks_like_debian_scheme() -> bool`

**Decorators:**
- `@functools.lru_cache(...)`

**Description:**
Debian adds two additional schemes.

**Line:** 116

---

### `def _looks_like_red_hat_scheme() -> bool`

**Decorators:**
- `@functools.lru_cache(...)`

**Description:**
Red Hat patches ``sys.prefix`` and ``sys.exec_prefix``.

Red Hat's ``00251-change-user-install-location.patch`` changes the install
command's ``prefix`` and ``exec_prefix`` to append ``"/local"``. This is
(fortunately?) done quite unconditionally, so we create a default command
object without any configuration to detect this.

**Line:** 124

---

### `def _looks_like_slackware_scheme() -> bool`

**Decorators:**
- `@functools.lru_cache(...)`

**Description:**
Slackware patches sysconfig but fails to patch distutils and site.

Slackware changes sysconfig's user scheme to use ``"lib64"`` for the lib
path, but does not do the same to the site module.

**Line:** 144

---

### `def _looks_like_msys2_mingw_scheme() -> bool`

**Decorators:**
- `@functools.lru_cache(...)`

**Description:**
MSYS2 patches distutils and sysconfig to use a UNIX-like scheme.

However, MSYS2 incorrectly patches sysconfig ``nt`` scheme. The fix is
likely going to be included in their 3.10 release, so we ignore the warning.
See msys2/MINGW-packages#9319.

MSYS2 MINGW's patch uses lowercase ``"lib"`` instead of the usual uppercase,
and is missing the final ``"site-packages"``.

**Line:** 160

---

### `def _warn_mismatched(old: pathlib.Path, new: pathlib.Path, key: str) -> None`

**Decorators:**
- `@functools.lru_cache(...)`

**Line:** 178

---

### `def _warn_if_mismatch(old: pathlib.Path, new: pathlib.Path, key: str) -> bool`

**Line:** 188

---

### `def _log_context(user: bool = False, home: Optional[str] = None, root: Optional[str] = None, prefix: Optional[str] = None) -> None`

**Decorators:**
- `@functools.lru_cache(...)`

**Line:** 196

---

### `def get_scheme(dist_name: str, user: bool = False, home: Optional[str] = None, root: Optional[str] = None, isolated: bool = False, prefix: Optional[str] = None) -> Scheme`

**Line:** 214

---

### `def get_bin_prefix() -> str`

**Line:** 380

---

### `def get_bin_user() -> str`

**Line:** 391

---

### `def _looks_like_deb_system_dist_packages(value: str) -> bool`

**Description:**
Check if the value is Debian's APT-controlled dist-packages.

Debian's ``distutils.sysconfig.get_python_lib()`` implementation returns the
default package path controlled by APT, but does not patch ``sysconfig`` to
do the same. This is similar to the bug worked around in ``get_scheme()``,
but here the default is ``deb_system`` instead of ``unix_local``. Ultimately
we can't do anything about this Debian bug, and this detection allows us to
skip the warning when needed.

**Line:** 395

---

### `def get_purelib() -> str`

**Description:**
Return the default pure-Python lib location.

**Line:** 412

---

### `def get_platlib() -> str`

**Description:**
Return the default platform-shared lib location.

**Line:** 426

---


## Module: venv2.libthon3.12.site-packages.pip._internal.locations._distutils
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/locations/_distutils.py`

**Imports:**
- base.get_major_minor_version
- distutils.cmd.Command
- distutils.command.install.SCHEME_KEYS
- distutils.command.install.install
- distutils.dist.Distribution
- distutils.sysconfig.get_python_lib
- logging
- os
- pip._internal.models.scheme.Scheme
- pip._internal.utils.compat.WINDOWS
- pip._internal.utils.virtualenv.running_under_virtualenv
- sys
- typing.Dict
- typing.List
- typing.Optional
- typing.Union

**Functions:**

### `def distutils_scheme(dist_name: str, user: bool = False, home: Optional[str] = None, root: Optional[str] = None, isolated: bool = False, prefix: Optional[str] = None, ignore_config_files: bool = False) -> Dict[(str, str)]`

**Description:**
Return a distutils install scheme

**Line:** 35

---

### `def get_scheme(dist_name: str, user: bool = False, home: Optional[str] = None, root: Optional[str] = None, isolated: bool = False, prefix: Optional[str] = None) -> Scheme`

**Description:**
Get the "scheme" corresponding to the input parameters. The distutils
documentation provides the context for the available schemes:
https://docs.python.org/3/install/index.html#alternate-installation

:param dist_name: the name of the package to retrieve the scheme for, used
in the headers scheme path
:param user: indicates to use the "user" scheme
:param home: indicates to use the "home" scheme and provides the base
directory for the same
:param root: root under which other directories are re-based
:param isolated: equivalent to --no-user-cfg, i.e. do not consider
~/.pydistutils.cfg (posix) or ~/pydistutils.cfg (non-posix) for
scheme paths
:param prefix: indicates to use the "prefix" scheme and provides the
base directory for the same

**Line:** 115

---

### `def get_bin_prefix() -> str`

**Line:** 150

---

### `def get_purelib() -> str`

**Line:** 167

---

### `def get_platlib() -> str`

**Line:** 171

---


## Module: venv2.libthon3.12.site-packages.pip._internal.locations._sysconfig
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/locations/_sysconfig.py`

**Imports:**
- base.change_root
- base.get_major_minor_version
- base.is_osx_framework
- logging
- os
- pip._internal.exceptions.InvalidSchemeCombination
- pip._internal.exceptions.UserInstallationInvalid
- pip._internal.models.scheme.SCHEME_KEYS
- pip._internal.models.scheme.Scheme
- pip._internal.utils.virtualenv.running_under_virtualenv
- sys
- sysconfig
- typing

**Functions:**

### `def _should_use_osx_framework_prefix() -> bool`

**Description:**
Check for Apple's ``osx_framework_library`` scheme.

Python distributed by Apple's Command Line Tools has this special scheme
that's used when:

* This is a framework build.
* We are installing into the system prefix.

This does not account for ``pip install --prefix`` (also means we're not
installing to the system prefix), which should use ``posix_prefix``, but
logic here means ``_infer_prefix()`` outputs ``osx_framework_library``. But
since ``prefix`` is not available for ``sysconfig.get_default_scheme()``,
which is the stdlib replacement for ``_infer_prefix()``, presumably Apple
wouldn't be able to magically switch between ``osx_framework_library`` and
``posix_prefix``. ``_infer_prefix()`` returning ``osx_framework_library``
means its behavior is consistent whether we use the stdlib implementation
or our own, and we deal with this special case in ``get_scheme()`` instead.

**Line:** 29

---

### `def _infer_prefix() -> str`

**Description:**
Try to find a prefix scheme for the current platform.

This tries:

* A special ``osx_framework_library`` for Python distributed by Apple's
Command Line Tools, when not running in a virtual environment.
* Implementation + OS, used by PyPy on Windows (``pypy_nt``).
* Implementation without OS, used by PyPy on POSIX (``pypy``).
* OS + "prefix", used by CPython on POSIX (``posix_prefix``).
* Just the OS name, used by CPython on Windows (``nt``).

If none of the above works, fall back to ``posix_prefix``.

**Line:** 55

---

### `def _infer_user() -> str`

**Description:**
Try to find a user scheme for the current platform.

**Line:** 86

---

### `def _infer_home() -> str`

**Description:**
Try to find a home for the current platform.

**Line:** 101

---

### `def get_scheme(dist_name: str, user: bool = False, home: typing.Optional[str] = None, root: typing.Optional[str] = None, isolated: bool = False, prefix: typing.Optional[str] = None) -> Scheme`

**Description:**
Get the "scheme" corresponding to the input parameters.

:param dist_name: the name of the package to retrieve the scheme for, used
in the headers scheme path
:param user: indicates to use the "user" scheme
:param home: indicates to use the "home" scheme
:param root: root under which other directories are re-based
:param isolated: ignored, but kept for distutils compatibility (where
this controls whether the user-site pydistutils.cfg is honored)
:param prefix: indicates to use the "prefix" scheme and provides the
base directory for the same

**Line:** 124

---

### `def get_bin_prefix() -> str`

**Line:** 202

---

### `def get_purelib() -> str`

**Line:** 209

---

### `def get_platlib() -> str`

**Line:** 213

---


## Module: venv2.libthon3.12.site-packages.pip._internal.locations.base
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/locations/base.py`

**Imports:**
- functools
- os
- pip._internal.exceptions.InstallationError
- pip._internal.utils.appdirs
- pip._internal.utils.virtualenv.running_under_virtualenv
- site
- sys
- sysconfig
- typing

**Functions:**

### `def get_major_minor_version() -> str`

**Description:**
Return the major-minor version of the current Python as a string, e.g.
"3.7" or "3.10".

**Line:** 19

---

### `def change_root(new_root: str, pathname: str) -> str`

**Description:**
Return 'pathname' with 'new_root' prepended.

If 'pathname' is relative, this is equivalent to os.path.join(new_root, pathname).
Otherwise, it requires making 'pathname' relative and then joining the
two, which is tricky on DOS/Windows and Mac OS.

This is borrowed from Python's standard library's distutils module.

**Line:** 27

---

### `def get_src_prefix() -> str`

**Line:** 55

---

### `def is_osx_framework() -> bool`

**Decorators:**
- `@functools.lru_cache(...)`

**Line:** 80

---


## Module: venv2.libthon3.12.site-packages.pip._internal.main
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/main.py`

**Imports:**
- pip._internal.utils.entrypoints._wrapper
- typing.List
- typing.Optional

**Functions:**

### `def main(args: Optional[List[str]] = None) -> int`

**Description:**
This is preserved for old console scripts that may still be referencing
it.

For additional details, see https://github.com/pypa/pip/issues/7498.

**Line:** 4

---


## Module: venv2.libthon3.12.site-packages.pip._internal.metadata.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/metadata/__init__.py`

**Imports:**
- base.BaseDistribution
- base.BaseEnvironment
- base.FilesystemWheel
- base.MemoryWheel
- base.Wheel
- contextlib
- functools
- importlib.metadata
- os
- pip._internal.utils.deprecation.deprecated
- pip._internal.utils.misc.strtobool
- sys
- typing.List
- typing.Literal
- typing.Optional
- typing.Protocol
- typing.Type
- typing.cast

**Functions:**

### `def _should_use_importlib_metadata() -> bool`

**Description:**
Whether to use the ``importlib.metadata`` or ``pkg_resources`` backend.

By default, pip uses ``importlib.metadata`` on Python 3.11+, and
``pkg_resources`` otherwise. Up to Python 3.13, This can be
overridden by a couple of ways:

* If environment variable ``_PIP_USE_IMPORTLIB_METADATA`` is set, it
dictates whether ``importlib.metadata`` is used, for Python <3.14.
* On Python 3.11, 3.12 and 3.13, Python distributors can patch
``importlib.metadata`` to add a global constant
``_PIP_USE_IMPORTLIB_METADATA = False``. This makes pip use
``pkg_resources`` (unless the user set the aforementioned environment
variable to *True*).

On Python 3.14+, the ``pkg_resources`` backend cannot be used.

**Line:** 25

---

### `def _emit_pkg_resources_deprecation_if_needed() -> None`

**Line:** 58

---

### `def select_backend() -> Backend`

**Decorators:**
- `@functools.lru_cache(...)`

**Line:** 90

---

### `def get_default_environment() -> BaseEnvironment`

**Description:**
Get the default representation for the current environment.

This returns an Environment instance from the chosen backend. The default
Environment instance should be built from ``sys.path`` and may use caching
to share instance state across calls.

**Line:** 103

---

### `def get_environment(paths: Optional[List[str]]) -> BaseEnvironment`

**Description:**
Get a representation of the environment specified by ``paths``.

This returns an Environment instance from the chosen backend based on the
given import paths. The backend must build a fresh instance representing
the state of installed distributions when this function is called.

**Line:** 113

---

### `def get_directory_distribution(directory: str) -> BaseDistribution`

**Description:**
Get the distribution metadata representation in the specified directory.

This returns a Distribution instance from the chosen backend based on
the given on-disk ``.dist-info`` directory.

**Line:** 123

---

### `def get_wheel_distribution(wheel: Wheel, canonical_name: str) -> BaseDistribution`

**Description:**
Get the representation of the specified wheel's distribution metadata.

This returns a Distribution instance from the chosen backend based on
the given wheel's ``.dist-info`` directory.

:param canonical_name: Normalized project name of the given wheel.

**Line:** 132

---

### `def get_metadata_distribution(metadata_contents: bytes, filename: str, canonical_name: str) -> BaseDistribution`

**Description:**
Get the dist representation of the specified METADATA file contents.

This returns a Distribution instance from the chosen backend sourced from the data
in `metadata_contents`.

:param metadata_contents: Contents of a METADATA file within a dist, or one served
via PEP 658.
:param filename: Filename for the dist this metadata represents.
:param canonical_name: Normalized project name of the given dist.

**Line:** 143

---


## Module: venv2.libthon3.12.site-packages.pip._internal.metadata._json
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/metadata/_json.py`

**Imports:**
- email.header.Header
- email.header.decode_header
- email.header.make_header
- email.message.Message
- typing.Any
- typing.Dict
- typing.List
- typing.Union
- typing.cast

**Functions:**

### `def json_name(field: str) -> str`

**Line:** 39

---

### `def msg_to_json(msg: Message) -> Dict[(str, Any)]`

**Description:**
Convert a Message object into a JSON-compatible dictionary.

**Line:** 43

---


## Module: venv2.libthon3.12.site-packages.pip._internal.metadata.base
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/metadata/base.py`

**Imports:**
- _json.msg_to_json
- csv
- email.message
- functools
- json
- logging
- pathlib
- pip._internal.exceptions.NoneMetadataError
- pip._internal.locations.site_packages
- pip._internal.locations.user_site
- pip._internal.models.direct_url.DIRECT_URL_METADATA_NAME
- pip._internal.models.direct_url.DirectUrl
- pip._internal.models.direct_url.DirectUrlValidationError
- pip._internal.utils.compat.stdlib_pkgs
- pip._internal.utils.egg_link.egg_link_path_from_sys_path
- pip._internal.utils.misc.is_local
- pip._internal.utils.misc.normalize_path
- pip._internal.utils.urls.url_to_path
- pip._vendor.packaging.requirements.Requirement
- pip._vendor.packaging.specifiers.InvalidSpecifier
- pip._vendor.packaging.specifiers.SpecifierSet
- pip._vendor.packaging.utils.NormalizedName
- pip._vendor.packaging.utils.canonicalize_name
- pip._vendor.packaging.version.Version
- re
- typing.Any
- typing.Collection
- typing.Container
- typing.Dict
- typing.IO
- typing.Iterable
- typing.Iterator
- typing.List
- typing.NamedTuple
- typing.Optional
- typing.Protocol
- typing.Tuple
- typing.Union
- zipfile

**Functions:**

### `def _convert_installed_files_path(entry: Tuple[(str, ...)], info: Tuple[(str, ...)]) -> str`

**Description:**
Convert a legacy installed-files.txt path into modern RECORD path.

The legacy format stores paths relative to the info directory, while the
modern format stores paths relative to the package root, e.g. the
site-packages directory.

:param entry: Path parts of the installed-files.txt entry.
:param info: Path parts of the egg-info directory relative to package root.
:returns: The converted entry.

For best compatibility with symlinks, this does not use ``abspath()`` or
``Path.resolve()``, but tries to work with path parts:

1. While ``entry`` starts with ``..``, remove the equal amounts of parts
from ``info``; if ``info`` is empty, start appending ``..`` instead.
2. Join the two directly.

**Line:** 63

---


## Module: venv2.libthon3.12.site-packages.pip._internal.metadata.importlib._compat
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_compat.py`

**Imports:**
- importlib.metadata
- os
- pip._vendor.packaging.utils.NormalizedName
- pip._vendor.packaging.utils.canonicalize_name
- typing.Any
- typing.Optional
- typing.Protocol
- typing.Tuple
- typing.cast

**Functions:**

### `def get_info_location(d: importlib.metadata.Distribution) -> Optional[BasePath]`

**Description:**
Find the path to the distribution's metadata directory.

HACK: This relies on importlib.metadata's private ``_path`` attribute. Not
all distributions exist on disk, so importlib.metadata is correct to not
expose the attribute as public. But pip's code base is old and not as clean,
so we do this to avoid having to rewrite too many things. Hopefully we can
eliminate this some day.

**Line:** 37

---

### `def parse_name_and_version_from_info_directory(dist: importlib.metadata.Distribution) -> Tuple[(Optional[str], Optional[str])]`

**Description:**
Get a name and version from the metadata directory name.

This is much faster than reading distribution metadata.

**Line:** 49

---

### `def get_dist_canonical_name(dist: importlib.metadata.Distribution) -> NormalizedName`

**Description:**
Get the distribution's normalized name.

The ``name`` attribute is only available in Python 3.10 or later. We are
targeting exactly that, but Mypy does not know this.

**Line:** 73

---


## Module: venv2.libthon3.12.site-packages.pip._internal.metadata.importlib._envs
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py`

**Imports:**
- _compat.BadMetadata
- _compat.BasePath
- _compat.get_dist_canonical_name
- _compat.get_info_location
- _dists.Distribution
- importlib.metadata
- logging
- os
- pathlib
- pip._internal.metadata.base.BaseDistribution
- pip._internal.metadata.base.BaseEnvironment
- pip._internal.utils.filetypes.WHEEL_EXTENSION
- pip._vendor.packaging.utils.InvalidWheelFilename
- pip._vendor.packaging.utils.NormalizedName
- pip._vendor.packaging.utils.canonicalize_name
- pip._vendor.packaging.utils.parse_wheel_filename
- sys
- typing.Iterator
- typing.List
- typing.Optional
- typing.Sequence
- typing.Set
- typing.Tuple
- zipfile

**Functions:**

### `def _looks_like_wheel(location: str) -> bool`

**Line:** 25

---


## Module: venv2.libthon3.12.site-packages.pip._internal.models.direct_url
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/models/direct_url.py`

**Imports:**
- dataclasses.dataclass
- json
- re
- typing.Any
- typing.ClassVar
- typing.Dict
- typing.Iterable
- typing.Optional
- typing.Type
- typing.TypeVar
- typing.Union
- urllib.parse

**Functions:**

### `def _get(d: Dict[(str, Any)], expected_type: Type[T], key: str, default: Optional[T] = None) -> Optional[T]`

**Description:**
Get value from dictionary and verify expected type.

**Line:** 27

---

### `def _get_required(d: Dict[(str, Any)], expected_type: Type[T], key: str, default: Optional[T] = None) -> T`

**Line:** 41

---

### `def _exactly_one_of(infos: Iterable[Optional['InfoType']]) -> 'InfoType'`

**Line:** 50

---

### `def _filter_none(**kwargs: Any) -> Dict[(str, Any)]`

**Description:**
Make dict excluding None values.

**Line:** 64

---


## Module: venv2.libthon3.12.site-packages.pip._internal.models.link
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/models/link.py`

**Imports:**
- dataclasses.dataclass
- functools
- itertools
- logging
- os
- pip._internal.index.collector.IndexContent
- pip._internal.utils.deprecation.deprecated
- pip._internal.utils.filetypes.WHEEL_EXTENSION
- pip._internal.utils.hashes.Hashes
- pip._internal.utils.misc.pairwise
- pip._internal.utils.misc.redact_auth_from_url
- pip._internal.utils.misc.split_auth_from_netloc
- pip._internal.utils.misc.splitext
- pip._internal.utils.urls.path_to_url
- pip._internal.utils.urls.url_to_path
- pip._internal.vcs.vcs
- posixpath
- re
- typing.Any
- typing.Dict
- typing.List
- typing.Mapping
- typing.NamedTuple
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- urllib.parse

**Functions:**

### `def supported_hashes(hashes: Optional[Dict[(str, str)]]) -> Optional[Dict[(str, str)]]`

**Line:** 108

---

### `def _clean_url_path_part(part: str) -> str`

**Description:**
Clean a "part" of a URL path (i.e. after splitting on "@" characters).

**Line:** 119

---

### `def _clean_file_url_path(part: str) -> str`

**Description:**
Clean the first part of a URL path that corresponds to a local
filesystem path (i.e. the first part after splitting on "@" characters).

**Line:** 127

---

### `def _clean_url_path(path: str, is_local_path: bool) -> str`

**Description:**
Clean the path portion of a URL.

**Line:** 144

---

### `def _ensure_quoted_url(url: str) -> str`

**Description:**
Make sure a link is fully quoted.
For example, if ' ' occurs in the URL, it will be replaced with "%20",
and without double-quoting other characters.

**Line:** 166

---

### `def _absolute_link_url(base_url: str, url: str) -> str`

**Description:**
A faster implementation of urllib.parse.urljoin with a shortcut
for absolute http/https URLs.

**Line:** 181

---

### `def _clean_link(link: Link) -> _CleanResult`

**Line:** 580

---

### `def links_equivalent(link1: Link, link2: Link) -> bool`

**Decorators:**
- `@functools.lru_cache(...)`

**Line:** 607

---


## Module: venv2.libthon3.12.site-packages.pip._internal.modelslock
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/models/pylock.py`

**Imports:**
- dataclasses
- dataclasses.dataclass
- pathlib.Path
- pip._internal.models.direct_url.ArchiveInfo
- pip._internal.models.direct_url.DirInfo
- pip._internal.models.direct_url.VcsInfo
- pip._internal.models.link.Link
- pip._internal.req.req_install.InstallRequirement
- pip._internal.utils.urls.url_to_path
- pip._vendor.tomli_w
- pip._vendor.typing_extensions.Self
- re
- typing.Any
- typing.Dict
- typing.Iterable
- typing.List
- typing.Optional
- typing.Tuple

**Functions:**

### `def is_valid_pylock_file_name(path: Path) -> bool`

**Line:** 18

---

### `def _toml_dict_factory(data: List[Tuple[(str, Any)]]) -> Dict[(str, Any)]`

**Line:** 22

---


## Module: venv2.libthon3.12.site-packages.pip._internal.network.auth
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/network/auth.py`

**Imports:**
- abc.ABC
- abc.abstractmethod
- functools.lru_cache
- keyring
- logging
- os
- os.path.commonprefix
- pathlib.Path
- pip._internal.utils.logging.getLogger
- pip._internal.utils.misc.ask
- pip._internal.utils.misc.ask_input
- pip._internal.utils.misc.ask_password
- pip._internal.utils.misc.remove_auth_from_url
- pip._internal.utils.misc.split_auth_netloc_from_url
- pip._internal.vcs.versioncontrol.AuthInfo
- pip._vendor.requests.auth.AuthBase
- pip._vendor.requests.auth.HTTPBasicAuth
- pip._vendor.requests.models.Request
- pip._vendor.requests.models.Response
- pip._vendor.requests.utils.get_netrc_auth
- shutil
- subprocess
- sysconfig
- typing
- typing.Any
- typing.Dict
- typing.List
- typing.NamedTuple
- typing.Optional
- typing.Tuple
- urllib.parse

**Functions:**

### `def get_keyring_provider(provider: str) -> KeyRingBaseProvider`

**Decorators:**
- `@lru_cache(...)`

**Line:** 163

---


## Module: venv2.libthon3.12.site-packages.pip._internal.network.cache
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/network/cache.py`

**Imports:**
- contextlib.contextmanager
- datetime.datetime
- os
- pip._internal.utils.filesystem.adjacent_tmp_file
- pip._internal.utils.filesystem.replace
- pip._internal.utils.misc.ensure_dir
- pip._vendor.cachecontrol.cache.SeparateBodyBaseCache
- pip._vendor.cachecontrol.caches.SeparateBodyFileCache
- pip._vendor.requests.models.Response
- typing.BinaryIO
- typing.Generator
- typing.Optional
- typing.Union

**Functions:**

### `def is_from_cache(response: Response) -> bool`

**Line:** 16

---

### `def suppressed_cache_errors() -> Generator[(None, None, None)]`

**Decorators:**
- `@contextmanager`

**Description:**
If we can't access the cache then we can just skip caching and process
requests as if caching wasn't enabled.

**Line:** 21

---


## Module: venv2.libthon3.12.site-packages.pip._internal.network.download
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/network/download.py`

**Imports:**
- email.message
- http.HTTPStatus
- logging
- mimetypes
- os
- pip._internal.cli.progress_bars.get_download_progress_renderer
- pip._internal.exceptions.IncompleteDownloadError
- pip._internal.exceptions.NetworkConnectionError
- pip._internal.models.index.PyPI
- pip._internal.models.link.Link
- pip._internal.network.cache.is_from_cache
- pip._internal.network.session.PipSession
- pip._internal.network.utils.HEADERS
- pip._internal.network.utils.raise_for_status
- pip._internal.network.utils.response_chunks
- pip._internal.utils.misc.format_size
- pip._internal.utils.misc.redact_auth_from_url
- pip._internal.utils.misc.splitext
- pip._vendor.requests.models.Response
- pip._vendor.urllib3.exceptions.ReadTimeoutError
- typing.BinaryIO
- typing.Iterable
- typing.Optional
- typing.Tuple

**Functions:**

### `def _get_http_response_size(resp: Response) -> Optional[int]`

**Line:** 25

---

### `def _get_http_response_etag_or_last_modified(resp: Response) -> Optional[str]`

**Description:**
Return either the ETag or Last-Modified header (or None if neither exists).
The return value can be used in an If-Range header.

**Line:** 32

---

### `def _prepare_download(resp: Response, link: Link, progress_bar: str, total_length: Optional[int], range_start: Optional[int] = 0) -> Iterable[bytes]`

**Line:** 40

---

### `def sanitize_content_filename(filename: str) -> str`

**Description:**
Sanitize the "filename" value from a Content-Disposition header.

**Line:** 91

---

### `def parse_content_disposition(content_disposition: str, default_filename: str) -> str`

**Description:**
Parse the "filename" value from a Content-Disposition header, and
return the default filename if the result is empty.

**Line:** 98

---

### `def _get_http_response_filename(resp: Response, link: Link) -> str`

**Description:**
Get an ideal filename from the given HTTP response, falling back to
the link filename if not provided.

**Line:** 113

---

### `def _http_get_download(session: PipSession, link: Link, range_start: Optional[int] = 0, if_range: Optional[str] = None) -> Response`

**Line:** 134

---


## Module: venv2.libthon3.12.site-packages.pip._internal.network.lazy_wheel
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/network/lazy_wheel.py`

**Imports:**
- bisect.bisect_left
- bisect.bisect_right
- contextlib.contextmanager
- pip._internal.metadata.BaseDistribution
- pip._internal.metadata.MemoryWheel
- pip._internal.metadata.get_wheel_distribution
- pip._internal.network.session.PipSession
- pip._internal.network.utils.HEADERS
- pip._internal.network.utils.raise_for_status
- pip._internal.network.utils.response_chunks
- pip._vendor.packaging.utils.canonicalize_name
- pip._vendor.requests.models.CONTENT_CHUNK_SIZE
- pip._vendor.requests.models.Response
- tempfile.NamedTemporaryFile
- typing.Any
- typing.Dict
- typing.Generator
- typing.List
- typing.Optional
- typing.Tuple
- zipfile.BadZipFile
- zipfile.ZipFile

**Functions:**

### `def dist_from_wheel_url(name: str, url: str, session: PipSession) -> BaseDistribution`

**Description:**
Return a distribution object from the given wheel URL.

This uses HTTP range requests to only fetch the portion of the wheel
containing metadata, just enough for the object to be constructed.
If such requests are not supported, HTTPRangeRequestUnsupported
is raised.

**Line:** 23

---


## Module: venv2.libthon3.12.site-packages.pip._internal.network.session
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/network/session.py`

**Imports:**
- _ssl
- email.utils
- functools
- io
- ipaddress
- json
- logging
- mimetypes
- os
- pip.__version__
- pip._internal.metadata.get_default_environment
- pip._internal.models.link.Link
- pip._internal.network.auth.MultiDomainBasicAuth
- pip._internal.network.cache.SafeFileCache
- pip._internal.utils.compat.has_tls
- pip._internal.utils.glibc.libc_ver
- pip._internal.utils.misc.build_url_from_netloc
- pip._internal.utils.misc.parse_netloc
- pip._internal.utils.urls.url_to_path
- pip._vendor.cachecontrol.CacheControlAdapter
- pip._vendor.distro
- pip._vendor.requests
- pip._vendor.requests.adapters.BaseAdapter
- pip._vendor.requests.adapters.DEFAULT_POOLBLOCK
- pip._vendor.requests.adapters.HTTPAdapter
- pip._vendor.requests.models.PreparedRequest
- pip._vendor.requests.models.Response
- pip._vendor.requests.structures.CaseInsensitiveDict
- pip._vendor.urllib3
- pip._vendor.urllib3.connectionpool.ConnectionPool
- pip._vendor.urllib3.exceptions.InsecureRequestWarning
- pip._vendor.urllib3.poolmanager.PoolManager
- platform
- shutil
- ssl.SSLContext
- subprocess
- sys
- typing.Any
- typing.Dict
- typing.Generator
- typing.List
- typing.Mapping
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- urllib.parse
- warnings

**Functions:**

### `def looks_like_ci() -> bool`

**Description:**
Return whether it looks like pip is running under CI.

**Line:** 100

---

### `def user_agent() -> str`

**Decorators:**
- `@functools.lru_cache(...)`

**Description:**
Return a string representing the user agent.

**Line:** 111

---


## Module: venv2.libthon3.12.site-packages.pip._internal.network.utils
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/network/utils.py`

**Imports:**
- pip._internal.exceptions.NetworkConnectionError
- pip._vendor.requests.models.Response
- typing.Dict
- typing.Generator

**Functions:**

### `def raise_for_status(resp: Response) -> None`

**Line:** 31

---

### `def response_chunks(response: Response, chunk_size: int = DOWNLOAD_CHUNK_SIZE) -> Generator[(bytes, None, None)]`

**Description:**
Given a requests Response, provide the data chunks.

**Line:** 59

---


## Module: venv2.libthon3.12.site-packages.pip._internal.operations.build.build_tracker
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/operations/build/build_tracker.py`

**Imports:**
- contextlib
- hashlib
- logging
- os
- pip._internal.req.req_install.InstallRequirement
- pip._internal.utils.temp_dir.TempDirectory
- types.TracebackType
- typing.Dict
- typing.Generator
- typing.Optional
- typing.Type
- typing.Union

**Functions:**

### `def update_env_context_manager(**changes: str) -> Generator[(None, None, None)]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 15

---

### `def get_build_tracker() -> Generator[('BuildTracker', None, None)]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 41

---


## Module: venv2.libthon3.12.site-packages.pip._internal.operations.build.metadata
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/operations/build/metadata.py`

**Imports:**
- os
- pip._internal.build_env.BuildEnvironment
- pip._internal.exceptions.InstallationSubprocessError
- pip._internal.exceptions.MetadataGenerationFailed
- pip._internal.utils.subprocess.runner_with_spinner_message
- pip._internal.utils.temp_dir.TempDirectory
- pip._vendor.pyproject_hooks.BuildBackendHookCaller

**Functions:**

### `def generate_metadata(build_env: BuildEnvironment, backend: BuildBackendHookCaller, details: str) -> str`

**Description:**
Generate metadata using mechanisms described in PEP 517.

Returns the generated metadata directory.

**Line:** 16

---


## Module: venv2.libthon3.12.site-packages.pip._internal.operations.build.metadata_editable
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/operations/build/metadata_editable.py`

**Imports:**
- os
- pip._internal.build_env.BuildEnvironment
- pip._internal.exceptions.InstallationSubprocessError
- pip._internal.exceptions.MetadataGenerationFailed
- pip._internal.utils.subprocess.runner_with_spinner_message
- pip._internal.utils.temp_dir.TempDirectory
- pip._vendor.pyproject_hooks.BuildBackendHookCaller

**Functions:**

### `def generate_editable_metadata(build_env: BuildEnvironment, backend: BuildBackendHookCaller, details: str) -> str`

**Description:**
Generate metadata using mechanisms described in PEP 660.

Returns the generated metadata directory.

**Line:** 16

---


## Module: venv2.libthon3.12.site-packages.pip._internal.operations.build.metadata_legacy
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/operations/build/metadata_legacy.py`

**Imports:**
- logging
- os
- pip._internal.build_env.BuildEnvironment
- pip._internal.cli.spinners.open_spinner
- pip._internal.exceptions.InstallationError
- pip._internal.exceptions.InstallationSubprocessError
- pip._internal.exceptions.MetadataGenerationFailed
- pip._internal.utils.setuptools_build.make_setuptools_egg_info_args
- pip._internal.utils.subprocess.call_subprocess
- pip._internal.utils.temp_dir.TempDirectory

**Functions:**

### `def _find_egg_info(directory: str) -> str`

**Description:**
Find an .egg-info subdirectory in `directory`.

**Line:** 20

---

### `def generate_metadata(build_env: BuildEnvironment, setup_py_path: str, source_dir: str, isolated: bool, details: str) -> str`

**Description:**
Generate metadata using setup.py-based defacto mechanisms.

Returns the generated metadata directory.

**Line:** 35

---


## Module: venv2.libthon3.12.site-packages.pip._internal.operations.build.wheel
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/operations/build/wheel.py`

**Imports:**
- logging
- os
- pip._internal.utils.subprocess.runner_with_spinner_message
- pip._vendor.pyproject_hooks.BuildBackendHookCaller
- typing.Optional

**Functions:**

### `def build_wheel_pep517(name: str, backend: BuildBackendHookCaller, metadata_directory: str, tempd: str) -> Optional[str]`

**Description:**
Build one InstallRequirement using the PEP 517 build process.

Returns path to wheel if successfully built. Otherwise, returns None.

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.pip._internal.operations.build.wheel_editable
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/operations/build/wheel_editable.py`

**Imports:**
- logging
- os
- pip._internal.utils.subprocess.runner_with_spinner_message
- pip._vendor.pyproject_hooks.BuildBackendHookCaller
- pip._vendor.pyproject_hooks.HookMissing
- typing.Optional

**Functions:**

### `def build_wheel_editable(name: str, backend: BuildBackendHookCaller, metadata_directory: str, tempd: str) -> Optional[str]`

**Description:**
Build one InstallRequirement using the PEP 660 build process.

Returns path to wheel if successfully built. Otherwise, returns None.

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.pip._internal.operations.build.wheel_legacy
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/operations/build/wheel_legacy.py`

**Imports:**
- logging
- os.path
- pip._internal.cli.spinners.open_spinner
- pip._internal.utils.deprecation.deprecated
- pip._internal.utils.setuptools_build.make_setuptools_bdist_wheel_args
- pip._internal.utils.subprocess.call_subprocess
- pip._internal.utils.subprocess.format_command_args
- typing.List
- typing.Optional

**Functions:**

### `def format_command_result(command_args: List[str], command_output: str) -> str`

**Description:**
Format command information for logging.

**Line:** 13

---

### `def get_legacy_build_wheel_path(names: List[str], temp_dir: str, name: str, command_args: List[str], command_output: str) -> Optional[str]`

**Description:**
Return the path to the wheel in the temporary build directory.

**Line:** 33

---

### `def build_wheel_legacy(name: str, setup_py_path: str, source_dir: str, global_options: List[str], build_options: List[str], tempd: str) -> Optional[str]`

**Description:**
Build one unpacked package using the "legacy" build process.

Returns path to wheel if successfully built. Otherwise, returns None.

**Line:** 60

---


## Module: venv2.libthon3.12.site-packages.pip._internal.operations.check
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/operations/check.py`

**Imports:**
- contextlib.suppress
- email.parser.Parser
- functools.reduce
- logging
- pip._internal.distributions.make_distribution_for_install_requirement
- pip._internal.metadata.base.BaseDistribution
- pip._internal.metadata.get_default_environment
- pip._internal.req.req_install.InstallRequirement
- pip._vendor.packaging.requirements.Requirement
- pip._vendor.packaging.tags.Tag
- pip._vendor.packaging.tags.parse_tag
- pip._vendor.packaging.utils.NormalizedName
- pip._vendor.packaging.utils.canonicalize_name
- pip._vendor.packaging.version.Version
- typing.Callable
- typing.Dict
- typing.FrozenSet
- typing.Generator
- typing.Iterable
- typing.List
- typing.NamedTuple
- typing.Optional
- typing.Set
- typing.Tuple

**Functions:**

### `def create_package_set_from_installed() -> Tuple[(PackageSet, bool)]`

**Description:**
Converts a list of distributions into a PackageSet.

**Line:** 49

---

### `def check_package_set(package_set: PackageSet, should_ignore: Optional[Callable[([str], bool)]] = None) -> CheckResult`

**Description:**
Check if a package set is consistent

If should_ignore is passed, it should be a callable that takes a
package name and returns a boolean.

**Line:** 66

---

### `def check_install_conflicts(to_install: List[InstallRequirement]) -> ConflictDetails`

**Description:**
For checking if the dependency graph would be consistent after     installing given requirements

**Line:** 111

---

### `def check_unsupported(packages: Iterable[BaseDistribution], supported_tags: Iterable[Tag]) -> Generator[(BaseDistribution, None, None)]`

**Line:** 131

---

### `def _simulate_installation_of(to_install: List[InstallRequirement], package_set: PackageSet) -> Set[NormalizedName]`

**Description:**
Computes the version of packages after installing to_install.

**Line:** 147

---

### `def _create_whitelist(would_be_installed: Set[NormalizedName], package_set: PackageSet) -> Set[NormalizedName]`

**Line:** 166

---


## Module: venv2.libthon3.12.site-packages.pip._internal.operations.freeze
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/operations/freeze.py`

**Imports:**
- collections
- dataclasses.dataclass
- dataclasses.field
- logging
- os
- pip._internal.exceptions.BadCommand
- pip._internal.exceptions.InstallationError
- pip._internal.metadata.BaseDistribution
- pip._internal.metadata.get_environment
- pip._internal.req.constructors.install_req_from_editable
- pip._internal.req.constructors.install_req_from_line
- pip._internal.req.req_file.COMMENT_RE
- pip._internal.utils.direct_url_helpers.direct_url_as_pep440_direct_reference
- pip._internal.vcs.RemoteNotFoundError
- pip._internal.vcs.RemoteNotValidError
- pip._internal.vcs.vcs
- pip._vendor.packaging.utils.NormalizedName
- pip._vendor.packaging.utils.canonicalize_name
- pip._vendor.packaging.version.InvalidVersion
- typing.Container
- typing.Dict
- typing.Generator
- typing.Iterable
- typing.List
- typing.NamedTuple
- typing.Optional
- typing.Set

**Functions:**

### `def freeze(requirement: Optional[List[str]] = None, local_only: bool = False, user_only: bool = False, paths: Optional[List[str]] = None, isolated: bool = False, exclude_editable: bool = False, skip: Container[str] = ()) -> Generator[(str, None, None)]`

**Line:** 27

---

### `def _format_as_name_version(dist: BaseDistribution) -> str`

**Line:** 148

---

### `def _get_editable_info(dist: BaseDistribution) -> _EditableInfo`

**Description:**
Compute and return values (req, comments) for use in
FrozenRequirement.from_dist().

**Line:** 158

---


## Module: venv2.libthon3.12.site-packages.pip._internal.operations.install.editable_legacy
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/operations/install/editable_legacy.py`

**Imports:**
- logging
- pip._internal.build_env.BuildEnvironment
- pip._internal.utils.logging.indent_log
- pip._internal.utils.setuptools_build.make_setuptools_develop_args
- pip._internal.utils.subprocess.call_subprocess
- typing.Optional
- typing.Sequence

**Functions:**

### `def install_editable(global_options: Sequence[str], prefix: Optional[str], home: Optional[str], use_user_site: bool, name: str, setup_py_path: str, isolated: bool, build_env: BuildEnvironment, unpacked_source_directory: str) -> None`

**Description:**
Install a package in editable mode. Most arguments are pass-through
to setuptools.

**Line:** 14

---


## Module: venv2.libthon3.12.site-packages.pip._internal.operations.install.wheel
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/operations/install/wheel.py`

**Imports:**
- base64.urlsafe_b64encode
- collections
- compileall
- contextlib
- csv
- email.message.Message
- importlib
- itertools.chain
- itertools.filterfalse
- itertools.starmap
- logging
- os.path
- pip._internal.exceptions.InstallationError
- pip._internal.locations.get_major_minor_version
- pip._internal.metadata.BaseDistribution
- pip._internal.metadata.FilesystemWheel
- pip._internal.metadata.get_wheel_distribution
- pip._internal.models.direct_url.DIRECT_URL_METADATA_NAME
- pip._internal.models.direct_url.DirectUrl
- pip._internal.models.scheme.SCHEME_KEYS
- pip._internal.models.scheme.Scheme
- pip._internal.utils.filesystem.adjacent_tmp_file
- pip._internal.utils.filesystem.replace
- pip._internal.utils.misc.StreamWrapper
- pip._internal.utils.misc.ensure_dir
- pip._internal.utils.misc.hash_file
- pip._internal.utils.misc.partition
- pip._internal.utils.unpacking.current_umask
- pip._internal.utils.unpacking.is_within_directory
- pip._internal.utils.unpacking.set_extracted_file_to_default_mode_plus_executable
- pip._internal.utils.unpacking.zip_item_is_executable
- pip._internal.utils.wheel.parse_wheel
- pip._vendor.distlib.scripts.ScriptMaker
- pip._vendor.distlib.util.get_export_entry
- pip._vendor.packaging.utils.canonicalize_name
- re
- shutil
- sys
- typing.Any
- typing.BinaryIO
- typing.Callable
- typing.Dict
- typing.Generator
- typing.IO
- typing.Iterable
- typing.Iterator
- typing.List
- typing.NewType
- typing.Optional
- typing.Protocol
- typing.Sequence
- typing.Set
- typing.Tuple
- typing.Union
- typing.cast
- warnings
- zipfile.ZipFile
- zipfile.ZipInfo

**Functions:**

### `def rehash(path: str, blocksize: int = 1 << 20) -> Tuple[(str, str)]`

**Description:**
Return (encoded_digest, length) for path using hashlib.sha256()

**Line:** 77

---

### `def csv_io_kwargs(mode: str) -> Dict[(str, Any)]`

**Description:**
Return keyword arguments to properly open a CSV file
in the given mode.

**Line:** 84

---

### `def fix_script(path: str) -> bool`

**Description:**
Replace #!python with #!/path/to/python
Return True if file was changed.

**Line:** 91

---

### `def wheel_root_is_purelib(metadata: Message) -> bool`

**Line:** 111

---

### `def get_entrypoints(dist: BaseDistribution) -> Tuple[(Dict[str, str], Dict[str, str])]`

**Line:** 115

---

### `def message_about_scripts_not_on_PATH(scripts: Sequence[str]) -> Optional[str]`

**Description:**
Determine if any scripts are not on PATH and format a warning.
Returns a warning message if one or more scripts are not on PATH,
otherwise None.

**Line:** 126

---

### `def _normalized_outrows(outrows: Iterable[InstalledCSVRow]) -> List[Tuple[(str, str, str)]]`

**Description:**
Normalize the given rows of a RECORD file.

Items in each row are converted into str. Rows are then sorted to make
the value more predictable for tests.

Each row is a 3-tuple (path, hash, size) and corresponds to a record of
a RECORD file (see PEP 376 and PEP 427 for details).  For the rows
passed to this function, the size can be an integer as an int or string,
or the empty string.

**Line:** 198

---

### `def _record_to_fs_path(record_path: RecordPath, lib_dir: str) -> str`

**Line:** 224

---

### `def _fs_to_record_path(path: str, lib_dir: str) -> RecordPath`

**Line:** 228

---

### `def get_csv_rows_for_installed(old_csv_rows: List[List[str]], installed: Dict[(RecordPath, RecordPath)], changed: Set[RecordPath], generated: List[str], lib_dir: str) -> List[InstalledCSVRow]`

**Description:**
:param installed: A map from archive RECORD path to installation RECORD
path.

**Line:** 238

---

### `def get_console_script_specs(console: Dict[(str, str)]) -> List[str]`

**Description:**
Given the mapping from entrypoint name to callable, return the relevant
console script specs.

**Line:** 270

---

### `def _raise_for_invalid_entrypoint(specification: str) -> None`

**Line:** 405

---

### `def _install_wheel(name: str, wheel_zip: ZipFile, wheel_path: str, scheme: Scheme, pycompile: bool = True, warn_script_location: bool = True, direct_url: Optional[DirectUrl] = None, requested: bool = False) -> None`

**Description:**
Install a wheel.

:param name: Name of the project to install
:param wheel_zip: open ZipFile for wheel being installed
:param scheme: Distutils scheme dictating the install directories
:param req_description: String used in place of the requirement, for
logging
:param pycompile: Whether to byte-compile installed Python files
:param warn_script_location: Whether to check that scripts are installed
into a directory on PATH
:raises UnsupportedWheel:
* when the directory holds an unpacked wheel with incompatible
Wheel-Version
* when the .dist-info dir does not match the wheel

**Line:** 419

---

### `def req_error_context(req_description: str) -> Generator[(None, None, None)]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 709

---

### `def install_wheel(name: str, wheel_path: str, scheme: Scheme, req_description: str, pycompile: bool = True, warn_script_location: bool = True, direct_url: Optional[DirectUrl] = None, requested: bool = False) -> None`

**Line:** 717

---


## Module: venv2.libthon3.12.site-packages.pip._internal.operations.prepare
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/operations/prepare.py`

**Imports:**
- dataclasses.dataclass
- mimetypes
- os
- pathlib.Path
- pip._internal.distributions.installed.InstalledDistribution
- pip._internal.distributions.make_distribution_for_install_requirement
- pip._internal.exceptions.DirectoryUrlHashUnsupported
- pip._internal.exceptions.HashMismatch
- pip._internal.exceptions.HashUnpinned
- pip._internal.exceptions.InstallationError
- pip._internal.exceptions.MetadataInconsistent
- pip._internal.exceptions.NetworkConnectionError
- pip._internal.exceptions.VcsHashUnsupported
- pip._internal.index.package_finder.PackageFinder
- pip._internal.metadata.BaseDistribution
- pip._internal.metadata.get_metadata_distribution
- pip._internal.models.direct_url.ArchiveInfo
- pip._internal.models.link.Link
- pip._internal.models.wheel.Wheel
- pip._internal.network.download.BatchDownloader
- pip._internal.network.download.Downloader
- pip._internal.network.lazy_wheel.HTTPRangeRequestUnsupported
- pip._internal.network.lazy_wheel.dist_from_wheel_url
- pip._internal.network.session.PipSession
- pip._internal.operations.build.build_tracker.BuildTracker
- pip._internal.req.req_install.InstallRequirement
- pip._internal.utils._log.getLogger
- pip._internal.utils.direct_url_helpers.direct_url_for_editable
- pip._internal.utils.direct_url_helpers.direct_url_from_link
- pip._internal.utils.hashes.Hashes
- pip._internal.utils.hashes.MissingHashes
- pip._internal.utils.logging.indent_log
- pip._internal.utils.misc.display_path
- pip._internal.utils.misc.hash_file
- pip._internal.utils.misc.hide_url
- pip._internal.utils.misc.redact_auth_from_requirement
- pip._internal.utils.temp_dir.TempDirectory
- pip._internal.utils.unpacking.unpack_file
- pip._internal.vcs.vcs
- pip._vendor.packaging.utils.canonicalize_name
- shutil
- typing.Dict
- typing.Iterable
- typing.List
- typing.Optional

**Functions:**

### `def _get_prepared_distribution(req: InstallRequirement, build_tracker: BuildTracker, finder: PackageFinder, build_isolation: bool, check_build_deps: bool) -> BaseDistribution`

**Description:**
Prepare a distribution for installation.

**Line:** 59

---

### `def unpack_vcs_link(link: Link, location: str, verbosity: int) -> None`

**Line:** 77

---

### `def get_http_url(link: Link, download: Downloader, download_dir: Optional[str] = None, hashes: Optional[Hashes] = None) -> File`

**Line:** 98

---

### `def get_file_url(link: Link, download_dir: Optional[str] = None, hashes: Optional[Hashes] = None) -> File`

**Description:**
Get file and optionally check its hash.

**Line:** 122

---

### `def unpack_url(link: Link, location: str, download: Downloader, verbosity: int, download_dir: Optional[str] = None, hashes: Optional[Hashes] = None) -> Optional[File]`

**Description:**
Unpack link into location, downloading if required.

:param hashes: A Hashes object, one of whose embedded hashes must match,
or HashMismatch will be raised. If the Hashes is empty, no matches are
required, and unhashable types of requirements (like VCS ones, which
would ordinarily raise HashUnsupported) are allowed.

**Line:** 146

---

### `def _check_download_dir(link: Link, download_dir: str, hashes: Optional[Hashes], warn_on_hash_mismatch: bool = True) -> Optional[str]`

**Description:**
Check download_dir for previously downloaded file with correct hash
If a correct file is found return its path else None

**Line:** 189

---


## Module: venv2.libthon3.12.site-packages.pip._internal.req.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/req/__init__.py`

**Imports:**
- collections
- dataclasses.dataclass
- logging
- pip._internal.cli.progress_bars.get_install_progress_renderer
- pip._internal.utils.logging.indent_log
- req_file.parse_requirements
- req_install.InstallRequirement
- req_set.RequirementSet
- typing.Generator
- typing.List
- typing.Optional
- typing.Sequence
- typing.Tuple

**Functions:**

### `def _validate_requirements(requirements: List[InstallRequirement]) -> Generator[(Tuple[str, InstallRequirement], None, None)]`

**Line:** 28

---

### `def install_given_reqs(requirements: List[InstallRequirement], global_options: Sequence[str], root: Optional[str], home: Optional[str], prefix: Optional[str], warn_script_location: bool, use_user_site: bool, pycompile: bool, progress_bar: str) -> List[InstallationResult]`

**Description:**
Install everything in the given list.

(to be called after having downloaded and unpacked the packages)

**Line:** 36

---


## Module: venv2.libthon3.12.site-packages.pip._internal.req.constructors
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/req/constructors.py`

**Imports:**
- copy
- dataclasses.dataclass
- logging
- os
- pip._internal.exceptions.InstallationError
- pip._internal.models.index.PyPI
- pip._internal.models.index.TestPyPI
- pip._internal.models.link.Link
- pip._internal.models.wheel.Wheel
- pip._internal.req.req_file.ParsedRequirement
- pip._internal.req.req_install.InstallRequirement
- pip._internal.utils.filetypes.is_archive_file
- pip._internal.utils.misc.is_installable_dir
- pip._internal.utils.packaging.get_requirement
- pip._internal.utils.urls.path_to_url
- pip._internal.vcs.is_url
- pip._internal.vcs.vcs
- pip._vendor.packaging.markers.Marker
- pip._vendor.packaging.requirements.InvalidRequirement
- pip._vendor.packaging.requirements.Requirement
- pip._vendor.packaging.specifiers.Specifier
- re
- typing.Collection
- typing.Dict
- typing.List
- typing.Optional
- typing.Set
- typing.Tuple
- typing.Union

**Functions:**

### `def _strip_extras(path: str) -> Tuple[(str, Optional[str])]`

**Line:** 44

---

### `def convert_extras(extras: Optional[str]) -> Set[str]`

**Line:** 56

---

### `def _set_requirement_extras(req: Requirement, new_extras: Set[str]) -> Requirement`

**Description:**
Returns a new requirement based on the given one, with the supplied extras. If the
given requirement already has extras those are replaced (or dropped if no new extras
are given).

**Line:** 62

---

### `def parse_editable(editable_req: str) -> Tuple[(Optional[str], str, Set[str])]`

**Description:**
Parses an editable requirement into:
- a requirement name
- an URL
- extras
- editable options
Accepted requirements:
svn+http://blahblah@rev#egg=Foobar[baz]&subdirectory=version_subdir
.[some_extra]

**Line:** 87

---

### `def check_first_requirement_in_file(filename: str) -> None`

**Description:**
Check if file is parsable as a requirements file.

This is heavily based on ``pkg_resources.parse_requirements``, but
simplified to just check the first meaningful line.

:raises InvalidRequirement: If the first meaningful line cannot be parsed
as an requirement.

**Line:** 142

---

### `def deduce_helpful_msg(req: str) -> str`

**Description:**
Returns helpful msg in case requirements file does not exist,
or cannot be parsed.

:params req: Requirements file path

**Line:** 170

---

### `def parse_req_from_editable(editable_req: str) -> RequirementParts`

**Line:** 203

---

### `def install_req_from_editable(editable_req: str, comes_from: Optional[Union[(InstallRequirement, str)]] = None, use_pep517: Optional[bool] = None, isolated: bool = False, global_options: Optional[List[str]] = None, hash_options: Optional[Dict[(str, List[str])]] = None, constraint: bool = False, user_supplied: bool = False, permit_editable_wheels: bool = False, config_settings: Optional[Dict[(str, Union[str, List[str]])]] = None) -> InstallRequirement`

**Line:** 222

---

### `def _looks_like_path(name: str) -> bool`

**Description:**
Checks whether the string "looks like" a path on the filesystem.

This does not check whether the target actually exists, only judge from the
appearance.

Returns true if any of the following conditions is true:
* a path separator is found (either os.path.sep or os.path.altsep);
* a dot is found (which represents the current directory).

**Line:** 254

---

### `def _get_url_from_path(path: str, name: str) -> Optional[str]`

**Description:**
First, it checks whether a provided path is an installable directory. If it
is, returns the path.

If false, check if the path is an archive file (such as a .whl).
The function checks if the path is a file. If false, if the path has
an @, it will treat it as a PEP 440 URL requirement and return the path.

**Line:** 273

---

### `def parse_req_from_line(name: str, line_source: Optional[str]) -> RequirementParts`

**Line:** 307

---

### `def install_req_from_line(name: str, comes_from: Optional[Union[(str, InstallRequirement)]] = None, use_pep517: Optional[bool] = None, isolated: bool = False, global_options: Optional[List[str]] = None, hash_options: Optional[Dict[(str, List[str])]] = None, constraint: bool = False, line_source: Optional[str] = None, user_supplied: bool = False, config_settings: Optional[Dict[(str, Union[str, List[str]])]] = None) -> InstallRequirement`

**Description:**
Creates an InstallRequirement from a name, which might be a
requirement, directory containing 'setup.py', filename, or URL.

:param line_source: An optional string describing where the line is from,
for logging purposes in case of an error.

**Line:** 386

---

### `def install_req_from_req_string(req_string: str, comes_from: Optional[InstallRequirement] = None, isolated: bool = False, use_pep517: Optional[bool] = None, user_supplied: bool = False) -> InstallRequirement`

**Line:** 423

---

### `def install_req_from_parsed_requirement(parsed_req: ParsedRequirement, isolated: bool = False, use_pep517: Optional[bool] = None, user_supplied: bool = False, config_settings: Optional[Dict[(str, Union[str, List[str]])]] = None) -> InstallRequirement`

**Line:** 461

---

### `def install_req_from_link_and_ireq(link: Link, ireq: InstallRequirement) -> InstallRequirement`

**Line:** 501

---

### `def install_req_drop_extras(ireq: InstallRequirement) -> InstallRequirement`

**Description:**
Creates a new InstallationRequirement using the given template but without
any extras. Sets the original requirement as the new one's parent
(comes_from).

**Line:** 519

---

### `def install_req_extend_extras(ireq: InstallRequirement, extras: Collection[str]) -> InstallRequirement`

**Description:**
Returns a copy of an installation requirement with some additional extras.
Makes a shallow copy of the ireq object.

**Line:** 545

---


## Module: venv2.libthon3.12.site-packages.pip._internal.req.req_dependency_group
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/req/req_dependency_group.py`

**Imports:**
- pip._internal.exceptions.InstallationError
- pip._vendor.dependency_groups.DependencyGroupResolver
- pip._vendor.tomli
- sys
- tomllib
- typing.Any
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Tuple

**Functions:**

### `def parse_dependency_groups(groups: List[Tuple[(str, str)]]) -> List[str]`

**Description:**
Parse dependency groups data as provided via the CLI, in a `[path:]group` syntax.

Raises InstallationErrors if anything goes wrong.

**Line:** 14

---

### `def _resolve_all_groups(resolvers: Dict[(str, DependencyGroupResolver)], groups: List[Tuple[(str, str)]]) -> Iterator[str]`

**Description:**
Run all resolution, converting any error from `DependencyGroupResolver` into
an InstallationError.

**Line:** 24

---

### `def _build_resolvers(paths: Iterable[str]) -> Dict[(str, Any)]`

**Line:** 42

---

### `def _load_pyproject(path: str) -> Dict[(str, Any)]`

**Description:**
This helper loads a pyproject.toml as TOML.

It raises an InstallationError if the operation fails.

**Line:** 65

---


## Module: venv2.libthon3.12.site-packages.pip._internal.req.req_file
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/req/req_file.py`

**Imports:**
- codecs
- dataclasses.dataclass
- locale
- logging
- optparse
- optparse.Values
- os
- pip._internal.cli.cmdoptions
- pip._internal.exceptions.InstallationError
- pip._internal.exceptions.RequirementsFileParseError
- pip._internal.index.package_finder.PackageFinder
- pip._internal.models.search_scope.SearchScope
- pip._internal.network.session.PipSession
- pip._internal.network.utils.raise_for_status
- re
- shlex
- sys
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generator
- typing.Iterable
- typing.List
- typing.NoReturn
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- urllib.parse

**Functions:**

### `def parse_requirements(filename: str, session: 'PipSession', finder: Optional['PackageFinder'] = None, options: Optional[optparse.Values] = None, constraint: bool = False) -> Generator[(ParsedRequirement, None, None)]`

**Description:**
Parse a requirements file and yield ParsedRequirement instances.

:param filename:    Path or url of requirements file.
:param session:     PipSession instance.
:param finder:      Instance of pip.index.PackageFinder.
:param options:     cli options.
:param constraint:  If true, parsing a constraint file rather than
requirements file.

**Line:** 149

---

### `def preprocess(content: str) -> ReqFileLines`

**Description:**
Split, filter, and join lines, and return a line iterator

:param content: the content of the requirements file

**Line:** 176

---

### `def handle_requirement_line(line: ParsedLine, options: Optional[optparse.Values] = None) -> ParsedRequirement`

**Line:** 188

---

### `def handle_option_line(opts: Values, filename: str, lineno: int, finder: Optional['PackageFinder'] = None, options: Optional[optparse.Values] = None, session: Optional['PipSession'] = None) -> None`

**Line:** 222

---

### `def handle_line(line: ParsedLine, options: Optional[optparse.Values] = None, finder: Optional['PackageFinder'] = None, session: Optional['PipSession'] = None) -> Optional[ParsedRequirement]`

**Description:**
Handle a single parsed requirements line; This can result in
creating/yielding requirements, or updating the finder.

:param line:        The parsed line to be processed.
:param options:     CLI options.
:param finder:      The finder - updated by non-requirement lines.
:param session:     The session - updated by non-requirement lines.

Returns a ParsedRequirement object if the line is a requirement line,
otherwise returns None.

For lines that contain requirements, the only options that have an effect
are from SUPPORTED_OPTIONS_REQ, and they are scoped to the
requirement. Other options from SUPPORTED_OPTIONS may be present, but are
ignored.

For lines that do not contain requirements, the only options that have an
effect are from SUPPORTED_OPTIONS. Options from SUPPORTED_OPTIONS_REQ may
be present, but are ignored. These lines may contain multiple options
(although our docs imply only one is supported), and all our parsed and
affect the finder.

**Line:** 292

---

### `def get_line_parser(finder: Optional['PackageFinder']) -> LineParser`

**Line:** 429

---

### `def break_args_options(line: str) -> Tuple[(str, str)]`

**Description:**
Break up the line into an args and options string.  We only want to shlex
(and then optparse) the options, not the args.  args can contain markers
which are corrupted by shlex.

**Line:** 453

---

### `def build_parser() -> optparse.OptionParser`

**Description:**
Return a parser for parsing requirement lines

**Line:** 475

---

### `def join_lines(lines_enum: ReqFileLines) -> ReqFileLines`

**Description:**
Joins a line ending in '' with the previous line (except when following
comments).  The joined line takes on the index of the first line.

**Line:** 498

---

### `def ignore_comments(lines_enum: ReqFileLines) -> ReqFileLines`

**Description:**
Strips comments and filter empty lines.

**Line:** 529

---

### `def expand_env_variables(lines_enum: ReqFileLines) -> ReqFileLines`

**Description:**
Replace all environment variables that can be retrieved via `os.getenv`.

The only allowed format for environment variables defined in the
requirement file is `${MY_VARIABLE_1}` to ensure two things:

1. Strings that contain a `$` aren't accidentally (partially) expanded.
2. Ensure consistency across platforms for requirement files.

These points are the result of a discussion on the `github pull
request #3514 <https://github.com/pypa/pip/pull/3514>`_.

Valid characters in variable names follow the `POSIX standard
<http://pubs.opengroup.org/onlinepubs/9699919799/>`_ and are limited
to uppercase letter, digits and the `_` (underscore).

**Line:** 540

---

### `def get_file_content(url: str, session: 'PipSession') -> Tuple[(str, str)]`

**Description:**
Gets the content of a file; it may be a filename, file: URL, or
http: URL.  Returns (location, content).  Content is unicode.
Respects # -*- coding: declarations on the retrieved files.

:param url:         File path or url.
:param session:     PipSession instance.

**Line:** 567

---

### `def _decode_req_file(data: bytes, url: str) -> str`

**Line:** 597

---


## Module: venv2.libthon3.12.site-packages.pip._internal.req.req_install
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/req/req_install.py`

**Imports:**
- functools
- logging
- optparse.Values
- os
- pathlib.Path
- pip._internal.build_env.BuildEnvironment
- pip._internal.build_env.NoOpBuildEnvironment
- pip._internal.exceptions.InstallationError
- pip._internal.exceptions.PreviousBuildDirError
- pip._internal.locations.get_scheme
- pip._internal.metadata.BaseDistribution
- pip._internal.metadata.base.FilesystemWheel
- pip._internal.metadata.get_default_environment
- pip._internal.metadata.get_directory_distribution
- pip._internal.metadata.get_wheel_distribution
- pip._internal.models.direct_url.DirectUrl
- pip._internal.models.link.Link
- pip._internal.operations.build.metadata.generate_metadata
- pip._internal.operations.build.metadata_editable.generate_editable_metadata
- pip._internal.operations.build.metadata_legacy.generate_metadata
- pip._internal.operations.install.editable_legacy.install_editable
- pip._internal.operations.install.wheel.install_wheel
- pip._internal.pyproject.load_pyproject_toml
- pip._internal.pyproject.make_pyproject_path
- pip._internal.req.req_uninstall.UninstallPathSet
- pip._internal.utils.deprecation.deprecated
- pip._internal.utils.hashes.Hashes
- pip._internal.utils.misc.ConfiguredBuildBackendHookCaller
- pip._internal.utils.misc.ask_path_exists
- pip._internal.utils.misc.backup_dir
- pip._internal.utils.misc.display_path
- pip._internal.utils.misc.hide_url
- pip._internal.utils.misc.is_installable_dir
- pip._internal.utils.misc.redact_auth_from_requirement
- pip._internal.utils.misc.redact_auth_from_url
- pip._internal.utils.packaging.get_requirement
- pip._internal.utils.subprocess.runner_with_spinner_message
- pip._internal.utils.temp_dir.TempDirectory
- pip._internal.utils.temp_dir.tempdir_kinds
- pip._internal.utils.unpacking.unpack_file
- pip._internal.utils.virtualenv.running_under_virtualenv
- pip._internal.vcs.vcs
- pip._vendor.packaging.markers.Marker
- pip._vendor.packaging.requirements.Requirement
- pip._vendor.packaging.specifiers.SpecifierSet
- pip._vendor.packaging.utils.canonicalize_name
- pip._vendor.packaging.version.Version
- pip._vendor.packaging.version.parse
- pip._vendor.pyproject_hooks.BuildBackendHookCaller
- shutil
- sys
- typing.Any
- typing.Collection
- typing.Dict
- typing.Iterable
- typing.List
- typing.Optional
- typing.Sequence
- typing.Union
- uuid
- zipfile

**Functions:**

### `def check_invalid_constraint_type(req: InstallRequirement) -> str`

**Line:** 880

---

### `def _has_option(options: Values, reqs: List[InstallRequirement], option: str) -> bool`

**Line:** 908

---

### `def check_legacy_setup_py_options(options: Values, reqs: List[InstallRequirement]) -> None`

**Line:** 917

---


## Module: venv2.libthon3.12.site-packages.pip._internal.req.req_uninstall
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/req/req_uninstall.py`

**Imports:**
- functools
- importlib.util.cache_from_source
- os
- pip._internal.exceptions.LegacyDistutilsInstall
- pip._internal.exceptions.UninstallMissingRecord
- pip._internal.locations.get_bin_prefix
- pip._internal.locations.get_bin_user
- pip._internal.metadata.BaseDistribution
- pip._internal.utils.compat.WINDOWS
- pip._internal.utils.egg_link.egg_link_path_from_location
- pip._internal.utils.logging.getLogger
- pip._internal.utils.logging.indent_log
- pip._internal.utils.misc.ask
- pip._internal.utils.misc.normalize_path
- pip._internal.utils.misc.renames
- pip._internal.utils.misc.rmtree
- pip._internal.utils.temp_dir.AdjacentTempDirectory
- pip._internal.utils.temp_dir.TempDirectory
- pip._internal.utils.virtualenv.running_under_virtualenv
- sys
- sysconfig
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generator
- typing.Iterable
- typing.List
- typing.Optional
- typing.Set
- typing.Tuple

**Functions:**

### `def _script_names(bin_dir: str, script_name: str, is_gui: bool) -> Generator[(str, None, None)]`

**Description:**
Create the fully qualified name of the files created by
{console,gui}_scripts for the given ``dist``.
Returns the list of file names

**Line:** 21

---

### `def _unique(fn: Callable[(..., Generator[Any, None, None])]) -> Callable[(..., Generator[Any, None, None])]`

**Line:** 40

---

### `def uninstallation_paths(dist: BaseDistribution) -> Generator[(str, None, None)]`

**Decorators:**
- `@_unique`

**Description:**
Yield all the uninstallation paths for dist based on RECORD-without-.py[co]

Yield paths to all the files in RECORD. For each .py file in RECORD, add
the .pyc and .pyo in the same directory.

UninstallPathSet.add() takes care of the __pycache__ .py[co].

If RECORD is not found, raises an error,
with possible information from the INSTALLER file.

https://packaging.python.org/specifications/recording-installed-packages/

**Line:** 55

---

### `def compact(paths: Iterable[str]) -> Set[str]`

**Description:**
Compact a path set to contain the minimal number of paths
necessary to contain all paths in the set. If /a/path/ and
/a/path/to/a/file.txt are both in the set, leave only the
shorter path.

**Line:** 88

---

### `def compress_for_rename(paths: Iterable[str]) -> Set[str]`

**Description:**
Returns a set containing the paths that need to be renamed.

This set may include directories when the original sequence of paths
included every file on disk.

**Line:** 107

---

### `def compress_for_output_listing(paths: Iterable[str]) -> Tuple[(Set[str], Set[str])]`

**Description:**
Returns a tuple of 2 sets of which paths to display to user

The first set contains paths that would be deleted. Files of a package
are not added and the top-level directory of the package has a '*' added
at the end - to signify that all it's contents are removed.

The second set contains files that would have been skipped in the above
folders.

**Line:** 141

---


## Module: venv2.libthon3.12.site-packages.pip._internal.resolution.legacy.resolver
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/resolution/legacy/resolver.py`

**Imports:**
- collections.defaultdict
- itertools.chain
- logging
- pip._internal.cache.WheelCache
- pip._internal.exceptions.BestVersionAlreadyInstalled
- pip._internal.exceptions.DistributionNotFound
- pip._internal.exceptions.HashError
- pip._internal.exceptions.HashErrors
- pip._internal.exceptions.InstallationError
- pip._internal.exceptions.NoneMetadataError
- pip._internal.exceptions.UnsupportedPythonVersion
- pip._internal.index.package_finder.PackageFinder
- pip._internal.metadata.BaseDistribution
- pip._internal.models.link.Link
- pip._internal.models.wheel.Wheel
- pip._internal.operations.prepare.RequirementPreparer
- pip._internal.req.req_install.InstallRequirement
- pip._internal.req.req_install.check_invalid_constraint_type
- pip._internal.req.req_set.RequirementSet
- pip._internal.resolution.base.BaseResolver
- pip._internal.resolution.base.InstallRequirementProvider
- pip._internal.utils.compatibility_tags
- pip._internal.utils.compatibility_tags.get_supported
- pip._internal.utils.direct_url_helpers.direct_url_from_link
- pip._internal.utils.logging.indent_log
- pip._internal.utils.misc.normalize_version_info
- pip._internal.utils.packaging.check_requires_python
- pip._vendor.packaging.requirements.Requirement
- pip._vendor.packaging.specifiers
- sys
- typing.DefaultDict
- typing.Iterable
- typing.List
- typing.Optional
- typing.Set
- typing.Tuple

**Functions:**

### `def _check_dist_requires_python(dist: BaseDistribution, version_info: Tuple[(int, int, int)], ignore_requires_python: bool = False) -> None`

**Description:**
Check whether the given Python version is compatible with a distribution's
"Requires-Python" value.

:param version_info: A 3-tuple of ints representing the Python
major-minor-micro version to check.
:param ignore_requires_python: Whether to ignore the "Requires-Python"
value if the given Python version isn't compatible.

:raises UnsupportedPythonVersion: When the given Python version isn't
compatible.

**Line:** 55

---


## Module: venv2.libthon3.12.site-packages.pip._internal.resolution.resolvelib.base
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py`

**Imports:**
- dataclasses.dataclass
- pip._internal.models.link.Link
- pip._internal.models.link.links_equivalent
- pip._internal.req.req_install.InstallRequirement
- pip._internal.utils.hashes.Hashes
- pip._vendor.packaging.specifiers.SpecifierSet
- pip._vendor.packaging.utils.NormalizedName
- pip._vendor.packaging.version.Version
- typing.FrozenSet
- typing.Iterable
- typing.Optional
- typing.Tuple

**Functions:**

### `def format_name(project: NormalizedName, extras: FrozenSet[NormalizedName]) -> str`

**Line:** 15

---

### `def _match_link(link: Link, candidate: 'Candidate') -> bool`

**Line:** 90

---


## Module: venv2.libthon3.12.site-packages.pip._internal.resolution.resolvelib.candidates
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py`

**Imports:**
- base.Candidate
- base.Requirement
- base.format_name
- factory.Factory
- logging
- pip._internal.exceptions.HashError
- pip._internal.exceptions.InstallationSubprocessError
- pip._internal.exceptions.InvalidInstalledPackage
- pip._internal.exceptions.MetadataInconsistent
- pip._internal.exceptions.MetadataInvalid
- pip._internal.metadata.BaseDistribution
- pip._internal.models.link.Link
- pip._internal.models.link.links_equivalent
- pip._internal.models.wheel.Wheel
- pip._internal.req.constructors.install_req_from_editable
- pip._internal.req.constructors.install_req_from_line
- pip._internal.req.req_install.InstallRequirement
- pip._internal.utils.direct_url_helpers.direct_url_from_link
- pip._internal.utils.misc.normalize_version_info
- pip._vendor.packaging.requirements.InvalidRequirement
- pip._vendor.packaging.utils.NormalizedName
- pip._vendor.packaging.utils.canonicalize_name
- pip._vendor.packaging.version.Version
- sys
- typing.Any
- typing.FrozenSet
- typing.Iterable
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- typing.cast

**Functions:**

### `def as_base_candidate(candidate: Candidate) -> Optional[BaseCandidate]`

**Description:**
The runtime version of BaseCandidate.

**Line:** 44

---

### `def make_install_req_from_link(link: Link, template: InstallRequirement) -> InstallRequirement`

**Line:** 56

---

### `def make_install_req_from_editable(link: Link, template: InstallRequirement) -> InstallRequirement`

**Line:** 81

---

### `def _make_install_req_from_dist(dist: BaseDistribution, template: InstallRequirement) -> InstallRequirement`

**Line:** 101

---


## Module: venv2.libthon3.12.site-packages.pip._internal.resolution.resolvelib.found_candidates
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py`

**Imports:**
- base.Candidate
- collections.abc.Sequence
- logging
- pip._internal.exceptions.MetadataInvalid
- pip._vendor.packaging.version._BaseVersion
- typing.Any
- typing.Callable
- typing.Iterator
- typing.Optional
- typing.Set
- typing.Tuple

**Functions:**

### `def _iter_built(infos: Iterator[IndexCandidateInfo]) -> Iterator[Candidate]`

**Description:**
Iterator for ``FoundCandidates``.

This iterator is used when the package is not already installed. Candidates
from index come later in their normal ordering.

**Line:** 26

---

### `def _iter_built_with_prepended(installed: Candidate, infos: Iterator[IndexCandidateInfo]) -> Iterator[Candidate]`

**Description:**
Iterator for ``FoundCandidates``.

This iterator is used when the resolver prefers the already-installed
candidate and NOT to upgrade. The installed candidate is therefore
always yielded first, and candidates from index come later in their
normal ordering, except skipped when the version is already installed.

**Line:** 57

---

### `def _iter_built_with_inserted(installed: Candidate, infos: Iterator[IndexCandidateInfo]) -> Iterator[Candidate]`

**Description:**
Iterator for ``FoundCandidates``.

This iterator is used when the resolver prefers to upgrade an
already-installed package. Candidates from index are returned in their
normal ordering, except replaced when the version is already installed.

The implementation iterates through and yields other candidates, inserting
the installed candidate exactly once before we start yielding older or
equivalent candidates, or after all other candidates if they are all newer.

**Line:** 79

---


## Module: venv2.libthon3.12.site-packages.pip._internal.resolution.resolvelib.provider
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/provider.py`

**Imports:**
- base.Candidate
- base.Constraint
- base.Requirement
- candidates.REQUIRES_PYTHON_IDENTIFIER
- factory.Factory
- functools.lru_cache
- math
- pip._internal.req.req_install.InstallRequirement
- pip._vendor.resolvelib.providers.AbstractProvider
- pip._vendor.resolvelib.providers.Preference
- pip._vendor.resolvelib.resolvers.RequirementInformation
- requirements.ExplicitRequirement
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.Mapping
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union

**Functions:**

### `def _get_with_identifier(mapping: Mapping[(str, V)], identifier: str, default: D) -> Union[(D, V)]`

**Description:**
Get item from a package name lookup mapping with a resolver identifier.

This extra logic is needed when the target mapping is keyed by package
name, which cannot be directly looked up with an identifier (which may
contain requested extras). Additional logic is added to also look up a value
by "cleaning up" the extras from the identifier.

**Line:** 58

---


## Module: venv2.libthon3.12.site-packages.pip._internal.resolution.resolvelib.resolver
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/resolver.py`

**Imports:**
- base.Candidate
- base.Requirement
- contextlib
- factory.Factory
- functools
- logging
- os
- pip._internal.cache.WheelCache
- pip._internal.exceptions.ResolutionTooDeepError
- pip._internal.index.package_finder.PackageFinder
- pip._internal.operations.prepare.RequirementPreparer
- pip._internal.req.constructors.install_req_extend_extras
- pip._internal.req.req_install.InstallRequirement
- pip._internal.req.req_set.RequirementSet
- pip._internal.resolution.base.BaseResolver
- pip._internal.resolution.base.InstallRequirementProvider
- pip._internal.resolution.resolvelib.provider.PipProvider
- pip._internal.resolution.resolvelib.reporter.PipDebuggingReporter
- pip._internal.resolution.resolvelib.reporter.PipReporter
- pip._internal.utils.packaging.get_requirement
- pip._vendor.packaging.utils.canonicalize_name
- pip._vendor.resolvelib.BaseReporter
- pip._vendor.resolvelib.ResolutionImpossible
- pip._vendor.resolvelib.ResolutionTooDeep
- pip._vendor.resolvelib.Resolver
- pip._vendor.resolvelib.resolvers.Result
- pip._vendor.resolvelib.structs.DirectedGraph
- typing.Dict
- typing.List
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.cast

**Functions:**

### `def get_topological_weights(graph: 'DirectedGraph[Optional[str]]', requirement_keys: Set[str]) -> Dict[(Optional[str], int)]`

**Description:**
Assign weights to each node based on how "deep" they are.

This implementation may change at any point in the future without prior
notice.

We first simplify the dependency graph by pruning any leaves and giving them
the highest weight: a package without any dependencies should be installed
first. This is done again and again in the same way, giving ever less weight
to the newly found leaves. The loop stops when no leaves are left: all
remaining packages have at least one dependency left in the graph.

Then we continue with the remaining graph, by taking the length for the
longest path to any node from root, ignoring any paths that contain a single
node twice (i.e. cycles). This is done through a depth-first search through
the graph, while keeping track of the path to the node.

Cycles in the graph result would result in node being revisited while also
being on its own path. In this case, take no action. This helps ensure we
don't get stuck in a cycle.

When assigning weight, the longer path (i.e. larger length) is preferred.

We are only interested in the weights of packages that are in the
requirement_keys.

**Line:** 220

---

### `def _req_set_item_sorter(item: Tuple[(str, InstallRequirement)], weights: Dict[(Optional[str], int)]) -> Tuple[(int, str)]`

**Description:**
Key function used to sort install requirements for installation.

Based on the "weight" mapping calculated in ``get_installation_order()``.
The canonical package name is returned as the second member as a tie-
breaker to ensure the result is predictable, which is useful in tests.

**Line:** 309

---


## Module: venv2.libthon3.12.site-packages.pip._internal.self_outdated_check
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/self_outdated_check.py`

**Imports:**
- dataclasses.dataclass
- datetime
- functools
- hashlib
- json
- logging
- optparse
- os.path
- pip._internal.index.collector.LinkCollector
- pip._internal.index.package_finder.PackageFinder
- pip._internal.metadata.get_default_environment
- pip._internal.models.selection_prefs.SelectionPreferences
- pip._internal.network.session.PipSession
- pip._internal.utils.compat.WINDOWS
- pip._internal.utils.entrypoints.get_best_invocation_for_this_pip
- pip._internal.utils.entrypoints.get_best_invocation_for_this_python
- pip._internal.utils.filesystem.adjacent_tmp_file
- pip._internal.utils.filesystem.check_path_owner
- pip._internal.utils.filesystem.replace
- pip._internal.utils.misc.ExternallyManagedEnvironment
- pip._internal.utils.misc.check_externally_managed
- pip._internal.utils.misc.ensure_dir
- pip._vendor.packaging.version.Version
- pip._vendor.packaging.version.parse
- pip._vendor.rich.console.Group
- pip._vendor.rich.markup.escape
- pip._vendor.rich.text.Text
- sys
- typing.Any
- typing.Callable
- typing.Dict
- typing.Optional

**Functions:**

### `def _get_statefile_name(key: str) -> str`

**Line:** 40

---

### `def _convert_date(isodate: str) -> datetime.datetime`

**Description:**
Convert an ISO format string to a date.

Handles the format 2020-01-22T14:24:01Z (trailing Z)
which is not supported by older versions of fromisoformat.

**Line:** 46

---

### `def was_installed_by_pip(pkg: str) -> bool`

**Description:**
Checks whether pkg was installed by pip

This is used not to display the upgrade message when pip is in fact
installed by system package manager, such as dnf on Fedora.

**Line:** 156

---

### `def _get_current_remote_pip_version(session: PipSession, options: optparse.Values) -> Optional[str]`

**Line:** 166

---

### `def _self_version_check_logic(state: SelfCheckState, current_time: datetime.datetime, local_version: Version, get_remote_version: Callable[([], Optional[str])]) -> Optional[UpgradePrompt]`

**Line:** 194

---

### `def pip_self_version_check(session: PipSession, options: optparse.Values) -> None`

**Description:**
Check for an update for pip.

Limit the frequency of checks to once per week. State is stored either in
the active virtualenv or in the user's USER_CACHE_DIR keyed off the prefix
of the pip script path.

**Line:** 228

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils._jaraco_text
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/_jaraco_text.py`

**Imports:**
- functools
- itertools

**Functions:**

### `def _nonblank(str)`

**Line:** 36

---

### `def yield_lines(iterable)`

**Decorators:**
- `@functools.singledispatch`

**Description:**
Yield valid lines of a string or iterable.

>>> list(yield_lines(''))
[]
>>> list(yield_lines(['foo', 'bar']))
['foo', 'bar']
>>> list(yield_lines('foo\nbar'))
['foo', 'bar']
>>> list(yield_lines('\nfoo\n#bar\nbaz #comment'))
['foo', 'baz #comment']
>>> list(yield_lines(['foo\nbar', 'baz', 'bing\n\n\n']))
['foo', 'bar', 'baz', 'bing']

**Line:** 41

---

### `def _(text)`

**Decorators:**
- `@yield_lines.register(...)`

**Line:** 60

---

### `def drop_comment(line)`

**Description:**
Drop comments.

>>> drop_comment('foo # bar')
'foo'

A hash without a space may be in a URL.

>>> drop_comment('http://example.com/foo#bar')
'http://example.com/foo#bar'

**Line:** 64

---

### `def join_continuation(lines)`

**Description:**
Join lines continued by a trailing backslash.

>>> list(join_continuation(['foo \\', 'bar', 'baz']))
['foobar', 'baz']
>>> list(join_continuation(['foo \\', 'bar', 'baz']))
['foobar', 'baz']
>>> list(join_continuation(['foo \\', 'bar \\', 'baz']))
['foobarbaz']

Not sure why, but...
The character preceding the backslash is also elided.

>>> list(join_continuation(['goo\\', 'dly']))
['godly']

A terrible idea, but...
If no line is available to continue, suppress the lines.

>>> list(join_continuation(['foo', 'bar\\', 'baz\\']))
['foo']

**Line:** 79

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils._log
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/_log.py`

**Imports:**
- logging
- typing.Any
- typing.cast

**Functions:**

### `def getLogger(name: str) -> VerboseLogger`

**Description:**
logging.getLogger, but ensures our VerboseLogger class is returned

**Line:** 26

---

### `def init_logging() -> None`

**Description:**
Register our VerboseLogger and VERBOSE log level.

Should be called before any calls to getLogger(),
i.e. in pip._internal.__init__

**Line:** 31

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.appdirs
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/appdirs.py`

**Imports:**
- os
- pip._vendor.platformdirs
- sys
- typing.List

**Functions:**

### `def user_cache_dir(appname: str) -> str`

**Line:** 16

---

### `def _macos_user_config_dir(appname: str, roaming: bool = True) -> str`

**Line:** 20

---

### `def user_config_dir(appname: str, roaming: bool = True) -> str`

**Line:** 34

---

### `def site_config_dirs(appname: str) -> List[str]`

**Line:** 43

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.compat
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/compat.py`

**Imports:**
- _ssl
- importlib.resources
- logging
- os
- pip._vendor.urllib3.util.IS_PYOPENSSL
- sys
- typing.IO

**Functions:**

### `def has_tls() -> bool`

**Line:** 16

---

### `def get_path_uid(path: str) -> int`

**Description:**
Return path's uid.

Does not follow symlinks:
https://github.com/pypa/pip/pull/935#discussion_r5307003

Placed this function in compat due to differences on AIX and
Jython, that should eventually go away.

:raises OSError: When path is a symlink or can't be read.

**Line:** 29

---

### `def open_text_resource(package: str, resource: str, encoding: str = 'utf-8', errors: str = 'strict') -> IO[str]`

**Line:** 62

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.compatibility_tags
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/compatibility_tags.py`

**Imports:**
- pip._vendor.packaging.tags.PythonVersion
- pip._vendor.packaging.tags.Tag
- pip._vendor.packaging.tags.android_platforms
- pip._vendor.packaging.tags.compatible_tags
- pip._vendor.packaging.tags.cpython_tags
- pip._vendor.packaging.tags.generic_tags
- pip._vendor.packaging.tags.interpreter_name
- pip._vendor.packaging.tags.interpreter_version
- pip._vendor.packaging.tags.ios_platforms
- pip._vendor.packaging.tags.mac_platforms
- re
- typing.List
- typing.Optional
- typing.Tuple

**Functions:**

### `def version_info_to_nodot(version_info: Tuple[(int, ...)]) -> str`

**Line:** 22

---

### `def _mac_platforms(arch: str) -> List[str]`

**Line:** 27

---

### `def _ios_platforms(arch: str) -> List[str]`

**Line:** 47

---

### `def _android_platforms(arch: str) -> List[str]`

**Line:** 67

---

### `def _custom_manylinux_platforms(arch: str) -> List[str]`

**Line:** 77

---

### `def _get_custom_platforms(arch: str) -> List[str]`

**Line:** 98

---

### `def _expand_allowed_platforms(platforms: Optional[List[str]]) -> Optional[List[str]]`

**Line:** 113

---

### `def _get_python_version(version: str) -> PythonVersion`

**Line:** 130

---

### `def _get_custom_interpreter(implementation: Optional[str] = None, version: Optional[str] = None) -> str`

**Line:** 137

---

### `def get_supported(version: Optional[str] = None, platforms: Optional[List[str]] = None, impl: Optional[str] = None, abis: Optional[List[str]] = None) -> List[Tag]`

**Description:**
Return a list of supported tags for each version specified in
`versions`.

:param version: a string version, of the form "33" or "32",
or None. The version will be assumed to support our ABI.
:param platform: specify a list of platforms you want valid
tags for, or None. If None, use the local system platform.
:param impl: specify the exact implementation you want valid
tags for, or None. If None, use the local interpreter impl.
:param abis: specify a list of abis you want valid
tags for, or None. If None, use the local interpreter abi.

**Line:** 147

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.datetime
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/datetime.py`

**Imports:**
- datetime

**Functions:**

### `def today_is_later_than(year: int, month: int, day: int) -> bool`

**Line:** 6

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.deprecation
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/deprecation.py`

**Imports:**
- logging
- pip.__version__
- pip._vendor.packaging.version.parse
- typing.Any
- typing.Optional
- typing.TextIO
- typing.Type
- typing.Union
- warnings

**Functions:**

### `def _showwarning(message: Union[(Warning, str)], category: Type[Warning], filename: str, lineno: int, file: Optional[TextIO] = None, line: Optional[str] = None) -> None`

**Line:** 24

---

### `def install_warning_logger() -> None`

**Line:** 44

---

### `def deprecated(reason: str, replacement: Optional[str], gone_in: Optional[str], feature_flag: Optional[str] = None, issue: Optional[int] = None) -> None`

**Description:**
Helper to deprecate existing functionality.

reason:
Textual reason shown to the user about why this functionality has
been deprecated. Should be a complete sentence.
replacement:
Textual suggestion shown to the user about what alternative
functionality they can use.
gone_in:
The version of pip does this functionality should get removed in.
Raises an error if pip's current version is greater than or equal to
this.
feature_flag:
Command-line flag of the form --use-feature={feature_flag} for testing
upcoming functionality.
issue:
Issue number on the tracker that would serve as a useful place for
users to find related discussion and provide feedback.

**Line:** 55

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.direct_url_helpers
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/direct_url_helpers.py`

**Imports:**
- pip._internal.models.direct_url.ArchiveInfo
- pip._internal.models.direct_url.DirInfo
- pip._internal.models.direct_url.DirectUrl
- pip._internal.models.direct_url.VcsInfo
- pip._internal.models.link.Link
- pip._internal.utils.urls.path_to_url
- pip._internal.vcs.vcs
- typing.Optional

**Functions:**

### `def direct_url_as_pep440_direct_reference(direct_url: DirectUrl, name: str) -> str`

**Description:**
Convert a DirectUrl to a pip requirement string.

**Line:** 9

---

### `def direct_url_for_editable(source_dir: str) -> DirectUrl`

**Line:** 32

---

### `def direct_url_from_link(link: Link, source_dir: Optional[str] = None, link_is_in_wheel_cache: bool = False) -> DirectUrl`

**Line:** 39

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.egg_link
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/egg_link.py`

**Imports:**
- os
- pip._internal.locations.site_packages
- pip._internal.locations.user_site
- pip._internal.utils.virtualenv.running_under_virtualenv
- pip._internal.utils.virtualenv.virtualenv_no_global
- re
- sys
- typing.List
- typing.Optional

**Functions:**

### `def _egg_link_names(raw_name: str) -> List[str]`

**Description:**
Convert a Name metadata value to a .egg-link name, by applying
the same substitution as pkg_resources's safe_name function.
Note: we cannot use canonicalize_name because it has a different logic.

We also look for the raw name (without normalization) as setuptools 69 changed
the way it names .egg-link files (https://github.com/pypa/setuptools/issues/4167).

**Line:** 18

---

### `def egg_link_path_from_sys_path(raw_name: str) -> Optional[str]`

**Description:**
Look for a .egg-link file for project name, by walking sys.path.

**Line:** 33

---

### `def egg_link_path_from_location(raw_name: str) -> Optional[str]`

**Description:**
Return the path for the .egg-link file if it exists, otherwise, None.

There's 3 scenarios:
1) not in a virtualenv
try to find in site.USER_SITE, then site_packages
2) in a no-global virtualenv
try to find in site_packages
3) in a yes-global virtualenv
try to find in site_packages, then site.USER_SITE
(don't look in global location)

For #1 and #3, there could be odd cases, where there's an egg-link in 2
locations.

This method will just return the first one found.

**Line:** 46

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.entrypoints
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/entrypoints.py`

**Imports:**
- itertools
- os
- pip._internal.cli.main.main
- pip._internal.utils.compat.WINDOWS
- shutil
- sys
- typing.List
- typing.Optional

**Functions:**

### `def _wrapper(args: Optional[List[str]] = None) -> int`

**Description:**
Central wrapper for all old entrypoints.

Historically pip has had several entrypoints defined. Because of issues
arising from PATH, sys.path, multiple Pythons, their interactions, and most
of them having a pip installed, users suffer every time an entrypoint gets
moved.

To alleviate this pain, and provide a mechanism for warning users and
directing them to an appropriate place for help, we now define all of
our old entrypoints as wrappers for the current one.

**Line:** 23

---

### `def get_best_invocation_for_this_pip() -> str`

**Description:**
Try to figure out the best way to invoke pip in the current environment.

**Line:** 46

---

### `def get_best_invocation_for_this_python() -> str`

**Description:**
Try to figure out the best way to invoke the current Python.

**Line:** 73

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.filesystem
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/filesystem.py`

**Imports:**
- contextlib.contextmanager
- fnmatch
- os
- os.path
- pip._internal.utils.compat.get_path_uid
- pip._internal.utils.misc.format_size
- pip._internal.utils.retry.retry
- random
- sys
- tempfile.NamedTemporaryFile
- typing.Any
- typing.BinaryIO
- typing.Generator
- typing.List
- typing.Union
- typing.cast

**Functions:**

### `def check_path_owner(path: str) -> bool`

**Line:** 15

---

### `def adjacent_tmp_file(path: str, **kwargs: Any) -> Generator[(BinaryIO, None, None)]`

**Decorators:**
- `@contextmanager`

**Description:**
Return a file-like object pointing to a tmp file next to path.

The file is created securely and is ensured to be written to disk
after the context reaches its end.

kwargs will be passed to tempfile.NamedTemporaryFile to control
the way the temporary file will be opened.

**Line:** 43

---

### `def test_writable_dir(path: str) -> bool`

**Description:**
Check if a directory is writable.

Uses os.access() on POSIX, tries creating files on Windows.

**Line:** 72

---

### `def _test_writable_dir_win(path: str) -> bool`

**Line:** 90

---

### `def find_files(path: str, pattern: str) -> List[str]`

**Description:**
Returns a list of absolute paths of files beneath path, recursively,
with filenames which match the UNIX-style shell glob pattern.

**Line:** 118

---

### `def file_size(path: str) -> Union[(int, float)]`

**Line:** 128

---

### `def format_file_size(path: str) -> str`

**Line:** 135

---

### `def directory_size(path: str) -> Union[(int, float)]`

**Line:** 139

---

### `def format_directory_size(path: str) -> str`

**Line:** 148

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.filetypes
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/filetypes.py`

**Imports:**
- pip._internal.utils.misc.splitext
- typing.Tuple

**Functions:**

### `def is_archive_file(name: str) -> bool`

**Description:**
Return True if `name` is a considered as an archive file.

**Line:** 21

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.glibc
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/glibc.py`

**Imports:**
- ctypes
- os
- sys
- typing.Optional
- typing.Tuple

**Functions:**

### `def glibc_version_string() -> Optional[str]`

**Description:**
Returns glibc version string, or None if not using glibc.

**Line:** 6

---

### `def glibc_version_string_confstr() -> Optional[str]`

**Description:**
Primary implementation of glibc_version_string using os.confstr.

**Line:** 11

---

### `def glibc_version_string_ctypes() -> Optional[str]`

**Description:**
Fallback implementation of glibc_version_string using ctypes.

**Line:** 31

---

### `def libc_ver() -> Tuple[(str, str)]`

**Description:**
Try to determine the glibc version

Returns a tuple of strings (lib, version) which default to empty strings
in case the lookup fails.

**Line:** 91

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.logging
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/logging.py`

**Imports:**
- contextlib
- dataclasses.dataclass
- errno
- io.TextIOWrapper
- logging
- logging.Filter
- logging.handlers
- os
- pip._internal.utils._log.VERBOSE
- pip._internal.utils._log.getLogger
- pip._internal.utils.compat.WINDOWS
- pip._internal.utils.deprecation.DEPRECATION_MSG_PREFIX
- pip._internal.utils.misc.ensure_dir
- pip._vendor.rich.console.Console
- pip._vendor.rich.console.ConsoleOptions
- pip._vendor.rich.console.ConsoleRenderable
- pip._vendor.rich.console.RenderResult
- pip._vendor.rich.console.RenderableType
- pip._vendor.rich.console.RichCast
- pip._vendor.rich.highlighter.NullHighlighter
- pip._vendor.rich.logging.RichHandler
- pip._vendor.rich.segment.Segment
- pip._vendor.rich.style.Style
- sys
- threading
- typing.Any
- typing.ClassVar
- typing.Generator
- typing.List
- typing.Optional
- typing.Type

**Functions:**

### `def _is_broken_pipe_error(exc_class: Type[BaseException], exc: BaseException) -> bool`

**Line:** 43

---

### `def indent_log(num: int = 2) -> Generator[(None, None, None)]`

**Decorators:**
- `@contextlib.contextmanager`

**Description:**
A context manager which will cause the log output to be indented for any
log messages emitted inside it.

**Line:** 57

---

### `def get_indentation() -> int`

**Line:** 71

---

### `def get_console(stderr: bool = False) -> Console`

**Line:** 149

---

### `def setup_logging(verbosity: int, no_color: bool, user_log_file: Optional[str]) -> int`

**Description:**
Configures and sets up all of the logging

Returns the requested logging level, as its integer value.

**Line:** 243

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.misc
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/misc.py`

**Imports:**
- dataclasses.dataclass
- errno
- functools.partial
- getpass
- hashlib
- io.StringIO
- itertools.filterfalse
- itertools.tee
- itertools.zip_longest
- logging
- os
- pathlib.Path
- pip.__version__
- pip._internal.exceptions.CommandError
- pip._internal.exceptions.ExternallyManagedEnvironment
- pip._internal.locations.get_major_minor_version
- pip._internal.utils.compat.WINDOWS
- pip._internal.utils.retry.retry
- pip._internal.utils.virtualenv.running_under_virtualenv
- pip._vendor.packaging.requirements.Requirement
- pip._vendor.pyproject_hooks.BuildBackendHookCaller
- posixpath
- shutil
- stat
- sys
- sysconfig
- types.FunctionType
- types.TracebackType
- typing.Any
- typing.BinaryIO
- typing.Callable
- typing.Generator
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.Optional
- typing.Sequence
- typing.TextIO
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- urllib.parse

**Functions:**

### `def get_pip_version() -> str`

**Line:** 76

---

### `def normalize_version_info(py_version_info: Tuple[(int, ...)]) -> Tuple[(int, int, int)]`

**Description:**
Convert a tuple of ints representing a Python version to one of length
three.

:param py_version_info: a tuple of ints representing a Python version,
or None to specify no version. The tuple can have any length.

:return: a tuple of length three if `py_version_info` is non-None.
Otherwise, return `py_version_info` unchanged (i.e. None).

**Line:** 83

---

### `def ensure_dir(path: str) -> None`

**Description:**
os.path.makedirs without EEXIST.

**Line:** 102

---

### `def get_prog() -> str`

**Line:** 112

---

### `def rmtree(dir: str, ignore_errors: bool = False, onexc: Optional[OnExc] = None) -> None`

**Decorators:**
- `@retry(...)`

**Line:** 126

---

### `def _onerror_ignore(*_args: Any) -> None`

**Line:** 141

---

### `def _onerror_reraise(*_args: Any) -> None`

**Line:** 145

---

### `def rmtree_errorhandler(func: FunctionType, path: Path, exc_info: Union[(ExcInfo, BaseException)], onexc: OnExc = _onerror_reraise) -> None`

**Description:**
`rmtree` error handler to 'force' a file remove (i.e. like `rm -f`).

* If a file is readonly then it's write flag is set and operation is
retried.

* `onerror` is the original callback from `rmtree(... onerror=onerror)`
that is chained at the end if the "rm -f" still fails.

**Line:** 149

---

### `def display_path(path: str) -> str`

**Description:**
Gives the display value for a given path, making it relative to cwd
if possible.

**Line:** 190

---

### `def backup_dir(dir: str, ext: str = '.bak') -> str`

**Description:**
Figure out the name of a directory to back up the given dir to
(adding .bak, .bak2, etc)

**Line:** 199

---

### `def ask_path_exists(message: str, options: Iterable[str]) -> str`

**Line:** 210

---

### `def _check_no_input(message: str) -> None`

**Description:**
Raise an error if no input is allowed.

**Line:** 217

---

### `def ask(message: str, options: Iterable[str]) -> str`

**Description:**
Ask the message interactively, with the given possible responses

**Line:** 225

---

### `def ask_input(message: str) -> str`

**Description:**
Ask for input interactively.

**Line:** 240

---

### `def ask_password(message: str) -> str`

**Description:**
Ask for a password interactively.

**Line:** 246

---

### `def strtobool(val: str) -> int`

**Description:**
Convert a string representation of truth to true (1) or false (0).

True values are 'y', 'yes', 't', 'true', 'on', and '1'; false values
are 'n', 'no', 'f', 'false', 'off', and '0'.  Raises ValueError if
'val' is anything else.

**Line:** 252

---

### `def format_size(bytes: float) -> str`

**Line:** 268

---

### `def tabulate(rows: Iterable[Iterable[Any]]) -> Tuple[(List[str], List[int])]`

**Description:**
Return a list of formatted rows and a list of column sizes.

For example::

>>> tabulate([['foobar', 2000], [0xdeadbeef]])
(['foobar     2000', '3735928559'], [10, 4])

**Line:** 279

---

### `def is_installable_dir(path: str) -> bool`

**Description:**
Is path is a directory containing pyproject.toml or setup.py?

If pyproject.toml exists, this is a PEP 517 project. Otherwise we look for
a legacy setuptools layout by identifying setup.py. We don't check for the
setup.cfg because using it without setup.py is only available for PEP 517
projects, which are already covered by the pyproject.toml check.

**Line:** 293

---

### `def read_chunks(file: BinaryIO, size: int = FILE_CHUNK_SIZE) -> Generator[(bytes, None, None)]`

**Description:**
Yield pieces of data from a file-like object until EOF.

**Line:** 310

---

### `def normalize_path(path: str, resolve_symlinks: bool = True) -> str`

**Description:**
Convert a path to its canonical, case-normalized, absolute version.

**Line:** 321

---

### `def splitext(path: str) -> Tuple[(str, str)]`

**Description:**
Like os.path.splitext, but take off .tar too

**Line:** 334

---

### `def renames(old: str, new: str) -> None`

**Description:**
Like os.renames(), but handles renaming across devices.

**Line:** 343

---

### `def is_local(path: str) -> bool`

**Description:**
Return True if path is within sys.prefix, if we're running in a virtualenv.

If we're not in a virtualenv, all paths are considered "local."

Caution: this function assumes the head of path has been normalized
with normalize_path.

**Line:** 360

---

### `def write_output(msg: Any, *args: Any) -> None`

**Line:** 374

---

### `def enum(*sequential: Any, **named: Any) -> Type[Any]`

**Line:** 395

---

### `def build_netloc(host: str, port: Optional[int]) -> str`

**Description:**
Build a netloc from a host-port pair

**Line:** 402

---

### `def build_url_from_netloc(netloc: str, scheme: str = 'https') -> str`

**Description:**
Build a full URL from a netloc.

**Line:** 414

---

### `def parse_netloc(netloc: str) -> Tuple[(Optional[str], Optional[int])]`

**Description:**
Return the host-port pair from a netloc.

**Line:** 424

---

### `def split_auth_from_netloc(netloc: str) -> NetlocTuple`

**Description:**
Parse out and remove the auth information from a netloc.

Returns: (netloc, (username, password)).

**Line:** 433

---

### `def redact_netloc(netloc: str) -> str`

**Description:**
Replace the sensitive data in a netloc with "****", if it exists.

For example:
- "user:pass@example.com" returns "user:****@example.com"
- "accesstoken@example.com" returns "****@example.com"

**Line:** 462

---

### `def _transform_url(url: str, transform_netloc: Callable[([str], Tuple[Any, ...])]) -> Tuple[(str, NetlocTuple)]`

**Description:**
Transform and replace netloc in a url.

transform_netloc is a function taking the netloc and returning a
tuple. The first element of this tuple is the new netloc. The
entire tuple is returned.

Returns a tuple containing the transformed url as item 0 and the
original tuple returned by transform_netloc as item 1.

**Line:** 482

---

### `def _get_netloc(netloc: str) -> NetlocTuple`

**Line:** 502

---

### `def _redact_netloc(netloc: str) -> Tuple[str]`

**Line:** 506

---

### `def split_auth_netloc_from_url(url: str) -> Tuple[(str, str, Tuple[Optional[str], Optional[str]])]`

**Description:**
Parse a url into separate netloc, auth, and url with no auth.

Returns: (url_without_auth, netloc, (username, password))

**Line:** 510

---

### `def remove_auth_from_url(url: str) -> str`

**Description:**
Return a copy of url with 'username:password@' removed.

**Line:** 522

---

### `def redact_auth_from_url(url: str) -> str`

**Description:**
Replace the password in a given url with ****.

**Line:** 529

---

### `def redact_auth_from_requirement(req: Requirement) -> str`

**Description:**
Replace the password in a given requirement url with ****.

**Line:** 534

---

### `def hide_value(value: str) -> HiddenText`

**Line:** 562

---

### `def hide_url(url: str) -> HiddenText`

**Line:** 566

---

### `def protect_pip_from_modification_on_windows(modifying_pip: bool) -> None`

**Description:**
Protection of pip.exe from modification on Windows

On Windows, any operation modifying pip should be run as:
python -m pip ...

**Line:** 571

---

### `def check_externally_managed() -> None`

**Description:**
Check whether the current environment is externally managed.

If the ``EXTERNALLY-MANAGED`` config file is found, the current environment
is considered externally managed, and an ExternallyManagedEnvironment is
raised.

**Line:** 597

---

### `def is_console_interactive() -> bool`

**Description:**
Is this console interactive?

**Line:** 612

---

### `def hash_file(path: str, blocksize: int = 1 << 20) -> Tuple[(Any, int)]`

**Description:**
Return (hash, length) for path using hashlib.sha256()

**Line:** 617

---

### `def pairwise(iterable: Iterable[Any]) -> Iterator[Tuple[(Any, Any)]]`

**Description:**
Return paired elements.

For example:
s -> (s0, s1), (s2, s3), (s4, s5), ...

**Line:** 629

---

### `def partition(pred: Callable[([T], bool)], iterable: Iterable[T]) -> Tuple[(Iterable[T], Iterable[T])]`

**Description:**
Use a predicate to partition entries into false entries and true entries,
like

partition(is_odd, range(10)) --> 0 2 4 6 8   and  1 3 5 7 9

**Line:** 640

---

### `def warn_if_run_as_root() -> None`

**Description:**
Output a warning for sudo users on Unix.

In a virtual environment, sudo pip still writes to virtualenv.
On Windows, users may run pip as Administrator without issues.
This warning only applies to Unix root users outside of virtualenv.

**Line:** 743

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.packaging
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/packaging.py`

**Imports:**
- functools
- logging
- pip._vendor.packaging.requirements.Requirement
- pip._vendor.packaging.specifiers
- pip._vendor.packaging.version
- typing.Optional
- typing.Tuple

**Functions:**

### `def check_requires_python(requires_python: Optional[str], version_info: Tuple[(int, ...)]) -> bool`

**Decorators:**
- `@functools.lru_cache(...)`

**Description:**
Check if the given Python version matches a "Requires-Python" specifier.

:param version_info: A 3-tuple of ints representing a Python
major-minor-micro version to check (e.g. `sys.version_info[:3]`).

:return: `True` if the given Python version satisfies the requirement.
Otherwise, return `False`.

:raises InvalidSpecifier: If `requires_python` has an invalid format.

**Line:** 12

---

### `def get_requirement(req_string: str) -> Requirement`

**Decorators:**
- `@functools.lru_cache(...)`

**Description:**
Construct a packaging.Requirement object with caching

**Line:** 36

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.retry
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/retry.py`

**Imports:**
- functools
- pip._vendor.typing_extensions.ParamSpec
- time.perf_counter
- time.sleep
- typing.Callable
- typing.TypeVar

**Functions:**

### `def retry(wait: float, stop_after_delay: float) -> Callable[([Callable[P, T]], Callable[P, T])]`

**Description:**
Decorator to automatically retry a function on error.

If the function raises, the function is recalled with the same arguments
until it returns or the time limit is reached. When the time limit is
surpassed, the last exception raised is reraised.

:param wait: The time to wait after an error before retrying, in seconds.
:param stop_after_delay: The time limit after which retries will cease,
in seconds.

**Line:** 11

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.setuptools_build
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/setuptools_build.py`

**Imports:**
- sys
- textwrap
- typing.List
- typing.Optional
- typing.Sequence

**Functions:**

### `def make_setuptools_shim_args(setup_py_path: str, global_options: Optional[Sequence[str]] = None, no_user_config: bool = False, unbuffered_output: bool = False) -> List[str]`

**Description:**
Get setuptools command arguments with shim wrapped setup file invocation.

:param setup_py_path: The path to setup.py to be wrapped.
:param global_options: Additional global options.
:param no_user_config: If True, disables personal user configuration.
:param unbuffered_output: If True, adds the unbuffered switch to the
argument list.

**Line:** 50

---

### `def make_setuptools_bdist_wheel_args(setup_py_path: str, global_options: Sequence[str], build_options: Sequence[str], destination_dir: str) -> List[str]`

**Line:** 76

---

### `def make_setuptools_clean_args(setup_py_path: str, global_options: Sequence[str]) -> List[str]`

**Line:** 94

---

### `def make_setuptools_develop_args(setup_py_path: str, global_options: Sequence[str], no_user_config: bool, prefix: Optional[str], home: Optional[str], use_user_site: bool) -> List[str]`

**Line:** 105

---

### `def make_setuptools_egg_info_args(setup_py_path: str, egg_info_dir: Optional[str], no_user_config: bool) -> List[str]`

**Line:** 135

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.subprocess
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/subprocess.py`

**Imports:**
- logging
- os
- pip._internal.cli.spinners.SpinnerInterface
- pip._internal.cli.spinners.open_spinner
- pip._internal.exceptions.InstallationSubprocessError
- pip._internal.utils.logging.VERBOSE
- pip._internal.utils.logging.subprocess_logger
- pip._internal.utils.misc.HiddenText
- pip._vendor.rich.markup.escape
- shlex
- subprocess
- typing.Any
- typing.Callable
- typing.Iterable
- typing.List
- typing.Literal
- typing.Mapping
- typing.Optional
- typing.Union

**Functions:**

### `def make_command(*args: Union[(str, HiddenText, CommandArgs)]) -> CommandArgs`

**Description:**
Create a CommandArgs object.

**Line:** 17

---

### `def format_command_args(args: Union[(List[str], CommandArgs)]) -> str`

**Description:**
Format command arguments for display.

**Line:** 34

---

### `def reveal_command_args(args: Union[(List[str], CommandArgs)]) -> List[str]`

**Description:**
Return the arguments in their raw, unredacted form.

**Line:** 49

---

### `def call_subprocess(cmd: Union[(List[str], CommandArgs)], show_stdout: bool = False, cwd: Optional[str] = None, on_returncode: 'Literal["raise", "warn", "ignore"]' = 'raise', extra_ok_returncodes: Optional[Iterable[int]] = None, extra_environ: Optional[Mapping[(str, Any)]] = None, unset_environ: Optional[Iterable[str]] = None, spinner: Optional[SpinnerInterface] = None, log_failed_cmd: Optional[bool] = True, stdout_only: Optional[bool] = False, command_desc: str) -> str`

**Description:**
Args:
show_stdout: if true, use INFO to log the subprocess's stderr and
stdout streams.  Otherwise, use DEBUG.  Defaults to False.
extra_ok_returncodes: an iterable of integer return codes that are
acceptable, in addition to 0. Defaults to None, which means [].
unset_environ: an iterable of environment variable names to unset
prior to calling subprocess.Popen().
log_failed_cmd: if false, failed commands are not logged, only raised.
stdout_only: if true, return only stdout, else return both. When true,
logging of both stdout and stderr occurs when the subprocess has
terminated, else logging occurs as subprocess output is produced.

**Line:** 56

---

### `def runner_with_spinner_message(message: str) -> Callable[(..., None)]`

**Description:**
Provide a subprocess_runner that shows a spinner message.

Intended for use with for BuildBackendHookCaller. Thus, the runner has
an API that matches what's expected by BuildBackendHookCaller.subprocess_runner.

**Line:** 224

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.temp_dir
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/temp_dir.py`

**Imports:**
- contextlib.ExitStack
- contextlib.contextmanager
- errno
- itertools
- logging
- os.path
- pathlib.Path
- pip._internal.utils.misc.enum
- pip._internal.utils.misc.rmtree
- tempfile
- traceback
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generator
- typing.List
- typing.Optional
- typing.TypeVar
- typing.Union

**Functions:**

### `def global_tempdir_manager() -> Generator[(None, None, None)]`

**Decorators:**
- `@contextmanager`

**Line:** 40

---

### `def tempdir_registry() -> Generator[(TempDirectoryTypeRegistry, None, None)]`

**Decorators:**
- `@contextmanager`

**Description:**
Provides a scoped global tempdir registry that can be used to dictate
whether directories should be deleted.

**Line:** 73

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.unpacking
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py`

**Imports:**
- bz2
- logging
- lzma
- os
- pip._internal.exceptions.InstallationError
- pip._internal.utils.filetypes.BZ2_EXTENSIONS
- pip._internal.utils.filetypes.TAR_EXTENSIONS
- pip._internal.utils.filetypes.XZ_EXTENSIONS
- pip._internal.utils.filetypes.ZIP_EXTENSIONS
- pip._internal.utils.misc.ensure_dir
- shutil
- stat
- sys
- tarfile
- typing.Iterable
- typing.List
- typing.Optional
- zipfile
- zipfile.ZipInfo

**Functions:**

### `def current_umask() -> int`

**Description:**
Get the current umask which involves having to set it temporarily.

**Line:** 43

---

### `def split_leading_dir(path: str) -> List[str]`

**Line:** 50

---

### `def has_leading_dir(paths: Iterable[str]) -> bool`

**Description:**
Returns true if all the paths have the same leading path name
(i.e., everything is in one subdirectory in an archive)

**Line:** 62

---

### `def is_within_directory(directory: str, target: str) -> bool`

**Description:**
Return true if the absolute path of target is within the directory

**Line:** 77

---

### `def _get_default_mode_plus_executable() -> int`

**Line:** 88

---

### `def set_extracted_file_to_default_mode_plus_executable(path: str) -> None`

**Description:**
Make file present at path have execute for user/group/world
(chmod +x) is no-op on windows per python docs

**Line:** 92

---

### `def zip_item_is_executable(info: ZipInfo) -> bool`

**Line:** 100

---

### `def unzip_file(filename: str, location: str, flatten: bool = True) -> None`

**Description:**
Unzip the file (with path `filename`) to the destination `location`.  All
files are written based on system defaults and umask (i.e. permissions are
not preserved), except that regular file members with any execute
permissions (user, group, or world) have "chmod +x" applied after being
written. Note that for windows, any execute changes using os.chmod are
no-ops per the python docs.

**Line:** 107

---

### `def untar_file(filename: str, location: str) -> None`

**Description:**
Untar the file (with path `filename`) to the destination `location`.
All files are written based on system defaults and umask (i.e. permissions
are not preserved), except that regular file members with any execute
permissions (user, group, or world) have "chmod +x" applied on top of the
default.  Note that for windows, any execute changes using os.chmod are
no-ops per the python docs.

**Line:** 153

---

### `def _untar_without_filter(filename: str, location: str, tar: tarfile.TarFile, leading: bool) -> None`

**Description:**
Fallback for Python without tarfile.data_filter

**Line:** 249

---

### `def unpack_file(filename: str, location: str, content_type: Optional[str] = None) -> None`

**Line:** 307

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.urls
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/urls.py`

**Imports:**
- compat.WINDOWS
- os
- string
- urllib.parse
- urllib.request

**Functions:**

### `def path_to_url(path: str) -> str`

**Description:**
Convert a path to a file: URL.  The path will be made absolute and have
quoted path parts.

**Line:** 9

---

### `def url_to_path(url: str) -> str`

**Description:**
Convert a file: URL to a path.

**Line:** 19

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.virtualenv
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/virtualenv.py`

**Imports:**
- logging
- os
- re
- site
- sys
- typing.List
- typing.Optional

**Functions:**

### `def _running_under_venv() -> bool`

**Description:**
Checks if sys.base_prefix and sys.prefix match.

This handles PEP 405 compliant virtual environments.

**Line:** 14

---

### `def _running_under_legacy_virtualenv() -> bool`

**Description:**
Checks if sys.real_prefix is set.

This handles virtual environments created with pypa's virtualenv.

**Line:** 22

---

### `def running_under_virtualenv() -> bool`

**Description:**
True if we're running inside a virtual environment, False otherwise.

**Line:** 31

---

### `def _get_pyvenv_cfg_lines() -> Optional[List[str]]`

**Description:**
Reads {sys.prefix}/pyvenv.cfg and returns its contents as list of lines

Returns None, if it could not read/access the file.

**Line:** 36

---

### `def _no_global_under_venv() -> bool`

**Description:**
Check `{sys.prefix}/pyvenv.cfg` for system site-packages inclusion

PEP 405 specifies that when system site-packages are not supposed to be
visible from a virtual environment, `pyvenv.cfg` must contain the following
line:

include-system-site-packages = false

Additionally, log a warning if accessing the file fails.

**Line:** 51

---

### `def _no_global_under_legacy_virtualenv() -> bool`

**Description:**
Check if "no-global-site-packages.txt" exists beside site.py

This mirrors logic in pypa/virtualenv for determining whether system
site-packages are visible in the virtual environment.

**Line:** 80

---

### `def virtualenv_no_global() -> bool`

**Description:**
Returns a boolean, whether running in venv with no system site-packages.

**Line:** 94

---


## Module: venv2.libthon3.12.site-packages.pip._internal.utils.wheel
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/utils/wheel.py`

**Imports:**
- email.message.Message
- email.parser.Parser
- logging
- pip._internal.exceptions.UnsupportedWheel
- pip._vendor.packaging.utils.canonicalize_name
- typing.Tuple
- zipfile.BadZipFile
- zipfile.ZipFile

**Functions:**

### `def parse_wheel(wheel_zip: ZipFile, name: str) -> Tuple[(str, Message)]`

**Description:**
Extract information from the provided wheel, ensuring it meets basic
standards.

Returns the name of the .dist-info directory and the parsed WHEEL metadata.

**Line:** 19

---

### `def wheel_dist_info_dir(source: ZipFile, name: str) -> str`

**Description:**
Returns the name of the contained .dist-info directory.

Raises AssertionError or UnsupportedWheel if not found, >1 found, or
it doesn't match the provided name.

**Line:** 37

---

### `def read_wheel_metadata_file(source: ZipFile, path: str) -> bytes`

**Line:** 68

---

### `def wheel_metadata(source: ZipFile, dist_info_dir: str) -> Message`

**Description:**
Return the WHEEL metadata of an extracted wheel, if possible.
Otherwise, raise UnsupportedWheel.

**Line:** 77

---

### `def wheel_version(wheel_data: Message) -> Tuple[(int, ...)]`

**Description:**
Given WHEEL metadata, return the parsed Wheel-Version.
Otherwise, raise UnsupportedWheel.

**Line:** 96

---

### `def check_compatibility(version: Tuple[(int, ...)], name: str) -> None`

**Description:**
Raises errors or warns if called with an incompatible Wheel-Version.

pip should refuse to install a Wheel-Version that's a major series
ahead of what it's compatible with (e.g 2.0 > 1.1); and warn when
installing a version only minor version ahead (e.g 1.2 > 1.1).

version: a 2-tuple representing a Wheel-Version (Major, Minor)
name: name of wheel or package to raise exception about

:raises UnsupportedWheel: when an incompatible Wheel-Version is given

**Line:** 112

---


## Module: venv2.libthon3.12.site-packages.pip._internal.vcs.git
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/vcs/git.py`

**Imports:**
- dataclasses.replace
- logging
- os.path
- pathlib
- pip._internal.exceptions.BadCommand
- pip._internal.exceptions.InstallationError
- pip._internal.utils.misc.HiddenText
- pip._internal.utils.misc.display_path
- pip._internal.utils.misc.hide_url
- pip._internal.utils.subprocess.make_command
- pip._internal.vcs.versioncontrol.AuthInfo
- pip._internal.vcs.versioncontrol.RemoteNotFoundError
- pip._internal.vcs.versioncontrol.RemoteNotValidError
- pip._internal.vcs.versioncontrol.RevOptions
- pip._internal.vcs.versioncontrol.VersionControl
- pip._internal.vcs.versioncontrol.find_path_to_project_root_from_repo_root
- pip._internal.vcs.versioncontrol.vcs
- re
- typing.Any
- typing.List
- typing.Optional
- typing.Tuple
- urllib.parse
- urllib.request

**Functions:**

### `def looks_like_hash(sha: str) -> bool`

**Line:** 56

---


## Module: venv2.libthon3.12.site-packages.pip._internal.vcs.versioncontrol
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py`

**Imports:**
- dataclasses.dataclass
- dataclasses.field
- logging
- os
- pip._internal.cli.spinners.SpinnerInterface
- pip._internal.exceptions.BadCommand
- pip._internal.exceptions.InstallationError
- pip._internal.utils.misc.HiddenText
- pip._internal.utils.misc.ask_path_exists
- pip._internal.utils.misc.backup_dir
- pip._internal.utils.misc.display_path
- pip._internal.utils.misc.hide_url
- pip._internal.utils.misc.hide_value
- pip._internal.utils.misc.is_installable_dir
- pip._internal.utils.misc.rmtree
- pip._internal.utils.subprocess.CommandArgs
- pip._internal.utils.subprocess.call_subprocess
- pip._internal.utils.subprocess.format_command_args
- pip._internal.utils.subprocess.make_command
- shutil
- sys
- typing.Any
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Literal
- typing.Mapping
- typing.Optional
- typing.Tuple
- typing.Type
- typing.Union
- urllib.parse

**Functions:**

### `def is_url(name: str) -> bool`

**Description:**
Return true if the name looks like a URL.

**Line:** 50

---

### `def make_vcs_requirement_url(repo_url: str, rev: str, project_name: str, subdir: Optional[str] = None) -> str`

**Description:**
Return the URL for a VCS requirement.

Args:
repo_url: the remote VCS url, with any needed VCS prefix (e.g. "git+").
project_name: the (unescaped) project name.

**Line:** 60

---

### `def find_path_to_project_root_from_repo_root(location: str, repo_root: str) -> Optional[str]`

**Description:**
Find the the Python project's root by searching up the filesystem from
`location`. Return the path to project root relative to `repo_root`.
Return None if the project root is `repo_root`, or cannot be found.

**Line:** 78

---


## Module: venv2.libthon3.12.site-packages.pip._internal.wheel_builder
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/wheel_builder.py`

**Imports:**
- logging
- os.path
- pip._internal.cache.WheelCache
- pip._internal.exceptions.InvalidWheelFilename
- pip._internal.exceptions.UnsupportedWheel
- pip._internal.metadata.FilesystemWheel
- pip._internal.metadata.get_wheel_distribution
- pip._internal.models.link.Link
- pip._internal.models.wheel.Wheel
- pip._internal.operations.build.wheel.build_wheel_pep517
- pip._internal.operations.build.wheel_editable.build_wheel_editable
- pip._internal.operations.build.wheel_legacy.build_wheel_legacy
- pip._internal.req.req_install.InstallRequirement
- pip._internal.utils.logging.indent_log
- pip._internal.utils.misc.ensure_dir
- pip._internal.utils.misc.hash_file
- pip._internal.utils.setuptools_build.make_setuptools_clean_args
- pip._internal.utils.subprocess.call_subprocess
- pip._internal.utils.temp_dir.TempDirectory
- pip._internal.utils.urls.path_to_url
- pip._internal.vcs.vcs
- pip._vendor.packaging.utils.canonicalize_name
- pip._vendor.packaging.utils.canonicalize_version
- pip._vendor.packaging.version.InvalidVersion
- pip._vendor.packaging.version.Version
- re
- shutil
- typing.Iterable
- typing.List
- typing.Optional
- typing.Tuple

**Functions:**

### `def _contains_egg_info(s: str) -> bool`

**Description:**
Determine whether the string looks like an egg_info.

:param s: The string to parse. E.g. foo-2.1

**Line:** 36

---

### `def _should_build(req: InstallRequirement) -> bool`

**Description:**
Return whether an InstallRequirement should be built into a wheel.

**Line:** 44

---

### `def should_build_for_install_command(req: InstallRequirement) -> bool`

**Line:** 62

---

### `def _should_cache(req: InstallRequirement) -> Optional[bool]`

**Description:**
Return whether a built InstallRequirement can be stored in the persistent
wheel cache, assuming the wheel cache is available, and _should_build()
has determined a wheel needs to be built.

**Line:** 68

---

### `def _get_cache_dir(req: InstallRequirement, wheel_cache: WheelCache) -> str`

**Description:**
Return the persistent or temporary cache directory where the built
wheel need to be stored.

**Line:** 100

---

### `def _verify_one(req: InstallRequirement, wheel_path: str) -> None`

**Line:** 116

---

### `def _build_one(req: InstallRequirement, output_dir: str, verify: bool, build_options: List[str], global_options: List[str], editable: bool) -> Optional[str]`

**Description:**
Build one wheel.

:return: The filename of the built wheel, or None if the build failed.

**Line:** 145

---

### `def _build_one_inside_env(req: InstallRequirement, output_dir: str, build_options: List[str], global_options: List[str], editable: bool) -> Optional[str]`

**Line:** 183

---

### `def _clean_one_legacy(req: InstallRequirement, global_options: List[str]) -> bool`

**Line:** 254

---

### `def build(requirements: Iterable[InstallRequirement], wheel_cache: WheelCache, verify: bool, build_options: List[str], global_options: List[str]) -> BuildResult`

**Description:**
Build wheels.

:return: The list of InstallRequirement that succeeded to build and
the list of InstallRequirement that failed to build.

**Line:** 271

---


## Module: venv2.libthon3.12.site-packages.pip._internalproject
**File:** `venv2/lib/python3.12/site-packages/pip/_internal/pyproject.py`

**Imports:**
- collections.namedtuple
- importlib.util
- os
- pip._internal.exceptions.InstallationError
- pip._internal.exceptions.InvalidPyProjectBuildRequires
- pip._internal.exceptions.MissingPyProjectBuildRequires
- pip._internal.utils.packaging.get_requirement
- pip._vendor.packaging.requirements.InvalidRequirement
- pip._vendor.tomli
- sys
- tomllib
- typing.Any
- typing.List
- typing.Optional

**Functions:**

### `def _is_list_of_str(obj: Any) -> bool`

**Line:** 22

---

### `def make_pyproject_path(unpacked_source_directory: str) -> str`

**Line:** 26

---

### `def load_pyproject_toml(use_pep517: Optional[bool], pyproject_toml: str, setup_py: str, req_name: str) -> Optional[BuildSystemDetails]`

**Description:**
Load the pyproject.toml file.

Parameters:
use_pep517 - Has the user requested PEP 517 processing? None
means the user hasn't explicitly specified.
pyproject_toml - Location of the project's pyproject.toml file
setup_py - Location of the project's setup.py file
req_name - The name of the requirement we're processing (for
error reporting)

Returns:
None if we should use the legacy code path, otherwise a tuple
(
requirements from pyproject.toml,
name of PEP 517 backend,
requirements we should check are installed after setting
up the build environment
directory paths to import the backend from (backend-path),
relative to the project root.
)

**Line:** 35

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/__init__.py`

**Imports:**
- __future__.absolute_import
- glob
- os.path
- sys

**Functions:**

### `def vendored(modulename)`

**Line:** 29

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.cachecontrol._cmd
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/cachecontrol/_cmd.py`

**Imports:**
- __future__.annotations
- argparse.ArgumentParser
- argparse.Namespace
- logging
- pip._vendor.cachecontrol.adapter.CacheControlAdapter
- pip._vendor.cachecontrol.cache.DictCache
- pip._vendor.cachecontrol.controller.CacheController
- pip._vendor.cachecontrol.controller.logger
- pip._vendor.requests
- typing.TYPE_CHECKING

**Functions:**

### `def setup_logging() -> None`

**Line:** 22

---

### `def get_session() -> requests.Session`

**Line:** 28

---

### `def get_args() -> Namespace`

**Line:** 40

---

### `def main() -> None`

**Line:** 46

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.cachecontrol.caches.file_cache
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/cachecontrol/caches/file_cache.py`

**Imports:**
- __future__.annotations
- datetime.datetime
- filelock.BaseFileLock
- filelock.FileLock
- hashlib
- os
- pathlib.Path
- pip._vendor.cachecontrol.cache.BaseCache
- pip._vendor.cachecontrol.cache.SeparateBodyBaseCache
- pip._vendor.cachecontrol.controller.CacheController
- tempfile
- textwrap.dedent
- typing.IO
- typing.TYPE_CHECKING

**Functions:**

### `def url_to_file_path(url: str, filecache: FileCache) -> str`

**Description:**
Return the file cache path based on the URL.

This does not ensure the file exists!

**Line:** 139

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.cachecontrol.controller
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/cachecontrol/controller.py`

**Imports:**
- __future__.annotations
- calendar
- email.utils.parsedate_tz
- logging
- pip._vendor.cachecontrol.cache.BaseCache
- pip._vendor.cachecontrol.cache.DictCache
- pip._vendor.cachecontrol.cache.SeparateBodyBaseCache
- pip._vendor.cachecontrol.serialize.Serializer
- pip._vendor.requests.PreparedRequest
- pip._vendor.requests.structures.CaseInsensitiveDict
- pip._vendor.urllib3.HTTPResponse
- re
- time
- typing.Collection
- typing.Literal
- typing.Mapping
- typing.TYPE_CHECKING
- weakref

**Functions:**

### `def parse_uri(uri: str) -> tuple[(str, str, str, str, str)]`

**Description:**
Parses a URI using the regex given in Appendix B of RFC 3986.

(scheme, authority, path, query, fragment) = parse_uri(uri)

**Line:** 39

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.cachecontrol.heuristics
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/cachecontrol/heuristics.py`

**Imports:**
- __future__.annotations
- calendar
- datetime.datetime
- datetime.timedelta
- datetime.timezone
- email.utils.formatdate
- email.utils.parsedate
- email.utils.parsedate_tz
- pip._vendor.urllib3.HTTPResponse
- time
- typing.Any
- typing.Mapping
- typing.TYPE_CHECKING

**Functions:**

### `def expire_after(delta: timedelta, date: datetime | None = None) -> datetime`

**Line:** 18

---

### `def datetime_to_header(dt: datetime) -> str`

**Line:** 23

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.cachecontrol.wrapper
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/cachecontrol/wrapper.py`

**Imports:**
- __future__.annotations
- pip._vendor.cachecontrol.adapter.CacheControlAdapter
- pip._vendor.cachecontrol.cache.BaseCache
- pip._vendor.cachecontrol.cache.DictCache
- pip._vendor.cachecontrol.controller.CacheController
- pip._vendor.cachecontrol.heuristics.BaseHeuristic
- pip._vendor.cachecontrol.serialize.Serializer
- pip._vendor.requests
- typing.Collection
- typing.TYPE_CHECKING

**Functions:**

### `def CacheControl(sess: requests.Session, cache: BaseCache | None = None, cache_etags: bool = True, serializer: Serializer | None = None, heuristic: BaseHeuristic | None = None, controller_class: type[CacheController] | None = None, adapter_class: type[CacheControlAdapter] | None = None, cacheable_methods: Collection[str] | None = None) -> requests.Session`

**Line:** 20

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.certifi.core
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/certifi/core.py`

**Imports:**
- atexit
- importlib.resources.as_file
- importlib.resources.files
- importlib.resources.path
- importlib.resources.read_text
- os
- sys
- types
- typing.Union

**Functions:**

### `def exit_cacert_ctx() -> None`

**Line:** 10

---

### `def where() -> str`

**Line:** 21

---

### `def contents() -> str`

**Line:** 46

---

### `def where() -> str`

**Line:** 56

---

### `def contents() -> str`

**Line:** 82

---

### `def read_text(package: Package, resource: Resource, encoding: str = 'utf-8', errors: str = 'strict') -> str`

**Line:** 97

---

### `def where() -> str`

**Line:** 108

---

### `def contents() -> str`

**Line:** 113

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.dependency_groups.__main__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/dependency_groups/__main__.py`

**Imports:**
- _implementation.resolve
- _toml_compat.tomllib
- argparse
- sys

**Functions:**

### `def main() -> None`

**Line:** 8

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.dependency_groups._implementation
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/dependency_groups/_implementation.py`

**Imports:**
- __future__.annotations
- collections.abc.Mapping
- dataclasses
- pip._vendor.packaging.requirements.Requirement
- re

**Functions:**

### `def _normalize_name(name: str) -> str`

**Line:** 10

---

### `def _normalize_group_names(dependency_groups: Mapping[(str, str | Mapping[str, str])]) -> Mapping[(str, str | Mapping[str, str])]`

**Line:** 14

---

### `def resolve(dependency_groups: Mapping[(str, str | Mapping[str, str])], *groups: str) -> tuple[(str, ...)]`

**Description:**
Resolve a dependency group to a tuple of requirements, as strings.

:param dependency_groups: the parsed contents of the ``[dependency-groups]`` table
from ``pyproject.toml``
:param groups: the name of the group(s) to resolve

:raises TypeError: if the inputs appear to be the wrong types
:raises ValueError: if the data does not appear to be valid dependency group data
:raises LookupError: if group name is absent
:raises packaging.requirements.InvalidRequirement: if a specifier is not valid

**Line:** 193

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.dependency_groups._lint_dependency_groups
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/dependency_groups/_lint_dependency_groups.py`

**Imports:**
- __future__.annotations
- _implementation.DependencyGroupResolver
- _toml_compat.tomllib
- argparse
- sys

**Functions:**

### `def main(argv: list[str] | None = None) -> None`

**Line:** 10

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.dependency_groups._pip_wrapper
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/dependency_groups/_pip_wrapper.py`

**Imports:**
- __future__.annotations
- _implementation.DependencyGroupResolver
- _toml_compat.tomllib
- argparse
- subprocess
- sys

**Functions:**

### `def _invoke_pip(deps: list[str]) -> None`

**Line:** 11

---

### `def main(argv: list[str] | None = None) -> None`

**Line:** 15

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.distlib.compat
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/distlib/compat.py`

**Imports:**
- ConfigParser
- HTMLParser.HTMLParser
- Queue
- StringIO.StringIO
- __builtin__
- __future__.absolute_import
- _abcoll.ItemsView
- _abcoll.KeysView
- _abcoll.ValuesView
- builtins
- cgi.escape
- codecs.BOM_UTF8
- codecs.lookup
- collections.ChainMap
- collections.MutableMapping
- collections.OrderedDict
- collections.abc.Callable
- configparser
- dummy_thread.get_ident
- html.entities
- html.escape
- html.parser.HTMLParser
- html.unescape
- htmlentitydefs
- http.client
- httplib
- importlib.util.cache_from_source
- io.StringIO
- io.TextIOWrapper
- itertools.filterfalse
- itertools.ifilter
- itertools.ifilterfalse
- logging.config.BaseConfigurator
- logging.config.valid_ident
- os
- platform.python_implementation
- queue
- re
- reprlib.recursive_repr
- shutil
- shutil.which
- ssl
- ssl.CertificateError
- ssl.match_hostname
- sys
- sysconfig
- thread.get_ident
- tokenize.detect_encoding
- types.FileType
- types.SimpleNamespace
- urllib.ContentTooShortError
- urllib.error.ContentTooShortError
- urllib.error.HTTPError
- urllib.error.URLError
- urllib.parse.quote
- urllib.parse.splittype
- urllib.parse.unquote
- urllib.parse.urljoin
- urllib.parse.urlparse
- urllib.parse.urlsplit
- urllib.parse.urlunparse
- urllib.parse.urlunsplit
- urllib.pathname2url
- urllib.quote
- urllib.request
- urllib.request.HTTPBasicAuthHandler
- urllib.request.HTTPHandler
- urllib.request.HTTPPasswordMgr
- urllib.request.HTTPRedirectHandler
- urllib.request.HTTPSHandler
- urllib.request.Request
- urllib.request.build_opener
- urllib.request.pathname2url
- urllib.request.url2pathname
- urllib.request.urlopen
- urllib.request.urlretrieve
- urllib.splittype
- urllib.unquote
- urllib.url2pathname
- urllib.urlretrieve
- urllib2
- urllib2.HTTPBasicAuthHandler
- urllib2.HTTPError
- urllib2.HTTPHandler
- urllib2.HTTPPasswordMgr
- urllib2.HTTPRedirectHandler
- urllib2.HTTPSHandler
- urllib2.Request
- urllib2.URLError
- urllib2.build_opener
- urllib2.urlopen
- urlparse.urljoin
- urlparse.urlparse
- urlparse.urlsplit
- urlparse.urlunparse
- urlparse.urlunsplit
- xmlrpc.client
- xmlrpclib
- zipfile.ZipExtFile
- zipfile.ZipFile

**Functions:**

### `def quote(s)`

**Line:** 30

---

### `def _dnsname_match(dn, hostname, max_wildcards = 1)`

**Description:**
Matching according to RFC 6125, section 6.4.3

http://tools.ietf.org/html/rfc6125#section-6.4.3

**Line:** 96

---

### `def match_hostname(cert, hostname)`

**Description:**
Verify that *cert* (in decoded format as returned by
SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
rules are followed, but IP addresses are not accepted for *hostname*.

CertificateError is raised on failure. On success, the function
returns nothing.

**Line:** 145

---

### `def which(cmd, mode = os.F_OK | os.X_OK, path = None)`

**Description:**
Given a command, mode, and a PATH string, return the path which
conforms to the given mode on the PATH, or None if there is no such
file.

`mode` defaults to os.F_OK | os.X_OK. `path` defaults to the result
of os.environ.get("PATH"), or can be overridden with a custom search
path.

**Line:** 205

---

### `def python_implementation()`

**Description:**
Return a string identifying the Python implementation.

**Line:** 307

---

### `def callable(obj)`

**Line:** 325

---

### `def fsencode(filename)`

**Line:** 345

---

### `def fsdecode(filename)`

**Line:** 354

---

### `def _get_normal_name(orig_enc)`

**Description:**
Imitates get_normal_name in tokenizer.c.

**Line:** 371

---

### `def detect_encoding(readline)`

**Description:**
The detect_encoding() function is used to detect the encoding that should
be used to decode a Python source file.  It requires one argument, readline,
in the same way as the tokenize() generator.

It will call readline a maximum of twice, and return the encoding used
(as a string) and a list of any lines (left as bytes) it has read in.

It detects the encoding from the presence of a utf-8 bom or an encoding
cookie as specified in pep-0263.  If both a bom and a cookie are present,
but disagree, a SyntaxError will be raised.  If the encoding cookie is an
invalid charset, raise a SyntaxError.  Note that if a utf-8 bom is found,
'utf-8-sig' is returned.

If no encoding is specified, then the default of 'utf-8' will be returned.

**Line:** 382

---

### `def _recursive_repr(fillvalue = '...')`

**Description:**
Decorator to make a repr function return fillvalue for a recursive
call

**Line:** 494

---

### `def cache_from_source(path, debug_override = None)`

**Line:** 632

---

### `def valid_ident(s)`

**Line:** 915

---

### `def pop(self, key, default = None)`

**Line:** 957

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.distlib.database
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/distlib/database.py`

**Imports:**
- __future__.unicode_literals
- base64
- codecs
- compat.StringIO
- contextlib
- hashlib
- logging
- metadata.LEGACY_METADATA_FILENAME
- metadata.METADATA_FILENAME
- metadata.Metadata
- metadata.WHEEL_METADATA_FILENAME
- os
- posixpath
- sys
- util.CSVReader
- util.CSVWriter
- util.cached_property
- util.parse_name_and_version
- util.parse_requirement
- util.read_exports
- util.write_exports
- version.UnsupportedVersionError
- version.get_scheme
- warnings
- zipimport

**Functions:**

### `def make_graph(dists, scheme = 'default')`

**Description:**
Makes a dependency graph from the given distributions.

:parameter dists: a list of distributions
:type dists: list of :class:`distutils2.database.InstalledDistribution` and
:class:`distutils2.database.EggInfoDistribution` instances
:rtype: a :class:`DependencyGraph` instance

**Line:** 1213

---

### `def get_dependent_dists(dists, dist)`

**Description:**
Recursively generate a list of distributions from *dists* that are
dependent on *dist*.

:param dists: a list of distributions
:param dist: a distribution, member of *dists* for which we are interested

**Line:** 1265

---

### `def get_required_dists(dists, dist)`

**Description:**
Recursively generate a list of distributions from *dists* that are
required by *dist*.

:param dists: a list of distributions
:param dist: a distribution, member of *dists* for which we are interested
in finding the dependencies.

**Line:** 1291

---

### `def make_dist(name, version, **kwargs)`

**Description:**
A convenience method for making a dist given just a name and version.

**Line:** 1320

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.distlib.locators
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py`

**Imports:**
- compat.HTTPError
- compat.HTTPRedirectHandler
- compat.Request
- compat.URLError
- compat.build_opener
- compat.pathname2url
- compat.queue
- compat.quote
- compat.text_type
- compat.unescape
- compat.url2pathname
- compat.urljoin
- compat.urlparse
- compat.urlunparse
- database.Distribution
- database.DistributionPath
- database.make_dist
- dummy_threading
- gzip
- io.BytesIO
- json
- logging
- metadata.Metadata
- metadata.MetadataInvalidError
- os
- posixpath
- re
- threading
- util.ServerProxy
- util.cached_property
- util.ensure_slash
- util.get_project_data
- util.normalize_name
- util.parse_name_and_version
- util.parse_requirement
- util.split_filename
- version.UnsupportedVersionError
- version.get_scheme
- wheel.Wheel
- wheel.is_compatible
- zlib

**Functions:**

### `def get_all_distribution_names(url = None)`

**Description:**
Return all distribution names known by an index.
:param url: The URL of the index.
:return: A list of all known distribution names.

**Line:** 39

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.distlib.markers
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/distlib/markers.py`

**Imports:**
- compat.string_types
- os
- platform
- re
- sys
- util.in_venv
- util.parse_marker
- version.LegacyVersion

**Functions:**

### `def _is_version_marker(s)`

**Line:** 30

---

### `def _is_literal(o)`

**Line:** 34

---

### `def _get_versions(s)`

**Line:** 40

---

### `def default_context()`

**Line:** 102

---

### `def interpret(marker, execution_context = None)`

**Description:**
Interpret a marker and return a result depending on environment.

:param marker: The marker to interpret.
:type marker: str
:param execution_context: The context used for name lookup.
:type execution_context: mapping

**Line:** 144

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.distlib.metadata
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py`

**Imports:**
- __future__.unicode_literals
- codecs
- compat.StringIO
- compat.string_types
- compat.text_type
- email.message_from_file
- json
- logging
- markers.interpret
- re
- util.extract_by_key
- util.get_extras
- version.PEP440_VERSION_RE
- version.get_scheme

**Functions:**

### `def _version2fieldlist(version)`

**Line:** 103

---

### `def _best_version(fields)`

**Description:**
Detect the best version depending on the fields used.

**Line:** 121

---

### `def _get_name_and_version(name, version, for_filename = False)`

**Description:**
Return the distribution name with version.

If for_filename is true, return a filename-escaped form.

**Line:** 215

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.distlib.resources
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/distlib/resources.py`

**Imports:**
- __future__.unicode_literals
- _frozen_importlib
- _frozen_importlib_external
- bisect
- io
- logging
- os
- pkgutil
- sys
- types
- util.Cache
- util.cached_property
- util.get_cache_base
- zipimport

**Functions:**

### `def register_finder(loader, finder_maker)`

**Line:** 306

---

### `def finder(package)`

**Description:**
Return a resource finder for a package.
:param package: The name of the package.
:return: A :class:`ResourceFinder` instance for the package.

**Line:** 313

---

### `def finder_for_path(path)`

**Description:**
Return a resource finder for a path, which should represent a container.

:param path: The path.
:return: A :class:`ResourceFinder` instance for the path.

**Line:** 341

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.distlib.scripts
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/distlib/scripts.py`

**Imports:**
- compat.ZipFile
- compat.detect_encoding
- compat.sysconfig
- io.BytesIO
- java
- logging
- os
- re
- resources.finder
- struct
- sys
- time
- util.FileOperator
- util.convert_path
- util.get_executable
- util.get_export_entry
- util.get_platform
- util.in_venv
- zipfile.ZipInfo

**Functions:**

### `def enquote_executable(executable)`

**Line:** 71

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.distlib.util
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/distlib/util.py`

**Imports:**
- _aix_support.aix_platform
- _osx_support
- codecs
- collections.deque
- compat.BaseConfigurator
- compat.CertificateError
- compat.Container
- compat.HTTPHandler
- compat.HTTPSHandler
- compat.StringIO
- compat.URLError
- compat.ZipFile
- compat.cache_from_source
- compat.configparser
- compat.fsdecode
- compat.httplib
- compat.match_hostname
- compat.raw_input
- compat.shutil
- compat.string_types
- compat.text_type
- compat.unquote
- compat.urljoin
- compat.urlopen
- compat.urlparse
- compat.valid_ident
- compat.xmlrpclib
- contextlib
- csv
- distutils.sysconfig
- dummy_threading
- glob.iglob
- io
- json
- logging
- os
- py_compile
- re
- socket
- ssl
- subprocess
- sys
- sysconfig
- tarfile
- tempfile
- textwrap
- threading
- time

**Functions:**

### `def parse_marker(marker_string)`

**Description:**
Parse a marker string and return a dictionary containing a marker expression.

The dictionary will contain keys "op", "lhs" and "rhs" for non-terminals in
the expression grammar, or strings. A string contained in quotes is to be
interpreted as a literal string, and a string not contained in quotes is a
variable (such as os_name).

**Line:** 54

---

### `def parse_requirement(req)`

**Description:**
Parse a requirement passed in as a string. Return a Container
whose attributes contain the various parts of the requirement.

**Line:** 144

---

### `def get_resources_dests(resources_root, rules)`

**Description:**
Find destinations for resources files

**Line:** 268

---

### `def in_venv()`

**Line:** 294

---

### `def get_executable()`

**Line:** 304

---

### `def proceed(prompt, allowed_chars, error_prompt = None, default = None)`

**Line:** 322

---

### `def extract_by_key(d, keys)`

**Line:** 338

---

### `def read_exports(stream)`

**Line:** 348

---

### `def write_exports(exports, stream)`

**Line:** 395

---

### `def tempdir()`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 415

---

### `def chdir(d)`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 424

---

### `def socket_timeout(seconds = 15)`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 434

---

### `def convert_path(pathname)`

**Description:**
Return 'pathname' as a name that will work on the native filesystem.

The path is split on '/' and put back together again using the current
directory separator.  Needed because filenames in the setup script are
always supplied in Unix style, and have to be converted to the local
convention before we can actually use them in the filesystem.  Raises
ValueError on non-Unix-ish systems if 'pathname' either starts or
ends with a slash.

**Line:** 459

---

### `def resolve(module_name, dotted_path)`

**Line:** 672

---

### `def get_export_entry(specification)`

**Line:** 720

---

### `def get_cache_base(suffix = None)`

**Description:**
Return the default base location for distlib caches. If the directory does
not exist, it is created. Use the suffix provided for the base directory,
and default to '.distlib' if it isn't provided.

On Windows, if LOCALAPPDATA is defined in the environment, then it is
assumed to be a directory, and will be the parent directory of the result.
On POSIX, and on Windows if LOCALAPPDATA is not defined, the user's home
directory - using os.expanduser('~') - will be the parent directory of
the result.

The result is just the directory '.distlib' in the parent directory as
determined above, or with the name specified with ``suffix``.

**Line:** 751

---

### `def path_to_cache_dir(path, use_abspath = True)`

**Description:**
Convert an absolute path to a directory name for use in a cache.

The algorithm used is:

#. On Windows, any ``':'`` in the drive is replaced with ``'---'``.
#. Any occurrence of ``os.sep`` is replaced with ``'--'``.
#. ``'.cache'`` is appended.

**Line:** 792

---

### `def ensure_slash(s)`

**Line:** 809

---

### `def parse_credentials(netloc)`

**Line:** 815

---

### `def get_process_umask()`

**Line:** 830

---

### `def is_string_sequence(seq)`

**Line:** 836

---

### `def split_filename(filename, project_name = None)`

**Description:**
Extract name, version, python version from a filename (no extension)

Return name, version, pyver or None

**Line:** 852

---

### `def parse_name_and_version(p)`

**Description:**
A utility method used to get name and version from a string.

From e.g. a Provides-Dist value.

:param p: A value in a form 'foo (1.0)'
:return: The name and version as a tuple.

**Line:** 882

---

### `def get_extras(requested, available)`

**Line:** 898

---

### `def _get_external_data(url)`

**Line:** 926

---

### `def get_project_data(name)`

**Line:** 950

---

### `def get_package_data(name, version)`

**Line:** 957

---

### `def unarchive(archive_filename, dest_dir, format = None, check = True)`

**Line:** 1224

---

### `def zip_dir(directory)`

**Description:**
zip a directory tree into a BytesIO object

**Line:** 1292

---

### `def iglob(path_glob)`

**Description:**
Extended globbing function that supports ** and {opt1,opt2,opt3}.

**Line:** 1412

---

### `def _iglob(path_glob)`

**Line:** 1423

---

### `def _csv_open(fn, mode, **kwargs)`

**Line:** 1601

---

### `def normalize_name(name)`

**Description:**
Normalize a python package name a la PEP 503

**Line:** 1777

---

### `def _load_pypirc(index)`

**Description:**
Read the PyPI access configuration as supported by distutils.

**Line:** 1871

---

### `def _store_pypirc(index)`

**Line:** 1878

---

### `def get_host_platform()`

**Description:**
Return a string that identifies the current platform.  This is used mainly to
distinguish platform-specific build directories and platform-specific built
distributions.  Typically includes the OS name and version and the
architecture (as supplied by 'os.uname()'), although the exact information
included depends on the OS; eg. on Linux, the kernel version isn't
particularly important.

Examples of returned values:
linux-i586
linux-alpha (?)
solaris-2.6-sun4u

Windows will return one of:
win-amd64 (64bit Windows on AMD64 (aka x86_64, Intel64, EM64T, etc)
win32 (all others - specifically, sys.platform is returned)

For other non-POSIX platforms, currently just returns 'sys.platform'.

**Line:** 1888

---

### `def get_platform()`

**Line:** 1978

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.distlib.version
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/distlib/version.py`

**Imports:**
- compat.string_types
- logging
- re
- util.parse_requirement

**Functions:**

### `def _pep_440_key(s)`

**Line:** 184

---

### `def _match_prefix(x, y)`

**Line:** 292

---

### `def _suggest_semantic_version(s)`

**Description:**
Try to suggest a semantic form for a version for which
_suggest_normalized_version couldn't come up with anything.

**Line:** 415

---

### `def _suggest_normalized_version(s)`

**Description:**
Suggest a normalized version close to the given version string.

If you have a version string that isn't rational (i.e. NormalizedVersion
doesn't like it) then you might be able to get an equivalent (or close)
rational version from this function.

This does a number of simple normalizations to the given string, based
on observation of versions currently in use on PyPI. Given a dump of
those version during PyCon 2009, 4287 of them:
- 2312 (53.93%) match NormalizedVersion without change
with the automatic suggestion
- 3474 (81.04%) match when using this suggestion method

@param s {str} An irrational version string.
@returns A rational version string, or None, if couldn't determine one.

**Line:** 461

---

### `def _legacy_key(s)`

**Line:** 588

---

### `def is_semver(s)`

**Line:** 659

---

### `def _semantic_key(s)`

**Line:** 663

---

### `def get_scheme(name)`

**Line:** 747

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.distlib.wheel
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/distlib/wheel.py`

**Imports:**
- __future__.unicode_literals
- base64
- codecs
- compat.ZipFile
- compat.filter
- compat.fsdecode
- compat.sysconfig
- compat.text_type
- database.InstalledDistribution
- datetime
- email.message_from_file
- hashlib
- imp
- importlib.machinery
- importlib.util
- json
- logging
- metadata.LEGACY_METADATA_FILENAME
- metadata.Metadata
- metadata.WHEEL_METADATA_FILENAME
- os
- platform
- posixpath
- re
- shutil
- sys
- tempfile
- util.CSVReader
- util.CSVWriter
- util.Cache
- util.FileOperator
- util.cached_property
- util.convert_path
- util.get_cache_base
- util.get_platform
- util.read_exports
- util.tempdir
- version.NormalizedVersion
- version.UnsupportedVersionError
- zipfile

**Functions:**

### `def _derive_abi()`

**Line:** 58

---

### `def _get_suffixes()`

**Line:** 114

---

### `def _load_dynamic(name, path)`

**Line:** 121

---

### `def _get_glibc_version()`

**Line:** 975

---

### `def compatible_tags()`

**Description:**
Return (pyver, abi, arch) tuples compatible with this Python.

**Line:** 986

---

### `def is_compatible(wheel, tags = None)`

**Line:** 1090

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.distro.distro
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/distro/distro.py`

**Imports:**
- argparse
- functools.cached_property
- json
- logging
- os
- re
- shlex
- subprocess
- sys
- typing.Any
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.Optional
- typing.Sequence
- typing.TextIO
- typing.Tuple
- typing.Type
- typing.TypedDict
- warnings

**Functions:**

### `def linux_distribution(full_distribution_name: bool = True) -> Tuple[(str, str, str)]`

**Description:**
.. deprecated:: 1.6.0

:func:`distro.linux_distribution()` is deprecated. It should only be
used as a compatibility shim with Python's
:py:func:`platform.linux_distribution()`. Please use :func:`distro.id`,
:func:`distro.version` and :func:`distro.name` instead.

Return information about the current OS distribution as a tuple
``(id_name, version, codename)`` with items as follows:

* ``id_name``:  If *full_distribution_name* is false, the result of
:func:`distro.id`. Otherwise, the result of :func:`distro.name`.

* ``version``:  The result of :func:`distro.version`.

* ``codename``:  The extra item (usually in parentheses) after the
os-release version number, or the result of :func:`distro.codename`.

The interface of this function is compatible with the original
:py:func:`platform.linux_distribution` function, supporting a subset of
its parameters.

The data it returns may not exactly be the same, because it uses more data
sources than the original function, and that may lead to different data if
the OS distribution is not consistent across multiple data sources it
provides (there are indeed such distributions ...).

Another reason for differences is the fact that the :func:`distro.id`
method normalizes the distro ID string to a reliable machine-readable value
for a number of popular OS distributions.

**Line:** 160

---

### `def id() -> str`

**Description:**
Return the distro ID of the current distribution, as a
machine-readable string.

For a number of OS distributions, the returned distro ID value is
*reliable*, in the sense that it is documented and that it does not change
across releases of the distribution.

This package maintains the following reliable distro ID values:

==============  =========================================
Distro ID       Distribution
==============  =========================================
"ubuntu"        Ubuntu
"debian"        Debian
"rhel"          RedHat Enterprise Linux
"centos"        CentOS
"fedora"        Fedora
"sles"          SUSE Linux Enterprise Server
"opensuse"      openSUSE
"amzn"          Amazon Linux
"arch"          Arch Linux
"buildroot"     Buildroot
"cloudlinux"    CloudLinux OS
"exherbo"       Exherbo Linux
"gentoo"        GenToo Linux
"ibm_powerkvm"  IBM PowerKVM
"kvmibm"        KVM for IBM z Systems
"linuxmint"     Linux Mint
"mageia"        Mageia
"mandriva"      Mandriva Linux
"parallels"     Parallels
"pidora"        Pidora
"raspbian"      Raspbian
"oracle"        Oracle Linux (and Oracle Enterprise Linux)
"scientific"    Scientific Linux
"slackware"     Slackware
"xenserver"     XenServer
"openbsd"       OpenBSD
"netbsd"        NetBSD
"freebsd"       FreeBSD
"midnightbsd"   MidnightBSD
"rocky"         Rocky Linux
"aix"           AIX
"guix"          Guix System
"altlinux"      ALT Linux
==============  =========================================

If you have a need to get distros for reliable IDs added into this set,
or if you find that the :func:`distro.id` function returns a different
distro ID for one of the listed distros, please create an issue in the
`distro issue tracker`_.

**Lookup hierarchy and transformations:**

First, the ID is obtained from the following sources, in the specified
order. The first available and non-empty value is used:

* the value of the "ID" attribute of the os-release file,

* the value of the "Distributor ID" attribute returned by the lsb_release
command,

* the first part of the file name of the distro release file,

The so determined ID value then passes the following transformations,
before it is returned by this method:

* it is translated to lower case,

* blanks (which should not be there anyway) are translated to underscores,

* a normalization of the ID is performed, based upon
`normalization tables`_. The purpose of this normalization is to ensure
that the ID is as reliable as possible, even across incompatible changes
in the OS distributions. A common reason for an incompatible change is
the addition of an os-release file, or the addition of the lsb_release
command, with ID values that differ from what was previously determined
from the distro release file name.

**Line:** 203

---

### `def name(pretty: bool = False) -> str`

**Description:**
Return the name of the current OS distribution, as a human-readable
string.

If *pretty* is false, the name is returned without version or codename.
(e.g. "CentOS Linux")

If *pretty* is true, the version and codename are appended.
(e.g. "CentOS Linux 7.1.1503 (Core)")

**Lookup hierarchy:**

The name is obtained from the following sources, in the specified order.
The first available and non-empty value is used:

* If *pretty* is false:

- the value of the "NAME" attribute of the os-release file,

- the value of the "Distributor ID" attribute returned by the lsb_release
command,

- the value of the "<name>" field of the distro release file.

* If *pretty* is true:

- the value of the "PRETTY_NAME" attribute of the os-release file,

- the value of the "Description" attribute returned by the lsb_release
command,

- the value of the "<name>" field of the distro release file, appended
with the value of the pretty version ("<version_id>" and "<codename>"
fields) of the distro release file, if available.

**Line:** 287

---

### `def version(pretty: bool = False, best: bool = False) -> str`

**Description:**
Return the version of the current OS distribution, as a human-readable
string.

If *pretty* is false, the version is returned without codename (e.g.
"7.0").

If *pretty* is true, the codename in parenthesis is appended, if the
codename is non-empty (e.g. "7.0 (Maipo)").

Some distributions provide version numbers with different precisions in
the different sources of distribution information. Examining the different
sources in a fixed priority order does not always yield the most precise
version (e.g. for Debian 8.2, or CentOS 7.1).

Some other distributions may not provide this kind of information. In these
cases, an empty string would be returned. This behavior can be observed
with rolling releases distributions (e.g. Arch Linux).

The *best* parameter can be used to control the approach for the returned
version:

If *best* is false, the first non-empty version number in priority order of
the examined sources is returned.

If *best* is true, the most precise version number out of all examined
sources is returned.

**Lookup hierarchy:**

In all cases, the version number is obtained from the following sources.
If *best* is false, this order represents the priority order:

* the value of the "VERSION_ID" attribute of the os-release file,
* the value of the "Release" attribute returned by the lsb_release
command,
* the version number parsed from the "<version_id>" field of the first line
of the distro release file,
* the version number parsed from the "PRETTY_NAME" attribute of the
os-release file, if it follows the format of the distro release files.
* the version number parsed from the "Description" attribute returned by
the lsb_release command, if it follows the format of the distro release
files.

**Line:** 326

---

### `def version_parts(best: bool = False) -> Tuple[(str, str, str)]`

**Description:**
Return the version of the current OS distribution as a tuple
``(major, minor, build_number)`` with items as follows:

* ``major``:  The result of :func:`distro.major_version`.

* ``minor``:  The result of :func:`distro.minor_version`.

* ``build_number``:  The result of :func:`distro.build_number`.

For a description of the *best* parameter, see the :func:`distro.version`
method.

**Line:** 374

---

### `def major_version(best: bool = False) -> str`

**Description:**
Return the major version of the current OS distribution, as a string,
if provided.
Otherwise, the empty string is returned. The major version is the first
part of the dot-separated version string.

For a description of the *best* parameter, see the :func:`distro.version`
method.

**Line:** 391

---

### `def minor_version(best: bool = False) -> str`

**Description:**
Return the minor version of the current OS distribution, as a string,
if provided.
Otherwise, the empty string is returned. The minor version is the second
part of the dot-separated version string.

For a description of the *best* parameter, see the :func:`distro.version`
method.

**Line:** 404

---

### `def build_number(best: bool = False) -> str`

**Description:**
Return the build number of the current OS distribution, as a string,
if provided.
Otherwise, the empty string is returned. The build number is the third part
of the dot-separated version string.

For a description of the *best* parameter, see the :func:`distro.version`
method.

**Line:** 417

---

### `def like() -> str`

**Description:**
Return a space-separated list of distro IDs of distributions that are
closely related to the current OS distribution in regards to packaging
and programming interfaces, for example distributions the current
distribution is a derivative from.

**Lookup hierarchy:**

This information item is only provided by the os-release file.
For details, see the description of the "ID_LIKE" attribute in the
`os-release man page
<http://www.freedesktop.org/software/systemd/man/os-release.html>`_.

**Line:** 430

---

### `def codename() -> str`

**Description:**
Return the codename for the release of the current OS distribution,
as a string.

If the distribution does not have a codename, an empty string is returned.

Note that the returned codename is not always really a codename. For
example, openSUSE returns "x86_64". This function does not handle such
cases in any special way and just returns the string it finds, if any.

**Lookup hierarchy:**

* the codename within the "VERSION" attribute of the os-release file, if
provided,

* the value of the "Codename" attribute returned by the lsb_release
command,

* the value of the "<codename>" field of the distro release file.

**Line:** 447

---

### `def info(pretty: bool = False, best: bool = False) -> InfoDict`

**Description:**
Return certain machine-readable information items about the current OS
distribution in a dictionary, as shown in the following example:

.. sourcecode:: python

{
'id': 'rhel',
'version': '7.0',
'version_parts': {
'major': '7',
'minor': '0',
'build_number': ''
},
'like': 'fedora',
'codename': 'Maipo'
}

The dictionary structure and keys are always the same, regardless of which
information items are available in the underlying data sources. The values
for the various keys are as follows:

* ``id``:  The result of :func:`distro.id`.

* ``version``:  The result of :func:`distro.version`.

* ``version_parts -> major``:  The result of :func:`distro.major_version`.

* ``version_parts -> minor``:  The result of :func:`distro.minor_version`.

* ``version_parts -> build_number``:  The result of
:func:`distro.build_number`.

* ``like``:  The result of :func:`distro.like`.

* ``codename``:  The result of :func:`distro.codename`.

For a description of the *pretty* and *best* parameters, see the
:func:`distro.version` method.

**Line:** 471

---

### `def os_release_info() -> Dict[(str, str)]`

**Description:**
Return a dictionary containing key-value pairs for the information items
from the os-release file data source of the current OS distribution.

See `os-release file`_ for details about these information items.

**Line:** 515

---

### `def lsb_release_info() -> Dict[(str, str)]`

**Description:**
Return a dictionary containing key-value pairs for the information items
from the lsb_release command data source of the current OS distribution.

See `lsb_release command output`_ for details about these information
items.

**Line:** 525

---

### `def distro_release_info() -> Dict[(str, str)]`

**Description:**
Return a dictionary containing key-value pairs for the information items
from the distro release file data source of the current OS distribution.

See `distro release file`_ for details about these information items.

**Line:** 536

---

### `def uname_info() -> Dict[(str, str)]`

**Description:**
Return a dictionary containing key-value pairs for the information items
from the distro release file data source of the current OS distribution.

**Line:** 546

---

### `def os_release_attr(attribute: str) -> str`

**Description:**
Return a single named information item from the os-release file data source
of the current OS distribution.

Parameters:

* ``attribute`` (string): Key of the information item.

Returns:

* (string): Value of the information item, if the item exists.
The empty string, if the item does not exist.

See `os-release file`_ for details about these information items.

**Line:** 554

---

### `def lsb_release_attr(attribute: str) -> str`

**Description:**
Return a single named information item from the lsb_release command output
data source of the current OS distribution.

Parameters:

* ``attribute`` (string): Key of the information item.

Returns:

* (string): Value of the information item, if the item exists.
The empty string, if the item does not exist.

See `lsb_release command output`_ for details about these information
items.

**Line:** 573

---

### `def distro_release_attr(attribute: str) -> str`

**Description:**
Return a single named information item from the distro release file
data source of the current OS distribution.

Parameters:

* ``attribute`` (string): Key of the information item.

Returns:

* (string): Value of the information item, if the item exists.
The empty string, if the item does not exist.

See `distro release file`_ for details about these information items.

**Line:** 593

---

### `def uname_attr(attribute: str) -> str`

**Description:**
Return a single named information item from the distro release file
data source of the current OS distribution.

Parameters:

* ``attribute`` (string): Key of the information item.

Returns:

* (string): Value of the information item, if the item exists.
The empty string, if the item does not exist.

**Line:** 612

---

### `def main() -> None`

**Line:** 1362

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.idna.codec
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/idna/codec.py`

**Imports:**
- codecs
- core.IDNAError
- core.alabel
- core.decode
- core.encode
- core.ulabel
- re
- typing.Any
- typing.Optional
- typing.Tuple

**Functions:**

### `def search_function(name: str) -> Optional[codecs.CodecInfo]`

**Line:** 108

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.idna.compat
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/idna/compat.py`

**Imports:**
- core.decode
- core.encode
- typing.Any
- typing.Union

**Functions:**

### `def ToASCII(label: str) -> bytes`

**Line:** 6

---

### `def ToUnicode(label: Union[(bytes, bytearray)]) -> str`

**Line:** 10

---

### `def nameprep(s: Any) -> None`

**Line:** 14

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.idna.core
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/idna/core.py`

**Imports:**
- bisect
- intranges.intranges_contain
- re
- typing.Optional
- typing.Union
- unicodedata
- uts46data.uts46data

**Functions:**

### `def _combining_class(cp: int) -> int`

**Line:** 38

---

### `def _is_script(cp: str, script: str) -> bool`

**Line:** 46

---

### `def _punycode(s: str) -> bytes`

**Line:** 50

---

### `def _unot(s: int) -> str`

**Line:** 54

---

### `def valid_label_length(label: Union[(bytes, str)]) -> bool`

**Line:** 58

---

### `def valid_string_length(label: Union[(bytes, str)], trailing_dot: bool) -> bool`

**Line:** 64

---

### `def check_bidi(label: str, check_ltr: bool = False) -> bool`

**Line:** 70

---

### `def check_initial_combiner(label: str) -> bool`

**Line:** 140

---

### `def check_hyphen_ok(label: str) -> bool`

**Line:** 146

---

### `def check_nfc(label: str) -> None`

**Line:** 154

---

### `def valid_contextj(label: str, pos: int) -> bool`

**Line:** 159

---

### `def valid_contexto(label: str, pos: int, exception: bool = False) -> bool`

**Line:** 203

---

### `def check_label(label: Union[(str, bytes, bytearray)]) -> None`

**Line:** 245

---

### `def alabel(label: str) -> bytes`

**Line:** 284

---

### `def ulabel(label: Union[(str, bytes, bytearray)]) -> str`

**Line:** 303

---

### `def uts46_remap(domain: str, std3_rules: bool = True, transitional: bool = False) -> str`

**Description:**
Re-map the characters in the string according to UTS46 processing.

**Line:** 332

---

### `def encode(s: Union[(str, bytes, bytearray)], strict: bool = False, uts46: bool = False, std3_rules: bool = False, transitional: bool = False) -> bytes`

**Line:** 366

---

### `def decode(s: Union[(str, bytes, bytearray)], strict: bool = False, uts46: bool = False, std3_rules: bool = False) -> str`

**Line:** 405

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.idna.intranges
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/idna/intranges.py`

**Imports:**
- bisect
- typing.List
- typing.Tuple

**Functions:**

### `def intranges_from_list(list_: List[int]) -> Tuple[(int, ...)]`

**Description:**
Represent a list of integers as a sequence of ranges:
((start_0, end_0), (start_1, end_1), ...), such that the original
integers are exactly those x such that start_i <= x < end_i for some i.

Ranges are encoded as single integers (start << 32 | end), not as tuples.

**Line:** 12

---

### `def _encode_range(start: int, end: int) -> int`

**Line:** 34

---

### `def _decode_range(r: int) -> Tuple[(int, int)]`

**Line:** 38

---

### `def intranges_contain(int_: int, ranges: Tuple[(int, ...)]) -> bool`

**Description:**
Determine if `int_` falls into one of the ranges in `ranges`.

**Line:** 42

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.idna.uts46data
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/idna/uts46data.py`

**Imports:**
- typing.List
- typing.Tuple
- typing.Union

**Functions:**

### `def _seg_0() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 12

---

### `def _seg_1() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 117

---

### `def _seg_2() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 222

---

### `def _seg_3() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 327

---

### `def _seg_4() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 432

---

### `def _seg_5() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 537

---

### `def _seg_6() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 642

---

### `def _seg_7() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 747

---

### `def _seg_8() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 852

---

### `def _seg_9() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 957

---

### `def _seg_10() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 1062

---

### `def _seg_11() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 1167

---

### `def _seg_12() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 1272

---

### `def _seg_13() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 1377

---

### `def _seg_14() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 1482

---

### `def _seg_15() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 1587

---

### `def _seg_16() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 1692

---

### `def _seg_17() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 1797

---

### `def _seg_18() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 1902

---

### `def _seg_19() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 2007

---

### `def _seg_20() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 2112

---

### `def _seg_21() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 2217

---

### `def _seg_22() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 2322

---

### `def _seg_23() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 2427

---

### `def _seg_24() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 2532

---

### `def _seg_25() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 2637

---

### `def _seg_26() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 2742

---

### `def _seg_27() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 2847

---

### `def _seg_28() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 2952

---

### `def _seg_29() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 3057

---

### `def _seg_30() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 3162

---

### `def _seg_31() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 3267

---

### `def _seg_32() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 3372

---

### `def _seg_33() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 3477

---

### `def _seg_34() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 3582

---

### `def _seg_35() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 3687

---

### `def _seg_36() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 3792

---

### `def _seg_37() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 3897

---

### `def _seg_38() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 4002

---

### `def _seg_39() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 4107

---

### `def _seg_40() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 4212

---

### `def _seg_41() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 4317

---

### `def _seg_42() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 4422

---

### `def _seg_43() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 4527

---

### `def _seg_44() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 4632

---

### `def _seg_45() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 4737

---

### `def _seg_46() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 4842

---

### `def _seg_47() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 4947

---

### `def _seg_48() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 5052

---

### `def _seg_49() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 5157

---

### `def _seg_50() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 5262

---

### `def _seg_51() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 5367

---

### `def _seg_52() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 5472

---

### `def _seg_53() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 5577

---

### `def _seg_54() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 5682

---

### `def _seg_55() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 5787

---

### `def _seg_56() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 5892

---

### `def _seg_57() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 5997

---

### `def _seg_58() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 6102

---

### `def _seg_59() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 6207

---

### `def _seg_60() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 6312

---

### `def _seg_61() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 6417

---

### `def _seg_62() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 6522

---

### `def _seg_63() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 6627

---

### `def _seg_64() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 6732

---

### `def _seg_65() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 6837

---

### `def _seg_66() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 6942

---

### `def _seg_67() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 7047

---

### `def _seg_68() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 7152

---

### `def _seg_69() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 7257

---

### `def _seg_70() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 7362

---

### `def _seg_71() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 7467

---

### `def _seg_72() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 7572

---

### `def _seg_73() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 7677

---

### `def _seg_74() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 7782

---

### `def _seg_75() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 7887

---

### `def _seg_76() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 7992

---

### `def _seg_77() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 8097

---

### `def _seg_78() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 8202

---

### `def _seg_79() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 8307

---

### `def _seg_80() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 8412

---

### `def _seg_81() -> List[Union[(Tuple[int, str], Tuple[int, str, str])]]`

**Line:** 8517

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.msgpack.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/msgpack/__init__.py`

**Imports:**
- _cmsgpack.Packer
- _cmsgpack.Unpacker
- _cmsgpack.unpackb
- exceptions.*
- ext.ExtType
- ext.Timestamp
- fallback.Packer
- fallback.Unpacker
- fallback.unpackb
- os

**Functions:**

### `def pack(o, stream, **kwargs)`

**Description:**
Pack object `o` and write it to `stream`

See :class:`Packer` for options.

**Line:** 20

---

### `def packb(o, **kwargs)`

**Description:**
Pack object `o` and return packed bytes

See :class:`Packer` for options.

**Line:** 30

---

### `def unpack(stream, **kwargs)`

**Description:**
Unpack an object from `stream`.

Raises `ExtraData` when `stream` contains extra bytes.
See :class:`Unpacker` for options.

**Line:** 39

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.msgpack.fallback
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py`

**Imports:**
- __pypy__.builders.BytesBuilder
- __pypy__.newlist_hint
- datetime.datetime
- exceptions.BufferFull
- exceptions.ExtraData
- exceptions.FormatError
- exceptions.OutOfData
- exceptions.StackError
- ext.ExtType
- ext.Timestamp
- io.BytesIO
- struct
- sys

**Functions:**

### `def newlist_hint(size)`

**Line:** 36

---

### `def _check_type_strict(obj, t, type = type, tuple = tuple)`

**Line:** 58

---

### `def _get_data_from_buffer(obj)`

**Line:** 65

---

### `def unpackb(packed, **kwargs)`

**Description:**
Unpack an object from `packed`.

Raises ``ExtraData`` when *packed* contains extra bytes.
Raises ``ValueError`` when *packed* is incomplete.
Raises ``FormatError`` when *packed* is not valid msgpack.
Raises ``StackError`` when *packed* contains too nested.
Other exceptions can be raised during unpacking.

See :class:`Unpacker` for options.

**Line:** 72

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.packaging._manylinux
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/packaging/_manylinux.py`

**Imports:**
- __future__.annotations
- _elffile.EIClass
- _elffile.EIData
- _elffile.ELFFile
- _elffile.EMachine
- _manylinux
- collections
- contextlib
- ctypes
- functools
- os
- re
- sys
- typing.Generator
- typing.Iterator
- typing.NamedTuple
- typing.Sequence
- warnings

**Functions:**

### `def _parse_elf(path: str) -> Generator[(ELFFile | None, None, None)]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 22

---

### `def _is_linux_armhf(executable: str) -> bool`

**Line:** 30

---

### `def _is_linux_i686(executable: str) -> bool`

**Line:** 45

---

### `def _have_compatible_abi(executable: str, archs: Sequence[str]) -> bool`

**Line:** 55

---

### `def _glibc_version_string_confstr() -> str | None`

**Description:**
Primary implementation of glibc_version_string using os.confstr.

**Line:** 85

---

### `def _glibc_version_string_ctypes() -> str | None`

**Description:**
Fallback implementation of glibc_version_string using ctypes.

**Line:** 104

---

### `def _glibc_version_string() -> str | None`

**Description:**
Returns glibc version string, or None if not using glibc.

**Line:** 148

---

### `def _parse_glibc_version(version_str: str) -> tuple[(int, int)]`

**Description:**
Parse glibc version.

We use a regexp instead of str.split because we want to discard any
random junk that might come after the minor version -- this might happen
in patched/forked versions of glibc (e.g. Linaro's version of glibc
uses version strings like "2.20-2014.11"). See gh-3588.

**Line:** 153

---

### `def _get_glibc_version() -> tuple[(int, int)]`

**Decorators:**
- `@functools.lru_cache`

**Line:** 173

---

### `def _is_compatible(arch: str, version: _GLibCVersion) -> bool`

**Line:** 181

---

### `def platform_tags(archs: Sequence[str]) -> Iterator[str]`

**Description:**
Generate manylinux tags compatible to the current platform.

:param archs: Sequence of compatible architectures.
The first one shall be the closest to the actual architecture and be the part of
platform tag after the ``linux_`` prefix, e.g. ``x86_64``.
The ``linux_`` prefix is assumed as a prerequisite for the current platform to
be manylinux-compatible.

:returns: An iterator of compatible manylinux tags.

**Line:** 217

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.packaging._musllinux
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/packaging/_musllinux.py`

**Imports:**
- __future__.annotations
- _elffile.ELFFile
- functools
- re
- subprocess
- sys
- sysconfig
- typing.Iterator
- typing.NamedTuple
- typing.Sequence

**Functions:**

### `def _parse_musl_version(output: str) -> _MuslVersion | None`

**Line:** 23

---

### `def _get_musl_version(executable: str) -> _MuslVersion | None`

**Decorators:**
- `@functools.lru_cache`

**Description:**
Detect currently-running musl runtime version.

This is done by checking the specified executable's dynamic linking
information, and invoking the loader to parse its output for a version
string. If the loader is musl, the output would be something like::

musl libc (x86_64)
Version 1.2.2
Dynamic Program Loader

**Line:** 34

---

### `def platform_tags(archs: Sequence[str]) -> Iterator[str]`

**Description:**
Generate musllinux tags compatible to the current platform.

:param archs: Sequence of compatible architectures.
The first one shall be the closest to the actual architecture and be the part of
platform tag after the ``linux_`` prefix, e.g. ``x86_64``.
The ``linux_`` prefix is assumed as a prerequisite for the current platform to
be musllinux-compatible.

:returns: An iterator of compatible musllinux tags.

**Line:** 56

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.packaging._parser
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/packaging/_parser.py`

**Imports:**
- __future__.annotations
- _tokenizer.DEFAULT_RULES
- _tokenizer.Tokenizer
- ast
- typing.NamedTuple
- typing.Sequence
- typing.Tuple
- typing.Union

**Functions:**

### `def parse_requirement(source: str) -> ParsedRequirement`

**Line:** 61

---

### `def _parse_requirement(tokenizer: Tokenizer) -> ParsedRequirement`

**Description:**
requirement = WS? IDENTIFIER WS? extras WS? requirement_details

**Line:** 65

---

### `def _parse_requirement_details(tokenizer: Tokenizer) -> tuple[(str, str, MarkerList | None)]`

**Description:**
requirement_details = AT URL (WS requirement_marker?)?
| specifier WS? (requirement_marker)?

**Line:** 86

---

### `def _parse_requirement_marker(tokenizer: Tokenizer, span_start: int, after: str) -> MarkerList`

**Description:**
requirement_marker = SEMICOLON marker WS?

**Line:** 137

---

### `def _parse_extras(tokenizer: Tokenizer) -> list[str]`

**Description:**
extras = (LEFT_BRACKET wsp* extras_list? wsp* RIGHT_BRACKET)?

**Line:** 157

---

### `def _parse_extras_list(tokenizer: Tokenizer) -> list[str]`

**Description:**
extras_list = identifier (wsp* ',' wsp* identifier)*

**Line:** 176

---

### `def _parse_specifier(tokenizer: Tokenizer) -> str`

**Description:**
specifier = LEFT_PARENTHESIS WS? version_many WS? RIGHT_PARENTHESIS
| WS? version_many WS?

**Line:** 203

---

### `def _parse_version_many(tokenizer: Tokenizer) -> str`

**Description:**
version_many = (SPECIFIER (WS? COMMA WS? SPECIFIER)*)?

**Line:** 220

---

### `def parse_marker(source: str) -> MarkerList`

**Line:** 252

---

### `def _parse_full_marker(tokenizer: Tokenizer) -> MarkerList`

**Line:** 256

---

### `def _parse_marker(tokenizer: Tokenizer) -> MarkerList`

**Description:**
marker = marker_atom (BOOLOP marker_atom)+

**Line:** 262

---

### `def _parse_marker_atom(tokenizer: Tokenizer) -> MarkerAtom`

**Description:**
marker_atom = WS? LEFT_PARENTHESIS WS? marker WS? RIGHT_PARENTHESIS WS?
| WS? marker_item WS?

**Line:** 274

---

### `def _parse_marker_item(tokenizer: Tokenizer) -> MarkerItem`

**Description:**
marker_item = WS? marker_var WS? marker_op WS? marker_var WS?

**Line:** 296

---

### `def _parse_marker_var(tokenizer: Tokenizer) -> MarkerVar`

**Description:**
marker_var = VARIABLE | QUOTED_STRING

**Line:** 310

---

### `def process_env_var(env_var: str) -> Variable`

**Line:** 324

---

### `def process_python_str(python_str: str) -> Value`

**Line:** 331

---

### `def _parse_marker_op(tokenizer: Tokenizer) -> Op`

**Description:**
marker_op = IN | NOT IN | OP

**Line:** 336

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.packaging.licenses.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/packaging/licenses/__init__.py`

**Imports:**
- __future__.annotations
- pip._vendor.packaging.licenses._spdx.EXCEPTIONS
- pip._vendor.packaging.licenses._spdx.LICENSES
- re
- typing.NewType
- typing.cast

**Functions:**

### `def canonicalize_license_expression(raw_license_expression: str) -> NormalizedLicenseExpression`

**Line:** 60

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.packaging.markers
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/packaging/markers.py`

**Imports:**
- __future__.annotations
- _parser.MarkerAtom
- _parser.MarkerList
- _parser.Op
- _parser.Value
- _parser.Variable
- _parser.parse_marker
- _tokenizer.ParserSyntaxError
- operator
- os
- platform
- specifiers.InvalidSpecifier
- specifiers.Specifier
- sys
- typing.AbstractSet
- typing.Any
- typing.Callable
- typing.Literal
- typing.TypedDict
- typing.Union
- typing.cast
- utils.canonicalize_name

**Functions:**

### `def _normalize_extra_values(results: Any) -> Any`

**Description:**
Normalize extra values.

**Line:** 124

---

### `def _format_marker(marker: list[str] | MarkerAtom | str, first: bool | None = True) -> str`

**Line:** 140

---

### `def _eval_op(lhs: str, op: Op, rhs: str | AbstractSet[str]) -> bool`

**Line:** 180

---

### `def _normalize(lhs: str, rhs: str | AbstractSet[str], key: str) -> tuple[(str, str | AbstractSet[str])]`

**Line:** 196

---

### `def _evaluate_markers(markers: MarkerList, environment: dict[(str, str | AbstractSet[str])]) -> bool`

**Line:** 216

---

### `def format_full_version(info: sys._version_info) -> str`

**Line:** 248

---

### `def default_environment() -> Environment`

**Line:** 256

---

### `def _repair_python_full_version(env: dict[(str, str | AbstractSet[str])]) -> dict[(str, str | AbstractSet[str])]`

**Description:**
Work around platform.python_version() returning something that is not PEP 440
compliant for non-tagged Python builds.

**Line:** 352

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.packaging.metadata
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py`

**Imports:**
- __future__.annotations
- email.feedparser
- email.header
- email.message
- email.parser
- email.policy
- licenses.NormalizedLicenseExpression
- pathlib
- sys
- typing
- typing.Any
- typing.Callable
- typing.Generic
- typing.Literal
- typing.TypedDict
- typing.cast

**Functions:**

### `def _parse_keywords(data: str) -> list[str]`

**Description:**
Split a string of comma-separated keywords into a list of keywords.

**Line:** 175

---

### `def _parse_project_urls(data: list[str]) -> dict[(str, str)]`

**Description:**
Parse a list of label/URL string pairings separated by a comma.

**Line:** 180

---

### `def _get_payload(msg: email.message.Message, source: bytes | str) -> str`

**Description:**
Get the body of the message.

**Line:** 220

---

### `def parse_email(data: bytes | str) -> tuple[(RawMetadata, dict[str, list[str]])]`

**Description:**
Parse a distribution's metadata stored as email headers (e.g. from ``METADATA``).

This function returns a two-item tuple of dicts. The first dict is of
recognized fields from the core metadata specification. Fields that can be
parsed and translated into Python's built-in types are converted
appropriately. All other fields are left as-is. Fields that are allowed to
appear multiple times are stored as lists.

The second dict contains all other fields from the metadata. This includes
any unrecognized fields. It also includes any fields which are expected to
be parsed into a built-in type but were not formatted appropriately. Finally,
any fields that are expected to appear only once but are repeated are
included in this dict.

**Line:** 286

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.packaging.specifiers
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/packaging/specifiers.py`

**Imports:**
- __future__.annotations
- abc
- itertools
- re
- typing.Callable
- typing.Iterable
- typing.Iterator
- typing.TypeVar
- typing.Union
- utils.canonicalize_version
- version.Version

**Functions:**

### `def _coerce_version(version: UnparsedVersion) -> Version`

**Line:** 26

---

### `def _version_split(version: str) -> list[str]`

**Description:**
Split version into components.

The split components are intended for version comparison. The logic does
not attempt to retain the original version string, so joining the
components back with :func:`_version_join` may not produce the original
version string.

**Line:** 630

---

### `def _version_join(components: list[str]) -> str`

**Description:**
Join split version components into a version string.

This function assumes the input came from :func:`_version_split`, where the
first component must be the epoch (either empty or numeric), and all other
components numeric.

**Line:** 652

---

### `def _is_not_suffix(segment: str) -> bool`

**Line:** 663

---

### `def _pad_version(left: list[str], right: list[str]) -> tuple[(list[str], list[str])]`

**Line:** 669

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.packaging.tags
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/packaging/tags.py`

**Imports:**
- __future__.annotations
- importlib.machinery.EXTENSION_SUFFIXES
- logging
- platform
- re
- struct
- subprocess
- sys
- sysconfig
- typing.Iterable
- typing.Iterator
- typing.Sequence
- typing.Tuple
- typing.cast

**Functions:**

### `def parse_tag(tag: str) -> frozenset[Tag]`

**Description:**
Parses the provided tag (e.g. `py3-none-any`) into a frozenset of Tag instances.

Returning a set is required due to the possibility that the tag is a
compressed tag set.

**Line:** 96

---

### `def _get_config_var(name: str, warn: bool = False) -> int | str | None`

**Line:** 112

---

### `def _normalize_string(string: str) -> str`

**Line:** 121

---

### `def _is_threaded_cpython(abis: list[str]) -> bool`

**Description:**
Determine if the ABI corresponds to a threaded (`--disable-gil`) build.

The threaded builds are indicated by a "t" in the abiflags.

**Line:** 125

---

### `def _abi3_applies(python_version: PythonVersion, threading: bool) -> bool`

**Description:**
Determine if the Python version supports abi3.

PEP 384 was first implemented in Python 3.2. The threaded (`--disable-gil`)
builds do not support abi3.

**Line:** 141

---

### `def _cpython_abis(py_version: PythonVersion, warn: bool = False) -> list[str]`

**Line:** 151

---

### `def cpython_tags(python_version: PythonVersion | None = None, abis: Iterable[str] | None = None, platforms: Iterable[str] | None = None, warn: bool = False) -> Iterator[Tag]`

**Description:**
Yields the tags for a CPython interpreter.

The tags consist of:
- cp<python_version>-<abi>-<platform>
- cp<python_version>-abi3-<platform>
- cp<python_version>-none-<platform>
- cp<less than python_version>-abi3-<platform>  # Older Python versions down to 3.2.

If python_version only specifies a major version then user-provided ABIs and
the 'none' ABItag will be used.

If 'abi3' or 'none' are specified in 'abis' then they will be yielded at
their normal position and not at the beginning.

**Line:** 184

---

### `def _generic_abi() -> list[str]`

**Description:**
Return the ABI tag based on EXT_SUFFIX.

**Line:** 243

---

### `def generic_tags(interpreter: str | None = None, abis: Iterable[str] | None = None, platforms: Iterable[str] | None = None, warn: bool = False) -> Iterator[Tag]`

**Description:**
Yields the tags for a generic interpreter.

The tags consist of:
- <interpreter>-<abi>-<platform>

The "none" ABI will be added if it was not explicitly provided.

**Line:** 284

---

### `def _py_interpreter_range(py_version: PythonVersion) -> Iterator[str]`

**Description:**
Yields Python versions in descending order.

After the latest version, the major-only version will be yielded, and then
all previous versions of that major version.

**Line:** 315

---

### `def compatible_tags(python_version: PythonVersion | None = None, interpreter: str | None = None, platforms: Iterable[str] | None = None) -> Iterator[Tag]`

**Description:**
Yields the sequence of tags that are compatible with a specific version of Python.

The tags consist of:
- py*-none-<platform>
- <interpreter>-none-any  # ... if `interpreter` is provided.
- py*-none-any

**Line:** 330

---

### `def _mac_arch(arch: str, is_32bit: bool = _32_BIT_INTERPRETER) -> str`

**Line:** 355

---

### `def _mac_binary_formats(version: AppleVersion, cpu_arch: str) -> list[str]`

**Line:** 365

---

### `def mac_platforms(version: AppleVersion | None = None, arch: str | None = None) -> Iterator[str]`

**Description:**
Yields the platform tags for a macOS system.

The `version` parameter is a two-item tuple specifying the macOS version to
generate platform tags for. The `arch` parameter is the CPU architecture to
generate platform tags for. Both parameters default to the appropriate value
for the current system.

**Line:** 397

---

### `def ios_platforms(version: AppleVersion | None = None, multiarch: str | None = None) -> Iterator[str]`

**Description:**
Yields the platform tags for an iOS system.

:param version: A two-item tuple specifying the iOS version to generate
platform tags for. Defaults to the current iOS version.
:param multiarch: The CPU architecture+ABI to generate platform tags for -
(the value used by `sys.implementation._multiarch` e.g.,
`arm64_iphoneos` or `x84_64_iphonesimulator`). Defaults to the current
multiarch value.

**Line:** 476

---

### `def android_platforms(api_level: int | None = None, abi: str | None = None) -> Iterator[str]`

**Description:**
Yields the :attr:`~Tag.platform` tags for Android. If this function is invoked on
non-Android platforms, the ``api_level`` and ``abi`` arguments are required.

:param int api_level: The maximum `API level
<https://developer.android.com/tools/releases/platforms>`__ to return. Defaults
to the current system's version, as returned by ``platform.android_ver``.
:param str abi: The `Android ABI <https://developer.android.com/ndk/guides/abis>`__,
e.g. ``arm64_v8a``. Defaults to the current system's ABI , as returned by
``sysconfig.get_platform``. Hyphens and periods will be replaced with
underscores.

**Line:** 533

---

### `def _linux_platforms(is_32bit: bool = _32_BIT_INTERPRETER) -> Iterator[str]`

**Line:** 570

---

### `def _generic_platforms() -> Iterator[str]`

**Line:** 589

---

### `def platform_tags() -> Iterator[str]`

**Description:**
Provides the platform tags for this installation.

**Line:** 593

---

### `def interpreter_name() -> str`

**Description:**
Returns the name of the running interpreter.

Some implementations have a reserved, two-letter abbreviation which will
be returned when appropriate.

**Line:** 609

---

### `def interpreter_version(warn: bool = False) -> str`

**Description:**
Returns the version of the running interpreter.

**Line:** 620

---

### `def _version_nodot(version: PythonVersion) -> str`

**Line:** 632

---

### `def sys_tags(warn: bool = False) -> Iterator[Tag]`

**Description:**
Returns the sequence of tag triples for the running interpreter.

The order of the sequence corresponds to priority order for the
interpreter, from most to least important.

**Line:** 636

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.packaging.utils
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/packaging/utils.py`

**Imports:**
- __future__.annotations
- functools
- re
- tags.Tag
- tags.parse_tag
- typing.NewType
- typing.Tuple
- typing.Union
- typing.cast
- version.InvalidVersion
- version.Version
- version._TrimmedRelease

**Functions:**

### `def canonicalize_name(name: str, validate: bool = False) -> NormalizedName`

**Line:** 46

---

### `def is_normalized_name(name: str) -> bool`

**Line:** 54

---

### `def canonicalize_version(version: Version | str, strip_trailing_zero: bool = True) -> str`

**Decorators:**
- `@functools.singledispatch`

**Description:**
Return a canonical form of a version as a string.

>>> canonicalize_version('1.0.1')
'1.0.1'

Per PEP 625, versions may have multiple canonical forms, differing
only by trailing zeros.

>>> canonicalize_version('1.0.0')
'1'
>>> canonicalize_version('1.0.0', strip_trailing_zero=False)
'1.0.0'

Invalid versions are returned unaltered.

>>> canonicalize_version('foo bar baz')
'foo bar baz'

**Line:** 59

---

### `def _(version: str, strip_trailing_zero: bool = True) -> str`

**Decorators:**
- `@canonicalize_version.register`

**Line:** 85

---

### `def parse_wheel_filename(filename: str) -> tuple[(NormalizedName, Version, BuildTag, frozenset[Tag])]`

**Line:** 94

---

### `def parse_sdist_filename(filename: str) -> tuple[(NormalizedName, Version)]`

**Line:** 137

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.packaging.version
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/packaging/version.py`

**Imports:**
- __future__.annotations
- _structures.Infinity
- _structures.InfinityType
- _structures.NegativeInfinity
- _structures.NegativeInfinityType
- itertools
- re
- typing.Any
- typing.Callable
- typing.NamedTuple
- typing.SupportsInt
- typing.Tuple
- typing.Union

**Functions:**

### `def parse(version: str) -> Version`

**Description:**
Parse the given version string.

>>> parse('1.0.dev1')
<Version('1.0.dev1')>

:param version: The version string to parse.
:raises InvalidVersion: When the version string is not a valid version.

**Line:** 47

---

### `def _parse_letter_version(letter: str | None, number: str | bytes | SupportsInt | None) -> tuple[str, int] | None`

**Line:** 471

---

### `def _parse_local_version(local: str | None) -> LocalType | None`

**Description:**
Takes a string like abc.1.twelve and turns it into ("abc", 1, "twelve").

**Line:** 511

---

### `def _cmpkey(epoch: int, release: tuple[(int, ...)], pre: tuple[str, int] | None, post: tuple[str, int] | None, dev: tuple[str, int] | None, local: LocalType | None) -> CmpKey`

**Line:** 523

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.pkg_resources.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py`

**Imports:**
- __future__.annotations
- __main__.__requires__
- _imp
- _typeshed.BytesPath
- _typeshed.StrOrBytesPath
- _typeshed.StrPath
- collections
- email.parser
- errno
- functools
- importlib
- importlib.abc
- importlib.machinery
- inspect
- io
- linecache.cache
- ntpath
- operator
- os
- os.mkdir
- os.open
- os.path.isdir
- os.path.split
- os.rename
- os.unlink
- os.utime
- pip._internal.utils._jaraco_text.drop_comment
- pip._internal.utils._jaraco_text.join_continuation
- pip._internal.utils._jaraco_text.yield_lines
- pip._vendor.packaging.markers
- pip._vendor.packaging.requirements
- pip._vendor.packaging.utils
- pip._vendor.packaging.version
- pip._vendor.platformdirs.user_cache_dir
- pip._vendor.typing_extensions.Self
- pkgutil
- pkgutil.get_importer
- platform
- plistlib
- posixpath
- re
- stat
- sys
- sysconfig.get_platform
- tempfile
- textwrap
- time
- types
- typing.Any
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.Literal
- typing.Mapping
- typing.MutableSequence
- typing.NamedTuple
- typing.NoReturn
- typing.Protocol
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.overload
- warnings
- zipfile
- zipimport

**Functions:**

### `def _declare_state(vartype: str, varname: str, initial_value: _T) -> _T`

**Line:** 159

---

### `def __getstate__() -> dict[(str, Any)]`

**Line:** 164

---

### `def __setstate__(state: dict[(str, Any)]) -> dict[(str, Any)]`

**Line:** 172

---

### `def _sget_dict(val)`

**Line:** 179

---

### `def _sset_dict(key, ob, state)`

**Line:** 183

---

### `def _sget_object(val)`

**Line:** 188

---

### `def _sset_object(key, ob, state)`

**Line:** 192

---

### `def get_supported_platform()`

**Description:**
Return this platform's maximum compatible version.

distutils.util.get_platform() normally reports the minimum version
of macOS that would be required to *use* extensions produced by
distutils.  But what we want when checking compatibility is to know the
version of macOS that we are *running*.  To allow usage of packages that
explicitly require a newer version of macOS, we must also know the
current version of the OS.

If this condition occurs for any other platform with a version in its
platform strings, this function should be extended accordingly.

**Line:** 199

---

### `def register_loader_type(loader_type: type[_ModuleLike], provider_factory: _ProviderFactoryType)`

**Description:**
Register `provider_factory` to make providers for `loader_type`

`loader_type` is the type or class of a PEP 302 ``module.__loader__``,
and `provider_factory` is a function that, passed a *module* object,
returns an ``IResourceProvider`` for that module.

**Line:** 404

---

### `def get_provider(moduleOrReq: str) -> IResourceProvider`

**Decorators:**
- `@overload`

**Line:** 417

---

### `def get_provider(moduleOrReq: Requirement) -> Distribution`

**Decorators:**
- `@overload`

**Line:** 419

---

### `def get_provider(moduleOrReq: str | Requirement) -> IResourceProvider | Distribution`

**Description:**
Return an IResourceProvider for the named module or requirement

**Line:** 420

---

### `def _macos_vers()`

**Decorators:**
- `@functools.lru_cache(...)`

**Line:** 434

---

### `def _macos_arch(machine)`

**Line:** 447

---

### `def get_build_platform()`

**Description:**
Return this platform's string for platform-specific distributions

XXX Currently this is the same as ``distutils.util.get_platform()``, but it
needs some hacks for Linux and macOS.

**Line:** 451

---

### `def compatible_platforms(provided: str | None, required: str | None)`

**Description:**
Can code for the `provided` platform run on the `required` platform?

Returns true if either platform is ``None``, or the platforms are equal.

XXX Needs compatibility checks for Linux and other unixy OSes.

**Line:** 482

---

### `def get_distribution(dist: _DistributionT) -> _DistributionT`

**Decorators:**
- `@overload`

**Line:** 532

---

### `def get_distribution(dist: _PkgReqType) -> Distribution`

**Decorators:**
- `@overload`

**Line:** 534

---

### `def get_distribution(dist: Distribution | _PkgReqType) -> Distribution`

**Description:**
Return a current distribution object for a Requirement or string

**Line:** 535

---

### `def load_entry_point(dist: _EPDistType, group: str, name: str) -> _ResolvedEntryPoint`

**Description:**
Return `name` entry point of `group` for `dist` or raise ImportError

**Line:** 547

---

### `def get_entry_map(dist: _EPDistType, group: None = None) -> dict[(str, dict[str, EntryPoint])]`

**Decorators:**
- `@overload`

**Line:** 553

---

### `def get_entry_map(dist: _EPDistType, group: str) -> dict[(str, EntryPoint)]`

**Decorators:**
- `@overload`

**Line:** 557

---

### `def get_entry_map(dist: _EPDistType, group: str | None = None)`

**Description:**
Return the entry point map for `group`, or the full entry map

**Line:** 558

---

### `def get_entry_info(dist: _EPDistType, group: str, name: str)`

**Description:**
Return the EntryPoint object for `group`+`name`, or ``None``

**Line:** 563

---

### `def get_default_cache() -> str`

**Description:**
Return the ``PYTHON_EGG_CACHE`` environment variable
or a platform-relevant user cache dir for an app
named "Python-Eggs".

**Line:** 1526

---

### `def safe_name(name: str)`

**Description:**
Convert an arbitrary string to a standard distribution name

Any runs of non-alphanumeric/. characters are replaced with a single '-'.

**Line:** 1535

---

### `def safe_version(version: str)`

**Description:**
Convert an arbitrary string to a standard version string

**Line:** 1543

---

### `def _forgiving_version(version)`

**Description:**
Fallback when ``safe_version`` is not safe enough
>>> parse_version(_forgiving_version('0.23ubuntu1'))
<Version('0.23.dev0+sanitized.ubuntu1')>
>>> parse_version(_forgiving_version('0.23-'))
<Version('0.23.dev0+sanitized')>
>>> parse_version(_forgiving_version('0.-_'))
<Version('0.dev0+sanitized')>
>>> parse_version(_forgiving_version('42.+?1'))
<Version('42.dev0+sanitized.1')>
>>> parse_version(_forgiving_version('hello world'))
<Version('0.dev0+sanitized.hello.world')>

**Line:** 1555

---

### `def _safe_segment(segment)`

**Description:**
Convert an arbitrary string into a safe segment

**Line:** 1580

---

### `def safe_extra(extra: str)`

**Description:**
Convert an arbitrary string to a standard 'extra' name

Any runs of non-alphanumeric characters are replaced with a single '_',
and the result is always lowercased.

**Line:** 1587

---

### `def to_filename(name: str)`

**Description:**
Convert a project or version name to its filename-escaped form

Any '-' characters are currently replaced with '_'.

**Line:** 1596

---

### `def invalid_marker(text: str)`

**Description:**
Validate text as a PEP 508 environment marker; return an exception
if invalid or False otherwise.

**Line:** 1604

---

### `def evaluate_marker(text: str, extra: str | None = None) -> bool`

**Description:**
Evaluate a PEP 508 environment marker.
Return a boolean indicating the marker result in this environment.
Raise SyntaxError if marker is invalid.

This implementation uses the 'pyparsing' module.

**Line:** 1618

---

### `def _parents(path)`

**Description:**
yield all parents of path including path

**Line:** 1839

---

### `def register_finder(importer_type: type[_T], distribution_finder: _DistFinderType[_T])`

**Description:**
Register `distribution_finder` to find distributions in sys.path items

`importer_type` is the type or class of a PEP 302 "Importer" (sys.path item
handler), and `distribution_finder` is a callable that, passed a path
item and the importer instance, yields ``Distribution`` instances found on
that path item.  See ``pkg_resources.find_on_path`` for an example.

**Line:** 2234

---

### `def find_distributions(path_item: str, only: bool = False)`

**Description:**
Yield distributions accessible via `path_item`

**Line:** 2244

---

### `def find_eggs_in_zip(importer: zipimport.zipimporter, path_item: str, only: bool = False) -> Iterator[Distribution]`

**Description:**
Find eggs in zip files; possibly multiple nested eggs.

**Line:** 2251

---

### `def find_nothing(importer: object | None, path_item: str | None, only: bool | None = False)`

**Line:** 2282

---

### `def find_on_path(importer: object | None, path_item, only = False)`

**Description:**
Yield distributions accessible on a sys.path directory

**Line:** 2291

---

### `def dist_factory(path_item, entry, only)`

**Description:**
Return a dist_factory for the given entry.

**Line:** 2311

---

### `def safe_listdir(path: StrOrBytesPath)`

**Description:**
Attempt to list contents of path, but suppress some exceptions.

**Line:** 2346

---

### `def distributions_from_metadata(path: str)`

**Line:** 2362

---

### `def non_empty_lines(path)`

**Description:**
Yield non-empty lines from file at path

**Line:** 2380

---

### `def resolve_egg_link(path)`

**Description:**
Given a path to an .egg-link, resolve distributions
present in the referenced path.

**Line:** 2390

---

### `def register_namespace_handler(importer_type: type[_T], namespace_handler: _NSHandlerType[_T])`

**Description:**
Register `namespace_handler` to declare namespace packages

`importer_type` is the type or class of a PEP 302 "Importer" (sys.path item
handler), and `namespace_handler` is a callable like this::

def namespace_handler(importer, path_entry, moduleName, module):
# return a path_entry to use for child packages

Namespace handlers are only called if the importer object has already
agreed that it can handle the relevant path item, and they should only
return a subpath if the module __path__ does not already contain an
equivalent subpath.  For an example namespace handler, see
``pkg_resources.file_ns_handler``.

**Line:** 2416

---

### `def _handle_ns(packageName, path_item)`

**Description:**
Ensure that named package includes a subpath of path_item (if needed)

**Line:** 2436

---

### `def _rebuild_mod_path(orig_path, package_name, module: types.ModuleType)`

**Description:**
Rebuild module.__path__ ensuring that all entries are ordered
corresponding to their sys.path order

**Line:** 2473

---

### `def declare_namespace(packageName: str)`

**Description:**
Declare that package 'packageName' is a namespace package

**Line:** 2507

---

### `def fixup_namespace_packages(path_item: str, parent: str | None = None)`

**Description:**
Ensure that previously-declared namespace packages include path_item

**Line:** 2550

---

### `def file_ns_handler(importer: object, path_item: StrPath, packageName: str, module: types.ModuleType)`

**Description:**
Compute an ns-package subpath for a filesystem or zipfile importer

**Line:** 2562

---

### `def null_ns_handler(importer: object, path_item: str | None, packageName: str | None, module: _ModuleLike | None)`

**Line:** 2587

---

### `def normalize_path(filename: StrPath) -> str`

**Decorators:**
- `@overload`

**Line:** 2600

---

### `def normalize_path(filename: BytesPath) -> bytes`

**Decorators:**
- `@overload`

**Line:** 2602

---

### `def normalize_path(filename: StrOrBytesPath)`

**Description:**
Normalize a file/dir name for comparison purposes

**Line:** 2603

---

### `def _cygwin_patch(filename: StrOrBytesPath)`

**Description:**
Contrary to POSIX 2008, on Cygwin, getcwd (3) contains
symlink components. Using
os.path.abspath() works around this limitation. A fix in os.getcwd()
would probably better, in Cygwin even more so, except
that this seems to be by design...

**Line:** 2608

---

### `def _normalize_cached(filename: StrPath) -> str`

**Decorators:**
- `@overload`

**Line:** 2623

---

### `def _normalize_cached(filename: BytesPath) -> bytes`

**Decorators:**
- `@overload`

**Line:** 2625

---

### `def _normalize_cached(filename: StrOrBytesPath) -> str | bytes`

**Line:** 2626

---

### `def _normalize_cached(filename)`

**Decorators:**
- `@functools.lru_cache(...)`

**Line:** 2630

---

### `def _is_egg_path(path)`

**Description:**
Determine if given path appears to be an egg.

**Line:** 2634

---

### `def _is_zip_egg(path)`

**Line:** 2641

---

### `def _is_unpacked_egg(path)`

**Description:**
Determine if given path appears to be an unpacked egg.

**Line:** 2649

---

### `def _set_parent_ns(packageName)`

**Line:** 2658

---

### `def _version_from_file(lines)`

**Description:**
Given an iterable of lines from a Metadata file, return
the value of the Version field, if present, or None otherwise.

**Line:** 2856

---

### `def issue_warning(*args, **kw)`

**Line:** 3405

---

### `def parse_requirements(strs: _NestedStr)`

**Description:**
Yield ``Requirement`` objects for each specification in `strs`.

`strs` must be a string, or a (possibly-nested) iterable thereof.

**Line:** 3418

---

### `def _always_object(classes)`

**Description:**
Ensure object appears in the mro even
for old-style classes.

**Line:** 3480

---

### `def _find_adapter(registry: Mapping[(type, _AdapterT)], ob: object) -> _AdapterT`

**Description:**
Return an adapter factory for `ob` from `registry`

**Line:** 3490

---

### `def ensure_directory(path: StrOrBytesPath)`

**Description:**
Ensure that the parent directory of `path` exists

**Line:** 3501

---

### `def _bypass_ensure_directory(path)`

**Description:**
Sandbox-bypassing version of ensure_directory()

**Line:** 3507

---

### `def split_sections(s: _NestedStr) -> Iterator[tuple[(str | None, list[str])]]`

**Description:**
Split a string or iterable thereof into (section, content) pairs

Each ``section`` is a stripped version of the section header ("[section]")
and each ``content`` is a list of stripped lines excluding blank lines and
comment-only lines.  If there are any such lines before the first section
header, they're returned in a first ``section`` of ``None``.

**Line:** 3520

---

### `def _mkstemp(*args, **kw)`

**Line:** 3546

---

### `def _read_utf8_with_fallback(file: str, fallback_encoding = _LOCALE_ENCODING) -> str`

**Description:**
See setuptools.unicode_utils._read_utf8_with_fallback

**Line:** 3577

---

### `def _call_aside(f, *args, **kwargs)`

**Line:** 3606

---

### `def _initialize(g = globals())`

**Decorators:**
- `@_call_aside`

**Description:**
Set up global resource manager (deliberately not state-saved)

**Line:** 3612

---

### `def _initialize_master_working_set()`

**Decorators:**
- `@_call_aside`

**Description:**
Prepare the master working set and make the ``require()``
API available.

This function has explicit effects on the global state
of pkg_resources. It is intended to be invoked once at
the initialization of this module.

Invocation by other packages is unsupported and done
at their own risk.

**Line:** 3624

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.platformdirs.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/platformdirs/__init__.py`

**Imports:**
- __future__.annotations
- api.PlatformDirsABC
- os
- pathlib.Path
- pip._vendor.platformdirs.android.Android
- pip._vendor.platformdirs.android._android_folder
- pip._vendor.platformdirs.macos.MacOS
- pip._vendor.platformdirs.unix.Unix
- pip._vendor.platformdirs.windows.Windows
- sys
- typing.Literal
- typing.TYPE_CHECKING
- version.__version__
- version.__version_tuple__

**Functions:**

### `def _set_platform_dir_class() -> type[PlatformDirsABC]`

**Line:** 30

---

### `def user_data_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, roaming: bool = False, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: data directory tied to the user

**Line:** 53

---

### `def site_data_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, multipath: bool = False, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param multipath: See `roaming <platformdirs.api.PlatformDirsABC.multipath>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: data directory shared by users

**Line:** 77

---

### `def user_config_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, roaming: bool = False, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: config directory tied to the user

**Line:** 101

---

### `def site_config_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, multipath: bool = False, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param multipath: See `roaming <platformdirs.api.PlatformDirsABC.multipath>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: config directory shared by the users

**Line:** 125

---

### `def user_cache_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: cache directory tied to the user

**Line:** 149

---

### `def site_cache_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: cache directory tied to the user

**Line:** 173

---

### `def user_state_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, roaming: bool = False, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: state directory tied to the user

**Line:** 197

---

### `def user_log_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: log directory tied to the user

**Line:** 221

---

### `def user_documents_dir() -> str`

**Description:**
:returns: documents directory tied to the user

**Line:** 245

---

### `def user_downloads_dir() -> str`

**Description:**
:returns: downloads directory tied to the user

**Line:** 250

---

### `def user_pictures_dir() -> str`

**Description:**
:returns: pictures directory tied to the user

**Line:** 255

---

### `def user_videos_dir() -> str`

**Description:**
:returns: videos directory tied to the user

**Line:** 260

---

### `def user_music_dir() -> str`

**Description:**
:returns: music directory tied to the user

**Line:** 265

---

### `def user_desktop_dir() -> str`

**Description:**
:returns: desktop directory tied to the user

**Line:** 270

---

### `def user_runtime_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: runtime directory tied to the user

**Line:** 275

---

### `def site_runtime_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: runtime directory shared by users

**Line:** 299

---

### `def user_data_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, roaming: bool = False, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: data path tied to the user

**Line:** 323

---

### `def site_data_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, multipath: bool = False, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param multipath: See `multipath <platformdirs.api.PlatformDirsABC.multipath>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: data path shared by users

**Line:** 347

---

### `def user_config_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, roaming: bool = False, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: config path tied to the user

**Line:** 371

---

### `def site_config_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, multipath: bool = False, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param multipath: See `roaming <platformdirs.api.PlatformDirsABC.multipath>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: config path shared by the users

**Line:** 395

---

### `def site_cache_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: cache directory tied to the user

**Line:** 419

---

### `def user_cache_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: cache path tied to the user

**Line:** 443

---

### `def user_state_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, roaming: bool = False, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: state path tied to the user

**Line:** 467

---

### `def user_log_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: log path tied to the user

**Line:** 491

---

### `def user_documents_path() -> Path`

**Description:**
:returns: documents a path tied to the user

**Line:** 515

---

### `def user_downloads_path() -> Path`

**Description:**
:returns: downloads path tied to the user

**Line:** 520

---

### `def user_pictures_path() -> Path`

**Description:**
:returns: pictures path tied to the user

**Line:** 525

---

### `def user_videos_path() -> Path`

**Description:**
:returns: videos path tied to the user

**Line:** 530

---

### `def user_music_path() -> Path`

**Description:**
:returns: music path tied to the user

**Line:** 535

---

### `def user_desktop_path() -> Path`

**Description:**
:returns: desktop path tied to the user

**Line:** 540

---

### `def user_runtime_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: runtime path tied to the user

**Line:** 545

---

### `def site_runtime_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: runtime path shared by users

**Line:** 569

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.platformdirs.__main__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/platformdirs/__main__.py`

**Imports:**
- __future__.annotations
- pip._vendor.platformdirs.PlatformDirs
- pip._vendor.platformdirs.__version__

**Functions:**

### `def main() -> None`

**Description:**
Run the main entry point.

**Line:** 26

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.platformdirs.android
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/platformdirs/android.py`

**Imports:**
- __future__.annotations
- android.mActivity
- api.PlatformDirsABC
- functools.lru_cache
- jnius.autoclass
- os
- re
- sys
- typing.TYPE_CHECKING
- typing.cast

**Functions:**

### `def _android_folder() -> str | None`

**Decorators:**
- `@lru_cache(...)`

**Description:**
:return: base folder for the Android OS or None if it cannot be found

**Line:** 120

---

### `def _android_documents_folder() -> str`

**Decorators:**
- `@lru_cache(...)`

**Description:**
:return: documents folder for the Android OS

**Line:** 168

---

### `def _android_downloads_folder() -> str`

**Decorators:**
- `@lru_cache(...)`

**Description:**
:return: downloads folder for the Android OS

**Line:** 184

---

### `def _android_pictures_folder() -> str`

**Decorators:**
- `@lru_cache(...)`

**Description:**
:return: pictures folder for the Android OS

**Line:** 200

---

### `def _android_videos_folder() -> str`

**Decorators:**
- `@lru_cache(...)`

**Description:**
:return: videos folder for the Android OS

**Line:** 216

---

### `def _android_music_folder() -> str`

**Decorators:**
- `@lru_cache(...)`

**Description:**
:return: music folder for the Android OS

**Line:** 232

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.platformdirs.unix
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/platformdirs/unix.py`

**Imports:**
- __future__.annotations
- api.PlatformDirsABC
- collections.abc.Iterator
- configparser.ConfigParser
- os
- os.getuid
- pathlib.Path
- sys
- typing.NoReturn
- typing.TYPE_CHECKING

**Functions:**

### `def getuid() -> NoReturn`

**Line:** 18

---

### `def _get_user_media_dir(env_var: str, fallback_tilde_path: str) -> str`

**Line:** 235

---

### `def _get_user_dirs_folder(key: str) -> str | None`

**Description:**
Return directory from user-dirs.dirs config file.

See https://freedesktop.org/wiki/Software/xdg-user-dirs/.

**Line:** 245

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.platformdirs.windows
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/platformdirs/windows.py`

**Imports:**
- __future__.annotations
- api.PlatformDirsABC
- collections.abc.Callable
- ctypes
- functools.lru_cache
- os
- sys
- typing.TYPE_CHECKING
- winreg

**Functions:**

### `def get_win_folder_from_env_vars(csidl_name: str) -> str`

**Description:**
Get folder from environment variables.

**Line:** 143

---

### `def get_win_folder_if_csidl_name_not_env_var(csidl_name: str) -> str | None`

**Description:**
Get a folder for a CSIDL name that does not exist as an environment variable.

**Line:** 164

---

### `def get_win_folder_from_registry(csidl_name: str) -> str`

**Description:**
Get folder from the registry.

This is a fallback technique at best. I'm not sure if using the registry for these guarantees us the correct answer
for all CSIDL_* names.

**Line:** 183

---

### `def get_win_folder_via_ctypes(csidl_name: str) -> str`

**Description:**
Get folder with ctypes.

**Line:** 213

---

### `def _pick_get_win_folder() -> Callable[([str], str)]`

**Line:** 252

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.requests.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/requests/__init__.py`

**Imports:**
- __version__.__author__
- __version__.__author_email__
- __version__.__build__
- __version__.__cake__
- __version__.__copyright__
- __version__.__description__
- __version__.__license__
- __version__.__title__
- __version__.__url__
- __version__.__version__
- api.delete
- api.get
- api.head
- api.options
- api.patch
- api.post
- api.put
- api.request
- cryptography.__version__
- exceptions.ConnectTimeout
- exceptions.ConnectionError
- exceptions.FileModeWarning
- exceptions.HTTPError
- exceptions.JSONDecodeError
- exceptions.ReadTimeout
- exceptions.RequestException
- exceptions.RequestsDependencyWarning
- exceptions.Timeout
- exceptions.TooManyRedirects
- exceptions.URLRequired
- logging
- logging.NullHandler
- models.PreparedRequest
- models.Request
- models.Response
- pip._internal.utils.compat.WINDOWS
- pip._vendor.urllib3
- pip._vendor.urllib3.contrib.pyopenssl
- pip._vendor.urllib3.exceptions.DependencyWarning
- sessions.Session
- sessions.session
- ssl
- status_codes.codes
- warnings

**Functions:**

### `def check_compatibility(urllib3_version, chardet_version, charset_normalizer_version)`

**Line:** 51

---

### `def _check_cryptography(cryptography_version)`

**Line:** 83

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.requests._internal_utils
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/requests/_internal_utils.py`

**Imports:**
- compat.builtin_str
- re

**Functions:**

### `def to_native_string(string, encoding = 'ascii')`

**Description:**
Given a string object, regardless of type, returns a representation of
that string in the native string type, encoding and decoding where
necessary. This assumes ASCII unless told otherwise.

**Line:** 25

---

### `def unicode_is_ascii(u_string)`

**Description:**
Determine if unicode string only contains ASCII characters.

:param str u_string: unicode string to check. Must be unicode
and not Python 2 `str`.
:rtype: bool

**Line:** 38

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.requests.adapters
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py`

**Imports:**
- auth._basic_auth_str
- compat.basestring
- compat.urlparse
- cookies.extract_cookies_to_jar
- exceptions.ConnectTimeout
- exceptions.ConnectionError
- exceptions.InvalidHeader
- exceptions.InvalidProxyURL
- exceptions.InvalidSchema
- exceptions.InvalidURL
- exceptions.ProxyError
- exceptions.ReadTimeout
- exceptions.RetryError
- exceptions.SSLError
- models.PreparedRequest
- models.Response
- os.path
- pip._vendor.urllib3.contrib.socks.SOCKSProxyManager
- pip._vendor.urllib3.exceptions.ClosedPoolError
- pip._vendor.urllib3.exceptions.ConnectTimeoutError
- pip._vendor.urllib3.exceptions.HTTPError
- pip._vendor.urllib3.exceptions.InvalidHeader
- pip._vendor.urllib3.exceptions.LocationValueError
- pip._vendor.urllib3.exceptions.MaxRetryError
- pip._vendor.urllib3.exceptions.NewConnectionError
- pip._vendor.urllib3.exceptions.ProtocolError
- pip._vendor.urllib3.exceptions.ProxyError
- pip._vendor.urllib3.exceptions.ReadTimeoutError
- pip._vendor.urllib3.exceptions.ResponseError
- pip._vendor.urllib3.exceptions.SSLError
- pip._vendor.urllib3.poolmanager.PoolManager
- pip._vendor.urllib3.poolmanager.proxy_from_url
- pip._vendor.urllib3.util.Timeout
- pip._vendor.urllib3.util.parse_url
- pip._vendor.urllib3.util.retry.Retry
- pip._vendor.urllib3.util.ssl_.create_urllib3_context
- socket
- ssl
- structures.CaseInsensitiveDict
- typing
- utils.DEFAULT_CA_BUNDLE_PATH
- utils.extract_zipped_paths
- utils.get_auth_from_url
- utils.get_encoding_from_headers
- utils.prepend_scheme_if_needed
- utils.select_proxy
- utils.urldefragauth
- warnings

**Functions:**

### `def SOCKSProxyManager(*args, **kwargs)`

**Line:** 63

---

### `def _urllib3_request_context(request: 'PreparedRequest', verify: 'bool | str | None', client_cert: 'typing.Tuple[str, str] | str | None', poolmanager: 'PoolManager') -> '(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])'`

**Line:** 90

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.requests.api
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/requests/api.py`

**Functions:**

### `def request(method, url, **kwargs)`

**Description:**
Constructs and sends a :class:`Request <Request>`.

:param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
:param url: URL for the new :class:`Request` object.
:param params: (optional) Dictionary, list of tuples or bytes to send
in the query string for the :class:`Request`.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
:param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
:param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string
defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
to add for the file.
:param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
:param timeout: (optional) How many seconds to wait for the server to send data
before giving up, as a float, or a :ref:`(connect timeout, read
timeout) <timeouts>` tuple.
:type timeout: float or tuple
:param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
:type allow_redirects: bool
:param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
:param verify: (optional) Either a boolean, in which case it controls whether we verify
the server's TLS certificate, or a string, in which case it must be a path
to a CA bundle to use. Defaults to ``True``.
:param stream: (optional) if ``False``, the response content will be immediately downloaded.
:param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
:return: :class:`Response <Response>` object
:rtype: requests.Response

Usage::

>>> import requests
>>> req = requests.request('GET', 'https://httpbin.org/get')
>>> req
<Response [200]>

**Line:** 14

---

### `def get(url, params = None, **kwargs)`

**Description:**
Sends a GET request.

:param url: URL for the new :class:`Request` object.
:param params: (optional) Dictionary, list of tuples or bytes to send
in the query string for the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Line:** 62

---

### `def options(url, **kwargs)`

**Description:**
Sends an OPTIONS request.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Line:** 76

---

### `def head(url, **kwargs)`

**Description:**
Sends a HEAD request.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes. If
`allow_redirects` is not provided, it will be set to `False` (as
opposed to the default :meth:`request` behavior).
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Line:** 88

---

### `def post(url, data = None, json = None, **kwargs)`

**Description:**
Sends a POST request.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Line:** 103

---

### `def put(url, data = None, **kwargs)`

**Description:**
Sends a PUT request.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Line:** 118

---

### `def patch(url, data = None, **kwargs)`

**Description:**
Sends a PATCH request.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Line:** 133

---

### `def delete(url, **kwargs)`

**Description:**
Sends a DELETE request.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Line:** 148

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.requests.auth
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/requests/auth.py`

**Imports:**
- _internal_utils.to_native_string
- base64.b64encode
- compat.basestring
- compat.str
- compat.urlparse
- cookies.extract_cookies_to_jar
- hashlib
- os
- re
- threading
- time
- utils.parse_dict_header
- warnings

**Functions:**

### `def _basic_auth_str(username, password)`

**Description:**
Returns a Basic Auth string.

**Line:** 25

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.requests.compat
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/requests/compat.py`

**Imports:**
- collections.OrderedDict
- collections.abc.Callable
- collections.abc.Mapping
- collections.abc.MutableMapping
- http.cookiejar
- http.cookies.Morsel
- io.StringIO
- json
- json.JSONDecodeError
- sys
- urllib.parse.quote
- urllib.parse.quote_plus
- urllib.parse.unquote
- urllib.parse.unquote_plus
- urllib.parse.urldefrag
- urllib.parse.urlencode
- urllib.parse.urljoin
- urllib.parse.urlparse
- urllib.parse.urlsplit
- urllib.parse.urlunparse
- urllib.request.getproxies
- urllib.request.getproxies_environment
- urllib.request.parse_http_list
- urllib.request.proxy_bypass
- urllib.request.proxy_bypass_environment

**Functions:**

### `def _resolve_char_detection()`

**Description:**
Find supported character detection libraries.

**Line:** 17

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.requests.cookies
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/requests/cookies.py`

**Imports:**
- _internal_utils.to_native_string
- calendar
- compat.Morsel
- compat.MutableMapping
- compat.cookielib
- compat.urlparse
- compat.urlunparse
- copy
- dummy_threading
- threading
- time

**Functions:**

### `def extract_cookies_to_jar(jar, request, response)`

**Description:**
Extract the cookies from the response into a CookieJar.

:param jar: http.cookiejar.CookieJar (not necessarily a RequestsCookieJar)
:param request: our own requests.Request object
:param response: urllib3.HTTPResponse object

**Line:** 124

---

### `def get_cookie_header(jar, request)`

**Description:**
Produce an appropriate Cookie header string to be sent with `request`, or None.

:rtype: str

**Line:** 140

---

### `def remove_cookie_by_name(cookiejar, name, domain = None, path = None)`

**Description:**
Unsets a cookie by name, by default over all domains and paths.

Wraps CookieJar.clear(), is O(n).

**Line:** 151

---

### `def _copy_cookie_jar(jar)`

**Line:** 440

---

### `def create_cookie(name, value, **kwargs)`

**Description:**
Make a cookie from underspecified parameters.

By default, the pair of `name` and `value` will be set for the domain ''
and sent on every request (this is sometimes called a "supercookie").

**Line:** 455

---

### `def morsel_to_cookie(morsel)`

**Description:**
Convert a Morsel object into a Cookie containing the one k/v pair.

**Line:** 492

---

### `def cookiejar_from_dict(cookie_dict, cookiejar = None, overwrite = True)`

**Description:**
Returns a CookieJar from a key/value dictionary.

:param cookie_dict: Dict of key/values to insert into CookieJar.
:param cookiejar: (optional) A cookiejar to add the cookies to.
:param overwrite: (optional) If False, will not replace cookies
already in the jar with new ones.
:rtype: CookieJar

**Line:** 521

---

### `def merge_cookies(cookiejar, cookies)`

**Description:**
Add cookies to cookiejar and returns a merged CookieJar.

:param cookiejar: CookieJar object to add the cookies to.
:param cookies: Dictionary or CookieJar object to be added.
:rtype: CookieJar

**Line:** 542

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.requests.help
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/requests/help.py`

**Imports:**
- OpenSSL
- cryptography
- json
- pip._vendor.idna
- pip._vendor.urllib3
- pip._vendor.urllib3.contrib.pyopenssl
- platform
- ssl
- sys

**Functions:**

### `def _implementation()`

**Description:**
Return a dict with the Python implementation and version.

Provide both the name and the version of the Python implementation
currently running. For example, on CPython 3.10.3 it will return
{'name': 'CPython', 'version': '3.10.3'}.

This function works best on CPython and PyPy: in particular, it probably
doesn't work for Jython or IronPython. Future investigation should be done
to work out the correct shape of the code for those platforms.

**Line:** 27

---

### `def info()`

**Description:**
Generate information for a bug report.

**Line:** 62

---

### `def main()`

**Description:**
Pretty-print the bug information as JSON.

**Line:** 121

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.requests.hooks
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/requests/hooks.py`

**Functions:**

### `def default_hooks()`

**Line:** 15

---

### `def dispatch_hook(key, hooks, hook_data, **kwargs)`

**Description:**
Dispatches a hook dictionary on a given piece of data.

**Line:** 22

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.requests.sessions
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/requests/sessions.py`

**Imports:**
- _internal_utils.to_native_string
- adapters.HTTPAdapter
- auth._basic_auth_str
- collections.OrderedDict
- compat.Mapping
- compat.cookielib
- compat.urljoin
- compat.urlparse
- cookies.RequestsCookieJar
- cookies.cookiejar_from_dict
- cookies.extract_cookies_to_jar
- cookies.merge_cookies
- datetime.timedelta
- exceptions.ChunkedEncodingError
- exceptions.ContentDecodingError
- exceptions.InvalidSchema
- exceptions.TooManyRedirects
- hooks.default_hooks
- hooks.dispatch_hook
- models.DEFAULT_REDIRECT_LIMIT
- models.PreparedRequest
- models.REDIRECT_STATI
- models.Request
- os
- status_codes.codes
- structures.CaseInsensitiveDict
- sys
- time
- utils.DEFAULT_PORTS
- utils.default_headers
- utils.get_auth_from_url
- utils.get_environ_proxies
- utils.get_netrc_auth
- utils.requote_uri
- utils.resolve_proxies
- utils.rewind_body
- utils.should_bypass_proxies
- utils.to_key_val_list

**Functions:**

### `def merge_setting(request_setting, session_setting, dict_class = OrderedDict)`

**Description:**
Determines appropriate setting for a given request, taking into account
the explicit setting on that request, and the setting in the session. If a
setting is a dictionary, they will be merged together using `dict_class`

**Line:** 61

---

### `def merge_hooks(request_hooks, session_hooks, dict_class = OrderedDict)`

**Description:**
Properly merges both requests and session hooks.

This is necessary because when request_hooks == {'response': []}, the
merge breaks Session hooks entirely.

**Line:** 91

---

### `def session()`

**Description:**
Returns a :class:`Session` for context-management.

.. deprecated:: 1.0.0

This method has been deprecated since version 1.0.0 and is only kept for
backwards compatibility. New code should use :class:`~requests.sessions.Session`
to create a session. This may be removed at a future date.

:rtype: Session

**Line:** 819

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.requests.status_codes
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/requests/status_codes.py`

**Imports:**
- structures.LookupDict

**Functions:**

### `def _init()`

**Line:** 109

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.requests.utils
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/requests/utils.py`

**Imports:**
- __version__.__version__
- _internal_utils.HEADER_VALIDATORS
- _internal_utils._HEADER_VALIDATORS_BYTE
- _internal_utils._HEADER_VALIDATORS_STR
- _internal_utils.to_native_string
- codecs
- collections.OrderedDict
- compat.Mapping
- compat.basestring
- compat.bytes
- compat.getproxies
- compat.getproxies_environment
- compat.integer_types
- compat.parse_http_list
- compat.proxy_bypass
- compat.proxy_bypass_environment
- compat.quote
- compat.str
- compat.unquote
- compat.urlparse
- compat.urlunparse
- contextlib
- cookies.cookiejar_from_dict
- exceptions.FileModeWarning
- exceptions.InvalidHeader
- exceptions.InvalidURL
- exceptions.UnrewindableBodyError
- io
- netrc.NetrcParseError
- netrc.netrc
- os
- pip._vendor.urllib3.util.make_headers
- pip._vendor.urllib3.util.parse_url
- re
- socket
- struct
- structures.CaseInsensitiveDict
- sys
- tempfile
- warnings
- winreg
- zipfile

**Functions:**

### `def proxy_bypass_registry(host)`

**Line:** 76

---

### `def proxy_bypass(host)`

**Description:**
Return True, if the host should be bypassed.

Checks proxy settings gathered from the environment, if specified,
or the registry.

**Line:** 114

---

### `def dict_to_sequence(d)`

**Description:**
Returns an internal sequence dictionary update.

**Line:** 126

---

### `def super_len(o)`

**Line:** 135

---

### `def get_netrc_auth(url, raise_errors = False)`

**Description:**
Returns the Requests tuple auth for a given url from netrc.

**Line:** 204

---

### `def guess_filename(obj)`

**Description:**
Tries to guess the filename of the given object.

**Line:** 261

---

### `def extract_zipped_paths(path)`

**Description:**
Replace nonexistent paths that look like they refer to a member of a zip
archive with the location of an extracted copy of the target, or else
just return the provided path unchanged.

**Line:** 268

---

### `def atomic_open(filename)`

**Decorators:**
- `@contextlib.contextmanager`

**Description:**
Write a file to the disk in an atomic fashion

**Line:** 306

---

### `def from_key_val_list(value)`

**Description:**
Take an object and test to see if it can be represented as a
dictionary. Unless it can not be represented as such, return an
OrderedDict, e.g.,

::

>>> from_key_val_list([('key', 'val')])
OrderedDict([('key', 'val')])
>>> from_key_val_list('string')
Traceback (most recent call last):
...
ValueError: cannot encode objects that are not 2-tuples
>>> from_key_val_list({'key': 'val'})
OrderedDict([('key', 'val')])

:rtype: OrderedDict

**Line:** 318

---

### `def to_key_val_list(value)`

**Description:**
Take an object and test to see if it can be represented as a
dictionary. If it can be, return a list of tuples, e.g.,

::

>>> to_key_val_list([('key', 'val')])
[('key', 'val')]
>>> to_key_val_list({'key': 'val'})
[('key', 'val')]
>>> to_key_val_list('string')
Traceback (most recent call last):
...
ValueError: cannot encode objects that are not 2-tuples

:rtype: list

**Line:** 345

---

### `def parse_list_header(value)`

**Description:**
Parse lists as described by RFC 2068 Section 2.

In particular, parse comma-separated lists where the elements of
the list may include quoted-strings.  A quoted-string could
contain a comma.  A non-quoted string could have quotes in the
middle.  Quotes are removed automatically after parsing.

It basically works like :func:`parse_set_header` just that items
may appear multiple times and case sensitivity is preserved.

The return value is a standard :class:`list`:

>>> parse_list_header('token, "quoted value"')
['token', 'quoted value']

To create a header from the :class:`list` again, use the
:func:`dump_header` function.

:param value: a string with a list header.
:return: :class:`list`
:rtype: list

**Line:** 375

---

### `def parse_dict_header(value)`

**Description:**
Parse lists of key, value pairs as described by RFC 2068 Section 2 and
convert them into a python dict:

>>> d = parse_dict_header('foo="is a fish", bar="as well"')
>>> type(d) is dict
True
>>> sorted(d.items())
[('bar', 'as well'), ('foo', 'is a fish')]

If there is no value for a key it will be `None`:

>>> parse_dict_header('key_without_value')
{'key_without_value': None}

To create a header from the :class:`dict` again, use the
:func:`dump_header` function.

:param value: a string with a dict header.
:return: :class:`dict`
:rtype: dict

**Line:** 407

---

### `def unquote_header_value(value, is_filename = False)`

**Description:**
Unquotes a header value.  (Reversal of :func:`quote_header_value`).
This does not use the real unquoting but what browsers are actually
using for quoting.

:param value: the header value to unquote.
:rtype: str

**Line:** 442

---

### `def dict_from_cookiejar(cj)`

**Description:**
Returns a key/value dictionary from a CookieJar.

:param cj: CookieJar object to extract cookies from.
:rtype: dict

**Line:** 467

---

### `def add_dict_to_cookiejar(cj, cookie_dict)`

**Description:**
Returns a CookieJar from a key/value dictionary.

:param cj: CookieJar to insert cookies into.
:param cookie_dict: Dict of key/values to insert into CookieJar.
:rtype: CookieJar

**Line:** 478

---

### `def get_encodings_from_content(content)`

**Description:**
Returns encodings from given content string.

:param content: bytestring to extract encodings from.

**Line:** 489

---

### `def _parse_content_type_header(header)`

**Description:**
Returns content type and parameters from given header

:param header: string
:return: tuple containing content type and dictionary of
parameters

**Line:** 514

---

### `def get_encoding_from_headers(headers)`

**Description:**
Returns encodings from given HTTP Header Dict.

:param headers: dictionary to extract encoding from.
:rtype: str

**Line:** 539

---

### `def stream_decode_response_unicode(iterator, r)`

**Description:**
Stream decodes an iterator.

**Line:** 564

---

### `def iter_slices(string, slice_length)`

**Description:**
Iterate over slices of a string.

**Line:** 581

---

### `def get_unicode_from_response(r)`

**Description:**
Returns the requested content back in unicode.

:param r: Response object to get unicode content from.

Tried:

1. charset from content-type
2. fall back and replace all unicode characters

:rtype: str

**Line:** 591

---

### `def unquote_unreserved(uri)`

**Description:**
Un-escape any percent-escape sequences in a URI that are unreserved
characters. This leaves all reserved, illegal and non-ASCII bytes encoded.

:rtype: str

**Line:** 636

---

### `def requote_uri(uri)`

**Description:**
Re-quote the given URI.

This function passes the given URI through an unquote/quote cycle to
ensure that it is fully and consistently quoted.

:rtype: str

**Line:** 660

---

### `def address_in_network(ip, net)`

**Description:**
This function allows you to check if an IP belongs to a network subnet

Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24
returns False if ip = 192.168.1.1 and net = 192.168.100.0/24

:rtype: bool

**Line:** 682

---

### `def dotted_netmask(mask)`

**Description:**
Converts mask from /xx format to xxx.xxx.xxx.xxx

Example: if mask is 24 function returns 255.255.255.0

:rtype: str

**Line:** 697

---

### `def is_ipv4_address(string_ip)`

**Description:**
:rtype: bool

**Line:** 708

---

### `def is_valid_cidr(string_network)`

**Description:**
Very simple check of the cidr format in no_proxy variable.

:rtype: bool

**Line:** 719

---

### `def set_environ(env_name, value)`

**Decorators:**
- `@contextlib.contextmanager`

**Description:**
Set the environment variable 'env_name' to 'value'

Save previous value, yield, and then restore the previous value stored in
the environment variable 'env_name'.

If 'value' is None, do nothing

**Line:** 744

---

### `def should_bypass_proxies(url, no_proxy)`

**Description:**
Returns whether we should bypass proxies or not.

:rtype: bool

**Line:** 765

---

### `def get_environ_proxies(url, no_proxy = None)`

**Description:**
Return a dict of environment proxies.

:rtype: dict

**Line:** 826

---

### `def select_proxy(url, proxies)`

**Description:**
Select a proxy for the url, if applicable.

:param url: The url being for the request
:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs

**Line:** 838

---

### `def resolve_proxies(request, proxies, trust_env = True)`

**Description:**
This method takes proxy information from a request and configuration
input to resolve a mapping of target proxies. This will consider settings
such as NO_PROXY to strip proxy configurations.

:param request: Request or PreparedRequest
:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs
:param trust_env: Boolean declaring whether to trust environment configs

:rtype: dict

**Line:** 864

---

### `def default_user_agent(name = 'python-requests')`

**Description:**
Return a string representing the default user agent.

:rtype: str

**Line:** 891

---

### `def default_headers()`

**Description:**
:rtype: requests.structures.CaseInsensitiveDict

**Line:** 900

---

### `def parse_header_links(value)`

**Description:**
Return a list of parsed link headers proxies.

i.e. Link: <http:/.../front.jpeg>; rel=front; type="image/jpeg",<http://.../back.jpeg>; rel=back;type="image/jpeg"

:rtype: list

**Line:** 914

---

### `def guess_json_utf(data)`

**Description:**
:rtype: str

**Line:** 957

---

### `def prepend_scheme_if_needed(url, new_scheme)`

**Description:**
Given a URL that may or may not have a scheme, prepend the given scheme.
Does not replace a present scheme with the one provided as an argument.

:rtype: str

**Line:** 989

---

### `def get_auth_from_url(url)`

**Description:**
Given a url with authentication components, extract them into a tuple of
username,password.

:rtype: (str,str)

**Line:** 1018

---

### `def check_header_validity(header)`

**Description:**
Verifies that header parts don't contain leading whitespace
reserved characters, or return characters.

:param header: tuple, in the format (name, value).

**Line:** 1034

---

### `def _validate_header_part(header, header_part, header_validator_index)`

**Line:** 1045

---

### `def urldefragauth(url)`

**Description:**
Given a url remove the fragment and the authentication part.

:rtype: str

**Line:** 1064

---

### `def rewind_body(prepared_request)`

**Description:**
Move file pointer back to its recorded starting position
so it can be read again on redirect.

**Line:** 1081

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.resolvelib.resolvers.resolution
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py`

**Imports:**
- __future__.annotations
- abstract.AbstractResolver
- abstract.Result
- collections
- criterion.Criterion
- exceptions.InconsistentCandidate
- exceptions.RequirementsConflicted
- exceptions.ResolutionImpossible
- exceptions.ResolutionTooDeep
- exceptions.ResolverException
- itertools
- operator
- providers.AbstractProvider
- providers.Preference
- reporters.BaseReporter
- structs.CT
- structs.DirectedGraph
- structs.IterableView
- structs.IteratorMapping
- structs.KT
- structs.RT
- structs.RequirementInformation
- structs.State
- structs.build_iter_view
- typing.Collection
- typing.Generic
- typing.Iterable
- typing.Mapping
- typing.TYPE_CHECKING

**Functions:**

### `def _build_result(state: State[(RT, CT, KT)]) -> Result[(RT, CT, KT)]`

**Line:** 34

---

### `def _has_route_to_root(criteria: Mapping[(KT, Criterion[RT, CT])], key: KT | None, all_keys: dict[(int, KT | None)], connected: set[KT | None]) -> bool`

**Line:** 519

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.resolvelib.structs
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/resolvelib/structs.py`

**Imports:**
- __future__.annotations
- collections.namedtuple
- itertools
- resolvers.criterion.Criterion
- typing.Callable
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.Mapping
- typing.NamedTuple
- typing.Sequence
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.Union

**Functions:**

### `def build_iter_view(matches: Matches[CT]) -> Iterable[CT]`

**Description:**
Build an iterable view from the value returned by `find_matches()`.

**Line:** 200

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/__init__.py`

**Imports:**
- _extension.load_ipython_extension
- console.Console
- os
- pip._vendor.rich._inspect.Inspect
- pip._vendor.rich.console.Console
- typing.Any
- typing.Callable
- typing.IO
- typing.Optional
- typing.TYPE_CHECKING
- typing.Union

**Functions:**

### `def get_console() -> 'Console'`

**Description:**
Get a global :class:`~rich.console.Console` instance. This function is used when Rich requires a Console,
and hasn't been explicitly given one.

Returns:
Console: A console instance.

**Line:** 23

---

### `def reconfigure(*args: Any, **kwargs: Any) -> None`

**Description:**
Reconfigures the global console by replacing it with another.

Args:
*args (Any): Positional arguments for the replacement :class:`~rich.console.Console`.
**kwargs (Any): Keyword arguments for the replacement :class:`~rich.console.Console`.

**Line:** 39

---

### `def print(sep: str = ' ', end: str = '\n', file: Optional[IO[str]] = None, flush: bool = False, *objects: Any) -> None`

**Description:**
Print object(s) supplied via positional arguments.
This function has an identical signature to the built-in print.
For more advanced features, see the :class:`~rich.console.Console` class.

Args:
sep (str, optional): Separator between printed objects. Defaults to " ".
end (str, optional): Character to write at end of output. Defaults to "\\n".
file (IO[str], optional): File to write to, or None for stdout. Defaults to None.
flush (bool, optional): Has no effect as Rich always flushes output. Defaults to False.

**Line:** 53

---

### `def print_json(json: Optional[str] = None, data: Any = None, indent: Union[(None, int, str)] = 2, highlight: bool = True, skip_keys: bool = False, ensure_ascii: bool = False, check_circular: bool = True, allow_nan: bool = True, default: Optional[Callable[([Any], Any)]] = None, sort_keys: bool = False) -> None`

**Description:**
Pretty prints JSON. Output will be valid JSON.

Args:
json (str): A string containing JSON.
data (Any): If json is not supplied, then encode this data.
indent (int, optional): Number of spaces to indent. Defaults to 2.
highlight (bool, optional): Enable highlighting of output: Defaults to True.
skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.
ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.
check_circular (bool, optional): Check for circular references. Defaults to True.
allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.
default (Callable, optional): A callable that converts values that can not be encoded
in to something that can be JSON encoded. Defaults to None.
sort_keys (bool, optional): Sort dictionary keys. Defaults to False.

**Line:** 77

---

### `def inspect(obj: Any, console: Optional['Console'] = None, title: Optional[str] = None, help: bool = False, methods: bool = False, docs: bool = True, private: bool = False, dunder: bool = False, sort: bool = True, all: bool = False, value: bool = True) -> None`

**Description:**
Inspect any Python object.

* inspect(<OBJECT>) to see summarized info.
* inspect(<OBJECT>, methods=True) to see methods.
* inspect(<OBJECT>, help=True) to see full (non-abbreviated) help.
* inspect(<OBJECT>, private=True) to see private attributes (single underscore).
* inspect(<OBJECT>, dunder=True) to see attributes beginning with double underscore.
* inspect(<OBJECT>, all=True) to see all attributes.

Args:
obj (Any): An object to inspect.
title (str, optional): Title to display over inspect result, or None use type. Defaults to None.
help (bool, optional): Show full help text rather than just first paragraph. Defaults to False.
methods (bool, optional): Enable inspection of callables. Defaults to False.
docs (bool, optional): Also render doc strings. Defaults to True.
private (bool, optional): Show private attributes (beginning with underscore). Defaults to False.
dunder (bool, optional): Show attributes starting with double underscore. Defaults to False.
sort (bool, optional): Sort attributes alphabetically. Defaults to True.
all (bool, optional): Show all attributes. Defaults to False.
value (bool, optional): Pretty print value. Defaults to True.

**Line:** 120

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.__main__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/__main__.py`

**Imports:**
- colorsys
- io
- pip._vendor.rich.box
- pip._vendor.rich.color.Color
- pip._vendor.rich.console.Console
- pip._vendor.rich.console.ConsoleOptions
- pip._vendor.rich.console.Group
- pip._vendor.rich.console.RenderResult
- pip._vendor.rich.console.RenderableType
- pip._vendor.rich.markdown.Markdown
- pip._vendor.rich.measure.Measurement
- pip._vendor.rich.panel.Panel
- pip._vendor.rich.pretty.Pretty
- pip._vendor.rich.segment.Segment
- pip._vendor.rich.style.Style
- pip._vendor.rich.syntax.Syntax
- pip._vendor.rich.table.Table
- pip._vendor.rich.text.Text
- time.process_time

**Functions:**

### `def make_test_card() -> Table`

**Description:**
Get a renderable that demonstrates a number of features.

**Line:** 39

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich._emoji_replace
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/_emoji_replace.py`

**Imports:**
- _emoji_codes.EMOJI
- re
- typing.Callable
- typing.Match
- typing.Optional

**Functions:**

### `def _emoji_replace(text: str, default_variant: Optional[str] = None, _emoji_sub: _EmojiSubMethod) -> str`

**Description:**
Replace emoji code in text.

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich._extension
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/_extension.py`

**Imports:**
- pip._vendor.rich.pretty.install
- pip._vendor.rich.traceback.install
- typing.Any

**Functions:**

### `def load_ipython_extension(ip: Any) -> None`

**Line:** 4

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich._fileno
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/_fileno.py`

**Imports:**
- __future__.annotations
- typing.Callable
- typing.IO

**Functions:**

### `def get_fileno(file_like: IO[str]) -> int | None`

**Description:**
Get fileno() from a file, accounting for poorly implemented file-like objects.

Args:
file_like (IO): A file-like object.

Returns:
int | None: The result of fileno if available, or None if operation failed.

**Line:** 6

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich._inspect
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/_inspect.py`

**Imports:**
- console.Group
- console.RenderableType
- control.escape_control_codes
- highlighter.ReprHighlighter
- inspect
- inspect.cleandoc
- inspect.getdoc
- inspect.getfile
- inspect.isclass
- inspect.ismodule
- inspect.signature
- jupyter.JupyterMixin
- panel.Panel
- pretty.Pretty
- table.Table
- text.Text
- text.TextType
- typing.Any
- typing.Collection
- typing.Iterable
- typing.Optional
- typing.Tuple
- typing.Type
- typing.Union

**Functions:**

### `def _first_paragraph(doc: str) -> str`

**Description:**
Get the first paragraph from a docstring.

**Line:** 15

---

### `def get_object_types_mro(obj: Union[(object, Type[Any])]) -> Tuple[(type, ...)]`

**Description:**
Returns the MRO of an object's class, or of the object itself if it's a class.

**Line:** 236

---

### `def get_object_types_mro_as_strings(obj: object) -> Collection[str]`

**Description:**
Returns the MRO of an object's class as full qualified names, or of the object itself if it's a class.

Examples:
`object_types_mro_as_strings(JSONDecoder)` will return `['json.decoder.JSONDecoder', 'builtins.object']`

**Line:** 245

---

### `def is_object_one_of_types(obj: object, fully_qualified_types_names: Collection[str]) -> bool`

**Description:**
Returns `True` if the given object's class (or the object itself, if it's a class) has one of the
fully qualified names in its MRO.

**Line:** 258

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich._loop
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/_loop.py`

**Imports:**
- typing.Iterable
- typing.Tuple
- typing.TypeVar

**Functions:**

### `def loop_first(values: Iterable[T]) -> Iterable[Tuple[(bool, T)]]`

**Description:**
Iterate and generate a tuple with a flag for first value.

**Line:** 6

---

### `def loop_last(values: Iterable[T]) -> Iterable[Tuple[(bool, T)]]`

**Description:**
Iterate and generate a tuple with a flag for last value.

**Line:** 18

---

### `def loop_first_last(values: Iterable[T]) -> Iterable[Tuple[(bool, bool, T)]]`

**Description:**
Iterate and generate a tuple with a flag for first and last value.

**Line:** 31

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich._pick
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/_pick.py`

**Imports:**
- typing.Optional

**Functions:**

### `def pick_bool(*values: Optional[bool]) -> bool`

**Description:**
Pick the first non-none bool or return the last value.

Args:
*values (bool): Any number of boolean or None values.

Returns:
bool: First non-none boolean.

**Line:** 4

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich._ratio
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/_ratio.py`

**Imports:**
- dataclasses.dataclass
- fractions.Fraction
- math.ceil
- pip._vendor.typing_extensions.Protocol
- sys
- typing.List
- typing.Optional
- typing.Protocol
- typing.Sequence
- typing.cast

**Functions:**

### `def ratio_resolve(total: int, edges: Sequence[Edge]) -> List[int]`

**Description:**
Divide total space to satisfy size, ratio, and minimum_size, constraints.

The returned list of integers should add up to total in most cases, unless it is
impossible to satisfy all the constraints. For instance, if there are two edges
with a minimum size of 20 each and `total` is 30 then the returned list will be
greater than total. In practice, this would mean that a Layout object would
clip the rows that would overflow the screen height.

Args:
total (int): Total number of characters.
edges (List[Edge]): Edges within total space.

Returns:
List[int]: Number of characters for each edge.

**Line:** 20

---

### `def ratio_reduce(total: int, ratios: List[int], maximums: List[int], values: List[int]) -> List[int]`

**Description:**
Divide an integer total in to parts based on ratios.

Args:
total (int): The total to divide.
ratios (List[int]): A list of integer ratios.
maximums (List[int]): List of maximums values for each slot.
values (List[int]): List of values

Returns:
List[int]: A list of integers guaranteed to sum to total.

**Line:** 81

---

### `def ratio_distribute(total: int, ratios: List[int], minimums: Optional[List[int]] = None) -> List[int]`

**Description:**
Distribute an integer total in to parts based on ratios.

Args:
total (int): The total to divide.
ratios (List[int]): A list of integer ratios.
minimums (List[int]): List of minimum values for each slot.

Returns:
List[int]: A list of integers guaranteed to sum to total.

**Line:** 113

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich._timer
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/_timer.py`

**Imports:**
- contextlib
- time.time
- typing.Generator

**Functions:**

### `def timer(subject: str = 'time') -> Generator[(None, None, None)]`

**Decorators:**
- `@contextlib.contextmanager`

**Description:**
print the elapsed time. (only used in debugging)

**Line:** 13

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich._win32_console
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/_win32_console.py`

**Imports:**
- ctypes
- ctypes.Structure
- ctypes.byref
- ctypes.wintypes
- pip._vendor.rich.color.ColorSystem
- pip._vendor.rich.console.Console
- pip._vendor.rich.style.Style
- sys
- time
- typing.Any
- typing.IO
- typing.NamedTuple
- typing.Type
- typing.cast

**Functions:**

### `def GetStdHandle(handle: int = STDOUT) -> wintypes.HANDLE`

**Description:**
Retrieves a handle to the specified standard device (standard input, standard output, or standard error).

Args:
handle (int): Integer identifier for the handle. Defaults to -11 (stdout).

Returns:
wintypes.HANDLE: The handle

**Line:** 78

---

### `def GetConsoleMode(std_handle: wintypes.HANDLE) -> int`

**Description:**
Retrieves the current input mode of a console's input buffer
or the current output mode of a console screen buffer.

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.

Raises:
LegacyWindowsError: If any error occurs while calling the Windows console API.

Returns:
int: Value representing the current console mode as documented at
https://docs.microsoft.com/en-us/windows/console/getconsolemode#parameters

**Line:** 95

---

### `def FillConsoleOutputCharacter(std_handle: wintypes.HANDLE, char: str, length: int, start: WindowsCoordinates) -> int`

**Description:**
Writes a character to the console screen buffer a specified number of times, beginning at the specified coordinates.

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
char (str): The character to write. Must be a string of length 1.
length (int): The number of times to write the character.
start (WindowsCoordinates): The coordinates to start writing at.

Returns:
int: The number of characters written.

**Line:** 128

---

### `def FillConsoleOutputAttribute(std_handle: wintypes.HANDLE, attributes: int, length: int, start: WindowsCoordinates) -> int`

**Description:**
Sets the character attributes for a specified number of character cells,
beginning at the specified coordinates in a screen buffer.

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
attributes (int): Integer value representing the foreground and background colours of the cells.
length (int): The number of cells to set the output attribute of.
start (WindowsCoordinates): The coordinates of the first cell whose attributes are to be set.

Returns:
int: The number of cells whose attributes were actually set.

**Line:** 169

---

### `def SetConsoleTextAttribute(std_handle: wintypes.HANDLE, attributes: wintypes.WORD) -> bool`

**Description:**
Set the colour attributes for all text written after this function is called.

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
attributes (int): Integer value representing the foreground and background colours.


Returns:
bool: True if the attribute was set successfully, otherwise False.

**Line:** 204

---

### `def GetConsoleScreenBufferInfo(std_handle: wintypes.HANDLE) -> CONSOLE_SCREEN_BUFFER_INFO`

**Description:**
Retrieves information about the specified console screen buffer.

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.

Returns:
CONSOLE_SCREEN_BUFFER_INFO: A CONSOLE_SCREEN_BUFFER_INFO ctype struct contain information about
screen size, cursor position, colour attributes, and more.

**Line:** 228

---

### `def SetConsoleCursorPosition(std_handle: wintypes.HANDLE, coords: WindowsCoordinates) -> bool`

**Description:**
Set the position of the cursor in the console screen

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
coords (WindowsCoordinates): The coordinates to move the cursor to.

Returns:
bool: True if the function succeeds, otherwise False.

**Line:** 252

---

### `def GetConsoleCursorInfo(std_handle: wintypes.HANDLE, cursor_info: CONSOLE_CURSOR_INFO) -> bool`

**Description:**
Get the cursor info - used to get cursor visibility and width

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
cursor_info (CONSOLE_CURSOR_INFO): CONSOLE_CURSOR_INFO ctype struct that receives information
about the console's cursor.

Returns:
bool: True if the function succeeds, otherwise False.

**Line:** 275

---

### `def SetConsoleCursorInfo(std_handle: wintypes.HANDLE, cursor_info: CONSOLE_CURSOR_INFO) -> bool`

**Description:**
Set the cursor info - used for adjusting cursor visibility and width

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
cursor_info (CONSOLE_CURSOR_INFO): CONSOLE_CURSOR_INFO ctype struct containing the new cursor info.

Returns:
bool: True if the function succeeds, otherwise False.

**Line:** 299

---

### `def SetConsoleTitle(title: str) -> bool`

**Description:**
Sets the title of the current console window

Args:
title (str): The new title of the console window.

Returns:
bool: True if the function succeeds, otherwise False.

**Line:** 319

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich._windows
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/_windows.py`

**Imports:**
- ctypes
- ctypes.LibraryLoader
- dataclasses.dataclass
- pip._vendor.rich._win32_console.ENABLE_VIRTUAL_TERMINAL_PROCESSING
- pip._vendor.rich._win32_console.GetConsoleMode
- pip._vendor.rich._win32_console.GetStdHandle
- pip._vendor.rich._win32_console.LegacyWindowsError
- pip._vendor.rich.print
- platform
- sys

**Functions:**

### `def get_windows_console_features() -> WindowsConsoleFeatures`

**Line:** 34

---

### `def get_windows_console_features() -> WindowsConsoleFeatures`

**Description:**
Get windows console features.

Returns:
WindowsConsoleFeatures: An instance of WindowsConsoleFeatures.

**Line:** 40

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich._windows_renderer
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/_windows_renderer.py`

**Imports:**
- pip._vendor.rich._win32_console.LegacyWindowsTerm
- pip._vendor.rich._win32_console.WindowsCoordinates
- pip._vendor.rich.segment.ControlCode
- pip._vendor.rich.segment.ControlType
- pip._vendor.rich.segment.Segment
- typing.Iterable
- typing.Sequence
- typing.Tuple
- typing.cast

**Functions:**

### `def legacy_windows_render(buffer: Iterable[Segment], term: LegacyWindowsTerm) -> None`

**Description:**
Makes appropriate Windows Console API calls based on the segments in the buffer.

Args:
buffer (Iterable[Segment]): Iterable of Segments to convert to Win32 API calls.
term (LegacyWindowsTerm): Used to call the Windows Console API.

**Line:** 7

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich._wrap
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/_wrap.py`

**Imports:**
- __future__.annotations
- _loop.loop_last
- cells.cell_len
- cells.chop_cells
- console.Console
- re
- typing.Iterable

**Functions:**

### `def words(text: str) -> Iterable[tuple[(int, int, str)]]`

**Description:**
Yields each word from the text as a tuple
containing (start_index, end_index, word). A "word" in this context may
include the actual word and any whitespace to the right.

**Line:** 12

---

### `def divide_line(text: str, width: int, fold: bool = True) -> list[int]`

**Description:**
Given a string of text, and a width (measured in cells), return a list
of cell offsets which the string should be split at in order for it to fit
within the given width.

Args:
text: The text to examine.
width: The available cell width.
fold: If True, words longer than `width` will be folded onto a new line.

Returns:
A list of indices to break the line at.

**Line:** 26

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.ansi
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/ansi.py`

**Imports:**
- color.Color
- console.Console
- contextlib.suppress
- io
- os
- pty
- re
- style.Style
- sys
- text.Text
- typing.Iterable
- typing.NamedTuple
- typing.Optional

**Functions:**

### `def _ansi_tokenize(ansi_text: str) -> Iterable[_AnsiToken]`

**Description:**
Tokenize a string in to plain text and ANSI codes.

Args:
ansi_text (str): A String containing ANSI codes.

Yields:
AnsiToken: A named tuple of (plain, sgr, osc)

**Line:** 28

---

### `def read(fd: int) -> bytes`

**Line:** 224

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.cells
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/cells.py`

**Imports:**
- __future__.annotations
- _cell_widths.CELL_WIDTHS
- functools.lru_cache
- typing.Callable

**Functions:**

### `def cached_cell_len(text: str) -> int`

**Decorators:**
- `@lru_cache(...)`

**Description:**
Get the number of cells required to display text.

This method always caches, which may use up a lot of memory. It is recommended to use
`cell_len` over this method.

Args:
text (str): Text to display.

Returns:
int: Get the number of cells required to display text.

**Line:** 34

---

### `def cell_len(text: str, _cell_len: Callable[([str], int)] = cached_cell_len) -> int`

**Description:**
Get the number of cells required to display text.

Args:
text (str): Text to display.

Returns:
int: Get the number of cells required to display text.

**Line:** 51

---

### `def get_character_cell_size(character: str) -> int`

**Decorators:**
- `@lru_cache(...)`

**Description:**
Get the cell size of a character.

Args:
character (str): A single character.

Returns:
int: Number of cells (0, 1 or 2) occupied by that character.

**Line:** 68

---

### `def set_cell_size(text: str, total: int) -> str`

**Description:**
Set the length of a string to fit within given number of cells.

**Line:** 96

---

### `def chop_cells(text: str, width: int) -> list[str]`

**Description:**
Split text into lines such that each line fits within the available (cell) width.

Args:
text: The text to fold such that it fits in the given width.
width: The width available (number of cells).

Returns:
A list of strings such that each string in the list has cell width
less than or equal to the available width.

**Line:** 131

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.color
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/color.py`

**Imports:**
- _palettes.EIGHT_BIT_PALETTE
- _palettes.STANDARD_PALETTE
- _palettes.WINDOWS_PALETTE
- color_triplet.ColorTriplet
- colorsys.rgb_to_hls
- console.Console
- enum.IntEnum
- functools.lru_cache
- re
- repr.Result
- repr.rich_repr
- style.Style
- sys
- table.Table
- terminal_theme.DEFAULT_TERMINAL_THEME
- terminal_theme.TerminalTheme
- text.Text
- typing.NamedTuple
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple

**Functions:**

### `def parse_rgb_hex(hex_color: str) -> ColorTriplet`

**Description:**
Parse six hex characters in to RGB triplet.

**Line:** 571

---

### `def blend_rgb(color1: ColorTriplet, color2: ColorTriplet, cross_fade: float = 0.5) -> ColorTriplet`

**Description:**
Blend one RGB color in to another.

**Line:** 580

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.console
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/console.py`

**Imports:**
- _emoji_replace._emoji_replace
- _export_format.CONSOLE_HTML_FORMAT
- _export_format.CONSOLE_SVG_FORMAT
- _fileno.get_fileno
- _log_render.FormatTimeCallable
- _log_render.LogRender
- _windows.WindowsConsoleFeatures
- _windows.get_windows_console_features
- abc.ABC
- abc.abstractmethod
- align.Align
- align.AlignMethod
- color.ColorSystem
- color.blend_rgb
- control.Control
- dataclasses.dataclass
- dataclasses.field
- datetime.datetime
- emoji.EmojiVariant
- functools.wraps
- getpass.getpass
- highlighter.NullHighlighter
- highlighter.ReprHighlighter
- html.escape
- inspect
- inspect.isclass
- itertools.islice
- jupyter.display
- live.Live
- markup.render
- math.ceil
- measure.Measurement
- measure.measure_renderables
- os
- pager.Pager
- pager.SystemPager
- pip._vendor.rich._null_file.NULL_FILE
- pip._vendor.rich._win32_console.LegacyWindowsTerm
- pip._vendor.rich._windows_renderer.legacy_windows_render
- pip._vendor.rich.cells.cell_len
- pip._vendor.rich.json.JSON
- pip._vendor.typing_extensions.Literal
- pip._vendor.typing_extensions.Protocol
- pip._vendor.typing_extensions.runtime_checkable
- pretty.Pretty
- pretty.is_expandable
- protocol.rich_cast
- region.Region
- rule.Rule
- scope.render_scope
- screen.Screen
- segment.Segment
- status.Status
- style.Style
- style.StyleType
- styled.Styled
- sys
- terminal_theme.DEFAULT_TERMINAL_THEME
- terminal_theme.SVG_EXPORT_THEME
- terminal_theme.TerminalTheme
- text.Text
- text.TextType
- theme.Theme
- theme.ThemeStack
- threading
- time.monotonic
- traceback.Traceback
- types.FrameType
- types.ModuleType
- types.TracebackType
- typing.Any
- typing.Callable
- typing.Dict
- typing.IO
- typing.Iterable
- typing.List
- typing.Literal
- typing.Mapping
- typing.NamedTuple
- typing.Optional
- typing.Protocol
- typing.TYPE_CHECKING
- typing.TextIO
- typing.Tuple
- typing.Type
- typing.Union
- typing.cast
- typing.runtime_checkable
- zlib

**Functions:**

### `def group(fit: bool = True) -> Callable[(..., Callable[..., Group])]`

**Description:**
A decorator that turns an iterable of renderables in to a group.

Args:
fit (bool, optional): Fit dimension of group to contents, or fill available space. Defaults to True.

**Line:** 495

---

### `def _is_jupyter() -> bool`

**Description:**
Check if we're running in a Jupyter notebook.

**Line:** 517

---

### `def get_windows_console_features() -> 'WindowsConsoleFeatures'`

**Line:** 578

---

### `def detect_legacy_windows() -> bool`

**Description:**
Detect legacy Windows.

**Line:** 588

---

### `def _svg_hash(svg_main_code: str) -> str`

**Description:**
Returns a unique hash for the given SVG main code.

Args:
svg_main_code (str): The content we're going to inject in the SVG envelope.

Returns:
str: a hash of the given content

**Line:** 2610

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.control
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/control.py`

**Imports:**
- console.Console
- console.ConsoleOptions
- console.RenderResult
- pip._vendor.rich.console.Console
- pip._vendor.typing_extensions.Final
- segment.ControlCode
- segment.ControlType
- segment.Segment
- sys
- time
- typing.Callable
- typing.Dict
- typing.Final
- typing.Iterable
- typing.List
- typing.TYPE_CHECKING
- typing.Union

**Functions:**

### `def strip_control_codes(text: str, _translate_table: Dict[(int, None)] = _CONTROL_STRIP_TRANSLATE) -> str`

**Description:**
Remove control codes from text.

Args:
text (str): A string possibly contain control codes.

Returns:
str: String with control codes removed.

**Line:** 187

---

### `def escape_control_codes(text: str, _translate_table: Dict[(int, str)] = CONTROL_ESCAPE) -> str`

**Description:**
Replace control codes with their "escaped" equivalent in the given text.
(e.g. "" becomes "\b")

Args:
text (str): A string possibly containing control codes.

Returns:
str: String with control codes replaced with their escaped version.

**Line:** 201

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.diagnose
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/diagnose.py`

**Imports:**
- os
- pip._vendor.rich.console.Console
- pip._vendor.rich.console.get_windows_console_features
- pip._vendor.rich.inspect
- pip._vendor.rich.panel.Panel
- pip._vendor.rich.pretty.Pretty
- platform

**Functions:**

### `def report() -> None`

**Description:**
Print a report to the terminal with debugging information

**Line:** 10

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.filesize
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/filesize.py`

**Imports:**
- typing.Iterable
- typing.List
- typing.Optional
- typing.Tuple

**Functions:**

### `def _to_str(size: int, suffixes: Iterable[str], base: int, precision: Optional[int] = 1, separator: Optional[str] = ' ') -> str`

**Line:** 18

---

### `def pick_unit_and_suffix(size: int, suffixes: List[str], base: int) -> Tuple[(int, str)]`

**Description:**
Pick a suffix and base for the given size.

**Line:** 43

---

### `def decimal(size: int, precision: Optional[int] = 1, separator: Optional[str] = ' ') -> str`

**Description:**
Convert a filesize in to a string (powers of 1000, SI prefixes).

In this convention, ``1000 B = 1 kB``.

This is typically the format used to advertise the storage
capacity of USB flash drives and the like (*256 MB* meaning
actually a storage capacity of more than *256 000 000 B*),
or used by **Mac OS X** since v10.6 to report file sizes.

Arguments:
int (size): A file size.
int (precision): The number of decimal places to include (default = 1).
str (separator): The string to separate the value from the units (default = " ").

Returns:
`str`: A string containing a abbreviated file size and units.

Example:
>>> filesize.decimal(30000)
'30.0 kB'
>>> filesize.decimal(30000, precision=2, separator="")
'30.00kB'

**Line:** 52

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.highlighter
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/highlighter.py`

**Imports:**
- abc.ABC
- abc.abstractmethod
- console.Console
- json
- re
- text.Span
- text.Text
- typing.List
- typing.Union

**Functions:**

### `def _combine_regex(*regexes: str) -> str`

**Description:**
Combine a number of regexes in to a single regex.

Returns:
str: New regex with all regexes ORed together.

**Line:** 8

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.jupyter
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/jupyter.py`

**Imports:**
- IPython.display.display
- pip._vendor.rich.console.ConsoleRenderable
- segment.Segment
- terminal_theme.DEFAULT_TERMINAL_THEME
- typing.Any
- typing.Dict
- typing.Iterable
- typing.List
- typing.Sequence
- typing.TYPE_CHECKING

**Functions:**

### `def _render_segments(segments: Iterable[Segment]) -> str`

**Line:** 59

---

### `def display(segments: Iterable[Segment], text: str) -> None`

**Description:**
Render segments to Jupyter.

**Line:** 84

---

### `def print(*args: Any, **kwargs: Any) -> None`

**Description:**
Proxy for Console print.

**Line:** 98

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.logging
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/logging.py`

**Imports:**
- _log_render.FormatTimeCallable
- _log_render.LogRender
- console.Console
- console.ConsoleRenderable
- datetime.datetime
- highlighter.Highlighter
- highlighter.ReprHighlighter
- logging
- logging.Handler
- logging.LogRecord
- pathlib.Path
- pip._vendor.rich._null_file.NullFile
- text.Text
- time.sleep
- traceback.Traceback
- types.ModuleType
- typing.ClassVar
- typing.Iterable
- typing.List
- typing.Optional
- typing.Type
- typing.Union

**Functions:**

### `def divide() -> None`

**Line:** 283

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.markup
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/markup.py`

**Imports:**
- _emoji_replace._emoji_replace
- ast.literal_eval
- emoji.EmojiVariant
- errors.MarkupError
- operator.attrgetter
- pip._vendor.rich.print
- pip._vendor.rich.table.Table
- re
- style.Style
- text.Span
- text.Text
- typing.Callable
- typing.Iterable
- typing.List
- typing.Match
- typing.NamedTuple
- typing.Optional
- typing.Tuple
- typing.Union

**Functions:**

### `def escape(markup: str, _escape: _EscapeSubMethod) -> str`

**Description:**
Escapes text so that it won't be interpreted as markup.

Args:
markup (str): Content to be inserted in to markup.

Returns:
str: Markup with square brackets escaped.

**Line:** 48

---

### `def _parse(markup: str) -> Iterable[Tuple[(int, Optional[str], Optional[Tag])]]`

**Description:**
Parse markup in to an iterable of tuples of (position, text, tag).

Args:
markup (str): A string containing console markup

**Line:** 73

---

### `def render(markup: str, style: Union[(str, Style)] = '', emoji: bool = True, emoji_variant: Optional[EmojiVariant] = None) -> Text`

**Description:**
Render console markup in to a Text instance.

Args:
markup (str): A string containing console markup.
style: (Union[str, Style]): The style to use.
emoji (bool, optional): Also render emoji code. Defaults to True.
emoji_variant (str, optional): Optional emoji variant, either "text" or "emoji". Defaults to None.


Raises:
MarkupError: If there is a syntax error in the markup.

Returns:
Text: A test instance.

**Line:** 106

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.measure
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/measure.py`

**Imports:**
- console.Console
- console.ConsoleOptions
- console.RenderableType
- operator.itemgetter
- protocol.is_renderable
- protocol.rich_cast
- typing.Callable
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING

**Functions:**

### `def measure_renderables(console: 'Console', options: 'ConsoleOptions', renderables: Sequence['RenderableType']) -> 'Measurement'`

**Description:**
Get a measurement that would fit a number of renderables.

Args:
console (~rich.console.Console): Console instance.
options (~rich.console.ConsoleOptions): Console options.
renderables (Iterable[RenderableType]): One or more renderable objects.

Returns:
Measurement: Measurement object containing range of character widths required to
contain all given renderables.

**Line:** 125

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.pretty
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/pretty.py`

**Imports:**
- IPython.core.formatters.BaseFormatter
- _loop.loop_last
- _pick.pick_bool
- abc.RichRenderable
- array.array
- attr
- builtins
- cells.cell_len
- collections
- collections.Counter
- collections.UserDict
- collections.UserList
- collections.defaultdict
- collections.deque
- console.Console
- console.ConsoleOptions
- console.ConsoleRenderable
- console.HighlighterType
- console.JustifyMethod
- console.OverflowMethod
- console.RenderResult
- dataclasses
- dataclasses.dataclass
- dataclasses.fields
- dataclasses.is_dataclass
- highlighter.ReprHighlighter
- inspect
- inspect.isclass
- itertools.islice
- jupyter.JupyterMixin
- jupyter.JupyterRenderable
- measure.Measurement
- os
- pip._vendor.rich.get_console
- pip._vendor.rich.print
- pip._vendor.rich.repr.RichReprResult
- reprlib
- sys
- text.Text
- types.MappingProxyType
- typing.Any
- typing.Callable
- typing.DefaultDict
- typing.Deque
- typing.Dict
- typing.Iterable
- typing.List
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union

**Functions:**

### `def _is_attr_object(obj: Any) -> bool`

**Description:**
Check if an object was created with attrs module.

**Line:** 60

---

### `def _get_attr_fields(obj: Any) -> Sequence['_attr_module.Attribute[Any]']`

**Description:**
Get fields for an attrs object.

**Line:** 65

---

### `def _is_dataclass_repr(obj: object) -> bool`

**Description:**
Check if an instance of a dataclass contains the default repr.

Args:
obj (object): A dataclass instance.

Returns:
bool: True if the default repr is used, False if there is a custom repr.

**Line:** 70

---

### `def _has_default_namedtuple_repr(obj: object) -> bool`

**Description:**
Check if an instance of namedtuple contains the default repr

Args:
obj (object): A namedtuple

Returns:
bool: True if the default repr is used, False if there's a custom repr.

**Line:** 93

---

### `def _ipy_display_hook(value: Any, console: Optional['Console'] = None, overflow: 'OverflowMethod' = 'ignore', crop: bool = False, indent_guides: bool = False, max_length: Optional[int] = None, max_string: Optional[int] = None, max_depth: Optional[int] = None, expand_all: bool = False) -> Union[(str, None)]`

**Line:** 113

---

### `def _safe_isinstance(obj: object, class_or_tuple: Union[(type, Tuple[type, ...])]) -> bool`

**Description:**
isinstance can fail in rare cases, for example types with no __class__

**Line:** 161

---

### `def install(console: Optional['Console'] = None, overflow: 'OverflowMethod' = 'ignore', crop: bool = False, indent_guides: bool = False, max_length: Optional[int] = None, max_string: Optional[int] = None, max_depth: Optional[int] = None, expand_all: bool = False) -> None`

**Description:**
Install automatic pretty printing in the Python REPL.

Args:
console (Console, optional): Console instance or ``None`` to use global console. Defaults to None.
overflow (Optional[OverflowMethod], optional): Overflow method. Defaults to "ignore".
crop (Optional[bool], optional): Enable cropping of long lines. Defaults to False.
indent_guides (bool, optional): Enable indentation guides. Defaults to False.
max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
Defaults to None.
max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.
max_depth (int, optional): Maximum depth of nested data structures, or None for no maximum. Defaults to None.
expand_all (bool, optional): Expand all containers. Defaults to False.
max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.

**Line:** 171

---

### `def _get_braces_for_defaultdict(_object: DefaultDict[(Any, Any)]) -> Tuple[(str, str, str)]`

**Line:** 357

---

### `def _get_braces_for_deque(_object: Deque[Any]) -> Tuple[(str, str, str)]`

**Line:** 365

---

### `def _get_braces_for_array(_object: 'array[Any]') -> Tuple[(str, str, str)]`

**Line:** 375

---

### `def is_expandable(obj: Any) -> bool`

**Description:**
Check if an object may be expanded by pretty print.

**Line:** 398

---

### `def _is_namedtuple(obj: Any) -> bool`

**Description:**
Checks if an object is most likely a namedtuple. It is possible
to craft an object that passes this check and isn't a namedtuple, but
there is only a minuscule chance of this happening unintentionally.

Args:
obj (Any): The object to test

Returns:
bool: True if the object is a namedtuple. False otherwise.

**Line:** 561

---

### `def traverse(_object: Any, max_length: Optional[int] = None, max_string: Optional[int] = None, max_depth: Optional[int] = None) -> Node`

**Description:**
Traverse object and generate a tree.

Args:
_object (Any): Object to be traversed.
max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
Defaults to None.
max_string (int, optional): Maximum length of string before truncating, or None to disable truncating.
Defaults to None.
max_depth (int, optional): Maximum depth of data structures, or None for no maximum.
Defaults to None.

Returns:
Node: The root of a tree structure which can be used to render a pretty repr.

**Line:** 580

---

### `def pretty_repr(_object: Any, max_width: int = 80, indent_size: int = 4, max_length: Optional[int] = None, max_string: Optional[int] = None, max_depth: Optional[int] = None, expand_all: bool = False) -> str`

**Description:**
Prettify repr string by expanding on to new lines to fit within a given width.

Args:
_object (Any): Object to repr.
max_width (int, optional): Desired maximum width of repr string. Defaults to 80.
indent_size (int, optional): Number of spaces to indent. Defaults to 4.
max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
Defaults to None.
max_string (int, optional): Maximum length of string before truncating, or None to disable truncating.
Defaults to None.
max_depth (int, optional): Maximum depth of nested data structure, or None for no depth.
Defaults to None.
expand_all (bool, optional): Expand all containers regardless of available width. Defaults to False.

Returns:
str: A possibly multi-line representation of the object.

**Line:** 878

---

### `def pprint(_object: Any, console: Optional['Console'] = None, indent_guides: bool = True, max_length: Optional[int] = None, max_string: Optional[int] = None, max_depth: Optional[int] = None, expand_all: bool = False) -> None`

**Description:**
A convenience function for pretty printing.

Args:
_object (Any): Object to pretty print.
console (Console, optional): Console instance, or None to use default. Defaults to None.
max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
Defaults to None.
max_string (int, optional): Maximum length of strings before truncating, or None to disable. Defaults to None.
max_depth (int, optional): Maximum depth for nested data structures, or None for unlimited depth. Defaults to None.
indent_guides (bool, optional): Enable indentation guides. Defaults to True.
expand_all (bool, optional): Expand all containers. Defaults to False.

**Line:** 918

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.progress
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/progress.py`

**Imports:**
- abc.ABC
- abc.abstractmethod
- collections.deque
- console.Console
- console.Group
- console.JustifyMethod
- console.RenderableType
- dataclasses.dataclass
- dataclasses.field
- datetime.timedelta
- highlighter.Highlighter
- io
- io.RawIOBase
- io.UnsupportedOperation
- itertools.cycle
- jupyter.JupyterMixin
- live.Live
- math.ceil
- mmap.mmap
- operator.length_hint
- os.PathLike
- os.stat
- panel.Panel
- pip._vendor.typing_extensions.Literal
- pip._vendor.typing_extensions.Self
- progress_bar.ProgressBar
- random
- rule.Rule
- spinner.Spinner
- style.StyleType
- syntax.Syntax
- sys
- table.Column
- table.Table
- text.Text
- text.TextType
- threading.Event
- threading.RLock
- threading.Thread
- time
- types.TracebackType
- typing
- typing.Any
- typing.BinaryIO
- typing.Callable
- typing.ContextManager
- typing.Deque
- typing.Dict
- typing.Generic
- typing.Iterable
- typing.List
- typing.Literal
- typing.NamedTuple
- typing.NewType
- typing.Optional
- typing.Self
- typing.Sequence
- typing.TextIO
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- warnings

**Functions:**

### `def track(sequence: Union[(Sequence[ProgressType], Iterable[ProgressType])], description: str = 'Working...', total: Optional[float] = None, completed: int = 0, auto_refresh: bool = True, console: Optional[Console] = None, transient: bool = False, get_time: Optional[Callable[([], float)]] = None, refresh_per_second: float = 10, style: StyleType = 'bar.back', complete_style: StyleType = 'bar.complete', finished_style: StyleType = 'bar.finished', pulse_style: StyleType = 'bar.pulse', update_period: float = 0.1, disable: bool = False, show_speed: bool = True) -> Iterable[ProgressType]`

**Description:**
Track progress by iterating over a sequence.

Args:
sequence (Iterable[ProgressType]): A sequence (must support "len") you wish to iterate over.
description (str, optional): Description of task show next to progress bar. Defaults to "Working".
total: (float, optional): Total number of steps. Default is len(sequence).
completed (int, optional): Number of steps completed so far. Defaults to 0.
auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
transient: (bool, optional): Clear the progress on exit. Defaults to False.
console (Console, optional): Console to write to. Default creates internal Console instance.
refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
update_period (float, optional): Minimum time (in seconds) between calls to update(). Defaults to 0.1.
disable (bool, optional): Disable display of progress.
show_speed (bool, optional): Show speed if total isn't known. Defaults to True.
Returns:
Iterable[ProgressType]: An iterable of the values in the sequence.

**Line:** 108

---

### `def wrap_file(file: BinaryIO, total: int, description: str = 'Reading...', auto_refresh: bool = True, console: Optional[Console] = None, transient: bool = False, get_time: Optional[Callable[([], float)]] = None, refresh_per_second: float = 10, style: StyleType = 'bar.back', complete_style: StyleType = 'bar.complete', finished_style: StyleType = 'bar.finished', pulse_style: StyleType = 'bar.pulse', disable: bool = False) -> ContextManager[BinaryIO]`

**Description:**
Read bytes from a file while tracking progress.

Args:
file (Union[str, PathLike[str], BinaryIO]): The path to the file to read, or a file-like object in binary mode.
total (int): Total number of bytes to read.
description (str, optional): Description of task show next to progress bar. Defaults to "Reading".
auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
transient: (bool, optional): Clear the progress on exit. Defaults to False.
console (Console, optional): Console to write to. Default creates internal Console instance.
refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
disable (bool, optional): Disable display of progress.
Returns:
ContextManager[BinaryIO]: A context manager yielding a progress reader.

**Line:** 308

---

### `def open(file: Union[(str, 'PathLike[str]', bytes)], mode: Union[(Literal['rt'], Literal['r'])], buffering: int = -1, encoding: Optional[str] = None, errors: Optional[str] = None, newline: Optional[str] = None, total: Optional[int] = None, description: str = 'Reading...', auto_refresh: bool = True, console: Optional[Console] = None, transient: bool = False, get_time: Optional[Callable[([], float)]] = None, refresh_per_second: float = 10, style: StyleType = 'bar.back', complete_style: StyleType = 'bar.complete', finished_style: StyleType = 'bar.finished', pulse_style: StyleType = 'bar.pulse', disable: bool = False) -> ContextManager[TextIO]`

**Decorators:**
- `@typing.overload`

**Line:** 374

---

### `def open(file: Union[(str, 'PathLike[str]', bytes)], mode: Literal['rb'], buffering: int = -1, encoding: Optional[str] = None, errors: Optional[str] = None, newline: Optional[str] = None, total: Optional[int] = None, description: str = 'Reading...', auto_refresh: bool = True, console: Optional[Console] = None, transient: bool = False, get_time: Optional[Callable[([], float)]] = None, refresh_per_second: float = 10, style: StyleType = 'bar.back', complete_style: StyleType = 'bar.complete', finished_style: StyleType = 'bar.finished', pulse_style: StyleType = 'bar.pulse', disable: bool = False) -> ContextManager[BinaryIO]`

**Decorators:**
- `@typing.overload`

**Line:** 399

---

### `def open(file: Union[(str, 'PathLike[str]', bytes)], mode: Union[(Literal['rb'], Literal['rt'], Literal['r'])] = 'r', buffering: int = -1, encoding: Optional[str] = None, errors: Optional[str] = None, newline: Optional[str] = None, total: Optional[int] = None, description: str = 'Reading...', auto_refresh: bool = True, console: Optional[Console] = None, transient: bool = False, get_time: Optional[Callable[([], float)]] = None, refresh_per_second: float = 10, style: StyleType = 'bar.back', complete_style: StyleType = 'bar.complete', finished_style: StyleType = 'bar.finished', pulse_style: StyleType = 'bar.pulse', disable: bool = False) -> Union[(ContextManager[BinaryIO], ContextManager[TextIO])]`

**Description:**
Read bytes from a file while tracking progress.

Args:
path (Union[str, PathLike[str], BinaryIO]): The path to the file to read, or a file-like object in binary mode.
mode (str): The mode to use to open the file. Only supports "r", "rb" or "rt".
buffering (int): The buffering strategy to use, see :func:`io.open`.
encoding (str, optional): The encoding to use when reading in text mode, see :func:`io.open`.
errors (str, optional): The error handling strategy for decoding errors, see :func:`io.open`.
newline (str, optional): The strategy for handling newlines in text mode, see :func:`io.open`
total: (int, optional): Total number of bytes to read. Must be provided if reading from a file handle. Default for a path is os.stat(file).st_size.
description (str, optional): Description of task show next to progress bar. Defaults to "Reading".
auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
transient: (bool, optional): Clear the progress on exit. Defaults to False.
console (Console, optional): Console to write to. Default creates internal Console instance.
refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
disable (bool, optional): Disable display of progress.
encoding (str, optional): The encoding to use when reading in text mode.

Returns:
ContextManager[BinaryIO]: A context manager yielding a progress reader.

**Line:** 423

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.protocol
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/protocol.py`

**Imports:**
- inspect.isclass
- pip._vendor.rich.console.RenderableType
- typing.Any
- typing.Set
- typing.TYPE_CHECKING
- typing.cast

**Functions:**

### `def is_renderable(check_object: Any) -> bool`

**Description:**
Check if an object may be rendered by Rich.

**Line:** 10

---

### `def rich_cast(renderable: object) -> 'RenderableType'`

**Description:**
Cast an object to a renderable by calling __rich__ if present.

Args:
renderable (object): A potentially renderable object

Returns:
object: The result of recursively calling __rich__.

**Line:** 19

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.repr
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/repr.py`

**Imports:**
- functools.partial
- inspect
- pip._vendor.rich.console.Console
- typing.Any
- typing.Callable
- typing.Iterable
- typing.List
- typing.Optional
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.overload

**Functions:**

### `def auto(cls: Optional[Type[T]]) -> Type[T]`

**Decorators:**
- `@overload`

**Line:** 28

---

### `def auto(angular: bool = False) -> Callable[([Type[T]], Type[T])]`

**Decorators:**
- `@overload`

**Line:** 33

---

### `def auto(cls: Optional[Type[T]] = None, angular: Optional[bool] = None) -> Union[(Type[T], Callable[[Type[T]], Type[T]])]`

**Description:**
Class decorator to create __repr__ from __rich_repr__

**Line:** 37

---

### `def rich_repr(cls: Optional[Type[T]]) -> Type[T]`

**Decorators:**
- `@overload`

**Line:** 105

---

### `def rich_repr(angular: bool = False) -> Callable[([Type[T]], Type[T])]`

**Decorators:**
- `@overload`

**Line:** 110

---

### `def rich_repr(cls: Optional[Type[T]] = None, angular: bool = False) -> Union[(Type[T], Callable[[Type[T]], Type[T]])]`

**Line:** 114

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.scope
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/scope.py`

**Imports:**
- collections.abc.Mapping
- console.ConsoleRenderable
- highlighter.ReprHighlighter
- panel.Panel
- pip._vendor.rich.print
- pretty.Pretty
- table.Table
- text.Text
- text.TextType
- typing.Any
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple

**Functions:**

### `def render_scope(scope: 'Mapping[str, Any]', title: Optional[TextType] = None, sort_keys: bool = True, indent_guides: bool = False, max_length: Optional[int] = None, max_string: Optional[int] = None) -> 'ConsoleRenderable'`

**Description:**
Render python variables in a given scope.

Args:
scope (Mapping): A mapping containing variable names and values.
title (str, optional): Optional title. Defaults to None.
sort_keys (bool, optional): Enable sorting of items. Defaults to True.
indent_guides (bool, optional): Enable indentation guides. Defaults to False.
max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
Defaults to None.
max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.

Returns:
ConsoleRenderable: A renderable object.

**Line:** 14

---

### `def test(foo: float, bar: float) -> None`

**Line:** 75

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.syntax
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/syntax.py`

**Imports:**
- _loop.loop_first
- abc.ABC
- abc.abstractmethod
- argparse
- cells.cell_len
- color.Color
- color.blend_rgb
- console.Console
- console.ConsoleOptions
- console.JustifyMethod
- console.RenderResult
- jupyter.JupyterMixin
- measure.Measurement
- os.path
- pathlib.Path
- pip._vendor.pygments.lexer.Lexer
- pip._vendor.pygments.lexers.get_lexer_by_name
- pip._vendor.pygments.lexers.guess_lexer_for_filename
- pip._vendor.pygments.style.Style
- pip._vendor.pygments.styles.get_style_by_name
- pip._vendor.pygments.token.Comment
- pip._vendor.pygments.token.Error
- pip._vendor.pygments.token.Generic
- pip._vendor.pygments.token.Keyword
- pip._vendor.pygments.token.Name
- pip._vendor.pygments.token.Number
- pip._vendor.pygments.token.Operator
- pip._vendor.pygments.token.String
- pip._vendor.pygments.token.Token
- pip._vendor.pygments.token.Whitespace
- pip._vendor.pygments.util.ClassNotFound
- pip._vendor.rich.console.Console
- pip._vendor.rich.containers.Lines
- pip._vendor.rich.padding.Padding
- pip._vendor.rich.padding.PaddingDimensions
- re
- segment.Segment
- segment.Segments
- style.Style
- style.StyleType
- sys
- text.Text
- textwrap
- typing.Any
- typing.Dict
- typing.Iterable
- typing.List
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.Set
- typing.Tuple
- typing.Type
- typing.Union

**Functions:**

### `def _get_code_index_for_syntax_position(newlines_offsets: Sequence[int], position: SyntaxPosition) -> Optional[int]`

**Description:**
Returns the index of the code string for the given positions.

Args:
newlines_offsets (Sequence[int]): The offset of each newline character found in the code snippet.
position (SyntaxPosition): The position to search for.

Returns:
Optional[int]: The index of the code string for this position, or `None`
if the given position's line number is out of range (if it's the column that is out of range
we silently clamp its value so that it reaches the end of the line)

**Line:** 822

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.table
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/table.py`

**Imports:**
- _loop.loop_first_last
- _loop.loop_last
- _pick.pick_bool
- _ratio.ratio_distribute
- _ratio.ratio_reduce
- _timer.timer
- align.VerticalAlignMethod
- console.Console
- console.ConsoleOptions
- console.JustifyMethod
- console.OverflowMethod
- console.RenderResult
- console.RenderableType
- dataclasses.dataclass
- dataclasses.field
- dataclasses.replace
- jupyter.JupyterMixin
- measure.Measurement
- padding.Padding
- padding.PaddingDimensions
- pip._vendor.rich.console.Console
- pip._vendor.rich.highlighter.ReprHighlighter
- protocol.is_renderable
- segment.Segment
- style.Style
- style.StyleType
- text.Text
- text.TextType
- typing.Dict
- typing.Iterable
- typing.List
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union

**Functions:**

### `def header(text: str) -> None`

**Line:** 967

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.rich.traceback
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/rich/traceback.py`

**Imports:**
- _loop.loop_first_last
- _loop.loop_last
- columns.Columns
- console.Console
- console.ConsoleOptions
- console.ConsoleRenderable
- console.Group
- console.RenderResult
- console.group
- constrain.Constrain
- dataclasses.dataclass
- dataclasses.field
- highlighter.RegexHighlighter
- highlighter.ReprHighlighter
- inspect
- itertools.islice
- linecache
- os
- panel.Panel
- pip._vendor.pygments.lexers.guess_lexer_for_filename
- pip._vendor.pygments.token.Comment
- pip._vendor.pygments.token.Keyword
- pip._vendor.pygments.token.Name
- pip._vendor.pygments.token.Number
- pip._vendor.pygments.token.Operator
- pip._vendor.pygments.token.String
- pip._vendor.pygments.token.Text
- pip._vendor.pygments.token.Token
- pip._vendor.pygments.util.ClassNotFound
- pip._vendor.rich._IMPORT_CWD
- scope.render_scope
- style.Style
- syntax.Syntax
- syntax.SyntaxPosition
- sys
- text.Text
- theme.Theme
- traceback.walk_tb
- types.ModuleType
- types.TracebackType
- typing.Any
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.List
- typing.Optional
- typing.Sequence
- typing.Tuple
- typing.Type
- typing.Union

**Functions:**

### `def _iter_syntax_lines(start: SyntaxPosition, end: SyntaxPosition) -> Iterable[Tuple[(int, int, int)]]`

**Description:**
Yield start and end positions per line.

Args:
start: Start position.
end: End position.

Returns:
Iterable of (LINE, COLUMN1, COLUMN2).

**Line:** 54

---

### `def install(console: Optional[Console] = None, width: Optional[int] = 100, code_width: Optional[int] = 88, extra_lines: int = 3, theme: Optional[str] = None, word_wrap: bool = False, show_locals: bool = False, locals_max_length: int = LOCALS_MAX_LENGTH, locals_max_string: int = LOCALS_MAX_STRING, locals_hide_dunder: bool = True, locals_hide_sunder: Optional[bool] = None, indent_guides: bool = True, suppress: Iterable[Union[(str, ModuleType)]] = (), max_frames: int = 100) -> Callable[([Type[BaseException], BaseException, Optional[TracebackType]], Any)]`

**Description:**
Install a rich traceback handler.

Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.


Args:
console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.
width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.
code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.
extra_lines (int, optional): Extra lines of code. Defaults to 3.
theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick
a theme appropriate for the platform.
word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
show_locals (bool, optional): Enable display of local variables. Defaults to False.
locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
Defaults to 10.
locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.
suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.

Returns:
Callable: The previous exception handler that was replaced.

**Line:** 82

---

### `def bar(a: Any) -> None`

**Line:** 862

---

### `def foo(a: Any) -> None`

**Line:** 868

---

### `def error() -> None`

**Line:** 881

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.tomli._parser
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/tomli/_parser.py`

**Imports:**
- __future__.annotations
- _re.RE_DATETIME
- _re.RE_LOCALTIME
- _re.RE_NUMBER
- _re.match_to_datetime
- _re.match_to_localtime
- _re.match_to_number
- _types.Key
- _types.ParseFloat
- _types.Pos
- collections.abc.Iterable
- string
- sys
- types.MappingProxyType
- typing.Any
- typing.Final
- typing.IO
- typing.NamedTuple
- warnings

**Functions:**

### `def load(__fp: IO[bytes], parse_float: ParseFloat = float) -> dict[(str, Any)]`

**Description:**
Parse TOML from a binary file object.

**Line:** 130

---

### `def loads(__s: str, parse_float: ParseFloat = float) -> dict[(str, Any)]`

**Description:**
Parse TOML from a string.

**Line:** 142

---

### `def skip_chars(src: str, pos: Pos, chars: Iterable[str]) -> Pos`

**Line:** 310

---

### `def skip_until(src: str, pos: Pos, expect: str, error_on: frozenset[str], error_on_eof: bool) -> Pos`

**Line:** 319

---

### `def skip_comment(src: str, pos: Pos) -> Pos`

**Line:** 341

---

### `def skip_comments_and_array_ws(src: str, pos: Pos) -> Pos`

**Line:** 353

---

### `def create_dict_rule(src: str, pos: Pos, out: Output) -> tuple[(Pos, Key)]`

**Line:** 362

---

### `def create_list_rule(src: str, pos: Pos, out: Output) -> tuple[(Pos, Key)]`

**Line:** 382

---

### `def key_value_rule(src: str, pos: Pos, out: Output, header: Key, parse_float: ParseFloat) -> Pos`

**Line:** 405

---

### `def parse_key_value_pair(src: str, pos: Pos, parse_float: ParseFloat, nest_lvl: int) -> tuple[(Pos, Key, Any)]`

**Line:** 439

---

### `def parse_key(src: str, pos: Pos) -> tuple[(Pos, Key)]`

**Line:** 455

---

### `def parse_key_part(src: str, pos: Pos) -> tuple[(Pos, str)]`

**Line:** 473

---

### `def parse_one_line_basic_str(src: str, pos: Pos) -> tuple[(Pos, str)]`

**Line:** 489

---

### `def parse_array(src: str, pos: Pos, parse_float: ParseFloat, nest_lvl: int) -> tuple[(Pos, list)]`

**Line:** 494

---

### `def parse_inline_table(src: str, pos: Pos, parse_float: ParseFloat, nest_lvl: int) -> tuple[(Pos, dict)]`

**Line:** 520

---

### `def parse_basic_str_escape(src: str, pos: Pos, multiline: bool = False) -> tuple[(Pos, str)]`

**Line:** 554

---

### `def parse_basic_str_escape_multiline(src: str, pos: Pos) -> tuple[(Pos, str)]`

**Line:** 583

---

### `def parse_hex_char(src: str, pos: Pos, hex_len: int) -> tuple[(Pos, str)]`

**Line:** 587

---

### `def parse_literal_str(src: str, pos: Pos) -> tuple[(Pos, str)]`

**Line:** 600

---

### `def parse_multiline_str(src: str, pos: Pos, literal: bool) -> tuple[(Pos, str)]`

**Line:** 609

---

### `def parse_basic_str(src: str, pos: Pos, multiline: bool) -> tuple[(Pos, str)]`

**Line:** 640

---

### `def parse_value(src: str, pos: Pos, parse_float: ParseFloat, nest_lvl: int) -> tuple[(Pos, Any)]`

**Line:** 672

---

### `def is_unicode_scalar_value(codepoint: int) -> bool`

**Line:** 748

---

### `def make_safe_parse_float(parse_float: ParseFloat) -> ParseFloat`

**Description:**
A decorator to make `parse_float` safe.

`parse_float` must not return dicts or lists, because these types
would be mixed with parsed TOML tables and arrays, thus confusing
the parser. The returned decorated callable raises `ValueError`
instead of returning illegal types.

**Line:** 752

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.tomli._re
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/tomli/_re.py`

**Imports:**
- __future__.annotations
- _types.ParseFloat
- datetime.date
- datetime.datetime
- datetime.time
- datetime.timedelta
- datetime.timezone
- datetime.tzinfo
- functools.lru_cache
- re
- typing.Any
- typing.Final

**Functions:**

### `def match_to_datetime(match: re.Match) -> datetime | date`

**Description:**
Convert a `RE_DATETIME` match to `datetime.datetime` or `datetime.date`.

Raises ValueError if the match does not correspond to a valid date
or datetime.

**Line:** 54

---

### `def cached_tz(hour_str: str, minute_str: str, sign_str: str) -> timezone`

**Decorators:**
- `@lru_cache(...)`

**Line:** 93

---

### `def match_to_localtime(match: re.Match) -> time`

**Line:** 103

---

### `def match_to_number(match: re.Match, parse_float: ParseFloat) -> Any`

**Line:** 109

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.tomli_w._writer
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/tomli_w/_writer.py`

**Imports:**
- __future__.annotations
- collections.abc.Generator
- collections.abc.Mapping
- datetime.date
- datetime.datetime
- datetime.time
- decimal.Decimal
- types.MappingProxyType
- typing.Any
- typing.Final
- typing.IO

**Functions:**

### `def dump(obj: Mapping[(str, Any)], fp: IO[bytes], multiline_strings: bool = False, indent: int = 4) -> None`

**Line:** 43

---

### `def dumps(obj: Mapping[(str, Any)], multiline_strings: bool = False, indent: int = 4) -> str`

**Line:** 56

---

### `def gen_table_chunks(table: Mapping[(str, Any)], ctx: Context, name: str, inside_aot: bool = False) -> Generator[(str, None, None)]`

**Line:** 63

---

### `def format_literal(obj: object, ctx: Context, nest_level: int = 0) -> str`

**Line:** 100

---

### `def format_decimal(obj: Decimal) -> str`

**Line:** 126

---

### `def format_inline_table(obj: Mapping, ctx: Context) -> str`

**Line:** 135

---

### `def format_inline_array(obj: tuple | list, ctx: Context, nest_level: int) -> str`

**Line:** 156

---

### `def format_key_part(part: str) -> str`

**Line:** 171

---

### `def format_string(s: str, allow_multiline: bool) -> str`

**Line:** 185

---

### `def is_aot(obj: Any) -> bool`

**Description:**
Decides if an object behaves as an array of tables (i.e. a nonempty list
of dicts).

**Line:** 215

---

### `def is_suitable_inline_table(obj: Mapping, ctx: Context) -> bool`

**Description:**
Use heuristics to decide if the inline-style representation is a good
choice for a given table.

**Line:** 225

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.truststore._api
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/truststore/_api.py`

**Imports:**
- _macos._configure_context
- _macos._verify_peercerts_impl
- _openssl._configure_context
- _openssl._verify_peercerts_impl
- _ssl
- _ssl_constants._original_SSLContext
- _ssl_constants._original_super_SSLContext
- _ssl_constants._truststore_SSLContext_dunder_class
- _ssl_constants._truststore_SSLContext_super_class
- _windows._configure_context
- _windows._verify_peercerts_impl
- os
- pip._vendor.requests.adapters
- pip._vendor.typing_extensions.Buffer
- pip._vendor.urllib3.util.ssl_
- platform
- socket
- ssl
- sys
- typing

**Functions:**

### `def inject_into_ssl() -> None`

**Description:**
Injects the :class:`truststore.SSLContext` into the ``ssl``
module by replacing :class:`ssl.SSLContext`.

**Line:** 32

---

### `def extract_from_ssl() -> None`

**Description:**
Restores the :class:`ssl.SSLContext` class to its original state

**Line:** 64

---

### `def _get_unverified_chain_bytes(sslobj: ssl.SSLObject) -> list[bytes]`

**Line:** 302

---

### `def _get_unverified_chain_bytes(sslobj: ssl.SSLObject) -> list[bytes]`

**Line:** 311

---

### `def _verify_peercerts(sock_or_sslobj: ssl.SSLSocket | ssl.SSLObject, server_hostname: str | None) -> None`

**Description:**
Verifies the peer certificates from an SSLSocket or SSLObject
against the certificates in the OS trust store.

**Line:** 316

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.truststore._macos
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/truststore/_macos.py`

**Imports:**
- _ssl_constants._set_ssl_context_verify_mode
- contextlib
- ctypes
- ctypes.CDLL
- ctypes.POINTER
- ctypes.c_bool
- ctypes.c_char_p
- ctypes.c_int32
- ctypes.c_long
- ctypes.c_uint32
- ctypes.c_ulong
- ctypes.c_void_p
- ctypes.util.find_library
- platform
- ssl
- typing

**Functions:**

### `def _load_cdll(name: str, macos10_16_path: str) -> CDLL`

**Description:**
Loads a CDLL by name, falling back to known path on 10.16+

**Line:** 31

---

### `def _handle_osstatus(result: OSStatus, _: typing.Any, args: typing.Any) -> typing.Any`

**Description:**
Raises an error if the OSStatus value is non-zero.

**Line:** 223

---

### `def _bytes_to_cf_data_ref(value: bytes) -> CFDataRef`

**Line:** 294

---

### `def _bytes_to_cf_string(value: bytes) -> CFString`

**Description:**
Given a Python binary data, create a CFString.
The string must be CFReleased by the caller.

**Line:** 300

---

### `def _cf_string_ref_to_str(cf_string_ref: CFStringRef) -> str | None`

**Description:**
Creates a Unicode string from a CFString object. Used entirely for error
reporting.
Yes, it annoys me quite a lot that this function is this complex.

**Line:** 314

---

### `def _der_certs_to_cf_cert_array(certs: list[bytes]) -> CFMutableArrayRef`

**Description:**
Builds a CFArray of SecCertificateRefs from a list of DER-encoded certificates.
Responsibility of the caller to call CoreFoundation.CFRelease on the CFArray.

**Line:** 337

---

### `def _configure_context(ctx: ssl.SSLContext) -> typing.Iterator[None]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 368

---

### `def _verify_peercerts_impl(ssl_context: ssl.SSLContext, cert_chain: list[bytes], server_hostname: str | None = None) -> None`

**Line:** 380

---

### `def _verify_peercerts_impl_macos_10_13(ssl_context: ssl.SSLContext, sec_trust_ref: typing.Any) -> None`

**Description:**
Verify using 'SecTrustEvaluate' API for macOS 10.13 and earlier.
macOS 10.14 added the 'SecTrustEvaluateWithError' API.

**Line:** 469

---

### `def _verify_peercerts_impl_macos_10_14(ssl_context: ssl.SSLContext, sec_trust_ref: typing.Any) -> None`

**Description:**
Verify using 'SecTrustEvaluateWithError' API for macOS 10.14+.

**Line:** 513

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.truststore._openssl
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/truststore/_openssl.py`

**Imports:**
- contextlib
- os
- re
- ssl
- typing

**Functions:**

### `def _configure_context(ctx: ssl.SSLContext) -> typing.Iterator[None]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 23

---

### `def _capath_contains_certs(capath: str) -> bool`

**Description:**
Check whether capath exists and contains certs in the expected format.

**Line:** 49

---

### `def _verify_peercerts_impl(ssl_context: ssl.SSLContext, cert_chain: list[bytes], server_hostname: str | None = None) -> None`

**Line:** 59

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.truststore._ssl_constants
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/truststore/_ssl_constants.py`

**Imports:**
- ssl
- sys
- typing

**Functions:**

### `def _set_ssl_context_verify_mode(ssl_context: ssl.SSLContext, verify_mode: ssl.VerifyMode) -> None`

**Line:** 28

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.truststore._windows
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/truststore/_windows.py`

**Imports:**
- _ssl_constants._set_ssl_context_verify_mode
- contextlib
- ctypes.POINTER
- ctypes.Structure
- ctypes.WinDLL
- ctypes.WinError
- ctypes.c_char_p
- ctypes.c_ulong
- ctypes.c_void_p
- ctypes.c_wchar_p
- ctypes.cast
- ctypes.create_unicode_buffer
- ctypes.pointer
- ctypes.sizeof
- ctypes.wintypes.BOOL
- ctypes.wintypes.DWORD
- ctypes.wintypes.HANDLE
- ctypes.wintypes.LONG
- ctypes.wintypes.LPCSTR
- ctypes.wintypes.LPCVOID
- ctypes.wintypes.LPCWSTR
- ctypes.wintypes.LPFILETIME
- ctypes.wintypes.LPSTR
- ctypes.wintypes.LPWSTR
- ssl
- typing
- typing.Any
- typing.TYPE_CHECKING

**Functions:**

### `def _handle_win_error(result: bool, _: Any, args: Any) -> Any`

**Line:** 238

---

### `def _verify_peercerts_impl(ssl_context: ssl.SSLContext, cert_chain: list[bytes], server_hostname: str | None = None) -> None`

**Description:**
Verify the cert_chain from the server using Windows APIs.

**Line:** 323

---

### `def _get_and_verify_cert_chain(ssl_context: ssl.SSLContext, hChainEngine: HCERTCHAINENGINE | None, hIntermediateCertStore: HCERTSTORE, pPeerCertContext: c_void_p, pChainPara: PCERT_CHAIN_PARA, server_hostname: str | None, chain_flags: int) -> None`

**Line:** 415

---

### `def _verify_using_custom_ca_certs(ssl_context: ssl.SSLContext, custom_ca_certs: list[bytes], hIntermediateCertStore: HCERTSTORE, pPeerCertContext: c_void_p, pChainPara: PCERT_CHAIN_PARA, server_hostname: str | None, chain_flags: int) -> None`

**Line:** 505

---

### `def _configure_context(ctx: ssl.SSLContext) -> typing.Iterator[None]`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 558

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.typing_extensions
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/typing_extensions.py`

**Imports:**
- _socket
- abc
- asyncio.coroutines
- builtins
- collections
- collections.abc
- contextlib
- enum
- functools
- inspect
- keyword
- operator
- sys
- types
- types.MethodType
- typing
- typing.Any
- typing.AsyncContextManager
- typing.AsyncGenerator
- typing.ContextManager
- typing.Generator
- typing.GenericAlias
- typing.ParamSpec
- typing.TypeVar
- typing.TypeVarTuple
- typing._BaseGenericAlias
- warnings

**Functions:**

### `def _should_collect_from_parameters(t)`

**Line:** 165

---

### `def _should_collect_from_parameters(t)`

**Line:** 170

---

### `def _should_collect_from_parameters(t)`

**Line:** 173

---

### `def final(f)`

**Description:**
This decorator can be used to indicate to type checkers that
the decorated method cannot be overridden, and decorated class
cannot be subclassed. For example:

class Base:
@final
def done(self) -> None:
...
class Sub(Base):
def done(self) -> None:  # Error reported by type checker
...
@final
class Leaf:
...
class Other(Leaf):  # Error reported by type checker
...

There is no runtime checking of these properties. The decorator
sets the ``__final__`` attribute to ``True`` on the decorated object
to allow runtime introspection.

**Line:** 234

---

### `def IntVar(name)`

**Line:** 266

---

### `def _flatten_literal_params(parameters)`

**Description:**
An internal helper for Literal creation: flatten Literals among parameters

**Line:** 274

---

### `def _value_and_type_iter(params)`

**Line:** 284

---

### `def overload(func)`

**Description:**
Decorator for overloaded functions/methods.

In a stub file, place two or more stub definitions for the same
function in a row, each decorated with @overload.  For example:

@overload
def utf8(value: None) -> None: ...
@overload
def utf8(value: bytes) -> bytes: ...
@overload
def utf8(value: str) -> bytes: ...

In a non-stub file (i.e. a regular .py file), do the same but
follow it with an implementation.  The implementation should *not*
be decorated with @overload.  For example:

@overload
def utf8(value: None) -> None: ...
@overload
def utf8(value: bytes) -> bytes: ...
@overload
def utf8(value: str) -> bytes: ...
def utf8(value):
# implementation goes here

The overloads for a function can be retrieved at runtime using the
get_overloads() function.

**Line:** 357

---

### `def get_overloads(func)`

**Description:**
Return all defined overloads for *func* as a sequence.

**Line:** 397

---

### `def clear_overloads()`

**Description:**
Clear all overloads in the registry.

**Line:** 408

---

### `def _is_dunder(attr)`

**Line:** 434

---

### `def _get_protocol_attrs(cls)`

**Line:** 529

---

### `def _caller(depth = 2)`

**Line:** 541

---

### `def _allow_reckless_class_checks(depth = 3)`

**Description:**
Allow instance and class checks for special stdlib modules.
The abc and functools modules indiscriminately call isinstance() and
issubclass() on the whole MRO of a user class, which may contain protocols.

**Line:** 553

---

### `def _no_init(self, *args, **kwargs)`

**Line:** 560

---

### `def _type_check_issubclass_arg_1(arg)`

**Description:**
Raise TypeError if `arg` is not an instance of `type`
in `issubclass(arg, <protocol>)`.

In most cases, this is verified by type.__subclasscheck__.
Checking it again unnecessarily would slow down issubclass() checks,
so, we don't perform this check unless we absolutely have to.

For various error paths, however,
we want to ensure that *this* error message is shown to the user
where relevant, rather than a typing.py-specific error message.

**Line:** 564

---

### `def _proto_hook(cls, other)`

**Decorators:**
- `@classmethod`

**Line:** 684

---

### `def runtime_checkable(cls)`

**Description:**
Mark a protocol class as a runtime protocol.

Such protocol can be used with isinstance() and issubclass().
Raise TypeError if applied to a non-protocol class.
This allows a simple-minded structural check very similar to
one trick ponies in collections.abc such as Iterable.

For example::

@runtime_checkable
class Closable(Protocol):
def close(self): ...

assert isinstance(open('/some/file'), Closable)

Warning: this will check only the presence of the required methods,
not their type signatures!

**Line:** 733

---

### `def _ensure_subclassable(mro_entries)`

**Line:** 866

---

### `def _get_typeddict_qualifiers(annotation_type)`

**Line:** 962

---

### `def TypedDict(typename, fields, total = True, closed = None, extra_items = NoExtraItems, **kwargs)`

**Decorators:**
- `@_ensure_subclassable(...)`

**Description:**
A simple typed namespace. At runtime it is equivalent to a plain dict.

TypedDict creates a dictionary type such that a type checker will expect all
instances to have a certain set of keys, where each key is
associated with a value of a consistent type. This expectation
is not checked at runtime.

Usage::

class Point2D(TypedDict):
x: int
y: int
label: str

a: Point2D = {'x': 1, 'y': 2, 'label': 'good'}  # OK
b: Point2D = {'z': 3, 'label': 'bad'}           # Fails type check

assert Point2D(x=1, y=2, label='first') == dict(x=1, y=2, label='first')

The type info can be accessed via the Point2D.__annotations__ dict, and
the Point2D.__required_keys__ and Point2D.__optional_keys__ frozensets.
TypedDict supports an additional equivalent form::

Point2D = TypedDict('Point2D', {'x': int, 'y': int, 'label': str})

By default, all keys must be present in a TypedDict. It is possible
to override this by specifying totality::

class Point2D(TypedDict, total=False):
x: int
y: int

This means that a Point2D TypedDict can have any of the keys omitted. A type
checker is only expected to support a literal False or True as the value of
the total argument. True is the default, and makes all items defined in the
class body be required.

The Required and NotRequired special forms can also be used to mark
individual keys as being required or not required::

class Point2D(TypedDict):
x: int  # the "x" key must always be present (Required is the default)
y: NotRequired[int]  # the "y" key can be omitted

See PEP 655 for more details on Required and NotRequired.

**Line:** 1109

---

### `def is_typeddict(tp)`

**Description:**
Check if an annotation is a TypedDict class

For example::
class Film(TypedDict):
title: str
year: int

is_typeddict(Film)  # => True
is_typeddict(Union[list, str])  # => False

**Line:** 1217

---

### `def assert_type(val, typ)`

**Description:**
Assert (to the type checker) that the value is of the given type.

When the type checker encounters a call to assert_type(), it
emits an error if the value is not of the specified type::

def greet(name: str) -> None:
assert_type(name, str)  # ok
assert_type(name, int)  # type checker error

At runtime this returns the first argument unchanged and otherwise
does nothing.

**Line:** 1238

---

### `def _strip_extras(t)`

**Description:**
Strips Annotated, Required and NotRequired from a given type.

**Line:** 1258

---

### `def get_type_hints(obj, globalns = None, localns = None, include_extras = False)`

**Description:**
Return type hints for an object.

This is often the same as obj.__annotations__, but it handles
forward references encoded as string literals, adds Optional[t] if a
default value equal to None is set and recursively replaces all
'Annotated[T, ...]', 'Required[T]' or 'NotRequired[T]' with 'T'
(unless 'include_extras=True').

The argument may be a module, class, method, or function. The annotations
are returned as a dictionary. For classes, annotations include also
inherited members.

TypeError is raised if the argument is not of a type that can contain
annotations, and an empty dictionary is returned if no annotations are
present.

BEWARE -- the behavior of globalns and localns is counterintuitive
(unless you are familiar with how eval() and exec() work).  The
search order is locals first, then globals.

- If no dict arguments are passed, an attempt is made to use the
globals from obj (or the respective module's globals for classes),
and these are also used as the locals.  If the object does not appear
to have globals, an empty dictionary is used.

- If one dict argument is passed, it is used for both globals and
locals.

- If two dict arguments are passed, they specify globals and
locals, respectively.

**Line:** 1282

---

### `def _could_be_inserted_optional(t)`

**Description:**
detects Union[..., None] pattern

**Line:** 1337

---

### `def _clean_optional(obj, hints, globalns = None, localns = None)`

**Line:** 1348

---

### `def get_origin(tp)`

**Description:**
Get the unsubscripted version of a type.

This supports generic types, Callable, Tuple, Union, Literal, Final, ClassVar
and Annotated. Return None for unsupported types. Examples::

get_origin(Literal[42]) is Literal
get_origin(int) is None
get_origin(ClassVar[int]) is ClassVar
get_origin(Generic) is Generic
get_origin(Generic[T]) is Generic
get_origin(Union[T, int]) is Union
get_origin(List[Tuple[T, T]][int]) == list
get_origin(P.args) is P

**Line:** 1529

---

### `def get_args(tp)`

**Description:**
Get type arguments with all substitutions performed.

For unions, basic simplifications used by Union constructor are performed.
Examples::
get_args(Dict[str, int]) == (str, int)
get_args(int) == ()
get_args(Union[int, Union[T, int], str][int]) == (int, str)
get_args(Union[int, Tuple[T, int]][str]) == (int, Tuple[str, int])
get_args(Callable[[], T][int]) == ([], int)

**Line:** 1553

---

### `def TypeAlias(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
Special marker indicating that an assignment should
be recognized as a proper type alias definition by type
checkers.

For example::

Predicate: TypeAlias = Callable[..., bool]

It's invalid when used anywhere except as in the example above.

**Line:** 1582

---

### `def _set_default(type_param, default)`

**Line:** 1611

---

### `def _set_module(typevarlike)`

**Line:** 1616

---

### `def _type_convert(arg, module = None, allow_special_forms = False)`

**Description:**
For converting None to type(None), and strings to ForwardRef.

**Line:** 1904

---

### `def _create_concatenate_alias(origin, parameters)`

**Line:** 2071

---

### `def _concatenate_getitem(self, parameters)`

**Decorators:**
- `@typing._tp_cache`

**Line:** 2096

---

### `def Concatenate(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
Used in conjunction with ``ParamSpec`` and ``Callable`` to represent a
higher order function which adds, removes or transforms parameters of a
callable.

For example::

Callable[Concatenate[int, P], int]

See PEP 612 for detailed information.

**Line:** 2116

---

### `def TypeGuard(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
Special typing form used to annotate the return type of a user-defined
type guard function.  ``TypeGuard`` only accepts a single type argument.
At runtime, functions marked this way should return a boolean.

``TypeGuard`` aims to benefit *type narrowing* -- a technique used by static
type checkers to determine a more precise type of an expression within a
program's code flow.  Usually type narrowing is done by analyzing
conditional code flow and applying the narrowing to a block of code.  The
conditional expression here is sometimes referred to as a "type guard".

Sometimes it would be convenient to use a user-defined boolean function
as a type guard.  Such a function should use ``TypeGuard[...]`` as its
return type to alert static type checkers to this intention.

Using  ``-> TypeGuard`` tells the static type checker that for a given
function:

1. The return value is a boolean.
2. If the return value is ``True``, the type of its argument
is the type inside ``TypeGuard``.

For example::

def is_str(val: Union[str, float]):
# "isinstance" type guard
if isinstance(val, str):
# Type of ``val`` is narrowed to ``str``
...
else:
# Else, type of ``val`` is narrowed to ``float``.
...

Strict type narrowing is not enforced -- ``TypeB`` need not be a narrower
form of ``TypeA`` (it can even be a wider form) and this may lead to
type-unsafe results.  The main reason is to allow for things like
narrowing ``List[object]`` to ``List[str]`` even though the latter is not
a subtype of the former, since ``List`` is invariant.  The responsibility of
writing type-safe type guards is left to the user.

``TypeGuard`` also works with type variables.  For more information, see
PEP 647 (User-Defined Type Guards).

**Line:** 2153

---

### `def TypeIs(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
Special typing form used to annotate the return type of a user-defined
type narrower function.  ``TypeIs`` only accepts a single type argument.
At runtime, functions marked this way should return a boolean.

``TypeIs`` aims to benefit *type narrowing* -- a technique used by static
type checkers to determine a more precise type of an expression within a
program's code flow.  Usually type narrowing is done by analyzing
conditional code flow and applying the narrowing to a block of code.  The
conditional expression here is sometimes referred to as a "type guard".

Sometimes it would be convenient to use a user-defined boolean function
as a type guard.  Such a function should use ``TypeIs[...]`` as its
return type to alert static type checkers to this intention.

Using  ``-> TypeIs`` tells the static type checker that for a given
function:

1. The return value is a boolean.
2. If the return value is ``True``, the type of its argument
is the intersection of the type inside ``TypeIs`` and the argument's
previously known type.

For example::

def is_awaitable(val: object) -> TypeIs[Awaitable[Any]]:
return hasattr(val, '__await__')

def f(val: Union[int, Awaitable[int]]) -> int:
if is_awaitable(val):
assert_type(val, Awaitable[int])
else:
assert_type(val, int)

``TypeIs`` also works with type variables.  For more information, see
PEP 742 (Narrowing types with TypeIs).

**Line:** 2257

---

### `def TypeForm(self, parameters)`

**Decorators:**
- `@_TypeFormForm`

**Description:**
A special form representing the value that results from the evaluation
of a type expression. This value encodes the information supplied in the
type expression, and it represents the type described by that type expression.

When used in a type expression, TypeForm describes a set of type form objects.
It accepts a single type argument, which must be a valid type expression.
``TypeForm[T]`` describes the set of all type form objects that represent
the type T or types that are assignable to T.

Usage:

def cast[T](typ: TypeForm[T], value: Any) -> T: ...

reveal_type(cast(int, "x"))  # int

See PEP 747 for more information.

**Line:** 2355

---

### `def LiteralString(self, params)`

**Decorators:**
- `@_SpecialForm`

**Description:**
Represents an arbitrary literal string.

Example::

from pip._vendor.typing_extensions import LiteralString

def query(sql: LiteralString) -> ...:
...

query("SELECT * FROM table")  # ok
query(f"SELECT * FROM {input()}")  # not ok

See PEP 675 for details.

**Line:** 2455

---

### `def Self(self, params)`

**Decorators:**
- `@_SpecialForm`

**Description:**
Used to spell the type of "self" in classes.

Example::

from typing import Self

class ReturnsSelf:
def parse(self, data: bytes) -> Self:
...
return self

**Line:** 2478

---

### `def Never(self, params)`

**Decorators:**
- `@_SpecialForm`

**Description:**
The bottom type, a type that has no members.

This can be used to define a function that should never be
called, or a function that never returns::

from pip._vendor.typing_extensions import Never

def never_call_me(arg: Never) -> None:
pass

def int_or_str(arg: int | str) -> None:
never_call_me(arg)  # type checker error
match arg:
case int():
print("It's an int")
case str():
print("It's a str")
case _:
never_call_me(arg)  # ok, arg is of type Never

**Line:** 2499

---

### `def Required(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
A special typing construct to mark a key of a total=False TypedDict
as required. For example:

class Movie(TypedDict, total=False):
title: Required[str]
year: int

m = Movie(
title='The Matrix',  # typechecker error if key is omitted
year=1999,
)

There is no runtime checking that a required key is actually provided
when instantiating a related TypedDict.

**Line:** 2530

---

### `def NotRequired(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
A special typing construct to mark a key of a TypedDict as
potentially missing. For example:

class Movie(TypedDict):
title: str
year: NotRequired[int]

m = Movie(
title='The Matrix',  # typechecker error if key is omitted
year=1999,
)

**Line:** 2550

---

### `def ReadOnly(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
A special typing construct to mark an item of a TypedDict as read-only.

For example:

class Movie(TypedDict):
title: ReadOnly[str]
year: int

def mutate_movie(m: Movie) -> None:
m["year"] = 1992  # allowed
m["title"] = "The Matrix"  # typechecker error

There is no runtime checking for this property.

**Line:** 2610

---

### `def _is_unpack(obj)`

**Line:** 2698

---

### `def Unpack(self, parameters)`

**Decorators:**
- `@_UnpackSpecialForm`

**Line:** 2735

---

### `def _is_unpack(obj)`

**Line:** 2739

---

### `def _is_unpack(obj)`

**Line:** 2776

---

### `def _unpack_args(*args)`

**Line:** 2780

---

### `def reveal_type(obj: T) -> T`

**Description:**
Reveal the inferred type of a variable.

When a static type checker encounters a call to ``reveal_type()``,
it will emit the inferred type of the argument::

x: int = 1
reveal_type(x)

Running a static type checker (e.g., ``mypy``) on this example
will produce output similar to 'Revealed type is "builtins.int"'.

At runtime, the function prints the runtime type of the
argument and returns it unchanged.

**Line:** 2940

---

### `def assert_never(arg: Never) -> Never`

**Description:**
Assert to the type checker that a line of code is unreachable.

Example::

def int_or_str(arg: int | str) -> None:
match arg:
case int():
print("It's an int")
case str():
print("It's a str")
case _:
assert_never(arg)

If a type checker finds that a call to assert_never() is
reachable, it will emit an error.

At runtime, this throws an exception when called.

**Line:** 2969

---

### `def dataclass_transform(eq_default: bool = True, order_default: bool = False, kw_only_default: bool = False, frozen_default: bool = False, field_specifiers: typing.Tuple[(typing.Union[typing.Type[typing.Any], typing.Callable[..., typing.Any]], ...)] = (), **kwargs: typing.Any) -> typing.Callable[([T], T)]`

**Description:**
Decorator that marks a function, class, or metaclass as providing
dataclass-like behavior.

Example:

from pip._vendor.typing_extensions import dataclass_transform

_T = TypeVar("_T")

# Used on a decorator function
@dataclass_transform()
def create_model(cls: type[_T]) -> type[_T]:
...
return cls

@create_model
class CustomerModel:
id: int
name: str

# Used on a base class
@dataclass_transform()
class ModelBase: ...

class CustomerModel(ModelBase):
id: int
name: str

# Used on a metaclass
@dataclass_transform()
class ModelMeta(type): ...

class ModelBase(metaclass=ModelMeta): ...

class CustomerModel(ModelBase):
id: int
name: str

Each of the ``CustomerModel`` classes defined in this example will now
behave similarly to a dataclass created with the ``@dataclasses.dataclass``
decorator. For example, the type checker will synthesize an ``__init__``
method.

The arguments to this decorator can be used to customize this behavior:
- ``eq_default`` indicates whether the ``eq`` parameter is assumed to be
True or False if it is omitted by the caller.
- ``order_default`` indicates whether the ``order`` parameter is
assumed to be True or False if it is omitted by the caller.
- ``kw_only_default`` indicates whether the ``kw_only`` parameter is
assumed to be True or False if it is omitted by the caller.
- ``frozen_default`` indicates whether the ``frozen`` parameter is
assumed to be True or False if it is omitted by the caller.
- ``field_specifiers`` specifies a static list of supported classes
or functions that describe fields, similar to ``dataclasses.field()``.

At runtime, this decorator records its arguments in the
``__dataclass_transform__`` attribute on the decorated object.

See PEP 681 for details.

**Line:** 2999

---

### `def override(arg: _F) -> _F`

**Description:**
Indicate that a method is intended to override a method in a base class.

Usage:

class Base:
def method(self) -> None:
pass

class Child(Base):
@override
def method(self) -> None:
super().method()

When this decorator is applied to a method, the type checker will
validate that it overrides a method with the same name on a base class.
This helps prevent bugs that may occur when a base class is changed
without an equivalent change to a child class.

There is no runtime checking of these properties. The decorator
sets the ``__override__`` attribute to ``True`` on the decorated object
to allow runtime introspection.

See PEP 698 for details.

**Line:** 3090

---

### `def _is_param_expr(arg)`

**Line:** 3270

---

### `def _is_param_expr(arg)`

**Line:** 3275

---

### `def _check_generic(cls, parameters, elen = _marker)`

**Description:**
Check correct count for parameters of a generic cls (internal helper).

This gives a nice error message in case of count mismatch.

**Line:** 3296

---

### `def _check_generic(cls, parameters, elen)`

**Description:**
Check correct count for parameters of a generic cls (internal helper).

This gives a nice error message in case of count mismatch.

**Line:** 3351

---

### `def _has_generic_or_protocol_as_origin() -> bool`

**Line:** 3389

---

### `def _is_unpacked_typevartuple(x) -> bool`

**Line:** 3411

---

### `def _collect_type_vars(types, typevar_types = None)`

**Description:**
Collect all type variable contained in types in order of
first appearance (lexicographic order). For example::

_collect_type_vars((T, List[S, T])) == (T, S)

**Line:** 3424

---

### `def _collect_parameters(args)`

**Description:**
Collect all type variables and parameter specifications in args
in order of first appearance (lexicographic order).

For example::

assert _collect_parameters((T, Callable[P, T])) == (T, P)

**Line:** 3474

---

### `def _make_nmtuple(name, types, module, defaults = ())`

**Line:** 3541

---

### `def _namedtuple_mro_entries(bases)`

**Line:** 3629

---

### `def NamedTuple(typename, fields, **kwargs)`

**Decorators:**
- `@_ensure_subclassable(...)`

**Description:**
Typed version of namedtuple.

Usage::

class Employee(NamedTuple):
name: str
id: int

This is equivalent to::

Employee = collections.namedtuple('Employee', ['name', 'id'])

The resulting class has an extra __annotations__ attribute, giving a
dict that maps field names to types.  (The field names are also in
the _fields attribute, which is part of the namedtuple API.)
An alternative equivalent functional syntax is also accepted::

Employee = NamedTuple('Employee', [('name', str), ('id', int)])

**Line:** 3634

---

### `def get_original_bases(cls)`

**Description:**
Return the class's "original" bases prior to modification by `__mro_entries__`.

Examples::

from typing import TypeVar, Generic
from pip._vendor.typing_extensions import NamedTuple, TypedDict

T = TypeVar("T")
class Foo(Generic[T]): ...
class Bar(Foo[int], float): ...
class Baz(list[str]): ...
Eggs = NamedTuple("Eggs", [("a", int), ("b", str)])
Spam = TypedDict("Spam", {"a": int, "b": str})

assert get_original_bases(Bar) == (Foo[int], float)
assert get_original_bases(Baz) == (list[str],)
assert get_original_bases(Eggs) == (NamedTuple,)
assert get_original_bases(Spam) == (TypedDict,)
assert get_original_bases(int) == (object,)

**Line:** 3733

---

### `def _is_unionable(obj)`

**Description:**
Corresponds to is_unionable() in unionobject.c in CPython.

**Line:** 3833

---

### `def _is_unionable(obj)`

**Description:**
Corresponds to is_unionable() in unionobject.c in CPython.

**Line:** 3844

---

### `def is_protocol(tp: type) -> bool`

**Description:**
Return True if the given type is a Protocol.

Example::

>>> from typing_extensions import Protocol, is_protocol
>>> class P(Protocol):
...     def a(self) -> str: ...
...     b: int
>>> is_protocol(P)
True
>>> is_protocol(int)
False

**Line:** 4049

---

### `def get_protocol_members(tp: type) -> typing.FrozenSet[str]`

**Description:**
Return the set of members defined in a Protocol.

Example::

>>> from typing_extensions import Protocol, get_protocol_members
>>> class P(Protocol):
...     def a(self) -> str: ...
...     b: int
>>> get_protocol_members(P)
frozenset({'a', 'b'})

Raise a TypeError for arguments that are not Protocols.

**Line:** 4070

---

### `def get_annotations(obj, globals = None, locals = None, eval_str = False, format = Format.VALUE)`

**Description:**
Compute the annotations dict for an object.

obj may be a callable, class, or module.
Passing in an object of any other type raises TypeError.

Returns a dict.  get_annotations() returns a new dict every time
it's called; calling it twice on the same object will return two
different but equivalent dicts.

This is a backport of `inspect.get_annotations`, which has been
in the standard library since Python 3.10. See the standard library
documentation for more:

https://docs.python.org/3/library/inspect.html#inspect.get_annotations

This backport adds the *format* argument introduced by PEP 649. The
three formats supported are:
* VALUE: the annotations are returned as-is. This is the default and
it is compatible with the behavior on previous Python versions.
* FORWARDREF: return annotations as-is if possible, but replace any
undefined names with ForwardRef objects. The implementation proposed by
PEP 649 relies on language changes that cannot be backported; the
typing-extensions implementation simply returns the same result as VALUE.
* STRING: return annotations as strings, in a format close to the original
source. Again, this behavior cannot be replicated directly in a backport.
As an approximation, typing-extensions retrieves the annotations under
VALUE semantics and then stringifies them.

The purpose of this backport is to allow users who would like to use
FORWARDREF or STRING semantics once PEP 649 is implemented, but who also
want to support earlier Python versions, to simply write:

typing_extensions.get_annotations(obj, format=Format.FORWARDREF)

**Line:** 4163

---

### `def _eval_with_owner(forward_ref, owner = None, globals = None, locals = None, type_params = None)`

**Line:** 4293

---

### `def _lax_type_check(value, msg, is_argument = True, module = None, allow_special_forms = False)`

**Description:**
A lax Python 3.11+ like version of typing._type_check

**Line:** 4381

---

### `def evaluate_forward_ref(forward_ref, owner = None, globals = None, locals = None, type_params = None, format = Format.VALUE, _recursive_guard = frozenset())`

**Description:**
Evaluate a forward reference as a type hint.

This is similar to calling the ForwardRef.evaluate() method,
but unlike that method, evaluate_forward_ref() also:

* Recursively evaluates forward references nested within the type hint.
* Rejects certain objects that are not valid type hints.
* Replaces type hints that evaluate to None with types.NoneType.
* Supports the *FORWARDREF* and *STRING* formats.

*forward_ref* must be an instance of ForwardRef. *owner*, if given,
should be the object that holds the annotations that the forward reference
derived from, such as a module, class object, or function. It is used to
infer the namespaces to use for looking up names. *globals* and *locals*
can also be explicitly given to provide the global and local namespaces.
*type_params* is a tuple of type parameters that are in scope when
evaluating the forward reference. This parameter must be provided (though
it may be an empty tuple) if *owner* is not given and the forward reference
does not already have an owner set. *format* specifies the format of the
annotation and is a member of the annotationlib.Format enum.

**Line:** 4432

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/__init__.py`

**Imports:**
- __future__.absolute_import
- _version.__version__
- connectionpool.HTTPConnectionPool
- connectionpool.HTTPSConnectionPool
- connectionpool.connection_from_url
- filepost.encode_multipart_formdata
- logging
- logging.NullHandler
- poolmanager.PoolManager
- poolmanager.ProxyManager
- poolmanager.proxy_from_url
- response.HTTPResponse
- urllib3_secure_extra
- util.request.make_headers
- util.retry.Retry
- util.timeout.Timeout
- util.url.get_host
- warnings

**Functions:**

### `def add_stderr_logger(level = logging.DEBUG)`

**Description:**
Helper for quickly adding a StreamHandler to the logger. Useful for
debugging.

Returns the handler after adding it.

**Line:** 63

---

### `def disable_warnings(category = exceptions.HTTPWarning)`

**Description:**
Helper for quickly disabling all urllib3 warnings.

**Line:** 98

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.connection
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py`

**Imports:**
- __future__.absolute_import
- _collections.HTTPHeaderDict
- _version.__version__
- datetime
- exceptions.ConnectTimeoutError
- exceptions.NewConnectionError
- exceptions.SubjectAltNameWarning
- exceptions.SystemTimeWarning
- logging
- os
- packages.six
- packages.six.moves.http_client.HTTPConnection
- packages.six.moves.http_client.HTTPException
- re
- socket
- socket.error
- socket.timeout
- ssl
- util.SKIPPABLE_HEADERS
- util.SKIP_HEADER
- util.connection
- util.proxy.create_proxy_ssl_context
- util.ssl_.assert_fingerprint
- util.ssl_.create_urllib3_context
- util.ssl_.is_ipaddress
- util.ssl_.resolve_cert_reqs
- util.ssl_.resolve_ssl_version
- util.ssl_.ssl_wrap_socket
- util.ssl_match_hostname.CertificateError
- util.ssl_match_hostname.match_hostname
- warnings

**Functions:**

### `def _match_hostname(cert, asserted_hostname)`

**Line:** 536

---

### `def _get_default_user_agent()`

**Line:** 558

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.connectionpool
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py`

**Imports:**
- __future__.absolute_import
- _collections.HTTPHeaderDict
- connection.BaseSSLError
- connection.BrokenPipeError
- connection.DummyConnection
- connection.HTTPConnection
- connection.HTTPException
- connection.HTTPSConnection
- connection.VerifiedHTTPSConnection
- connection.port_by_scheme
- errno
- exceptions.ClosedPoolError
- exceptions.EmptyPoolError
- exceptions.HeaderParsingError
- exceptions.HostChangedError
- exceptions.InsecureRequestWarning
- exceptions.LocationValueError
- exceptions.MaxRetryError
- exceptions.NewConnectionError
- exceptions.ProtocolError
- exceptions.ProxyError
- exceptions.ReadTimeoutError
- exceptions.SSLError
- exceptions.TimeoutError
- logging
- packages.backports.weakref_finalize.weakref_finalize
- packages.six
- packages.six.moves.queue
- re
- request.RequestMethods
- response.HTTPResponse
- socket
- socket.error
- socket.timeout
- sys
- util.connection.is_connection_dropped
- util.proxy.connection_requires_http_tunnel
- util.queue.LifoQueue
- util.request.set_file_position
- util.response.assert_header_parsing
- util.retry.Retry
- util.ssl_match_hostname.CertificateError
- util.timeout.Timeout
- util.url.Url
- util.url._encode_target
- util.url._normalize_host
- util.url.get_host
- util.url.parse_url
- warnings
- weakref

**Functions:**

### `def connection_from_url(url, **kw)`

**Description:**
Given a url, return an :class:`.ConnectionPool` instance of its host.

This is a shortcut for not having to parse out the scheme, host, and port
of the url before creating an :class:`.ConnectionPool` instance.

:param url:
Absolute URL string that must include the scheme. Port is optional.

:param \**kw:
Passes additional parameters to the constructor of the appropriate
:class:`.ConnectionPool`. Useful for specifying things like
timeout, maxsize, headers, etc.

Example::

>>> conn = connection_from_url('http://google.com/')
>>> r = conn.request('GET', '/')

**Line:** 1086

---

### `def _normalize_host(host, scheme)`

**Description:**
Normalize hosts for comparisons and use with sockets.

**Line:** 1114

---

### `def _close_pool_connections(pool)`

**Description:**
Drains a queue of connections and closes each one.

**Line:** 1132

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.contrib._appengine_environ
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/_appengine_environ.py`

**Imports:**
- os

**Functions:**

### `def is_appengine()`

**Line:** 8

---

### `def is_appengine_sandbox()`

**Description:**
Reports if the app is running in the first generation sandbox.

The second generation runtimes are technically still in a sandbox, but it
is much less restrictive, so generally you shouldn't need to check for it.
see https://cloud.google.com/appengine/docs/standard/runtimes

**Line:** 12

---

### `def is_local_appengine()`

**Line:** 22

---

### `def is_prod_appengine()`

**Line:** 28

---

### `def is_prod_appengine_mvms()`

**Description:**
Deprecated.

**Line:** 34

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.contrib._securetransport.bindings
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/_securetransport/bindings.py`

**Imports:**
- __future__.absolute_import
- ctypes.CDLL
- ctypes.CFUNCTYPE
- ctypes.POINTER
- ctypes.c_bool
- ctypes.c_byte
- ctypes.c_char_p
- ctypes.c_int32
- ctypes.c_long
- ctypes.c_size_t
- ctypes.c_uint32
- ctypes.c_ulong
- ctypes.c_void_p
- ctypes.util.find_library
- packages.six.raise_from
- platform

**Functions:**

### `def load_cdll(name, macos10_16_path)`

**Description:**
Loads a CDLL by name, falling back to known path on 10.16+

**Line:** 65

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.contrib._securetransport.low_level
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/_securetransport/low_level.py`

**Imports:**
- base64
- bindings.CFConst
- bindings.CoreFoundation
- bindings.Security
- ctypes
- itertools
- os
- re
- ssl
- struct
- tempfile

**Functions:**

### `def _cf_data_from_bytes(bytestring)`

**Description:**
Given a bytestring, create a CFData object from it. This CFData object must
be CFReleased by the caller.

**Line:** 27

---

### `def _cf_dictionary_from_tuples(tuples)`

**Description:**
Given a list of Python tuples, create an associated CFDictionary.

**Line:** 37

---

### `def _cfstr(py_bstr)`

**Description:**
Given a Python binary data, create a CFString.
The string must be CFReleased by the caller.

**Line:** 59

---

### `def _create_cfstring_array(lst)`

**Description:**
Given a list of Python binary data, create an associated CFMutableArray.
The array must be CFReleased by the caller.

Raises an ssl.SSLError on failure.

**Line:** 73

---

### `def _cf_string_to_unicode(value)`

**Description:**
Creates a Unicode string from a CFString object. Used entirely for error
reporting.

Yes, it annoys me quite a lot that this function is this complex.

**Line:** 104

---

### `def _assert_no_error(error, exception_class = None)`

**Description:**
Checks the return code and throws an exception if there is an error to
report

**Line:** 129

---

### `def _cert_array_from_pem(pem_bundle)`

**Description:**
Given a bundle of certs in PEM format, turns them into a CFArray of certs
that can be used to validate a cert chain.

**Line:** 150

---

### `def _is_cert(item)`

**Description:**
Returns True if a given CFTypeRef is a certificate.

**Line:** 196

---

### `def _is_identity(item)`

**Description:**
Returns True if a given CFTypeRef is an identity.

**Line:** 204

---

### `def _temporary_keychain()`

**Description:**
This function creates a temporary Mac keychain that we can use to work with
credentials. This keychain uses a one-time password and a temporary file to
store the data. We expect to have one keychain per socket. The returned
SecKeychainRef must be freed by the caller, including calling
SecKeychainDelete.

Returns a tuple of the SecKeychainRef and the path to the temporary
directory that contains it.

**Line:** 212

---

### `def _load_items_from_file(keychain, path)`

**Description:**
Given a single file, loads all the trust objects from it into arrays and
the keychain.
Returns a tuple of lists: the first list is a list of identities, the
second a list of certs.

**Line:** 247

---

### `def _load_client_cert_chain(keychain, *paths)`

**Description:**
Load certificates and maybe keys from a number of files. Has the end goal
of returning a CFArray containing one SecIdentityRef, and then zero or more
SecCertificateRef objects, suitable for use as a client certificate trust
chain.

**Line:** 302

---

### `def _build_tls_unknown_ca_alert(version)`

**Description:**
Builds a TLS alert record for an unknown CA.

**Line:** 386

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.contrib.securetransport
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py`

**Imports:**
- __future__.absolute_import
- _securetransport.bindings.CoreFoundation
- _securetransport.bindings.Security
- _securetransport.bindings.SecurityConst
- _securetransport.low_level._assert_no_error
- _securetransport.low_level._build_tls_unknown_ca_alert
- _securetransport.low_level._cert_array_from_pem
- _securetransport.low_level._create_cfstring_array
- _securetransport.low_level._load_client_cert_chain
- _securetransport.low_level._temporary_keychain
- contextlib
- ctypes
- errno
- os.path
- packages.backports.makefile.backport_makefile
- packages.six
- shutil
- socket
- socket._fileobject
- ssl
- struct
- threading
- util.ssl_.PROTOCOL_TLS_CLIENT
- weakref

**Functions:**

### `def inject_into_urllib3()`

**Description:**
Monkey-patch urllib3 with SecureTransport-backed SSL-support.

**Line:** 188

---

### `def extract_from_urllib3()`

**Description:**
Undo monkey-patching by :func:`inject_into_urllib3`.

**Line:** 200

---

### `def _read_callback(connection_id, data_buffer, data_length_pointer)`

**Description:**
SecureTransport read callback. This is called by ST to request that data
be returned from the socket.

**Line:** 212

---

### `def _write_callback(connection_id, data_buffer, data_length_pointer)`

**Description:**
SecureTransport write callback. This is called by ST to request that data
actually be sent on the network.

**Line:** 267

---

### `def makefile(self, mode, bufsize = -1)`

**Line:** 768

---

### `def makefile(self, mode = 'r', buffering = None, *args, **kwargs)`

**Line:** 774

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.contribopenssl
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py`

**Imports:**
- OpenSSL.SSL
- OpenSSL.crypto
- OpenSSL.crypto.X509
- __future__.absolute_import
- cryptography.hazmat.backends.openssl.backend
- cryptography.x509
- cryptography.x509.UnsupportedExtension
- cryptography.x509.extensions.Extensions
- io.BytesIO
- logging
- packages.backports.makefile.backport_makefile
- packages.six
- pip._vendor.idna
- socket._fileobject
- socket.error
- socket.timeout
- ssl
- sys
- util.ssl_.PROTOCOL_TLS_CLIENT
- warnings

**Functions:**

### `def inject_into_urllib3()`

**Description:**
Monkey-patch urllib3 with PyOpenSSL-backed SSL-support.

**Line:** 130

---

### `def extract_from_urllib3()`

**Description:**
Undo monkey-patching by :func:`inject_into_urllib3`.

**Line:** 143

---

### `def _validate_dependencies_met()`

**Description:**
Verifies that PyOpenSSL's package-level dependencies have been met.
Throws `ImportError` if they are not met.

**Line:** 154

---

### `def _dnsname_to_stdlib(name)`

**Description:**
Converts a dNSName SubjectAlternativeName field to the form used by the
standard library on the given Python version.

Cryptography produces a dNSName as a unicode string that was idna-decoded
from ASCII bytes. We need to idna-encode that string to get it back, and
then on Python 3 we also need to convert to unicode via UTF-8 (the stdlib
uses PyUnicode_FromStringAndSize on it, which decodes via UTF-8).

If the name cannot be idna-encoded then we return None signalling that
the name given should be skipped.

**Line:** 180

---

### `def get_subj_alt_name(peer_cert)`

**Description:**
Given an PyOpenSSL certificate, provides all the subject alternative names.

**Line:** 223

---

### `def makefile(self, mode, bufsize = -1)`

**Line:** 413

---

### `def _verify_callback(cnx, x509, err_no, err_depth, return_code)`

**Line:** 517

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.fields
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/fields.py`

**Imports:**
- __future__.absolute_import
- email.utils
- mimetypes
- packages.six
- re

**Functions:**

### `def guess_content_type(filename, default = 'application/octet-stream')`

**Description:**
Guess the "Content-Type" of a file.

:param filename:
The filename to guess the "Content-Type" of using :mod:`mimetypes`.
:param default:
If no "Content-Type" can be guessed, default to `default`.

**Line:** 10

---

### `def format_header_param_rfc2231(name, value)`

**Description:**
Helper function to format and quote a single header parameter using the
strategy defined in RFC 2231.

Particularly useful for header parameters which might contain
non-ASCII values, like file names. This follows
`RFC 2388 Section 4.4 <https://tools.ietf.org/html/rfc2388#section-4.4>`_.

:param name:
The name of the parameter, a string expected to be ASCII only.
:param value:
The value of the parameter, provided as ``bytes`` or `str``.
:ret:
An RFC-2231-formatted unicode string.

**Line:** 24

---

### `def _replace_multiple(value, needles_and_replacements)`

**Line:** 82

---

### `def format_header_param_html5(name, value)`

**Description:**
Helper function to format and quote a single header parameter using the
HTML5 strategy.

Particularly useful for header parameters which might contain
non-ASCII values, like file names. This follows the `HTML5 Working Draft
Section 4.10.22.7`_ and matches the behavior of curl and modern browsers.

.. _HTML5 Working Draft Section 4.10.22.7:
https://w3c.github.io/html/sec-forms.html#multipart-form-data

:param name:
The name of the parameter, a string expected to be ASCII only.
:param value:
The value of the parameter, provided as ``bytes`` or `str``.
:ret:
A unicode string, stripped of troublesome characters.

**Line:** 95

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.filepost
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/filepost.py`

**Imports:**
- __future__.absolute_import
- binascii
- codecs
- fields.RequestField
- io.BytesIO
- os
- packages.six
- packages.six.b

**Functions:**

### `def choose_boundary()`

**Description:**
Our embarrassingly-simple replacement for mimetools.choose_boundary.

**Line:** 15

---

### `def iter_field_objects(fields)`

**Description:**
Iterate over fields.

Supports list of (k, v) tuples and dicts, and lists of
:class:`~urllib3.fields.RequestField`.

**Line:** 25

---

### `def iter_fields(fields)`

**Description:**
.. deprecated:: 1.6

Iterate over fields.

The addition of :class:`~urllib3.fields.RequestField` makes this function
obsolete. Instead, use :func:`iter_field_objects`, which returns
:class:`~urllib3.fields.RequestField` objects.

Supports list of (k, v) tuples and dicts.

**Line:** 45

---

### `def encode_multipart_formdata(fields, boundary = None)`

**Description:**
Encode a dictionary of ``fields`` using the multipart/form-data MIME format.

:param fields:
Dictionary of fields or list of (key, :class:`~urllib3.fields.RequestField`).

:param boundary:
If not specified, then a random boundary will be generated using
:func:`urllib3.filepost.choose_boundary`.

**Line:** 63

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.packages.backports.makefile
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/packages/backports/makefile.py`

**Imports:**
- io
- socket.SocketIO

**Functions:**

### `def backport_makefile(self, mode = 'r', buffering = None, encoding = None, errors = None, newline = None)`

**Description:**
Backport of ``socket.makefile`` from Python 3.5.

**Line:** 13

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.packages.six
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/packages/six.py`

**Imports:**
- StringIO
- __future__.absolute_import
- functools
- importlib.util.spec_from_loader
- io
- itertools
- operator
- struct
- sys
- types

**Functions:**

### `def _add_doc(func, doc)`

**Description:**
Add documentation to a function.

**Line:** 80

---

### `def _import_module(name)`

**Description:**
Import module, returning the module after the last dot.

**Line:** 85

---

### `def add_move(move)`

**Description:**
Add an item to six.moves.

**Line:** 544

---

### `def remove_move(name)`

**Description:**
Remove item from six.moves.

**Line:** 549

---

### `def advance_iterator(it)`

**Line:** 582

---

### `def callable(obj)`

**Line:** 593

---

### `def get_unbound_function(unbound)`

**Line:** 599

---

### `def create_unbound_method(func, cls)`

**Line:** 604

---

### `def get_unbound_function(unbound)`

**Line:** 610

---

### `def create_bound_method(func, obj)`

**Line:** 613

---

### `def create_unbound_method(func, cls)`

**Line:** 616

---

### `def iterkeys(d, **kw)`

**Line:** 639

---

### `def itervalues(d, **kw)`

**Line:** 642

---

### `def iteritems(d, **kw)`

**Line:** 645

---

### `def iterlists(d, **kw)`

**Line:** 648

---

### `def iterkeys(d, **kw)`

**Line:** 658

---

### `def itervalues(d, **kw)`

**Line:** 661

---

### `def iteritems(d, **kw)`

**Line:** 664

---

### `def iterlists(d, **kw)`

**Line:** 667

---

### `def b(s)`

**Line:** 686

---

### `def u(s)`

**Line:** 689

---

### `def b(s)`

**Line:** 716

---

### `def u(s)`

**Line:** 721

---

### `def byte2int(bs)`

**Line:** 727

---

### `def indexbytes(buf, i)`

**Line:** 730

---

### `def assertCountEqual(self, *args, **kwargs)`

**Line:** 745

---

### `def assertRaisesRegex(self, *args, **kwargs)`

**Line:** 749

---

### `def assertRegex(self, *args, **kwargs)`

**Line:** 753

---

### `def assertNotRegex(self, *args, **kwargs)`

**Line:** 757

---

### `def reraise(tp, value, tb = None)`

**Line:** 764

---

### `def exec_(_code_, _globs_ = None, _locs_ = None)`

**Description:**
Execute code in a namespace.

**Line:** 777

---

### `def raise_from(value, from_value)`

**Line:** 810

---

### `def print_(*args, **kwargs)`

**Description:**
The new-style print function for Python 2.4 and 2.5.

**Line:** 817

---

### `def print_(*args, **kwargs)`

**Line:** 878

---

### `def _update_wrapper(wrapper, wrapped, assigned = functools.WRAPPER_ASSIGNMENTS, updated = functools.WRAPPER_UPDATES)`

**Line:** 894

---

### `def wraps(wrapped, assigned = functools.WRAPPER_ASSIGNMENTS, updated = functools.WRAPPER_UPDATES)`

**Line:** 914

---

### `def with_metaclass(meta, *bases)`

**Description:**
Create a base class with a metaclass.

**Line:** 929

---

### `def add_metaclass(metaclass)`

**Description:**
Class decorator for creating a class with a metaclass.

**Line:** 953

---

### `def ensure_binary(s, encoding = 'utf-8', errors = 'strict')`

**Description:**
Coerce **s** to six.binary_type.

For Python 2:
- `unicode` -> encoded to `str`
- `str` -> `str`

For Python 3:
- `str` -> encoded to `bytes`
- `bytes` -> `bytes`

**Line:** 973

---

### `def ensure_str(s, encoding = 'utf-8', errors = 'strict')`

**Description:**
Coerce *s* to `str`.

For Python 2:
- `unicode` -> encoded to `str`
- `str` -> `str`

For Python 3:
- `str` -> `str`
- `bytes` -> decoded to `str`

**Line:** 991

---

### `def ensure_text(s, encoding = 'utf-8', errors = 'strict')`

**Description:**
Coerce *s* to six.text_type.

For Python 2:
- `unicode` -> `unicode`
- `str` -> `unicode`

For Python 3:
- `str` -> `str`
- `bytes` -> decoded to `str`

**Line:** 1014

---

### `def python_2_unicode_compatible(klass)`

**Description:**
A class decorator that defines __unicode__ and __str__ methods under Python 2.
Under Python 3 it does nothing.

To support Python 2 and 3 with a single code base, define a __str__ method
returning text and apply this decorator to the class.

**Line:** 1033

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.poolmanager
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/poolmanager.py`

**Imports:**
- __future__.absolute_import
- _collections.HTTPHeaderDict
- _collections.RecentlyUsedContainer
- collections
- connectionpool.HTTPConnectionPool
- connectionpool.HTTPSConnectionPool
- connectionpool.port_by_scheme
- exceptions.LocationValueError
- exceptions.MaxRetryError
- exceptions.ProxySchemeUnknown
- exceptions.ProxySchemeUnsupported
- exceptions.URLSchemeUnknown
- functools
- logging
- packages.six
- packages.six.moves.urllib.parse.urljoin
- request.RequestMethods
- util.proxy.connection_requires_http_tunnel
- util.retry.Retry
- util.url.parse_url

**Functions:**

### `def _default_key_normalizer(key_class, request_context)`

**Description:**
Create a pool key out of a request context dictionary.

According to RFC 3986, both the scheme and host are case-insensitive.
Therefore, this function normalizes both before constructing the pool
key for an HTTPS request. If you wish to change this behaviour, provide
alternate callables to ``key_fn_by_scheme``.

:param key_class:
The class to use when constructing the key. This should be a namedtuple
with the ``scheme`` and ``host`` keys at a minimum.
:type  key_class: namedtuple
:param request_context:
A dictionary-like object that contain the context for a request.
:type  request_context: dict

:return: A namedtuple that can be used as a connection pool key.
:rtype:  PoolKey

**Line:** 79

---

### `def proxy_from_url(url, **kw)`

**Line:** 539

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.response
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py`

**Imports:**
- __future__.absolute_import
- _collections.HTTPHeaderDict
- connection.BaseSSLError
- connection.HTTPException
- contextlib.contextmanager
- exceptions.BodyNotHttplibCompatible
- exceptions.DecodeError
- exceptions.HTTPError
- exceptions.IncompleteRead
- exceptions.InvalidChunkLength
- exceptions.InvalidHeader
- exceptions.ProtocolError
- exceptions.ReadTimeoutError
- exceptions.ResponseNotChunked
- exceptions.SSLError
- io
- logging
- packages.six
- socket.error
- socket.timeout
- sys
- util.response.is_fp_closed
- util.response.is_response_to_head
- warnings
- zlib

**Functions:**

### `def _get_decoder(mode)`

**Line:** 144

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.util.connection
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/util/connection.py`

**Imports:**
- __future__.absolute_import
- contrib._appengine_environ
- exceptions.LocationParseError
- packages.six
- socket
- wait.NoWayToWaitForSocketError
- wait.wait_for_read

**Functions:**

### `def is_connection_dropped(conn)`

**Description:**
Returns True if the connection is dropped and should be closed.

:param conn:
:class:`http.client.HTTPConnection` object.

Note: For platforms like AppEngine, this will always return ``False`` to
let the platform handle connection recycling transparently for us.

**Line:** 11

---

### `def create_connection(address, timeout = socket._GLOBAL_DEFAULT_TIMEOUT, source_address = None, socket_options = None)`

**Description:**
Connect to *address* and return the socket object.

Convenience function.  Connect to *address* (a 2-tuple ``(host,
port)``) and return the socket object.  Passing the optional
*timeout* parameter will set the timeout on the socket instance
before attempting to connect.  If no *timeout* is supplied, the
global default timeout setting returned by :func:`socket.getdefaulttimeout`
is used.  If *source_address* is set it must be a tuple of (host, port)
for the socket to bind as a source address before making the connection.
An host of '' or port 0 tells the OS to use the default.

**Line:** 37

---

### `def _set_socket_options(sock, options)`

**Line:** 100

---

### `def allowed_gai_family()`

**Description:**
This function is designed to work in the context of
getaddrinfo, where family=socket.AF_UNSPEC is the default and
will perform a DNS search for both IPv6 and IPv4 records.

**Line:** 108

---

### `def _has_ipv6(host)`

**Description:**
Returns True if the system can bind an IPv6 address.

**Line:** 119

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.util.proxy
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/util/proxy.py`

**Imports:**
- ssl_.create_urllib3_context
- ssl_.resolve_cert_reqs
- ssl_.resolve_ssl_version

**Functions:**

### `def connection_requires_http_tunnel(proxy_url = None, proxy_config = None, destination_scheme = None)`

**Description:**
Returns True if the connection requires an HTTP CONNECT through the proxy.

:param URL proxy_url:
URL of the proxy.
:param ProxyConfig proxy_config:
Proxy configuration from poolmanager.py
:param str destination_scheme:
The scheme of the destination. (i.e https, http, etc)

**Line:** 4

---

### `def create_proxy_ssl_context(ssl_version, cert_reqs, ca_certs = None, ca_cert_dir = None, ca_cert_data = None)`

**Description:**
Generates a default proxy ssl context if one hasn't been provided by the
user.

**Line:** 37

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.util.request
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/util/request.py`

**Imports:**
- __future__.absolute_import
- base64.b64encode
- exceptions.UnrewindableBodyError
- packages.six.b
- packages.six.integer_types

**Functions:**

### `def make_headers(keep_alive = None, accept_encoding = None, user_agent = None, basic_auth = None, proxy_basic_auth = None, disable_cache = None)`

**Description:**
Shortcuts for generating request headers.

:param keep_alive:
If ``True``, adds 'connection: keep-alive' header.

:param accept_encoding:
Can be a boolean, list, or string.
``True`` translates to 'gzip,deflate'.
List will get joined by comma.
String will be used as provided.

:param user_agent:
String representing the user-agent you want, such as
"python-urllib3/0.6"

:param basic_auth:
Colon-separated username:password string for 'authorization: basic ...'
auth header.

:param proxy_basic_auth:
Colon-separated username:password string for 'proxy-authorization: basic ...'
auth header.

:param disable_cache:
If ``True``, adds 'cache-control: no-cache' header.

Example::

>>> make_headers(keep_alive=True, user_agent="Batman/1.0")
{'connection': 'keep-alive', 'user-agent': 'Batman/1.0'}
>>> make_headers(accept_encoding=True)
{'accept-encoding': 'gzip,deflate'}

**Line:** 20

---

### `def set_file_position(body, pos)`

**Description:**
If a position is provided, move file to that point.
Otherwise, we'll attempt to record a position for future use.

**Line:** 92

---

### `def rewind_body(body, body_pos)`

**Description:**
Attempt to rewind body to a certain position.
Primarily used for request redirects and retries.

:param body:
File-like object that supports seek.

:param int pos:
Position to seek to in file.

**Line:** 110

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.util.response
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/util/response.py`

**Imports:**
- __future__.absolute_import
- email.errors.MultipartInvariantViolationDefect
- email.errors.StartBoundaryNotFoundDefect
- exceptions.HeaderParsingError
- packages.six.moves.http_client

**Functions:**

### `def is_fp_closed(obj)`

**Description:**
Checks whether a given file-like object is closed.

:param obj:
The file-like object to check.

**Line:** 9

---

### `def assert_header_parsing(headers)`

**Description:**
Asserts whether all headers have been successfully parsed.
Extracts encountered errors from the result of parsing headers.

Only works on Python 3.

:param http.client.HTTPMessage headers: Headers to verify.

:raises urllib3.exceptions.HeaderParsingError:
If parsing errors are found.

**Line:** 40

---

### `def is_response_to_head(response)`

**Description:**
Checks whether the request of a response has been a HEAD-request.
Handles the quirks of AppEngine.

:param http.client.HTTPResponse response:
Response to check if the originating request
used 'HEAD' as a method.

**Line:** 94

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.util.ssl_
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py`

**Imports:**
- __future__.absolute_import
- binascii.hexlify
- binascii.unhexlify
- exceptions.InsecurePlatformWarning
- exceptions.ProxySchemeUnsupported
- exceptions.SNIMissingWarning
- exceptions.SSLError
- hashlib
- hmac
- os
- packages.six
- ssl
- ssl.CERT_REQUIRED
- ssl.HAS_SNI
- ssl.OP_NO_COMPRESSION
- ssl.OP_NO_SSLv2
- ssl.OP_NO_SSLv3
- ssl.OP_NO_TICKET
- ssl.PROTOCOL_SSLv23
- ssl.PROTOCOL_TLS
- ssl.PROTOCOL_TLS_CLIENT
- ssl.SSLContext
- ssl.wrap_socket
- ssltransport.SSLTransport
- sys
- url.BRACELESS_IPV6_ADDRZ_RE
- url.IPV4_RE
- warnings

**Functions:**

### `def _const_compare_digest_backport(a, b)`

**Description:**
Compare two digests of equal length in constant time.

The digests must be of type str/bytes.
Returns True if the digests match, and False otherwise.

**Line:** 33

---

### `def assert_fingerprint(cert, fingerprint)`

**Description:**
Checks if given fingerprint matches the supplied certificate.

:param cert:
Certificate as bytes object.
:param fingerprint:
Fingerprint as string of hexdigits, can be interspersed by colons.

**Line:** 185

---

### `def resolve_cert_reqs(candidate)`

**Description:**
Resolves the argument to a numeric constant, which can be passed to
the wrap_socket function/method from the ssl module.
Defaults to :data:`ssl.CERT_REQUIRED`.
If given a string it is assumed to be the name of the constant in the
:mod:`ssl` module or its abbreviation.
(So you can specify `REQUIRED` instead of `CERT_REQUIRED`.
If it's neither `None` nor a string we assume it is already the numeric
constant which can directly be passed to wrap_socket.

**Line:** 220

---

### `def resolve_ssl_version(candidate)`

**Description:**
like resolve_cert_reqs

**Line:** 243

---

### `def create_urllib3_context(ssl_version = None, cert_reqs = None, options = None, ciphers = None)`

**Description:**
All arguments have the same meaning as ``ssl_wrap_socket``.

By default, this function does a lot of the same work that
``ssl.create_default_context`` does on Python 3.4+. It:

- Disables SSLv2, SSLv3, and compression
- Sets a restricted set of server ciphers

If you wish to enable SSLv3, you can do::

from pip._vendor.urllib3.util import ssl_
context = ssl_.create_urllib3_context()
context.options &= ~ssl_.OP_NO_SSLv3

You can do the same to enable compression (substituting ``COMPRESSION``
for ``SSLv3`` in the last line above).

:param ssl_version:
The desired protocol version to use. This will default to
PROTOCOL_SSLv23 which will negotiate the highest protocol that both
the server and your installation of OpenSSL support.
:param cert_reqs:
Whether to require the certificate verification. This defaults to
``ssl.CERT_REQUIRED``.
:param options:
Specific OpenSSL options. These default to ``ssl.OP_NO_SSLv2``,
``ssl.OP_NO_SSLv3``, ``ssl.OP_NO_COMPRESSION``, and ``ssl.OP_NO_TICKET``.
:param ciphers:
Which cipher suites to allow the server to select.
:returns:
Constructed SSLContext object with specified options
:rtype: SSLContext

**Line:** 259

---

### `def ssl_wrap_socket(sock, keyfile = None, certfile = None, cert_reqs = None, ca_certs = None, server_hostname = None, ssl_version = None, ciphers = None, ssl_context = None, ca_cert_dir = None, key_password = None, ca_cert_data = None, tls_in_tls = False)`

**Description:**
All arguments except for server_hostname, ssl_context, and ca_cert_dir have
the same meaning as they do when using :func:`ssl.wrap_socket`.

:param server_hostname:
When SNI is supported, the expected hostname of the certificate
:param ssl_context:
A pre-made :class:`SSLContext` object. If none is provided, one will
be created using :func:`create_urllib3_context`.
:param ciphers:
A string of ciphers we wish the client to support.
:param ca_cert_dir:
A directory containing CA certificates in multiple separate files, as
supported by OpenSSL's -CApath flag or the capath argument to
SSLContext.load_verify_locations().
:param key_password:
Optional password if the keyfile is encrypted.
:param ca_cert_data:
Optional string containing CA certificates in PEM format suitable for
passing as the cadata parameter to SSLContext.load_verify_locations()
:param tls_in_tls:
Use SSLTransport to wrap the existing socket.

**Line:** 364

---

### `def is_ipaddress(hostname)`

**Description:**
Detects whether the hostname given is an IPv4 or IPv6 address.
Also detects IPv6 addresses with Zone IDs.

:param str hostname: Hostname to examine.
:return: True if the hostname is an IP address, False otherwise.

**Line:** 466

---

### `def _is_key_file_encrypted(key_file)`

**Description:**
Detects if a key file is encrypted or not.

**Line:** 479

---

### `def _ssl_wrap_socket_impl(sock, ssl_context, tls_in_tls, server_hostname = None)`

**Line:** 490

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.util.ssl_match_hostname
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_match_hostname.py`

**Imports:**
- ipaddress
- re
- sys

**Functions:**

### `def _dnsname_match(dn, hostname, max_wildcards = 1)`

**Description:**
Matching according to RFC 6125, section 6.4.3

http://tools.ietf.org/html/rfc6125#section-6.4.3

**Line:** 25

---

### `def _to_unicode(obj)`

**Line:** 79

---

### `def _ipaddress_match(ipname, host_ip)`

**Description:**
Exact matching of IP addresses.

RFC 6125 explicitly doesn't define an algorithm for this
(section 1.7.2 - "Out of Scope").

**Line:** 86

---

### `def match_hostname(cert, hostname)`

**Description:**
Verify that *cert* (in decoded format as returned by
SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
rules are followed, but IP addresses are not accepted for *hostname*.

CertificateError is raised on failure. On success, the function
returns nothing.

**Line:** 98

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.util.url
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/util/url.py`

**Imports:**
- __future__.absolute_import
- collections.namedtuple
- exceptions.LocationParseError
- packages.six
- pip._vendor.idna
- re

**Functions:**

### `def split_first(s, delims)`

**Description:**
.. deprecated:: 1.25

Given a string and an iterable of delimiters, split on the first found
delimiter. Return two split parts and the matched delimiter.

If not found, then the first part is the full input string.

Example::

>>> split_first('foo/bar?baz', '?/=')
('foo', 'bar?baz', '/')
>>> split_first('foo/bar?baz', '123')
('foo/bar?baz', '', None)

Scales linearly with number of delims. Not ideal for large number of delims.

**Line:** 175

---

### `def _encode_invalid_chars(component, allowed_chars, encoding = 'utf-8')`

**Description:**
Percent-encodes a URI component without reapplying
onto an already percent-encoded component.

**Line:** 210

---

### `def _remove_path_dot_segments(path)`

**Line:** 244

---

### `def _normalize_host(host, scheme)`

**Line:** 274

---

### `def _idna_encode(name)`

**Line:** 305

---

### `def _encode_target(target)`

**Description:**
Percent-encodes a request target so that there are no invalid characters

**Line:** 323

---

### `def parse_url(url)`

**Description:**
Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is
performed to parse incomplete urls. Fields not provided will be None.
This parser is RFC 3986 and RFC 6874 compliant.

The parser logic and helper functions are based heavily on
work done in the ``rfc3986`` module.

:param str url: URL to parse into a :class:`.Url` namedtuple.

Partly backwards-compatible with :mod:`urlparse`.

Example::

>>> parse_url('http://google.com/mail/')
Url(scheme='http', host='google.com', port=None, path='/mail/', ...)
>>> parse_url('google.com:80')
Url(scheme=None, host='google.com', port=80, path=None, ...)
>>> parse_url('/foo?bar')
Url(scheme=None, host=None, port=None, path='/foo', query='bar', ...)

**Line:** 333

---

### `def get_host(url)`

**Description:**
Deprecated. Use :func:`parse_url` instead.

**Line:** 430

---


## Module: venv2.libthon3.12.site-packages.pip._vendor.urllib3.util.wait
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/urllib3/util/wait.py`

**Imports:**
- errno
- functools.partial
- select
- sys
- time.monotonic
- time.time

**Functions:**

### `def _retry_on_intr(fn, timeout)`

**Line:** 42

---

### `def _retry_on_intr(fn, timeout)`

**Line:** 47

---

### `def select_wait_for_socket(sock, read = False, write = False, timeout = None)`

**Line:** 70

---

### `def poll_wait_for_socket(sock, read = False, write = False, timeout = None)`

**Line:** 89

---

### `def null_wait_for_socket(*args, **kwargs)`

**Line:** 109

---

### `def _have_working_poll()`

**Line:** 113

---

### `def wait_for_socket(*args, **kwargs)`

**Line:** 126

---

### `def wait_for_read(sock, timeout = None)`

**Description:**
Waits for reading to be available on a given socket.
Returns True if the socket is readable, or False if the timeout expired.

**Line:** 141

---

### `def wait_for_write(sock, timeout = None)`

**Description:**
Waits for writing to be available on a given socket.
Returns True if the socket is readable, or False if the timeout expired.

**Line:** 148

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/__init__.py`

**Imports:**
- io.BytesIO
- io.StringIO
- pip._vendor.pygments.formatter.Formatter
- pip._vendor.pygments.lexer.RegexLexer

**Functions:**

### `def lex(code, lexer)`

**Description:**
Lex `code` with the `lexer` (must be a `Lexer` instance)
and return an iterable of tokens. Currently, this only calls
`lexer.get_tokens()`.

**Line:** 35

---

### `def format(tokens, formatter, outfile = None)`

**Description:**
Format ``tokens`` (an iterable of tokens) with the formatter ``formatter``
(a `Formatter` instance).

If ``outfile`` is given and a valid file object (an object with a
``write`` method), the result will be written to it, otherwise it
is returned as a string.

**Line:** 52

---

### `def highlight(code, lexer, formatter, outfile = None)`

**Description:**
This is the most high-level highlighting function. It combines `lex` and
`format` in one function.

**Line:** 77

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.console
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/console.py`

**Functions:**

### `def reset_color()`

**Line:** 40

---

### `def colorize(color_key, text)`

**Line:** 44

---

### `def ansiformat(attr, text)`

**Description:**
Format ``text`` with a color and/or some attributes::

color       normal color
*color*     bold color
_color_     underlined color
+color+     blinking color

**Line:** 48

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.filter
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/filter.py`

**Functions:**

### `def apply_filters(stream, filters, lexer = None)`

**Description:**
Use this method to apply an iterable of filters to
a stream. If lexer is given it's forwarded to the
filter, otherwise the filter receives `None`.

**Line:** 12

---

### `def simplefilter(f)`

**Description:**
Decorator that converts a function into a filter::

@simplefilter
def lowercase(self, lexer, stream, options):
for ttype, value in stream:
yield ttype, value.lower()

**Line:** 25

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.filters.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py`

**Imports:**
- pip._vendor.pygments.filter.Filter
- pip._vendor.pygments.plugin.find_plugin_filters
- pip._vendor.pygments.token.Comment
- pip._vendor.pygments.token.Error
- pip._vendor.pygments.token.Keyword
- pip._vendor.pygments.token.Name
- pip._vendor.pygments.token.String
- pip._vendor.pygments.token.Whitespace
- pip._vendor.pygments.token.string_to_tokentype
- pip._vendor.pygments.util.ClassNotFound
- pip._vendor.pygments.util.OptionError
- pip._vendor.pygments.util.get_bool_opt
- pip._vendor.pygments.util.get_choice_opt
- pip._vendor.pygments.util.get_int_opt
- pip._vendor.pygments.util.get_list_opt
- re

**Functions:**

### `def find_filter_class(filtername)`

**Description:**
Lookup a filter by name. Return None if not found.

**Line:** 22

---

### `def get_filter_by_name(filtername, **options)`

**Description:**
Return an instantiated filter.

Options are passed to the filter initializer if wanted.
Raise a ClassNotFound if not found.

**Line:** 32

---

### `def get_all_filters()`

**Description:**
Return a generator of all filter names.

**Line:** 45

---

### `def _replace_special(ttype, value, regex, specialttype, replacefunc = lambda x: x)`

**Line:** 52

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.formatter
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/formatter.py`

**Imports:**
- codecs
- pip._vendor.pygments.styles.get_style_by_name
- pip._vendor.pygments.util.get_bool_opt

**Functions:**

### `def _lookup_style(style)`

**Line:** 19

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.formatters.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/formatters/__init__.py`

**Imports:**
- fnmatch
- os.path.basename
- pip._vendor.pygments.formatters._mapping.FORMATTERS
- pip._vendor.pygments.plugin.find_plugin_formatters
- pip._vendor.pygments.util.ClassNotFound
- re
- sys
- types

**Functions:**

### `def _fn_matches(fn, glob)`

**Description:**
Return whether the supplied file name fn matches pattern filename.

**Line:** 28

---

### `def _load_formatters(module_name)`

**Description:**
Load a formatter (and all others in the module too).

**Line:** 36

---

### `def get_all_formatters()`

**Description:**
Return a generator for all formatter classes.

**Line:** 44

---

### `def find_formatter_class(alias)`

**Description:**
Lookup a formatter by alias.

Returns None if not found.

**Line:** 55

---

### `def get_formatter_by_name(_alias, **options)`

**Description:**
Return an instance of a :class:`.Formatter` subclass that has `alias` in its
aliases list. The formatter is given the `options` at its instantiation.

Will raise :exc:`pygments.util.ClassNotFound` if no formatter with that
alias is found.

**Line:** 70

---

### `def load_formatter_from_file(filename, formattername = 'CustomFormatter', **options)`

**Description:**
Return a `Formatter` subclass instance loaded from the provided file, relative
to the current directory.

The file is expected to contain a Formatter class named ``formattername``
(by default, CustomFormatter). Users should be very careful with the input, because
this method is equivalent to running ``eval()`` on the input file. The formatter is
given the `options` at its instantiation.

:exc:`pygments.util.ClassNotFound` is raised if there are any errors loading
the formatter.

.. versionadded:: 2.2

**Line:** 84

---

### `def get_formatter_for_filename(fn, **options)`

**Description:**
Return a :class:`.Formatter` subclass instance that has a filename pattern
matching `fn`. The formatter is given the `options` at its instantiation.

Will raise :exc:`pygments.util.ClassNotFound` if no formatter for that filename
is found.

**Line:** 118

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.lexer
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py`

**Imports:**
- pip._vendor.pygments.filter.Filter
- pip._vendor.pygments.filter.apply_filters
- pip._vendor.pygments.filters.get_filter_by_name
- pip._vendor.pygments.regexopt.regex_opt
- pip._vendor.pygments.token.Error
- pip._vendor.pygments.token.Other
- pip._vendor.pygments.token.Text
- pip._vendor.pygments.token.Whitespace
- pip._vendor.pygments.token._TokenType
- pip._vendor.pygments.util.Future
- pip._vendor.pygments.util.get_bool_opt
- pip._vendor.pygments.util.get_int_opt
- pip._vendor.pygments.util.get_list_opt
- pip._vendor.pygments.util.guess_decode
- pip._vendor.pygments.util.make_analysator
- re
- sys
- time

**Functions:**

### `def bygroups(*args)`

**Description:**
Callback that yields multiple actions for each group in the match.

**Line:** 387

---

### `def using(_other, **kwargs)`

**Description:**
Callback that processes the match with a different lexer.

The keyword arguments are forwarded to the lexer, except `state` which
is handled separately.

`state` specifies the state that the new lexer will start in, and can
be an enumerable such as ('root', 'inline', 'string') or a simple
string which is assumed to be on top of the root state.

Note: For that to work, `_other` must not be an `ExtendedRegexLexer`.

**Line:** 422

---

### `def do_insertions(insertions, tokens)`

**Description:**
Helper for lexers which must combine the results of several
sublexers.

``insertions`` is a list of ``(index, itokens)`` pairs.
Each ``itokens`` iterable should be inserted at position
``index`` into the token stream given by the ``tokens``
argument.

The result is a combined token stream.

TODO: clean up the code here.

**Line:** 851

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.lexers.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/__init__.py`

**Imports:**
- fnmatch
- os.path.basename
- pip._vendor.pygments.lexers._mapping.LEXERS
- pip._vendor.pygments.modeline.get_filetype_from_buffer
- pip._vendor.pygments.plugin.find_plugin_lexers
- pip._vendor.pygments.util.ClassNotFound
- pip._vendor.pygments.util.guess_decode
- re
- sys
- types

**Functions:**

### `def _fn_matches(fn, glob)`

**Description:**
Return whether the supplied file name fn matches pattern filename.

**Line:** 35

---

### `def _load_lexers(module_name)`

**Description:**
Load a lexer (and all others in the module too).

**Line:** 43

---

### `def get_all_lexers(plugins = True)`

**Description:**
Return a generator of tuples in the form ``(name, aliases,
filenames, mimetypes)`` of all know lexers.

If *plugins* is true (the default), plugin lexers supplied by entrypoints
are also returned.  Otherwise, only builtin ones are considered.

**Line:** 51

---

### `def find_lexer_class(name)`

**Description:**
Return the `Lexer` subclass that with the *name* attribute as given by
the *name* argument.

**Line:** 65

---

### `def find_lexer_class_by_name(_alias)`

**Description:**
Return the `Lexer` subclass that has `alias` in its aliases list, without
instantiating it.

Like `get_lexer_by_name`, but does not instantiate the class.

Will raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is
found.

.. versionadded:: 2.2

**Line:** 83

---

### `def get_lexer_by_name(_alias, **options)`

**Description:**
Return an instance of a `Lexer` subclass that has `alias` in its
aliases list. The lexer is given the `options` at its
instantiation.

Will raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is
found.

**Line:** 110

---

### `def load_lexer_from_file(filename, lexername = 'CustomLexer', **options)`

**Description:**
Load a lexer from a file.

This method expects a file located relative to the current working
directory, which contains a Lexer class. By default, it expects the
Lexer to be name CustomLexer; you can specify your own class name
as the second argument to this function.

Users should be very careful with the input, because this method
is equivalent to running eval on the input file.

Raises ClassNotFound if there are any problems importing the Lexer.

.. versionadded:: 2.2

**Line:** 135

---

### `def find_lexer_class_for_filename(_fn, code = None)`

**Description:**
Get a lexer for a filename.

If multiple lexers match the filename pattern, use ``analyse_text()`` to
figure out which one is more appropriate.

Returns None if not found.

**Line:** 169

---

### `def get_lexer_for_filename(_fn, code = None, **options)`

**Description:**
Get a lexer for a filename.

Return a `Lexer` subclass instance that has a filename pattern
matching `fn`. The lexer is given the `options` at its
instantiation.

Raise :exc:`pygments.util.ClassNotFound` if no lexer for that filename
is found.

If multiple lexers match the filename pattern, use their ``analyse_text()``
methods to figure out which one is more appropriate.

**Line:** 212

---

### `def get_lexer_for_mimetype(_mime, **options)`

**Description:**
Return a `Lexer` subclass instance that has `mime` in its mimetype
list. The lexer is given the `options` at its instantiation.

Will raise :exc:`pygments.util.ClassNotFound` if not lexer for that mimetype
is found.

**Line:** 231

---

### `def _iter_lexerclasses(plugins = True)`

**Description:**
Return an iterator over all lexer classes.

**Line:** 250

---

### `def guess_lexer_for_filename(_fn, _text, **options)`

**Description:**
As :func:`guess_lexer()`, but only lexers which have a pattern in `filenames`
or `alias_filenames` that matches `filename` are taken into consideration.

:exc:`pygments.util.ClassNotFound` is raised if no lexer thinks it can
handle the content.

**Line:** 261

---

### `def guess_lexer(_text, **options)`

**Description:**
Return a `Lexer` subclass instance that's guessed from the text in
`text`. For that, the :meth:`.analyse_text()` method of every known lexer
class is called with the text as argument, and the lexer which returned the
highest value will be instantiated and returned.

:exc:`pygments.util.ClassNotFound` is raised if no lexer thinks it can
handle the content.

**Line:** 304

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.modeline
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/modeline.py`

**Imports:**
- re

**Functions:**

### `def get_filetype_from_line(l)`

**Line:** 22

---

### `def get_filetype_from_buffer(buf, max_lines = 5)`

**Description:**
Scan the buffer for modelines and return filetype if one is found.

**Line:** 28

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.plugin
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/plugin.py`

**Imports:**
- importlib.metadata.entry_points

**Functions:**

### `def iter_entry_points(group_name)`

**Line:** 43

---

### `def find_plugin_lexers()`

**Line:** 55

---

### `def find_plugin_formatters()`

**Line:** 60

---

### `def find_plugin_styles()`

**Line:** 65

---

### `def find_plugin_filters()`

**Line:** 70

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.regexopt
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/regexopt.py`

**Imports:**
- itertools.groupby
- operator.itemgetter
- os.path.commonprefix
- re
- re.escape

**Functions:**

### `def make_charset(letters)`

**Line:** 22

---

### `def regex_opt_inner(strings, open_paren)`

**Description:**
Return a regex that matches any string in the sorted list of strings.

**Line:** 26

---

### `def regex_opt(strings, prefix = '', suffix = '')`

**Description:**
Return a compiled regex that matches any string in the given list.

The strings to match must be literal strings, not regexes.  They will be
regex-escaped.

*prefix* and *suffix* are pre- and appended to the final regex.

**Line:** 82

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.sphinxext
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/sphinxext.py`

**Imports:**
- docutils.nodes
- docutils.parsers.rst.Directive
- docutils.statemachine.ViewList
- inspect
- pathlib
- pip._vendor.pygments
- pip._vendor.pygments.filters.FILTERS
- pip._vendor.pygments.formatters.FORMATTERS
- pip._vendor.pygments.lexers._mapping.LEXERS
- pip._vendor.pygments.lexers.find_lexer_class
- sphinx.util.nodes.nested_parse_with_titles
- sys

**Functions:**

### `def setup(app)`

**Line:** 246

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.styles.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/styles/__init__.py`

**Imports:**
- pip._vendor.pygments.plugin.find_plugin_styles
- pip._vendor.pygments.styles._mapping.STYLES
- pip._vendor.pygments.util.ClassNotFound

**Functions:**

### `def get_style_by_name(name)`

**Description:**
Return a style class by its short name. The names of the builtin styles
are listed in :data:`pygments.styles.STYLE_MAP`.

Will raise :exc:`pygments.util.ClassNotFound` if no style of that name is
found.

**Line:** 24

---

### `def get_all_styles()`

**Description:**
Return a generator for all styles by name, both builtin and plugin.

**Line:** 56

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.token
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/token.py`

**Functions:**

### `def is_token_subtype(ttype, other)`

**Description:**
Return True if ``ttype`` is a subtype of ``other``.

exists for backwards compatibility. use ``ttype in other`` now.

**Line:** 85

---

### `def string_to_tokentype(s)`

**Description:**
Convert a string into a token type::

>>> string_to_token('String.Double')
Token.Literal.String.Double
>>> string_to_token('Token.Literal.Number')
Token.Literal.Number
>>> string_to_token('')
Token

Tokens that are already tokens are returned unchanged:

>>> string_to_token(String)
Token.Literal.String

**Line:** 94

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.unistring
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/unistring.py`

**Imports:**
- unicodedata

**Functions:**

### `def combine(*args)`

**Line:** 82

---

### `def allexcept(*args)`

**Line:** 86

---

### `def _handle_runs(char_list)`

**Line:** 93

---


## Module: venv2.libthon3.12.site-packages.pip._vendorgments.util
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pygments/util.py`

**Imports:**
- io.TextIOWrapper
- locale
- re

**Functions:**

### `def get_choice_opt(options, optname, allowed, default = None, normcase = False)`

**Description:**
If the key `optname` from the dictionary is not in the sequence
`allowed`, raise an error, otherwise return it.

**Line:** 40

---

### `def get_bool_opt(options, optname, default = None)`

**Description:**
Intuitively, this is `options.get(optname, default)`, but restricted to
Boolean value. The Booleans can be represented as string, in order to accept
Boolean value from the command line arguments. If the key `optname` is
present in the dictionary `options` and is not associated with a Boolean,
raise an `OptionError`. If it is absent, `default` is returned instead.

The valid string values for ``True`` are ``1``, ``yes``, ``true`` and
``on``, the ones for ``False`` are ``0``, ``no``, ``false`` and ``off``
(matched case-insensitively).

**Line:** 53

---

### `def get_int_opt(options, optname, default = None)`

**Description:**
As :func:`get_bool_opt`, but interpret the value as an integer.

**Line:** 82

---

### `def get_list_opt(options, optname, default = None)`

**Description:**
If the key `optname` from the dictionary `options` is a string,
split it at whitespace and return it. If it is already a list
or a tuple, it is returned as a list.

**Line:** 94

---

### `def docstring_headline(obj)`

**Line:** 110

---

### `def make_analysator(f)`

**Description:**
Return a static text analyser function that returns float values.

**Line:** 122

---

### `def shebang_matches(text, regex)`

**Description:**
Check if the given regular expression matches the last part of the
shebang if one exists.

>>> from pygments.util import shebang_matches
>>> shebang_matches('#!/usr/bin/env python', r'python(2\.\d)?')
True
>>> shebang_matches('#!/usr/bin/python2.4', r'python(2\.\d)?')
True
>>> shebang_matches('#!/usr/bin/python-ruby', r'python(2\.\d)?')
False
>>> shebang_matches('#!/usr/bin/python/ruby', r'python(2\.\d)?')
False
>>> shebang_matches('#!/usr/bin/startsomethingwith python',
...                 r'python(2\.\d)?')
True

It also checks for common windows executable file extensions::

>>> shebang_matches('#!C:\\Python2.4\\Python.exe', r'python(2\.\d)?')
True

Parameters (``'-f'`` or ``'--foo'`` are ignored so ``'perl'`` does
the same as ``'perl -e'``)

Note that this method automatically searches the whole string (eg:
the regular expression is wrapped in ``'^$'``)

**Line:** 139

---

### `def doctype_matches(text, regex)`

**Description:**
Check if the doctype matches a regular expression (if present).

Note that this method only checks the first part of a DOCTYPE.
eg: 'html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"'

**Line:** 184

---

### `def html_doctype_matches(text)`

**Description:**
Check if the file looks like it has a html doctype.

**Line:** 197

---

### `def looks_like_xml(text)`

**Description:**
Check if a doctype exists or if we have some tags.

**Line:** 205

---

### `def surrogatepair(c)`

**Description:**
Given a unicode character code with length greater than 16 bits,
return the two 16 bit surrogate pair.

**Line:** 221

---

### `def format_lines(var_name, seq, raw = False, indent_level = 0)`

**Description:**
Formats a sequence of strings for output.

**Line:** 230

---

### `def duplicates_removed(it, already_seen = ())`

**Description:**
Returns a list with duplicates removed from the iterable `it`.

Order is preserved.

**Line:** 249

---

### `def guess_decode(text)`

**Description:**
Decode *text* with guessed encoding.

First try UTF-8; this should fail for non-UTF-8 encodings.
Then try the preferred locale encoding.
Fall back to latin-1, which always works.

**Line:** 275

---

### `def guess_decode_from_terminal(text, term)`

**Description:**
Decode *text* coming from terminal *term*.

First try the terminal encoding, if given.
Then try UTF-8.  Then try the preferred locale encoding.
Fall back to latin-1, which always works.

**Line:** 296

---

### `def terminal_encoding(term)`

**Description:**
Return our best guess of encoding for the given *term*.

**Line:** 313

---


## Module: venv2.libthon3.12.site-packages.pip._vendorproject_hooks._impl
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_impl.py`

**Imports:**
- _in_process._in_proc_script_path
- contextlib.contextmanager
- json
- os
- os.path.abspath
- os.path.join
- subprocess.STDOUT
- subprocess.check_call
- subprocess.check_output
- sys
- tempfile
- typing.Any
- typing.Iterator
- typing.Mapping
- typing.Optional
- typing.Protocol
- typing.Sequence
- typing.TYPE_CHECKING

**Functions:**

### `def write_json(obj: Mapping[(str, Any)], path: str, **kwargs) -> None`

**Line:** 28

---

### `def read_json(path: str) -> Mapping[(str, Any)]`

**Line:** 33

---

### `def default_subprocess_runner(cmd: Sequence[str], cwd: Optional[str] = None, extra_environ: Optional[Mapping[(str, str)]] = None) -> None`

**Description:**
The default method of calling the wrapper subprocess.

This uses :func:`subprocess.check_call` under the hood.

**Line:** 70

---

### `def quiet_subprocess_runner(cmd: Sequence[str], cwd: Optional[str] = None, extra_environ: Optional[Mapping[(str, str)]] = None) -> None`

**Description:**
Call the subprocess while suppressing output.

This uses :func:`subprocess.check_output` under the hood.

**Line:** 86

---

### `def norm_and_check(source_tree: str, requested: str) -> str`

**Description:**
Normalise and check a backend path.

Ensure that the requested backend path is specified as a relative path,
and resolves to a location under the given source tree.

Return an absolute version of the requested path.

**Line:** 102

---


## Module: venv2.libthon3.12.site-packages.pip._vendorproject_hooks._in_process.__init__
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/__init__.py`

**Imports:**
- importlib.resources

**Functions:**

### `def _in_proc_script_path()`

**Line:** 13

---

### `def _in_proc_script_path()`

**Line:** 18

---


## Module: venv2.libthon3.12.site-packages.pip._vendorproject_hooks._in_process._in_process
**File:** `venv2/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py`

**Imports:**
- glob.glob
- importlib.import_module
- importlib.machinery.PathFinder
- importlib.metadata.DistributionFinder
- importlib.metadata.MetadataPathFinder
- json
- os
- os.path
- os.path.join
- re
- shutil
- sys
- traceback
- zipfile.ZipFile

**Functions:**

### `def write_json(obj, path, **kwargs)`

**Line:** 31

---

### `def read_json(path)`

**Line:** 36

---

### `def _build_backend()`

**Description:**
Find and load the build backend

**Line:** 58

---

### `def _supported_features()`

**Description:**
Return the list of options features supported by the backend.

Returns a list of strings.
The only possible value is 'build_editable'.

**Line:** 119

---

### `def get_requires_for_build_wheel(config_settings)`

**Description:**
Invoke the optional get_requires_for_build_wheel hook

Returns [] if the hook is not defined.

**Line:** 132

---

### `def get_requires_for_build_editable(config_settings)`

**Description:**
Invoke the optional get_requires_for_build_editable hook

Returns [] if the hook is not defined.

**Line:** 146

---

### `def prepare_metadata_for_build_wheel(metadata_directory, config_settings, _allow_fallback)`

**Description:**
Invoke optional prepare_metadata_for_build_wheel

Implements a fallback by building a wheel if the hook isn't defined,
unless _allow_fallback is False in which case HookMissing is raised.

**Line:** 160

---

### `def prepare_metadata_for_build_editable(metadata_directory, config_settings, _allow_fallback)`

**Description:**
Invoke optional prepare_metadata_for_build_editable

Implements a fallback by building an editable wheel if the hook isn't
defined, unless _allow_fallback is False in which case HookMissing is
raised.

**Line:** 184

---

### `def _dist_info_files(whl_zip)`

**Description:**
Identify the .dist-info folder inside a wheel ZipFile.

**Line:** 215

---

### `def _get_wheel_metadata_from_wheel(whl_basename, metadata_directory, config_settings)`

**Description:**
Extract the metadata from a wheel.

Fallback for when the build backend does not
define the 'get_wheel_metadata' hook.

**Line:** 227

---

### `def _find_already_built_wheel(metadata_directory)`

**Description:**
Check for a wheel already built during the get_wheel_metadata hook.

**Line:** 245

---

### `def build_wheel(wheel_directory, config_settings, metadata_directory = None)`

**Description:**
Invoke the mandatory build_wheel hook.

If a wheel was already built in the
prepare_metadata_for_build_wheel fallback, this
will copy it rather than rebuilding the wheel.

**Line:** 268

---

### `def build_editable(wheel_directory, config_settings, metadata_directory = None)`

**Description:**
Invoke the optional build_editable hook.

If a wheel was already built in the
prepare_metadata_for_build_editable fallback, this
will copy it rather than rebuilding the wheel.

**Line:** 285

---

### `def get_requires_for_build_sdist(config_settings)`

**Description:**
Invoke the optional get_requires_for_build_wheel hook

Returns [] if the hook is not defined.

**Line:** 306

---

### `def build_sdist(sdist_directory, config_settings)`

**Description:**
Invoke the mandatory build_sdist hook.

**Line:** 331

---

### `def main()`

**Line:** 353

---


## Module: venv2.libthon3.12.site-packages.platformdirs.__init__
**File:** `venv2/lib/python3.12/site-packages/platformdirs/__init__.py`

**Imports:**
- __future__.annotations
- api.PlatformDirsABC
- os
- pathlib.Path
- platformdirs.android.Android
- platformdirs.android._android_folder
- platformdirs.macos.MacOS
- platformdirs.unix.Unix
- platformdirs.windows.Windows
- sys
- typing.Literal
- typing.TYPE_CHECKING
- version.__version__
- version.__version_tuple__

**Functions:**

### `def _set_platform_dir_class() -> type[PlatformDirsABC]`

**Line:** 30

---

### `def user_data_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, roaming: bool = False, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: data directory tied to the user

**Line:** 53

---

### `def site_data_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, multipath: bool = False, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param multipath: See `roaming <platformdirs.api.PlatformDirsABC.multipath>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: data directory shared by users

**Line:** 77

---

### `def user_config_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, roaming: bool = False, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: config directory tied to the user

**Line:** 101

---

### `def site_config_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, multipath: bool = False, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param multipath: See `roaming <platformdirs.api.PlatformDirsABC.multipath>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: config directory shared by the users

**Line:** 125

---

### `def user_cache_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: cache directory tied to the user

**Line:** 149

---

### `def site_cache_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: cache directory tied to the user

**Line:** 173

---

### `def user_state_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, roaming: bool = False, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: state directory tied to the user

**Line:** 197

---

### `def user_log_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: log directory tied to the user

**Line:** 221

---

### `def user_documents_dir() -> str`

**Description:**
:returns: documents directory tied to the user

**Line:** 245

---

### `def user_downloads_dir() -> str`

**Description:**
:returns: downloads directory tied to the user

**Line:** 250

---

### `def user_pictures_dir() -> str`

**Description:**
:returns: pictures directory tied to the user

**Line:** 255

---

### `def user_videos_dir() -> str`

**Description:**
:returns: videos directory tied to the user

**Line:** 260

---

### `def user_music_dir() -> str`

**Description:**
:returns: music directory tied to the user

**Line:** 265

---

### `def user_desktop_dir() -> str`

**Description:**
:returns: desktop directory tied to the user

**Line:** 270

---

### `def user_runtime_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: runtime directory tied to the user

**Line:** 275

---

### `def site_runtime_dir(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> str`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: runtime directory shared by users

**Line:** 299

---

### `def user_data_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, roaming: bool = False, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: data path tied to the user

**Line:** 323

---

### `def site_data_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, multipath: bool = False, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param multipath: See `multipath <platformdirs.api.PlatformDirsABC.multipath>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: data path shared by users

**Line:** 347

---

### `def user_config_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, roaming: bool = False, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: config path tied to the user

**Line:** 371

---

### `def site_config_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, multipath: bool = False, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param multipath: See `roaming <platformdirs.api.PlatformDirsABC.multipath>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: config path shared by the users

**Line:** 395

---

### `def site_cache_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: cache directory tied to the user

**Line:** 419

---

### `def user_cache_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: cache path tied to the user

**Line:** 443

---

### `def user_state_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, roaming: bool = False, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: state path tied to the user

**Line:** 467

---

### `def user_log_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: log path tied to the user

**Line:** 491

---

### `def user_documents_path() -> Path`

**Description:**
:returns: documents a path tied to the user

**Line:** 515

---

### `def user_downloads_path() -> Path`

**Description:**
:returns: downloads path tied to the user

**Line:** 520

---

### `def user_pictures_path() -> Path`

**Description:**
:returns: pictures path tied to the user

**Line:** 525

---

### `def user_videos_path() -> Path`

**Description:**
:returns: videos path tied to the user

**Line:** 530

---

### `def user_music_path() -> Path`

**Description:**
:returns: music path tied to the user

**Line:** 535

---

### `def user_desktop_path() -> Path`

**Description:**
:returns: desktop path tied to the user

**Line:** 540

---

### `def user_runtime_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: runtime path tied to the user

**Line:** 545

---

### `def site_runtime_path(appname: str | None = None, appauthor: str | Literal[False] | None = None, version: str | None = None, opinion: bool = True, ensure_exists: bool = False) -> Path`

**Description:**
:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: runtime path shared by users

**Line:** 569

---


## Module: venv2.libthon3.12.site-packages.platformdirs.__main__
**File:** `venv2/lib/python3.12/site-packages/platformdirs/__main__.py`

**Imports:**
- __future__.annotations
- platformdirs.PlatformDirs
- platformdirs.__version__

**Functions:**

### `def main() -> None`

**Description:**
Run the main entry point.

**Line:** 26

---


## Module: venv2.libthon3.12.site-packages.platformdirs.android
**File:** `venv2/lib/python3.12/site-packages/platformdirs/android.py`

**Imports:**
- __future__.annotations
- android.mActivity
- api.PlatformDirsABC
- functools.lru_cache
- jnius.autoclass
- os
- re
- sys
- typing.TYPE_CHECKING
- typing.cast

**Functions:**

### `def _android_folder() -> str | None`

**Decorators:**
- `@lru_cache(...)`

**Description:**
:return: base folder for the Android OS or None if it cannot be found

**Line:** 120

---

### `def _android_documents_folder() -> str`

**Decorators:**
- `@lru_cache(...)`

**Description:**
:return: documents folder for the Android OS

**Line:** 168

---

### `def _android_downloads_folder() -> str`

**Decorators:**
- `@lru_cache(...)`

**Description:**
:return: downloads folder for the Android OS

**Line:** 184

---

### `def _android_pictures_folder() -> str`

**Decorators:**
- `@lru_cache(...)`

**Description:**
:return: pictures folder for the Android OS

**Line:** 200

---

### `def _android_videos_folder() -> str`

**Decorators:**
- `@lru_cache(...)`

**Description:**
:return: videos folder for the Android OS

**Line:** 216

---

### `def _android_music_folder() -> str`

**Decorators:**
- `@lru_cache(...)`

**Description:**
:return: music folder for the Android OS

**Line:** 232

---


## Module: venv2.libthon3.12.site-packages.platformdirs.unix
**File:** `venv2/lib/python3.12/site-packages/platformdirs/unix.py`

**Imports:**
- __future__.annotations
- api.PlatformDirsABC
- collections.abc.Iterator
- configparser.ConfigParser
- os
- os.getuid
- pathlib.Path
- sys
- typing.NoReturn
- typing.TYPE_CHECKING

**Functions:**

### `def getuid() -> NoReturn`

**Line:** 18

---

### `def _get_user_media_dir(env_var: str, fallback_tilde_path: str) -> str`

**Line:** 235

---

### `def _get_user_dirs_folder(key: str) -> str | None`

**Description:**
Return directory from user-dirs.dirs config file.

See https://freedesktop.org/wiki/Software/xdg-user-dirs/.

**Line:** 245

---


## Module: venv2.libthon3.12.site-packages.platformdirs.windows
**File:** `venv2/lib/python3.12/site-packages/platformdirs/windows.py`

**Imports:**
- __future__.annotations
- api.PlatformDirsABC
- collections.abc.Callable
- ctypes
- functools.lru_cache
- os
- sys
- typing.TYPE_CHECKING
- winreg

**Functions:**

### `def get_win_folder_from_env_vars(csidl_name: str) -> str`

**Description:**
Get folder from environment variables.

**Line:** 143

---

### `def get_win_folder_if_csidl_name_not_env_var(csidl_name: str) -> str | None`

**Description:**
Get a folder for a CSIDL name that does not exist as an environment variable.

**Line:** 164

---

### `def get_win_folder_from_registry(csidl_name: str) -> str`

**Description:**
Get folder from the registry.

This is a fallback technique at best. I'm not sure if using the registry for these guarantees us the correct answer
for all CSIDL_* names.

**Line:** 183

---

### `def get_win_folder_via_ctypes(csidl_name: str) -> str`

**Description:**
Get folder with ctypes.

**Line:** 213

---

### `def _pick_get_win_folder() -> Callable[([str], str)]`

**Line:** 252

---


## Module: venv2.libthon3.12.site-packages.pluggy._callers
**File:** `venv2/lib/python3.12/site-packages/pluggy/_callers.py`

**Imports:**
- __future__.annotations
- _hooks.HookImpl
- _result.HookCallError
- _result.Result
- _warnings.PluggyTeardownRaisedWarning
- collections.abc.Generator
- collections.abc.Mapping
- collections.abc.Sequence
- typing.NoReturn
- typing.cast
- warnings

**Functions:**

### `def run_old_style_hookwrapper(hook_impl: HookImpl, hook_name: str, args: Sequence[object]) -> Teardown`

**Description:**
backward compatibility wrapper to run a old style hookwrapper as a wrapper

**Line:** 25

---

### `def _raise_wrapfail(wrap_controller: Generator[(None, object, object)], msg: str) -> NoReturn`

**Line:** 56

---

### `def _warn_teardown_exception(hook_name: str, hook_impl: HookImpl, e: BaseException) -> None`

**Line:** 66

---

### `def _multicall(hook_name: str, hook_impls: Sequence[HookImpl], caller_kwargs: Mapping[(str, object)], firstresult: bool) -> object | list[object]`

**Description:**
Execute a call into multiple python functions/methods and return the
result(s).

``caller_kwargs`` comes from HookCaller.__call__().

**Line:** 76

---


## Module: venv2.libthon3.12.site-packages.pluggy._hooks
**File:** `venv2/lib/python3.12/site-packages/pluggy/_hooks.py`

**Imports:**
- __future__.annotations
- _result.Result
- collections.abc.Generator
- collections.abc.Mapping
- collections.abc.Sequence
- collections.abc.Set
- inspect
- sys
- types.ModuleType
- typing.Any
- typing.Callable
- typing.Final
- typing.Optional
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.TypedDict
- typing.Union
- typing.final
- typing.overload
- warnings

**Functions:**

### `def normalize_hookimpl_opts(opts: HookimplOpts) -> None`

**Line:** 281

---

### `def varnames(func: object) -> tuple[(tuple[str, ...], tuple[str, ...])]`

**Description:**
Return tuple of positional and keywrord argument names for a function,
method, class or callable.

In case of a class, its ``__init__`` method is considered.
For methods the ``self`` parameter is not included.

**Line:** 293

---


## Module: venv2.libthon3.12.site-packages.pluggy._manager
**File:** `venv2/lib/python3.12/site-packages/pluggy/_manager.py`

**Imports:**
- __future__.annotations
- _callers._multicall
- _hooks.HookCaller
- _hooks.HookImpl
- _hooks.HookRelay
- _hooks.HookimplOpts
- _hooks.HookspecOpts
- _hooks._HookImplFunction
- _hooks._Namespace
- _hooks._Plugin
- _hooks._SubsetHookCaller
- _hooks.normalize_hookimpl_opts
- _result.Result
- collections.abc.Iterable
- collections.abc.Mapping
- collections.abc.Sequence
- importlib.metadata
- inspect
- types
- typing.Any
- typing.Callable
- typing.Final
- typing.TYPE_CHECKING
- typing.cast
- warnings

**Functions:**

### `def _warn_for_function(warning: Warning, function: Callable[(..., object)]) -> None`

**Line:** 39

---

### `def _formatdef(func: Callable[(..., object)]) -> str`

**Line:** 522

---


## Module: venv2.libthon3.12.site-packages.psycopg2.__init__
**File:** `venv2/lib/python3.12/site-packages/psycopg2/__init__.py`

**Imports:**
- decimal.Decimal
- psycopg2._psycopg.BINARY
- psycopg2._psycopg.Binary
- psycopg2._psycopg.DATETIME
- psycopg2._psycopg.DataError
- psycopg2._psycopg.DatabaseError
- psycopg2._psycopg.Date
- psycopg2._psycopg.DateFromTicks
- psycopg2._psycopg.Decimal
- psycopg2._psycopg.Error
- psycopg2._psycopg.IntegrityError
- psycopg2._psycopg.InterfaceError
- psycopg2._psycopg.InternalError
- psycopg2._psycopg.NUMBER
- psycopg2._psycopg.NotSupportedError
- psycopg2._psycopg.OperationalError
- psycopg2._psycopg.ProgrammingError
- psycopg2._psycopg.ROWID
- psycopg2._psycopg.STRING
- psycopg2._psycopg.Time
- psycopg2._psycopg.TimeFromTicks
- psycopg2._psycopg.Timestamp
- psycopg2._psycopg.TimestampFromTicks
- psycopg2._psycopg.Warning
- psycopg2._psycopg.__libpq_version__
- psycopg2._psycopg.__version__
- psycopg2._psycopg._connect
- psycopg2._psycopg.apilevel
- psycopg2._psycopg.paramstyle
- psycopg2._psycopg.threadsafety
- psycopg2.extensions

**Functions:**

### `def connect(dsn = None, connection_factory = None, cursor_factory = None, **kwargs)`

**Description:**
Create a new database connection.

The connection parameters can be specified as a string:

conn = psycopg2.connect("dbname=test user=postgres password=secret")

or using a set of keyword arguments:

conn = psycopg2.connect(database="test", user="postgres", password="secret")

Or as a mix of both. The basic connection parameters are:

- *dbname*: the database name
- *database*: the database name (only as keyword argument)
- *user*: user name used to authenticate
- *password*: password used to authenticate
- *host*: database host address (defaults to UNIX socket if not provided)
- *port*: connection port number (defaults to 5432 if not provided)

Using the *connection_factory* parameter a different class or connections
factory can be specified. It should be a callable object taking a dsn
argument.

Using the *cursor_factory* parameter, a new default cursor factory will be
used by cursor().

Using *async*=True an asynchronous connection will be created. *async_* is
a valid alias (for Python versions where ``async`` is a keyword).

Any other keyword parameter will be passed to the underlying client
library: the list of supported parameters depends on the library version.

**Line:** 80

---


## Module: venv2.libthon3.12.site-packages.psycopg2._ipaddress
**File:** `venv2/lib/python3.12/site-packages/psycopg2/_ipaddress.py`

**Imports:**
- ipaddress
- psycopg2.extensions.QuotedString
- psycopg2.extensions.new_array_type
- psycopg2.extensions.new_type
- psycopg2.extensions.register_adapter
- psycopg2.extensions.register_type

**Functions:**

### `def register_ipaddress(conn_or_curs = None)`

**Description:**
Register conversion support between `ipaddress` objects and `network types`__.

:param conn_or_curs: the scope where to register the type casters.
If `!None` register them globally.

After the function is called, PostgreSQL :sql:`inet` values will be
converted into `~ipaddress.IPv4Interface` or `~ipaddress.IPv6Interface`
objects, :sql:`cidr` values into into `~ipaddress.IPv4Network` or
`~ipaddress.IPv6Network`.

.. __: https://www.postgresql.org/docs/current/static/datatype-net-types.html

**Line:** 37

---

### `def _make_casters()`

**Line:** 66

---

### `def cast_interface(s, cur = None)`

**Line:** 76

---

### `def cast_network(s, cur = None)`

**Line:** 83

---

### `def adapt_ipaddress(obj)`

**Line:** 89

---


## Module: venv2.libthon3.12.site-packages.psycopg2._json
**File:** `venv2/lib/python3.12/site-packages/psycopg2/_json.py`

**Imports:**
- json
- psycopg2._psycopg.ISQLQuote
- psycopg2._psycopg.QuotedString
- psycopg2._psycopg.new_array_type
- psycopg2._psycopg.new_type
- psycopg2._psycopg.register_type
- psycopg2.extensions.STATUS_IN_TRANSACTION
- psycopg2.extras._solve_conn_curs

**Functions:**

### `def register_json(conn_or_curs = None, globally = False, loads = None, oid = None, array_oid = None, name = 'json')`

**Description:**
Create and register typecasters converting :sql:`json` type to Python objects.

:param conn_or_curs: a connection or cursor used to find the :sql:`json`
and :sql:`json[]` oids; the typecasters are registered in a scope
limited to this object, unless *globally* is set to `!True`. It can be
`!None` if the oids are provided
:param globally: if `!False` register the typecasters only on
*conn_or_curs*, otherwise register them globally
:param loads: the function used to parse the data into a Python object. If
`!None` use `!json.loads()`, where `!json` is the module chosen
according to the Python version (see above)
:param oid: the OID of the :sql:`json` type if known; If not, it will be
queried on *conn_or_curs*
:param array_oid: the OID of the :sql:`json[]` array type if known;
if not, it will be queried on *conn_or_curs*
:param name: the name of the data type to look for in *conn_or_curs*

The connection or cursor passed to the function will be used to query the
database and look for the OID of the :sql:`json` type (or an alternative
type if *name* if provided). No query is performed if *oid* and *array_oid*
are provided.  Raise `~psycopg2.ProgrammingError` if the type is not found.

**Line:** 89

---

### `def register_default_json(conn_or_curs = None, globally = False, loads = None)`

**Description:**
Create and register :sql:`json` typecasters for PostgreSQL 9.2 and following.

Since PostgreSQL 9.2 :sql:`json` is a builtin type, hence its oid is known
and fixed. This function allows specifying a customized *loads* function
for the default :sql:`json` type without querying the database.
All the parameters have the same meaning of `register_json()`.

**Line:** 128

---

### `def register_default_jsonb(conn_or_curs = None, globally = False, loads = None)`

**Description:**
Create and register :sql:`jsonb` typecasters for PostgreSQL 9.4 and following.

As in `register_default_json()`, the function allows to register a
customized *loads* function for the :sql:`jsonb` type at its known oid for
PostgreSQL 9.4 and following versions.  All the parameters have the same
meaning of `register_json()`.

**Line:** 141

---

### `def _create_json_typecasters(oid, array_oid, loads = None, name = 'JSON')`

**Description:**
Create typecasters for json data type.

**Line:** 154

---

### `def _get_json_oids(conn_or_curs, name = 'json')`

**Line:** 173

---


## Module: venv2.libthon3.12.site-packages.psycopg2._range
**File:** `venv2/lib/python3.12/site-packages/psycopg2/_range.py`

**Imports:**
- psycopg2._psycopg.InterfaceError
- psycopg2._psycopg.ProgrammingError
- psycopg2.extensions.ISQLQuote
- psycopg2.extensions.STATUS_IN_TRANSACTION
- psycopg2.extensions.adapt
- psycopg2.extensions.new_array_type
- psycopg2.extensions.new_type
- psycopg2.extensions.register_adapter
- psycopg2.extensions.register_type
- psycopg2.extras._solve_conn_curs
- re

**Functions:**

### `def register_range(pgrange, pyrange, conn_or_curs, globally = False)`

**Description:**
Create and register an adapter and the typecasters to convert between
a PostgreSQL |range|_ type and a PostgreSQL `Range` subclass.

:param pgrange: the name of the PostgreSQL |range| type. Can be
schema-qualified
:param pyrange: a `Range` strict subclass, or just a name to give to a new
class
:param conn_or_curs: a connection or cursor used to find the oid of the
range and its subtype; the typecaster is registered in a scope limited
to this object, unless *globally* is set to `!True`
:param globally: if `!False` (default) register the typecaster only on
*conn_or_curs*, otherwise register it globally
:return: `RangeCaster` instance responsible for the conversion

If a string is passed to *pyrange*, a new `Range` subclass is created
with such name and will be available as the `~RangeCaster.range` attribute
of the returned `RangeCaster` object.

The function queries the database on *conn_or_curs* to inspect the
*pgrange* type and raises `~psycopg2.ProgrammingError` if the type is not
found.  If querying the database is not advisable, use directly the
`RangeCaster` class and register the adapter and typecasters using the
provided functions.

**Line:** 206

---


## Module: venv2.libthon3.12.site-packages.psycopg2.errorcodes
**File:** `venv2/lib/python3.12/site-packages/psycopg2/errorcodes.py`

**Functions:**

### `def lookup(code, _cache = {})`

**Description:**
Lookup an error code or class code and return its symbolic name.

Raise `KeyError` if the code is not found.

**Line:** 34

---


## Module: venv2.libthon3.12.site-packages.psycopg2.errors
**File:** `venv2/lib/python3.12/site-packages/psycopg2/errors.py`

**Imports:**
- psycopg2._psycopg.sqlstate_errors

**Functions:**

### `def lookup(code)`

**Description:**
Lookup an error code and return its exception class.

Raise `!KeyError` if the code is not found.

**Line:** 32

---


## Module: venv2.libthon3.12.site-packages.psycopg2.extensions
**File:** `venv2/lib/python3.12/site-packages/psycopg2/extensions.py`

**Imports:**
- psycopg2._json.register_default_json
- psycopg2._json.register_default_jsonb
- psycopg2._psycopg.AsIs
- psycopg2._psycopg.BINARYARRAY
- psycopg2._psycopg.BOOLEAN
- psycopg2._psycopg.BOOLEANARRAY
- psycopg2._psycopg.BYTES
- psycopg2._psycopg.BYTESARRAY
- psycopg2._psycopg.Binary
- psycopg2._psycopg.Boolean
- psycopg2._psycopg.Column
- psycopg2._psycopg.ConnectionInfo
- psycopg2._psycopg.DATE
- psycopg2._psycopg.DATEARRAY
- psycopg2._psycopg.DATETIMEARRAY
- psycopg2._psycopg.DECIMAL
- psycopg2._psycopg.DECIMALARRAY
- psycopg2._psycopg.DateFromPy
- psycopg2._psycopg.Diagnostics
- psycopg2._psycopg.FLOAT
- psycopg2._psycopg.FLOATARRAY
- psycopg2._psycopg.Float
- psycopg2._psycopg.INTEGER
- psycopg2._psycopg.INTEGERARRAY
- psycopg2._psycopg.INTERVAL
- psycopg2._psycopg.INTERVALARRAY
- psycopg2._psycopg.ISQLQuote
- psycopg2._psycopg.Int
- psycopg2._psycopg.IntervalFromPy
- psycopg2._psycopg.LONGINTEGER
- psycopg2._psycopg.LONGINTEGERARRAY
- psycopg2._psycopg.Notify
- psycopg2._psycopg.PYDATE
- psycopg2._psycopg.PYDATEARRAY
- psycopg2._psycopg.PYDATETIME
- psycopg2._psycopg.PYDATETIMEARRAY
- psycopg2._psycopg.PYDATETIMETZ
- psycopg2._psycopg.PYDATETIMETZARRAY
- psycopg2._psycopg.PYINTERVAL
- psycopg2._psycopg.PYINTERVALARRAY
- psycopg2._psycopg.PYTIME
- psycopg2._psycopg.PYTIMEARRAY
- psycopg2._psycopg.QueryCanceledError
- psycopg2._psycopg.QuotedString
- psycopg2._psycopg.ROWIDARRAY
- psycopg2._psycopg.STRINGARRAY
- psycopg2._psycopg.TIME
- psycopg2._psycopg.TIMEARRAY
- psycopg2._psycopg.TimeFromPy
- psycopg2._psycopg.TimestampFromPy
- psycopg2._psycopg.TransactionRollbackError
- psycopg2._psycopg.UNICODE
- psycopg2._psycopg.UNICODEARRAY
- psycopg2._psycopg.Xid
- psycopg2._psycopg.adapt
- psycopg2._psycopg.adapters
- psycopg2._psycopg.binary_types
- psycopg2._psycopg.connection
- psycopg2._psycopg.cursor
- psycopg2._psycopg.encodings
- psycopg2._psycopg.encrypt_password
- psycopg2._psycopg.get_wait_callback
- psycopg2._psycopg.libpq_version
- psycopg2._psycopg.lobject
- psycopg2._psycopg.new_array_type
- psycopg2._psycopg.new_type
- psycopg2._psycopg.parse_dsn
- psycopg2._psycopg.quote_ident
- psycopg2._psycopg.register_type
- psycopg2._psycopg.set_wait_callback
- psycopg2._psycopg.string_types
- psycopg2._range.Range
- re

**Functions:**

### `def register_adapter(typ, callable)`

**Description:**
Register 'callable' as an ISQLQuote adapter for type 'typ'.

**Line:** 95

---

### `def make_dsn(dsn = None, **kwargs)`

**Description:**
Convert a set of keywords into a connection strings.

**Line:** 138

---

### `def _param_escape(s, re_escape = _re.compile("([\\\\'])"), re_space = _re.compile('\\s'))`

**Description:**
Apply the escaping rule required by PQconnectdb

**Line:** 172

---


## Module: venv2.libthon3.12.site-packages.psycopg2.extras
**File:** `venv2/lib/python3.12/site-packages/psycopg2/extras.py`

**Imports:**
- collections.OrderedDict
- collections.namedtuple
- extensions.adapt
- extensions.connection
- extensions.cursor
- extensions.quote_ident
- functools.lru_cache
- logging
- os
- psycopg2
- psycopg2._ipaddress.register_ipaddress
- psycopg2._json.Json
- psycopg2._json.json
- psycopg2._json.register_default_json
- psycopg2._json.register_default_jsonb
- psycopg2._json.register_json
- psycopg2._psycopg.REPLICATION_LOGICAL
- psycopg2._psycopg.REPLICATION_PHYSICAL
- psycopg2._psycopg.ReplicationConnection
- psycopg2._psycopg.ReplicationCursor
- psycopg2._psycopg.ReplicationMessage
- psycopg2._range.DateRange
- psycopg2._range.DateTimeRange
- psycopg2._range.DateTimeTZRange
- psycopg2._range.NumericRange
- psycopg2._range.Range
- psycopg2._range.RangeAdapter
- psycopg2._range.RangeCaster
- psycopg2._range.register_range
- psycopg2.extensions
- psycopg2.extensions.POLL_OK
- psycopg2.extensions.POLL_READ
- psycopg2.extensions.POLL_WRITE
- psycopg2.sql.Composable
- re
- select
- time
- uuid
- warnings

**Functions:**

### `def _cached_make_nt(cls, key)`

**Decorators:**
- `@lru_cache(...)`

**Line:** 380

---

### `def register_uuid(oids = None, conn_or_curs = None)`

**Description:**
Create the UUID type and an uuid.UUID adapter.

:param oids: oid for the PostgreSQL :sql:`uuid` type, or 2-items sequence
with oids of the type and the array. If not specified, use PostgreSQL
standard oids.
:param conn_or_curs: where to register the typecaster. If not specified,
register it globally.

**Line:** 647

---

### `def register_inet(oid = None, conn_or_curs = None)`

**Description:**
Create the INET type and an Inet adapter.

:param oid: oid for the PostgreSQL :sql:`inet` type, or 2-items sequence
with oids of the type and the array. If not specified, use PostgreSQL
standard oids.
:param conn_or_curs: where to register the typecaster. If not specified,
register it globally.

**Line:** 712

---

### `def wait_select(conn)`

**Description:**
Wait until a connection or cursor has data available.

The function is an example of a wait callback to be registered with
`~psycopg2.extensions.set_wait_callback()`. This function uses
:py:func:`~select.select()` to wait for data to become available, and
therefore is able to handle/receive SIGINT/KeyboardInterrupt.

**Line:** 745

---

### `def _solve_conn_curs(conn_or_curs)`

**Description:**
Return the connection and a DBAPI cursor from a connection or cursor.

**Line:** 773

---

### `def register_hstore(conn_or_curs, globally = False, unicode = False, oid = None, array_oid = None)`

**Description:**
Register adapter and typecaster for `!dict`\-\ |hstore| conversions.

:param conn_or_curs: a connection or cursor: the typecaster will be
registered only on this object unless *globally* is set to `!True`
:param globally: register the adapter globally, not only on *conn_or_curs*
:param unicode: if `!True`, keys and values returned from the database
will be `!unicode` instead of `!str`. The option is not available on
Python 3
:param oid: the OID of the |hstore| type if known. If not, it will be
queried on *conn_or_curs*.
:param array_oid: the OID of the |hstore| array type if known. If not, it
will be queried on *conn_or_curs*.

The connection or cursor passed to the function will be used to query the
database and look for the OID of the |hstore| type (which may be different
across databases). If querying is not desirable (e.g. with
:ref:`asynchronous connections <async-support>`) you may specify it in the
*oid* parameter, which can be found using a query such as :sql:`SELECT
'hstore'::regtype::oid`. Analogously you can obtain a value for *array_oid*
using a query such as :sql:`SELECT 'hstore[]'::regtype::oid`.

Note that, when passing a dictionary from Python to the database, both
strings and unicode keys and values are supported. Dictionaries returned
from the database have keys/values according to the *unicode* parameter.

The |hstore| contrib module must be already installed in the database
(executing the ``hstore.sql`` script in your ``contrib`` directory).
Raise `~psycopg2.ProgrammingError` if the type is not found.

**Line:** 924

---

### `def register_composite(name, conn_or_curs, globally = False, factory = None)`

**Description:**
Register a typecaster to convert a composite type into a tuple.

:param name: the name of a PostgreSQL composite type, e.g. created using
the |CREATE TYPE|_ command
:param conn_or_curs: a connection or cursor used to find the type oid and
components; the typecaster is registered in a scope limited to this
object, unless *globally* is set to `!True`
:param globally: if `!False` (default) register the typecaster only on
*conn_or_curs*, otherwise register it globally
:param factory: if specified it should be a `CompositeCaster` subclass: use
it to :ref:`customize how to cast composite types <custom-composite>`
:return: the registered `CompositeCaster` or *factory* instance
responsible for the conversion

**Line:** 1147

---

### `def _paginate(seq, page_size)`

**Description:**
Consume an iterable and return it in chunks.

Every chunk is at most `page_size`. Never return an empty chunk.

**Line:** 1175

---

### `def execute_batch(cur, sql, argslist, page_size = 100)`

**Description:**
Execute groups of statements in fewer server roundtrips.

Execute *sql* several times, against all parameters set (sequences or
mappings) found in *argslist*.

The function is semantically similar to

.. parsed-literal::

*cur*\.\ `~cursor.executemany`\ (\ *sql*\ , *argslist*\ )

but has a different implementation: Psycopg will join the statements into
fewer multi-statement commands, each one containing at most *page_size*
statements, resulting in a reduced number of server roundtrips.

After the execution of the function the `cursor.rowcount` property will
**not** contain a total result.

**Line:** 1194

---

### `def execute_values(cur, sql, argslist, template = None, page_size = 100, fetch = False)`

**Description:**
Execute a statement using :sql:`VALUES` with a sequence of parameters.

:param cur: the cursor to use to execute the query.

:param sql: the query to execute. It must contain a single ``%s``
placeholder, which will be replaced by a `VALUES list`__.
Example: ``"INSERT INTO mytable (id, f1, f2) VALUES %s"``.

:param argslist: sequence of sequences or dictionaries with the arguments
to send to the query. The type and content must be consistent with
*template*.

:param template: the snippet to merge to every item in *argslist* to
compose the query.

- If the *argslist* items are sequences it should contain positional
placeholders (e.g. ``"(%s, %s, %s)"``, or ``"(%s, %s, 42)``" if there
are constants value...).

- If the *argslist* items are mappings it should contain named
placeholders (e.g. ``"(%(id)s, %(f1)s, 42)"``).

If not specified, assume the arguments are sequence and use a simple
positional template (i.e.  ``(%s, %s, ...)``), with the number of
placeholders sniffed by the first element in *argslist*.

:param page_size: maximum number of *argslist* items to include in every
statement. If there are more items the function will execute more than
one statement.

:param fetch: if `!True` return the query results into a list (like in a
`~cursor.fetchall()`).  Useful for queries with :sql:`RETURNING`
clause.

.. __: https://www.postgresql.org/docs/current/static/queries-values.html

After the execution of the function the `cursor.rowcount` property will
**not** contain a total result.

While :sql:`INSERT` is an obvious candidate for this function it is
possible to use it with other statements, for example::

>>> cur.execute(
... "create table test (id int primary key, v1 int, v2 int)")

>>> execute_values(cur,
... "INSERT INTO test (id, v1, v2) VALUES %s",
... [(1, 2, 3), (4, 5, 6), (7, 8, 9)])

>>> execute_values(cur,
... """UPDATE test SET v1 = data.v1 FROM (VALUES %s) AS data (id, v1)
... WHERE test.id = data.id""",
... [(1, 20), (4, 50)])

>>> cur.execute("select * from test order by id")
>>> cur.fetchall()
[(1, 20, 3), (4, 50, 6), (7, 8, 9)])

**Line:** 1219

---

### `def _split_sql(sql)`

**Description:**
Split *sql* on a single ``%s`` placeholder.

Split on the %s, perform %% replacement and return pre, post lists of
snippets.

**Line:** 1306

---


## Module: venv2.libthon3.12.site-packages.rich.__init__
**File:** `venv2/lib/python3.12/site-packages/rich/__init__.py`

**Imports:**
- _extension.load_ipython_extension
- console.Console
- os
- rich._inspect.Inspect
- rich.console.Console
- typing.Any
- typing.Callable
- typing.IO
- typing.Optional
- typing.TYPE_CHECKING
- typing.Union

**Functions:**

### `def get_console() -> 'Console'`

**Description:**
Get a global :class:`~rich.console.Console` instance. This function is used when Rich requires a Console,
and hasn't been explicitly given one.

Returns:
Console: A console instance.

**Line:** 23

---

### `def reconfigure(*args: Any, **kwargs: Any) -> None`

**Description:**
Reconfigures the global console by replacing it with another.

Args:
*args (Any): Positional arguments for the replacement :class:`~rich.console.Console`.
**kwargs (Any): Keyword arguments for the replacement :class:`~rich.console.Console`.

**Line:** 39

---

### `def print(sep: str = ' ', end: str = '\n', file: Optional[IO[str]] = None, flush: bool = False, *objects: Any) -> None`

**Description:**
Print object(s) supplied via positional arguments.
This function has an identical signature to the built-in print.
For more advanced features, see the :class:`~rich.console.Console` class.

Args:
sep (str, optional): Separator between printed objects. Defaults to " ".
end (str, optional): Character to write at end of output. Defaults to "\\n".
file (IO[str], optional): File to write to, or None for stdout. Defaults to None.
flush (bool, optional): Has no effect as Rich always flushes output. Defaults to False.

**Line:** 53

---

### `def print_json(json: Optional[str] = None, data: Any = None, indent: Union[(None, int, str)] = 2, highlight: bool = True, skip_keys: bool = False, ensure_ascii: bool = False, check_circular: bool = True, allow_nan: bool = True, default: Optional[Callable[([Any], Any)]] = None, sort_keys: bool = False) -> None`

**Description:**
Pretty prints JSON. Output will be valid JSON.

Args:
json (str): A string containing JSON.
data (Any): If json is not supplied, then encode this data.
indent (int, optional): Number of spaces to indent. Defaults to 2.
highlight (bool, optional): Enable highlighting of output: Defaults to True.
skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.
ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.
check_circular (bool, optional): Check for circular references. Defaults to True.
allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.
default (Callable, optional): A callable that converts values that can not be encoded
in to something that can be JSON encoded. Defaults to None.
sort_keys (bool, optional): Sort dictionary keys. Defaults to False.

**Line:** 77

---

### `def inspect(obj: Any, console: Optional['Console'] = None, title: Optional[str] = None, help: bool = False, methods: bool = False, docs: bool = True, private: bool = False, dunder: bool = False, sort: bool = True, all: bool = False, value: bool = True) -> None`

**Description:**
Inspect any Python object.

* inspect(<OBJECT>) to see summarized info.
* inspect(<OBJECT>, methods=True) to see methods.
* inspect(<OBJECT>, help=True) to see full (non-abbreviated) help.
* inspect(<OBJECT>, private=True) to see private attributes (single underscore).
* inspect(<OBJECT>, dunder=True) to see attributes beginning with double underscore.
* inspect(<OBJECT>, all=True) to see all attributes.

Args:
obj (Any): An object to inspect.
title (str, optional): Title to display over inspect result, or None use type. Defaults to None.
help (bool, optional): Show full help text rather than just first paragraph. Defaults to False.
methods (bool, optional): Enable inspection of callables. Defaults to False.
docs (bool, optional): Also render doc strings. Defaults to True.
private (bool, optional): Show private attributes (beginning with underscore). Defaults to False.
dunder (bool, optional): Show attributes starting with double underscore. Defaults to False.
sort (bool, optional): Sort attributes alphabetically. Defaults to True.
all (bool, optional): Show all attributes. Defaults to False.
value (bool, optional): Pretty print value. Defaults to True.

**Line:** 120

---


## Module: venv2.libthon3.12.site-packages.rich.__main__
**File:** `venv2/lib/python3.12/site-packages/rich/__main__.py`

**Imports:**
- colorsys
- io
- rich.box
- rich.color.Color
- rich.console.Console
- rich.console.ConsoleOptions
- rich.console.Group
- rich.console.RenderResult
- rich.console.RenderableType
- rich.markdown.Markdown
- rich.measure.Measurement
- rich.panel.Panel
- rich.pretty.Pretty
- rich.segment.Segment
- rich.style.Style
- rich.syntax.Syntax
- rich.table.Table
- rich.text.Text
- time.process_time

**Functions:**

### `def make_test_card() -> Table`

**Description:**
Get a renderable that demonstrates a number of features.

**Line:** 39

---


## Module: venv2.libthon3.12.site-packages.rich._emoji_replace
**File:** `venv2/lib/python3.12/site-packages/rich/_emoji_replace.py`

**Imports:**
- _emoji_codes.EMOJI
- re
- typing.Callable
- typing.Match
- typing.Optional

**Functions:**

### `def _emoji_replace(text: str, default_variant: Optional[str] = None, _emoji_sub: _EmojiSubMethod) -> str`

**Description:**
Replace emoji code in text.

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.rich._extension
**File:** `venv2/lib/python3.12/site-packages/rich/_extension.py`

**Imports:**
- rich.pretty.install
- rich.traceback.install
- typing.Any

**Functions:**

### `def load_ipython_extension(ip: Any) -> None`

**Line:** 4

---


## Module: venv2.libthon3.12.site-packages.rich._fileno
**File:** `venv2/lib/python3.12/site-packages/rich/_fileno.py`

**Imports:**
- __future__.annotations
- typing.Callable
- typing.IO

**Functions:**

### `def get_fileno(file_like: IO[str]) -> int | None`

**Description:**
Get fileno() from a file, accounting for poorly implemented file-like objects.

Args:
file_like (IO): A file-like object.

Returns:
int | None: The result of fileno if available, or None if operation failed.

**Line:** 6

---


## Module: venv2.libthon3.12.site-packages.rich._inspect
**File:** `venv2/lib/python3.12/site-packages/rich/_inspect.py`

**Imports:**
- console.Group
- console.RenderableType
- control.escape_control_codes
- highlighter.ReprHighlighter
- inspect
- inspect.cleandoc
- inspect.getdoc
- inspect.getfile
- inspect.isclass
- inspect.ismodule
- inspect.signature
- jupyter.JupyterMixin
- panel.Panel
- pretty.Pretty
- table.Table
- text.Text
- text.TextType
- typing.Any
- typing.Collection
- typing.Iterable
- typing.Optional
- typing.Tuple
- typing.Type
- typing.Union

**Functions:**

### `def _first_paragraph(doc: str) -> str`

**Description:**
Get the first paragraph from a docstring.

**Line:** 15

---

### `def get_object_types_mro(obj: Union[(object, Type[Any])]) -> Tuple[(type, ...)]`

**Description:**
Returns the MRO of an object's class, or of the object itself if it's a class.

**Line:** 236

---

### `def get_object_types_mro_as_strings(obj: object) -> Collection[str]`

**Description:**
Returns the MRO of an object's class as full qualified names, or of the object itself if it's a class.

Examples:
`object_types_mro_as_strings(JSONDecoder)` will return `['json.decoder.JSONDecoder', 'builtins.object']`

**Line:** 245

---

### `def is_object_one_of_types(obj: object, fully_qualified_types_names: Collection[str]) -> bool`

**Description:**
Returns `True` if the given object's class (or the object itself, if it's a class) has one of the
fully qualified names in its MRO.

**Line:** 258

---


## Module: venv2.libthon3.12.site-packages.rich._loop
**File:** `venv2/lib/python3.12/site-packages/rich/_loop.py`

**Imports:**
- typing.Iterable
- typing.Tuple
- typing.TypeVar

**Functions:**

### `def loop_first(values: Iterable[T]) -> Iterable[Tuple[(bool, T)]]`

**Description:**
Iterate and generate a tuple with a flag for first value.

**Line:** 6

---

### `def loop_last(values: Iterable[T]) -> Iterable[Tuple[(bool, T)]]`

**Description:**
Iterate and generate a tuple with a flag for last value.

**Line:** 18

---

### `def loop_first_last(values: Iterable[T]) -> Iterable[Tuple[(bool, bool, T)]]`

**Description:**
Iterate and generate a tuple with a flag for first and last value.

**Line:** 31

---


## Module: venv2.libthon3.12.site-packages.rich._pick
**File:** `venv2/lib/python3.12/site-packages/rich/_pick.py`

**Imports:**
- typing.Optional

**Functions:**

### `def pick_bool(*values: Optional[bool]) -> bool`

**Description:**
Pick the first non-none bool or return the last value.

Args:
*values (bool): Any number of boolean or None values.

Returns:
bool: First non-none boolean.

**Line:** 4

---


## Module: venv2.libthon3.12.site-packages.rich._ratio
**File:** `venv2/lib/python3.12/site-packages/rich/_ratio.py`

**Imports:**
- dataclasses.dataclass
- fractions.Fraction
- math.ceil
- sys
- typing.List
- typing.Optional
- typing.Protocol
- typing.Sequence
- typing.cast
- typing_extensions.Protocol

**Functions:**

### `def ratio_resolve(total: int, edges: Sequence[Edge]) -> List[int]`

**Description:**
Divide total space to satisfy size, ratio, and minimum_size, constraints.

The returned list of integers should add up to total in most cases, unless it is
impossible to satisfy all the constraints. For instance, if there are two edges
with a minimum size of 20 each and `total` is 30 then the returned list will be
greater than total. In practice, this would mean that a Layout object would
clip the rows that would overflow the screen height.

Args:
total (int): Total number of characters.
edges (List[Edge]): Edges within total space.

Returns:
List[int]: Number of characters for each edge.

**Line:** 20

---

### `def ratio_reduce(total: int, ratios: List[int], maximums: List[int], values: List[int]) -> List[int]`

**Description:**
Divide an integer total in to parts based on ratios.

Args:
total (int): The total to divide.
ratios (List[int]): A list of integer ratios.
maximums (List[int]): List of maximums values for each slot.
values (List[int]): List of values

Returns:
List[int]: A list of integers guaranteed to sum to total.

**Line:** 81

---

### `def ratio_distribute(total: int, ratios: List[int], minimums: Optional[List[int]] = None) -> List[int]`

**Description:**
Distribute an integer total in to parts based on ratios.

Args:
total (int): The total to divide.
ratios (List[int]): A list of integer ratios.
minimums (List[int]): List of minimum values for each slot.

Returns:
List[int]: A list of integers guaranteed to sum to total.

**Line:** 113

---


## Module: venv2.libthon3.12.site-packages.rich._timer
**File:** `venv2/lib/python3.12/site-packages/rich/_timer.py`

**Imports:**
- contextlib
- time.time
- typing.Generator

**Functions:**

### `def timer(subject: str = 'time') -> Generator[(None, None, None)]`

**Decorators:**
- `@contextlib.contextmanager`

**Description:**
print the elapsed time. (only used in debugging)

**Line:** 13

---


## Module: venv2.libthon3.12.site-packages.rich._win32_console
**File:** `venv2/lib/python3.12/site-packages/rich/_win32_console.py`

**Imports:**
- ctypes
- ctypes.Structure
- ctypes.byref
- ctypes.wintypes
- rich.color.ColorSystem
- rich.console.Console
- rich.style.Style
- sys
- time
- typing.Any
- typing.IO
- typing.NamedTuple
- typing.Type
- typing.cast

**Functions:**

### `def GetStdHandle(handle: int = STDOUT) -> wintypes.HANDLE`

**Description:**
Retrieves a handle to the specified standard device (standard input, standard output, or standard error).

Args:
handle (int): Integer identifier for the handle. Defaults to -11 (stdout).

Returns:
wintypes.HANDLE: The handle

**Line:** 78

---

### `def GetConsoleMode(std_handle: wintypes.HANDLE) -> int`

**Description:**
Retrieves the current input mode of a console's input buffer
or the current output mode of a console screen buffer.

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.

Raises:
LegacyWindowsError: If any error occurs while calling the Windows console API.

Returns:
int: Value representing the current console mode as documented at
https://docs.microsoft.com/en-us/windows/console/getconsolemode#parameters

**Line:** 95

---

### `def FillConsoleOutputCharacter(std_handle: wintypes.HANDLE, char: str, length: int, start: WindowsCoordinates) -> int`

**Description:**
Writes a character to the console screen buffer a specified number of times, beginning at the specified coordinates.

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
char (str): The character to write. Must be a string of length 1.
length (int): The number of times to write the character.
start (WindowsCoordinates): The coordinates to start writing at.

Returns:
int: The number of characters written.

**Line:** 128

---

### `def FillConsoleOutputAttribute(std_handle: wintypes.HANDLE, attributes: int, length: int, start: WindowsCoordinates) -> int`

**Description:**
Sets the character attributes for a specified number of character cells,
beginning at the specified coordinates in a screen buffer.

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
attributes (int): Integer value representing the foreground and background colours of the cells.
length (int): The number of cells to set the output attribute of.
start (WindowsCoordinates): The coordinates of the first cell whose attributes are to be set.

Returns:
int: The number of cells whose attributes were actually set.

**Line:** 169

---

### `def SetConsoleTextAttribute(std_handle: wintypes.HANDLE, attributes: wintypes.WORD) -> bool`

**Description:**
Set the colour attributes for all text written after this function is called.

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
attributes (int): Integer value representing the foreground and background colours.


Returns:
bool: True if the attribute was set successfully, otherwise False.

**Line:** 204

---

### `def GetConsoleScreenBufferInfo(std_handle: wintypes.HANDLE) -> CONSOLE_SCREEN_BUFFER_INFO`

**Description:**
Retrieves information about the specified console screen buffer.

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.

Returns:
CONSOLE_SCREEN_BUFFER_INFO: A CONSOLE_SCREEN_BUFFER_INFO ctype struct contain information about
screen size, cursor position, colour attributes, and more.

**Line:** 228

---

### `def SetConsoleCursorPosition(std_handle: wintypes.HANDLE, coords: WindowsCoordinates) -> bool`

**Description:**
Set the position of the cursor in the console screen

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
coords (WindowsCoordinates): The coordinates to move the cursor to.

Returns:
bool: True if the function succeeds, otherwise False.

**Line:** 252

---

### `def GetConsoleCursorInfo(std_handle: wintypes.HANDLE, cursor_info: CONSOLE_CURSOR_INFO) -> bool`

**Description:**
Get the cursor info - used to get cursor visibility and width

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
cursor_info (CONSOLE_CURSOR_INFO): CONSOLE_CURSOR_INFO ctype struct that receives information
about the console's cursor.

Returns:
bool: True if the function succeeds, otherwise False.

**Line:** 275

---

### `def SetConsoleCursorInfo(std_handle: wintypes.HANDLE, cursor_info: CONSOLE_CURSOR_INFO) -> bool`

**Description:**
Set the cursor info - used for adjusting cursor visibility and width

Args:
std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
cursor_info (CONSOLE_CURSOR_INFO): CONSOLE_CURSOR_INFO ctype struct containing the new cursor info.

Returns:
bool: True if the function succeeds, otherwise False.

**Line:** 299

---

### `def SetConsoleTitle(title: str) -> bool`

**Description:**
Sets the title of the current console window

Args:
title (str): The new title of the console window.

Returns:
bool: True if the function succeeds, otherwise False.

**Line:** 319

---


## Module: venv2.libthon3.12.site-packages.rich._windows
**File:** `venv2/lib/python3.12/site-packages/rich/_windows.py`

**Imports:**
- ctypes
- ctypes.LibraryLoader
- dataclasses.dataclass
- platform
- rich._win32_console.ENABLE_VIRTUAL_TERMINAL_PROCESSING
- rich._win32_console.GetConsoleMode
- rich._win32_console.GetStdHandle
- rich._win32_console.LegacyWindowsError
- rich.print
- sys

**Functions:**

### `def get_windows_console_features() -> WindowsConsoleFeatures`

**Line:** 34

---

### `def get_windows_console_features() -> WindowsConsoleFeatures`

**Description:**
Get windows console features.

Returns:
WindowsConsoleFeatures: An instance of WindowsConsoleFeatures.

**Line:** 40

---


## Module: venv2.libthon3.12.site-packages.rich._windows_renderer
**File:** `venv2/lib/python3.12/site-packages/rich/_windows_renderer.py`

**Imports:**
- rich._win32_console.LegacyWindowsTerm
- rich._win32_console.WindowsCoordinates
- rich.segment.ControlCode
- rich.segment.ControlType
- rich.segment.Segment
- typing.Iterable
- typing.Sequence
- typing.Tuple
- typing.cast

**Functions:**

### `def legacy_windows_render(buffer: Iterable[Segment], term: LegacyWindowsTerm) -> None`

**Description:**
Makes appropriate Windows Console API calls based on the segments in the buffer.

Args:
buffer (Iterable[Segment]): Iterable of Segments to convert to Win32 API calls.
term (LegacyWindowsTerm): Used to call the Windows Console API.

**Line:** 7

---


## Module: venv2.libthon3.12.site-packages.rich._wrap
**File:** `venv2/lib/python3.12/site-packages/rich/_wrap.py`

**Imports:**
- __future__.annotations
- _loop.loop_last
- cells.cell_len
- cells.chop_cells
- console.Console
- re
- typing.Iterable

**Functions:**

### `def words(text: str) -> Iterable[tuple[(int, int, str)]]`

**Description:**
Yields each word from the text as a tuple
containing (start_index, end_index, word). A "word" in this context may
include the actual word and any whitespace to the right.

**Line:** 12

---

### `def divide_line(text: str, width: int, fold: bool = True) -> list[int]`

**Description:**
Given a string of text, and a width (measured in cells), return a list
of cell offsets which the string should be split at in order for it to fit
within the given width.

Args:
text: The text to examine.
width: The available cell width.
fold: If True, words longer than `width` will be folded onto a new line.

Returns:
A list of indices to break the line at.

**Line:** 26

---


## Module: venv2.libthon3.12.site-packages.rich.ansi
**File:** `venv2/lib/python3.12/site-packages/rich/ansi.py`

**Imports:**
- color.Color
- console.Console
- contextlib.suppress
- io
- os
- pty
- re
- style.Style
- sys
- text.Text
- typing.Iterable
- typing.NamedTuple
- typing.Optional

**Functions:**

### `def _ansi_tokenize(ansi_text: str) -> Iterable[_AnsiToken]`

**Description:**
Tokenize a string in to plain text and ANSI codes.

Args:
ansi_text (str): A String containing ANSI codes.

Yields:
AnsiToken: A named tuple of (plain, sgr, osc)

**Line:** 28

---

### `def read(fd: int) -> bytes`

**Line:** 224

---


## Module: venv2.libthon3.12.site-packages.rich.cells
**File:** `venv2/lib/python3.12/site-packages/rich/cells.py`

**Imports:**
- __future__.annotations
- _cell_widths.CELL_WIDTHS
- functools.lru_cache
- typing.Callable

**Functions:**

### `def cached_cell_len(text: str) -> int`

**Decorators:**
- `@lru_cache(...)`

**Description:**
Get the number of cells required to display text.

This method always caches, which may use up a lot of memory. It is recommended to use
`cell_len` over this method.

Args:
text (str): Text to display.

Returns:
int: Get the number of cells required to display text.

**Line:** 34

---

### `def cell_len(text: str, _cell_len: Callable[([str], int)] = cached_cell_len) -> int`

**Description:**
Get the number of cells required to display text.

Args:
text (str): Text to display.

Returns:
int: Get the number of cells required to display text.

**Line:** 51

---

### `def get_character_cell_size(character: str) -> int`

**Decorators:**
- `@lru_cache(...)`

**Description:**
Get the cell size of a character.

Args:
character (str): A single character.

Returns:
int: Number of cells (0, 1 or 2) occupied by that character.

**Line:** 68

---

### `def set_cell_size(text: str, total: int) -> str`

**Description:**
Set the length of a string to fit within given number of cells.

**Line:** 96

---

### `def chop_cells(text: str, width: int) -> list[str]`

**Description:**
Split text into lines such that each line fits within the available (cell) width.

Args:
text: The text to fold such that it fits in the given width.
width: The width available (number of cells).

Returns:
A list of strings such that each string in the list has cell width
less than or equal to the available width.

**Line:** 131

---


## Module: venv2.libthon3.12.site-packages.rich.color
**File:** `venv2/lib/python3.12/site-packages/rich/color.py`

**Imports:**
- _palettes.EIGHT_BIT_PALETTE
- _palettes.STANDARD_PALETTE
- _palettes.WINDOWS_PALETTE
- color_triplet.ColorTriplet
- colorsys.rgb_to_hls
- console.Console
- enum.IntEnum
- functools.lru_cache
- re
- repr.Result
- repr.rich_repr
- style.Style
- sys
- table.Table
- terminal_theme.DEFAULT_TERMINAL_THEME
- terminal_theme.TerminalTheme
- text.Text
- typing.NamedTuple
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple

**Functions:**

### `def parse_rgb_hex(hex_color: str) -> ColorTriplet`

**Description:**
Parse six hex characters in to RGB triplet.

**Line:** 571

---

### `def blend_rgb(color1: ColorTriplet, color2: ColorTriplet, cross_fade: float = 0.5) -> ColorTriplet`

**Description:**
Blend one RGB color in to another.

**Line:** 580

---


## Module: venv2.libthon3.12.site-packages.rich.console
**File:** `venv2/lib/python3.12/site-packages/rich/console.py`

**Imports:**
- _emoji_replace._emoji_replace
- _export_format.CONSOLE_HTML_FORMAT
- _export_format.CONSOLE_SVG_FORMAT
- _fileno.get_fileno
- _log_render.FormatTimeCallable
- _log_render.LogRender
- _windows.WindowsConsoleFeatures
- _windows.get_windows_console_features
- abc.ABC
- abc.abstractmethod
- align.Align
- align.AlignMethod
- color.ColorSystem
- color.blend_rgb
- control.Control
- dataclasses.dataclass
- dataclasses.field
- datetime.datetime
- emoji.EmojiVariant
- functools.wraps
- getpass.getpass
- highlighter.NullHighlighter
- highlighter.ReprHighlighter
- html.escape
- inspect
- inspect.isclass
- itertools.islice
- jupyter.display
- live.Live
- markup.render
- math.ceil
- measure.Measurement
- measure.measure_renderables
- os
- pager.Pager
- pager.SystemPager
- pretty.Pretty
- pretty.is_expandable
- protocol.rich_cast
- region.Region
- rich._null_file.NULL_FILE
- rich._win32_console.LegacyWindowsTerm
- rich._windows_renderer.legacy_windows_render
- rich.cells.cell_len
- rich.json.JSON
- rule.Rule
- scope.render_scope
- screen.Screen
- segment.Segment
- status.Status
- style.Style
- style.StyleType
- styled.Styled
- sys
- terminal_theme.DEFAULT_TERMINAL_THEME
- terminal_theme.SVG_EXPORT_THEME
- terminal_theme.TerminalTheme
- text.Text
- text.TextType
- theme.Theme
- theme.ThemeStack
- threading
- time.monotonic
- traceback.Traceback
- types.FrameType
- types.ModuleType
- types.TracebackType
- typing.Any
- typing.Callable
- typing.Dict
- typing.IO
- typing.Iterable
- typing.List
- typing.Literal
- typing.Mapping
- typing.NamedTuple
- typing.Optional
- typing.Protocol
- typing.TYPE_CHECKING
- typing.TextIO
- typing.Tuple
- typing.Type
- typing.Union
- typing.cast
- typing.runtime_checkable
- typing_extensions.Literal
- typing_extensions.Protocol
- typing_extensions.runtime_checkable
- zlib

**Functions:**

### `def group(fit: bool = True) -> Callable[(..., Callable[..., Group])]`

**Description:**
A decorator that turns an iterable of renderables in to a group.

Args:
fit (bool, optional): Fit dimension of group to contents, or fill available space. Defaults to True.

**Line:** 495

---

### `def _is_jupyter() -> bool`

**Description:**
Check if we're running in a Jupyter notebook.

**Line:** 517

---

### `def get_windows_console_features() -> 'WindowsConsoleFeatures'`

**Line:** 578

---

### `def detect_legacy_windows() -> bool`

**Description:**
Detect legacy Windows.

**Line:** 588

---

### `def _svg_hash(svg_main_code: str) -> str`

**Description:**
Returns a unique hash for the given SVG main code.

Args:
svg_main_code (str): The content we're going to inject in the SVG envelope.

Returns:
str: a hash of the given content

**Line:** 2596

---


## Module: venv2.libthon3.12.site-packages.rich.control
**File:** `venv2/lib/python3.12/site-packages/rich/control.py`

**Imports:**
- console.Console
- console.ConsoleOptions
- console.RenderResult
- rich.console.Console
- segment.ControlCode
- segment.ControlType
- segment.Segment
- sys
- time
- typing.Callable
- typing.Dict
- typing.Final
- typing.Iterable
- typing.List
- typing.TYPE_CHECKING
- typing.Union
- typing_extensions.Final

**Functions:**

### `def strip_control_codes(text: str, _translate_table: Dict[(int, None)] = _CONTROL_STRIP_TRANSLATE) -> str`

**Description:**
Remove control codes from text.

Args:
text (str): A string possibly contain control codes.

Returns:
str: String with control codes removed.

**Line:** 187

---

### `def escape_control_codes(text: str, _translate_table: Dict[(int, str)] = CONTROL_ESCAPE) -> str`

**Description:**
Replace control codes with their "escaped" equivalent in the given text.
(e.g. "" becomes "\b")

Args:
text (str): A string possibly containing control codes.

Returns:
str: String with control codes replaced with their escaped version.

**Line:** 201

---


## Module: venv2.libthon3.12.site-packages.rich.diagnose
**File:** `venv2/lib/python3.12/site-packages/rich/diagnose.py`

**Imports:**
- os
- platform
- rich.console.Console
- rich.console.get_windows_console_features
- rich.inspect
- rich.panel.Panel
- rich.pretty.Pretty

**Functions:**

### `def report() -> None`

**Description:**
Print a report to the terminal with debugging information

**Line:** 10

---


## Module: venv2.libthon3.12.site-packages.rich.filesize
**File:** `venv2/lib/python3.12/site-packages/rich/filesize.py`

**Imports:**
- typing.Iterable
- typing.List
- typing.Optional
- typing.Tuple

**Functions:**

### `def _to_str(size: int, suffixes: Iterable[str], base: int, precision: Optional[int] = 1, separator: Optional[str] = ' ') -> str`

**Line:** 18

---

### `def pick_unit_and_suffix(size: int, suffixes: List[str], base: int) -> Tuple[(int, str)]`

**Description:**
Pick a suffix and base for the given size.

**Line:** 43

---

### `def decimal(size: int, precision: Optional[int] = 1, separator: Optional[str] = ' ') -> str`

**Description:**
Convert a filesize in to a string (powers of 1000, SI prefixes).

In this convention, ``1000 B = 1 kB``.

This is typically the format used to advertise the storage
capacity of USB flash drives and the like (*256 MB* meaning
actually a storage capacity of more than *256 000 000 B*),
or used by **Mac OS X** since v10.6 to report file sizes.

Arguments:
int (size): A file size.
int (precision): The number of decimal places to include (default = 1).
str (separator): The string to separate the value from the units (default = " ").

Returns:
`str`: A string containing a abbreviated file size and units.

Example:
>>> filesize.decimal(30000)
'30.0 kB'
>>> filesize.decimal(30000, precision=2, separator="")
'30.00kB'

**Line:** 52

---


## Module: venv2.libthon3.12.site-packages.rich.highlighter
**File:** `venv2/lib/python3.12/site-packages/rich/highlighter.py`

**Imports:**
- abc.ABC
- abc.abstractmethod
- console.Console
- json
- re
- text.Span
- text.Text
- typing.List
- typing.Union

**Functions:**

### `def _combine_regex(*regexes: str) -> str`

**Description:**
Combine a number of regexes in to a single regex.

Returns:
str: New regex with all regexes ORed together.

**Line:** 8

---


## Module: venv2.libthon3.12.site-packages.rich.jupyter
**File:** `venv2/lib/python3.12/site-packages/rich/jupyter.py`

**Imports:**
- IPython.display.display
- rich.console.ConsoleRenderable
- segment.Segment
- terminal_theme.DEFAULT_TERMINAL_THEME
- typing.Any
- typing.Dict
- typing.Iterable
- typing.List
- typing.Sequence
- typing.TYPE_CHECKING

**Functions:**

### `def _render_segments(segments: Iterable[Segment]) -> str`

**Line:** 59

---

### `def display(segments: Iterable[Segment], text: str) -> None`

**Description:**
Render segments to Jupyter.

**Line:** 84

---

### `def print(*args: Any, **kwargs: Any) -> None`

**Description:**
Proxy for Console print.

**Line:** 98

---


## Module: venv2.libthon3.12.site-packages.rich.logging
**File:** `venv2/lib/python3.12/site-packages/rich/logging.py`

**Imports:**
- _log_render.FormatTimeCallable
- _log_render.LogRender
- console.Console
- console.ConsoleRenderable
- datetime.datetime
- highlighter.Highlighter
- highlighter.ReprHighlighter
- logging
- logging.Handler
- logging.LogRecord
- pathlib.Path
- rich._null_file.NullFile
- text.Text
- time.sleep
- traceback.Traceback
- types.ModuleType
- typing.ClassVar
- typing.Iterable
- typing.List
- typing.Optional
- typing.Type
- typing.Union

**Functions:**

### `def divide() -> None`

**Line:** 283

---


## Module: venv2.libthon3.12.site-packages.rich.markup
**File:** `venv2/lib/python3.12/site-packages/rich/markup.py`

**Imports:**
- _emoji_replace._emoji_replace
- ast.literal_eval
- emoji.EmojiVariant
- errors.MarkupError
- operator.attrgetter
- re
- rich.print
- rich.table.Table
- style.Style
- text.Span
- text.Text
- typing.Callable
- typing.Iterable
- typing.List
- typing.Match
- typing.NamedTuple
- typing.Optional
- typing.Tuple
- typing.Union

**Functions:**

### `def escape(markup: str, _escape: _EscapeSubMethod) -> str`

**Description:**
Escapes text so that it won't be interpreted as markup.

Args:
markup (str): Content to be inserted in to markup.

Returns:
str: Markup with square brackets escaped.

**Line:** 48

---

### `def _parse(markup: str) -> Iterable[Tuple[(int, Optional[str], Optional[Tag])]]`

**Description:**
Parse markup in to an iterable of tuples of (position, text, tag).

Args:
markup (str): A string containing console markup

**Line:** 73

---

### `def render(markup: str, style: Union[(str, Style)] = '', emoji: bool = True, emoji_variant: Optional[EmojiVariant] = None) -> Text`

**Description:**
Render console markup in to a Text instance.

Args:
markup (str): A string containing console markup.
style: (Union[str, Style]): The style to use.
emoji (bool, optional): Also render emoji code. Defaults to True.
emoji_variant (str, optional): Optional emoji variant, either "text" or "emoji". Defaults to None.


Raises:
MarkupError: If there is a syntax error in the markup.

Returns:
Text: A test instance.

**Line:** 106

---


## Module: venv2.libthon3.12.site-packages.rich.measure
**File:** `venv2/lib/python3.12/site-packages/rich/measure.py`

**Imports:**
- console.Console
- console.ConsoleOptions
- console.RenderableType
- operator.itemgetter
- protocol.is_renderable
- protocol.rich_cast
- typing.Callable
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING

**Functions:**

### `def measure_renderables(console: 'Console', options: 'ConsoleOptions', renderables: Sequence['RenderableType']) -> 'Measurement'`

**Description:**
Get a measurement that would fit a number of renderables.

Args:
console (~rich.console.Console): Console instance.
options (~rich.console.ConsoleOptions): Console options.
renderables (Iterable[RenderableType]): One or more renderable objects.

Returns:
Measurement: Measurement object containing range of character widths required to
contain all given renderables.

**Line:** 125

---


## Module: venv2.libthon3.12.site-packages.rich.pretty
**File:** `venv2/lib/python3.12/site-packages/rich/pretty.py`

**Imports:**
- IPython.core.formatters.BaseFormatter
- _loop.loop_last
- _pick.pick_bool
- abc.RichRenderable
- array.array
- attr
- builtins
- cells.cell_len
- collections
- collections.Counter
- collections.UserDict
- collections.UserList
- collections.defaultdict
- collections.deque
- console.Console
- console.ConsoleOptions
- console.ConsoleRenderable
- console.HighlighterType
- console.JustifyMethod
- console.OverflowMethod
- console.RenderResult
- dataclasses
- dataclasses.dataclass
- dataclasses.fields
- dataclasses.is_dataclass
- highlighter.ReprHighlighter
- inspect
- inspect.isclass
- itertools.islice
- jupyter.JupyterMixin
- jupyter.JupyterRenderable
- measure.Measurement
- os
- reprlib
- rich.get_console
- rich.print
- rich.repr.RichReprResult
- sys
- text.Text
- types.MappingProxyType
- typing.Any
- typing.Callable
- typing.DefaultDict
- typing.Deque
- typing.Dict
- typing.Iterable
- typing.List
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union

**Functions:**

### `def _is_attr_object(obj: Any) -> bool`

**Description:**
Check if an object was created with attrs module.

**Line:** 60

---

### `def _get_attr_fields(obj: Any) -> Sequence['_attr_module.Attribute[Any]']`

**Description:**
Get fields for an attrs object.

**Line:** 65

---

### `def _is_dataclass_repr(obj: object) -> bool`

**Description:**
Check if an instance of a dataclass contains the default repr.

Args:
obj (object): A dataclass instance.

Returns:
bool: True if the default repr is used, False if there is a custom repr.

**Line:** 70

---

### `def _has_default_namedtuple_repr(obj: object) -> bool`

**Description:**
Check if an instance of namedtuple contains the default repr

Args:
obj (object): A namedtuple

Returns:
bool: True if the default repr is used, False if there's a custom repr.

**Line:** 93

---

### `def _ipy_display_hook(value: Any, console: Optional['Console'] = None, overflow: 'OverflowMethod' = 'ignore', crop: bool = False, indent_guides: bool = False, max_length: Optional[int] = None, max_string: Optional[int] = None, max_depth: Optional[int] = None, expand_all: bool = False) -> Union[(str, None)]`

**Line:** 113

---

### `def _safe_isinstance(obj: object, class_or_tuple: Union[(type, Tuple[type, ...])]) -> bool`

**Description:**
isinstance can fail in rare cases, for example types with no __class__

**Line:** 161

---

### `def install(console: Optional['Console'] = None, overflow: 'OverflowMethod' = 'ignore', crop: bool = False, indent_guides: bool = False, max_length: Optional[int] = None, max_string: Optional[int] = None, max_depth: Optional[int] = None, expand_all: bool = False) -> None`

**Description:**
Install automatic pretty printing in the Python REPL.

Args:
console (Console, optional): Console instance or ``None`` to use global console. Defaults to None.
overflow (Optional[OverflowMethod], optional): Overflow method. Defaults to "ignore".
crop (Optional[bool], optional): Enable cropping of long lines. Defaults to False.
indent_guides (bool, optional): Enable indentation guides. Defaults to False.
max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
Defaults to None.
max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.
max_depth (int, optional): Maximum depth of nested data structures, or None for no maximum. Defaults to None.
expand_all (bool, optional): Expand all containers. Defaults to False.
max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.

**Line:** 171

---

### `def _get_braces_for_defaultdict(_object: DefaultDict[(Any, Any)]) -> Tuple[(str, str, str)]`

**Line:** 357

---

### `def _get_braces_for_deque(_object: Deque[Any]) -> Tuple[(str, str, str)]`

**Line:** 365

---

### `def _get_braces_for_array(_object: 'array[Any]') -> Tuple[(str, str, str)]`

**Line:** 375

---

### `def is_expandable(obj: Any) -> bool`

**Description:**
Check if an object may be expanded by pretty print.

**Line:** 398

---

### `def _is_namedtuple(obj: Any) -> bool`

**Description:**
Checks if an object is most likely a namedtuple. It is possible
to craft an object that passes this check and isn't a namedtuple, but
there is only a minuscule chance of this happening unintentionally.

Args:
obj (Any): The object to test

Returns:
bool: True if the object is a namedtuple. False otherwise.

**Line:** 561

---

### `def traverse(_object: Any, max_length: Optional[int] = None, max_string: Optional[int] = None, max_depth: Optional[int] = None) -> Node`

**Description:**
Traverse object and generate a tree.

Args:
_object (Any): Object to be traversed.
max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
Defaults to None.
max_string (int, optional): Maximum length of string before truncating, or None to disable truncating.
Defaults to None.
max_depth (int, optional): Maximum depth of data structures, or None for no maximum.
Defaults to None.

Returns:
Node: The root of a tree structure which can be used to render a pretty repr.

**Line:** 580

---

### `def pretty_repr(_object: Any, max_width: int = 80, indent_size: int = 4, max_length: Optional[int] = None, max_string: Optional[int] = None, max_depth: Optional[int] = None, expand_all: bool = False) -> str`

**Description:**
Prettify repr string by expanding on to new lines to fit within a given width.

Args:
_object (Any): Object to repr.
max_width (int, optional): Desired maximum width of repr string. Defaults to 80.
indent_size (int, optional): Number of spaces to indent. Defaults to 4.
max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
Defaults to None.
max_string (int, optional): Maximum length of string before truncating, or None to disable truncating.
Defaults to None.
max_depth (int, optional): Maximum depth of nested data structure, or None for no depth.
Defaults to None.
expand_all (bool, optional): Expand all containers regardless of available width. Defaults to False.

Returns:
str: A possibly multi-line representation of the object.

**Line:** 878

---

### `def pprint(_object: Any, console: Optional['Console'] = None, indent_guides: bool = True, max_length: Optional[int] = None, max_string: Optional[int] = None, max_depth: Optional[int] = None, expand_all: bool = False) -> None`

**Description:**
A convenience function for pretty printing.

Args:
_object (Any): Object to pretty print.
console (Console, optional): Console instance, or None to use default. Defaults to None.
max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
Defaults to None.
max_string (int, optional): Maximum length of strings before truncating, or None to disable. Defaults to None.
max_depth (int, optional): Maximum depth for nested data structures, or None for unlimited depth. Defaults to None.
indent_guides (bool, optional): Enable indentation guides. Defaults to True.
expand_all (bool, optional): Expand all containers. Defaults to False.

**Line:** 918

---


## Module: venv2.libthon3.12.site-packages.rich.progress
**File:** `venv2/lib/python3.12/site-packages/rich/progress.py`

**Imports:**
- abc.ABC
- abc.abstractmethod
- collections.deque
- console.Console
- console.Group
- console.JustifyMethod
- console.RenderableType
- dataclasses.dataclass
- dataclasses.field
- datetime.timedelta
- highlighter.Highlighter
- io
- io.RawIOBase
- io.UnsupportedOperation
- itertools.cycle
- jupyter.JupyterMixin
- live.Live
- math.ceil
- mmap.mmap
- operator.length_hint
- os.PathLike
- os.stat
- panel.Panel
- progress_bar.ProgressBar
- random
- rule.Rule
- spinner.Spinner
- style.StyleType
- syntax.Syntax
- sys
- table.Column
- table.Table
- text.Text
- text.TextType
- threading.Event
- threading.RLock
- threading.Thread
- time
- types.TracebackType
- typing
- typing.Any
- typing.BinaryIO
- typing.Callable
- typing.ContextManager
- typing.Deque
- typing.Dict
- typing.Generic
- typing.Iterable
- typing.List
- typing.Literal
- typing.NamedTuple
- typing.NewType
- typing.Optional
- typing.Self
- typing.Sequence
- typing.TextIO
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing_extensions.Literal
- typing_extensions.Self
- warnings

**Functions:**

### `def track(sequence: Union[(Sequence[ProgressType], Iterable[ProgressType])], description: str = 'Working...', total: Optional[float] = None, completed: int = 0, auto_refresh: bool = True, console: Optional[Console] = None, transient: bool = False, get_time: Optional[Callable[([], float)]] = None, refresh_per_second: float = 10, style: StyleType = 'bar.back', complete_style: StyleType = 'bar.complete', finished_style: StyleType = 'bar.finished', pulse_style: StyleType = 'bar.pulse', update_period: float = 0.1, disable: bool = False, show_speed: bool = True) -> Iterable[ProgressType]`

**Description:**
Track progress by iterating over a sequence.

Args:
sequence (Iterable[ProgressType]): A sequence (must support "len") you wish to iterate over.
description (str, optional): Description of task show next to progress bar. Defaults to "Working".
total: (float, optional): Total number of steps. Default is len(sequence).
completed (int, optional): Number of steps completed so far. Defaults to 0.
auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
transient: (bool, optional): Clear the progress on exit. Defaults to False.
console (Console, optional): Console to write to. Default creates internal Console instance.
refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
update_period (float, optional): Minimum time (in seconds) between calls to update(). Defaults to 0.1.
disable (bool, optional): Disable display of progress.
show_speed (bool, optional): Show speed if total isn't known. Defaults to True.
Returns:
Iterable[ProgressType]: An iterable of the values in the sequence.

**Line:** 108

---

### `def wrap_file(file: BinaryIO, total: int, description: str = 'Reading...', auto_refresh: bool = True, console: Optional[Console] = None, transient: bool = False, get_time: Optional[Callable[([], float)]] = None, refresh_per_second: float = 10, style: StyleType = 'bar.back', complete_style: StyleType = 'bar.complete', finished_style: StyleType = 'bar.finished', pulse_style: StyleType = 'bar.pulse', disable: bool = False) -> ContextManager[BinaryIO]`

**Description:**
Read bytes from a file while tracking progress.

Args:
file (Union[str, PathLike[str], BinaryIO]): The path to the file to read, or a file-like object in binary mode.
total (int): Total number of bytes to read.
description (str, optional): Description of task show next to progress bar. Defaults to "Reading".
auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
transient: (bool, optional): Clear the progress on exit. Defaults to False.
console (Console, optional): Console to write to. Default creates internal Console instance.
refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
disable (bool, optional): Disable display of progress.
Returns:
ContextManager[BinaryIO]: A context manager yielding a progress reader.

**Line:** 308

---

### `def open(file: Union[(str, 'PathLike[str]', bytes)], mode: Union[(Literal['rt'], Literal['r'])], buffering: int = -1, encoding: Optional[str] = None, errors: Optional[str] = None, newline: Optional[str] = None, total: Optional[int] = None, description: str = 'Reading...', auto_refresh: bool = True, console: Optional[Console] = None, transient: bool = False, get_time: Optional[Callable[([], float)]] = None, refresh_per_second: float = 10, style: StyleType = 'bar.back', complete_style: StyleType = 'bar.complete', finished_style: StyleType = 'bar.finished', pulse_style: StyleType = 'bar.pulse', disable: bool = False) -> ContextManager[TextIO]`

**Decorators:**
- `@typing.overload`

**Line:** 374

---

### `def open(file: Union[(str, 'PathLike[str]', bytes)], mode: Literal['rb'], buffering: int = -1, encoding: Optional[str] = None, errors: Optional[str] = None, newline: Optional[str] = None, total: Optional[int] = None, description: str = 'Reading...', auto_refresh: bool = True, console: Optional[Console] = None, transient: bool = False, get_time: Optional[Callable[([], float)]] = None, refresh_per_second: float = 10, style: StyleType = 'bar.back', complete_style: StyleType = 'bar.complete', finished_style: StyleType = 'bar.finished', pulse_style: StyleType = 'bar.pulse', disable: bool = False) -> ContextManager[BinaryIO]`

**Decorators:**
- `@typing.overload`

**Line:** 399

---

### `def open(file: Union[(str, 'PathLike[str]', bytes)], mode: Union[(Literal['rb'], Literal['rt'], Literal['r'])] = 'r', buffering: int = -1, encoding: Optional[str] = None, errors: Optional[str] = None, newline: Optional[str] = None, total: Optional[int] = None, description: str = 'Reading...', auto_refresh: bool = True, console: Optional[Console] = None, transient: bool = False, get_time: Optional[Callable[([], float)]] = None, refresh_per_second: float = 10, style: StyleType = 'bar.back', complete_style: StyleType = 'bar.complete', finished_style: StyleType = 'bar.finished', pulse_style: StyleType = 'bar.pulse', disable: bool = False) -> Union[(ContextManager[BinaryIO], ContextManager[TextIO])]`

**Description:**
Read bytes from a file while tracking progress.

Args:
path (Union[str, PathLike[str], BinaryIO]): The path to the file to read, or a file-like object in binary mode.
mode (str): The mode to use to open the file. Only supports "r", "rb" or "rt".
buffering (int): The buffering strategy to use, see :func:`io.open`.
encoding (str, optional): The encoding to use when reading in text mode, see :func:`io.open`.
errors (str, optional): The error handling strategy for decoding errors, see :func:`io.open`.
newline (str, optional): The strategy for handling newlines in text mode, see :func:`io.open`
total: (int, optional): Total number of bytes to read. Must be provided if reading from a file handle. Default for a path is os.stat(file).st_size.
description (str, optional): Description of task show next to progress bar. Defaults to "Reading".
auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
transient: (bool, optional): Clear the progress on exit. Defaults to False.
console (Console, optional): Console to write to. Default creates internal Console instance.
refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
disable (bool, optional): Disable display of progress.
encoding (str, optional): The encoding to use when reading in text mode.

Returns:
ContextManager[BinaryIO]: A context manager yielding a progress reader.

**Line:** 423

---


## Module: venv2.libthon3.12.site-packages.rich.protocol
**File:** `venv2/lib/python3.12/site-packages/rich/protocol.py`

**Imports:**
- inspect.isclass
- rich.console.RenderableType
- typing.Any
- typing.Set
- typing.TYPE_CHECKING
- typing.cast

**Functions:**

### `def is_renderable(check_object: Any) -> bool`

**Description:**
Check if an object may be rendered by Rich.

**Line:** 10

---

### `def rich_cast(renderable: object) -> 'RenderableType'`

**Description:**
Cast an object to a renderable by calling __rich__ if present.

Args:
renderable (object): A potentially renderable object

Returns:
object: The result of recursively calling __rich__.

**Line:** 19

---


## Module: venv2.libthon3.12.site-packages.rich.repr
**File:** `venv2/lib/python3.12/site-packages/rich/repr.py`

**Imports:**
- functools.partial
- inspect
- rich.console.Console
- typing.Any
- typing.Callable
- typing.Iterable
- typing.List
- typing.Optional
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.overload

**Functions:**

### `def auto(cls: Optional[Type[T]]) -> Type[T]`

**Decorators:**
- `@overload`

**Line:** 28

---

### `def auto(angular: bool = False) -> Callable[([Type[T]], Type[T])]`

**Decorators:**
- `@overload`

**Line:** 33

---

### `def auto(cls: Optional[Type[T]] = None, angular: Optional[bool] = None) -> Union[(Type[T], Callable[[Type[T]], Type[T]])]`

**Description:**
Class decorator to create __repr__ from __rich_repr__

**Line:** 37

---

### `def rich_repr(cls: Optional[Type[T]]) -> Type[T]`

**Decorators:**
- `@overload`

**Line:** 105

---

### `def rich_repr(angular: bool = False) -> Callable[([Type[T]], Type[T])]`

**Decorators:**
- `@overload`

**Line:** 110

---

### `def rich_repr(cls: Optional[Type[T]] = None, angular: bool = False) -> Union[(Type[T], Callable[[Type[T]], Type[T]])]`

**Line:** 114

---


## Module: venv2.libthon3.12.site-packages.rich.scope
**File:** `venv2/lib/python3.12/site-packages/rich/scope.py`

**Imports:**
- collections.abc.Mapping
- console.ConsoleRenderable
- highlighter.ReprHighlighter
- panel.Panel
- pretty.Pretty
- rich.print
- table.Table
- text.Text
- text.TextType
- typing.Any
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple

**Functions:**

### `def render_scope(scope: 'Mapping[str, Any]', title: Optional[TextType] = None, sort_keys: bool = True, indent_guides: bool = False, max_length: Optional[int] = None, max_string: Optional[int] = None) -> 'ConsoleRenderable'`

**Description:**
Render python variables in a given scope.

Args:
scope (Mapping): A mapping containing variable names and values.
title (str, optional): Optional title. Defaults to None.
sort_keys (bool, optional): Enable sorting of items. Defaults to True.
indent_guides (bool, optional): Enable indentation guides. Defaults to False.
max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
Defaults to None.
max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.

Returns:
ConsoleRenderable: A renderable object.

**Line:** 14

---

### `def test(foo: float, bar: float) -> None`

**Line:** 75

---


## Module: venv2.libthon3.12.site-packages.rich.syntax
**File:** `venv2/lib/python3.12/site-packages/rich/syntax.py`

**Imports:**
- _loop.loop_first
- abc.ABC
- abc.abstractmethod
- argparse
- cells.cell_len
- color.Color
- color.blend_rgb
- console.Console
- console.ConsoleOptions
- console.JustifyMethod
- console.RenderResult
- jupyter.JupyterMixin
- measure.Measurement
- os.path
- pathlib.Path
- pygments.lexer.Lexer
- pygments.lexers.get_lexer_by_name
- pygments.lexers.guess_lexer_for_filename
- pygments.style.Style
- pygments.styles.get_style_by_name
- pygments.token.Comment
- pygments.token.Error
- pygments.token.Generic
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.String
- pygments.token.Token
- pygments.token.Whitespace
- pygments.util.ClassNotFound
- re
- rich.console.Console
- rich.containers.Lines
- rich.padding.Padding
- rich.padding.PaddingDimensions
- segment.Segment
- segment.Segments
- style.Style
- style.StyleType
- sys
- text.Text
- textwrap
- typing.Any
- typing.Dict
- typing.Iterable
- typing.List
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.Set
- typing.Tuple
- typing.Type
- typing.Union

**Functions:**

### `def _get_code_index_for_syntax_position(newlines_offsets: Sequence[int], position: SyntaxPosition) -> Optional[int]`

**Description:**
Returns the index of the code string for the given positions.

Args:
newlines_offsets (Sequence[int]): The offset of each newline character found in the code snippet.
position (SyntaxPosition): The position to search for.

Returns:
Optional[int]: The index of the code string for this position, or `None`
if the given position's line number is out of range (if it's the column that is out of range
we silently clamp its value so that it reaches the end of the line)

**Line:** 822

---


## Module: venv2.libthon3.12.site-packages.rich.table
**File:** `venv2/lib/python3.12/site-packages/rich/table.py`

**Imports:**
- _loop.loop_first_last
- _loop.loop_last
- _pick.pick_bool
- _ratio.ratio_distribute
- _ratio.ratio_reduce
- _timer.timer
- align.VerticalAlignMethod
- console.Console
- console.ConsoleOptions
- console.JustifyMethod
- console.OverflowMethod
- console.RenderResult
- console.RenderableType
- dataclasses.dataclass
- dataclasses.field
- dataclasses.replace
- jupyter.JupyterMixin
- measure.Measurement
- padding.Padding
- padding.PaddingDimensions
- protocol.is_renderable
- rich.console.Console
- rich.highlighter.ReprHighlighter
- rich.table.Table
- segment.Segment
- style.Style
- style.StyleType
- text.Text
- text.TextType
- typing.Dict
- typing.Iterable
- typing.List
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union

**Functions:**

### `def header(text: str) -> None`

**Line:** 968

---


## Module: venv2.libthon3.12.site-packages.rich.traceback
**File:** `venv2/lib/python3.12/site-packages/rich/traceback.py`

**Imports:**
- _loop.loop_last
- columns.Columns
- console.Console
- console.ConsoleOptions
- console.ConsoleRenderable
- console.RenderResult
- console.group
- constrain.Constrain
- dataclasses.dataclass
- dataclasses.field
- highlighter.RegexHighlighter
- highlighter.ReprHighlighter
- inspect
- itertools.islice
- linecache
- os
- panel.Panel
- pygments.lexers.guess_lexer_for_filename
- pygments.token.Comment
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.String
- pygments.token.Text
- pygments.token.Token
- pygments.util.ClassNotFound
- rich._IMPORT_CWD
- scope.render_scope
- style.Style
- syntax.Syntax
- sys
- text.Text
- theme.Theme
- traceback.walk_tb
- types.ModuleType
- types.TracebackType
- typing.Any
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.List
- typing.Optional
- typing.Sequence
- typing.Tuple
- typing.Type
- typing.Union

**Functions:**

### `def install(console: Optional[Console] = None, width: Optional[int] = 100, code_width: Optional[int] = 88, extra_lines: int = 3, theme: Optional[str] = None, word_wrap: bool = False, show_locals: bool = False, locals_max_length: int = LOCALS_MAX_LENGTH, locals_max_string: int = LOCALS_MAX_STRING, locals_hide_dunder: bool = True, locals_hide_sunder: Optional[bool] = None, indent_guides: bool = True, suppress: Iterable[Union[(str, ModuleType)]] = (), max_frames: int = 100) -> Callable[([Type[BaseException], BaseException, Optional[TracebackType]], Any)]`

**Description:**
Install a rich traceback handler.

Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.


Args:
console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.
width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.
code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.
extra_lines (int, optional): Extra lines of code. Defaults to 3.
theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick
a theme appropriate for the platform.
word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
show_locals (bool, optional): Enable display of local variables. Defaults to False.
locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
Defaults to 10.
locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.
suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.

Returns:
Callable: The previous exception handler that was replaced.

**Line:** 47

---

### `def bar(a: Any) -> None`

**Line:** 775

---

### `def foo(a: Any) -> None`

**Line:** 781

---

### `def error() -> None`

**Line:** 794

---


## Module: venv2.libthon3.12.site-packages.ruff.__main__
**File:** `venv2/lib/python3.12/site-packages/ruff/__main__.py`

**Imports:**
- os
- pathlib.Path
- subprocess
- sys
- sysconfig

**Functions:**

### `def find_ruff_bin() -> Path`

**Description:**
Return the ruff binary path.

**Line:** 8

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.__init__
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/__init__.py`

**Imports:**
- __future__.annotations
- engine.AdaptedConnection
- engine.BaseRow
- engine.BindTyping
- engine.ChunkedIteratorResult
- engine.Compiled
- engine.Connection
- engine.CreateEnginePlugin
- engine.CursorResult
- engine.Dialect
- engine.Engine
- engine.ExceptionContext
- engine.ExecutionContext
- engine.FrozenResult
- engine.Inspector
- engine.IteratorResult
- engine.MappingResult
- engine.MergedResult
- engine.NestedTransaction
- engine.Result
- engine.ResultProxy
- engine.RootTransaction
- engine.Row
- engine.RowMapping
- engine.ScalarResult
- engine.Transaction
- engine.TwoPhaseTransaction
- engine.TypeCompiler
- engine.URL
- engine.create_engine
- engine.create_mock_engine
- engine.create_pool_from_url
- engine.engine_from_config
- engine.make_url
- engine.result_tuple
- inspection.inspect
- pool.AssertionPool
- pool.AsyncAdaptedQueuePool
- pool.FallbackAsyncAdaptedQueuePool
- pool.NullPool
- pool.Pool
- pool.PoolProxiedConnection
- pool.PoolResetState
- pool.QueuePool
- pool.SingletonThreadPool
- pool.StaticPool
- schema.BLANK_SCHEMA
- schema.BaseDDLElement
- schema.CheckConstraint
- schema.Column
- schema.ColumnDefault
- schema.Computed
- schema.Constraint
- schema.DDL
- schema.DDLElement
- schema.DefaultClause
- schema.ExecutableDDLElement
- schema.FetchedValue
- schema.ForeignKey
- schema.ForeignKeyConstraint
- schema.Identity
- schema.Index
- schema.MetaData
- schema.PrimaryKeyConstraint
- schema.Sequence
- schema.Table
- schema.UniqueConstraint
- schema.insert_sentinel
- sql.ColumnExpressionArgument
- sql.NotNullable
- sql.Nullable
- sql.SelectLabelStyle
- sql.expression.Alias
- sql.expression.AliasedReturnsRows
- sql.expression.BinaryExpression
- sql.expression.BindParameter
- sql.expression.BooleanClauseList
- sql.expression.CTE
- sql.expression.CacheKey
- sql.expression.Case
- sql.expression.Cast
- sql.expression.ClauseElement
- sql.expression.ClauseList
- sql.expression.CollectionAggregate
- sql.expression.ColumnClause
- sql.expression.ColumnCollection
- sql.expression.ColumnElement
- sql.expression.ColumnOperators
- sql.expression.CompoundSelect
- sql.expression.Delete
- sql.expression.Executable
- sql.expression.Exists
- sql.expression.Extract
- sql.expression.False_
- sql.expression.FromClause
- sql.expression.FromGrouping
- sql.expression.Function
- sql.expression.FunctionElement
- sql.expression.FunctionFilter
- sql.expression.GenerativeSelect
- sql.expression.Grouping
- sql.expression.HasCTE
- sql.expression.HasPrefixes
- sql.expression.HasSuffixes
- sql.expression.Insert
- sql.expression.Join
- sql.expression.LABEL_STYLE_DEFAULT
- sql.expression.LABEL_STYLE_DISAMBIGUATE_ONLY
- sql.expression.LABEL_STYLE_NONE
- sql.expression.LABEL_STYLE_TABLENAME_PLUS_COL
- sql.expression.Label
- sql.expression.LambdaElement
- sql.expression.Lateral
- sql.expression.Null
- sql.expression.Operators
- sql.expression.Over
- sql.expression.ReleaseSavepointClause
- sql.expression.ReturnsRows
- sql.expression.RollbackToSavepointClause
- sql.expression.SQLColumnExpression
- sql.expression.SavepointClause
- sql.expression.ScalarSelect
- sql.expression.Select
- sql.expression.SelectBase
- sql.expression.Selectable
- sql.expression.StatementLambdaElement
- sql.expression.Subquery
- sql.expression.TableClause
- sql.expression.TableSample
- sql.expression.TableValuedAlias
- sql.expression.TextAsFrom
- sql.expression.TextClause
- sql.expression.TextualSelect
- sql.expression.True_
- sql.expression.TryCast
- sql.expression.Tuple
- sql.expression.TypeClause
- sql.expression.TypeCoerce
- sql.expression.UnaryExpression
- sql.expression.Update
- sql.expression.UpdateBase
- sql.expression.Values
- sql.expression.ValuesBase
- sql.expression.Visitable
- sql.expression.WithinGroup
- sql.expression.alias
- sql.expression.all_
- sql.expression.and_
- sql.expression.any_
- sql.expression.asc
- sql.expression.between
- sql.expression.bindparam
- sql.expression.bitwise_not
- sql.expression.case
- sql.expression.cast
- sql.expression.collate
- sql.expression.column
- sql.expression.cte
- sql.expression.custom_op
- sql.expression.delete
- sql.expression.desc
- sql.expression.distinct
- sql.expression.except_
- sql.expression.except_all
- sql.expression.exists
- sql.expression.extract
- sql.expression.false
- sql.expression.func
- sql.expression.funcfilter
- sql.expression.insert
- sql.expression.intersect
- sql.expression.intersect_all
- sql.expression.join
- sql.expression.label
- sql.expression.lambda_stmt
- sql.expression.lateral
- sql.expression.literal
- sql.expression.literal_column
- sql.expression.modifier
- sql.expression.not_
- sql.expression.null
- sql.expression.nulls_first
- sql.expression.nulls_last
- sql.expression.nullsfirst
- sql.expression.nullslast
- sql.expression.or_
- sql.expression.outerjoin
- sql.expression.outparam
- sql.expression.over
- sql.expression.quoted_name
- sql.expression.select
- sql.expression.table
- sql.expression.tablesample
- sql.expression.text
- sql.expression.true
- sql.expression.try_cast
- sql.expression.tuple_
- sql.expression.type_coerce
- sql.expression.union
- sql.expression.union_all
- sql.expression.update
- sql.expression.values
- sql.expression.within_group
- types.ARRAY
- types.BIGINT
- types.BINARY
- types.BLOB
- types.BOOLEAN
- types.BigInteger
- types.Boolean
- types.CHAR
- types.CLOB
- types.DATE
- types.DATETIME
- types.DECIMAL
- types.DOUBLE
- types.DOUBLE_PRECISION
- types.Date
- types.DateTime
- types.Double
- types.Enum
- types.FLOAT
- types.Float
- types.INT
- types.INTEGER
- types.Integer
- types.Interval
- types.JSON
- types.LargeBinary
- types.NCHAR
- types.NUMERIC
- types.NVARCHAR
- types.Numeric
- types.PickleType
- types.REAL
- types.SMALLINT
- types.SmallInteger
- types.String
- types.TEXT
- types.TIME
- types.TIMESTAMP
- types.Text
- types.Time
- types.TupleType
- types.TypeDecorator
- types.UUID
- types.Unicode
- types.UnicodeText
- types.Uuid
- types.VARBINARY
- types.VARCHAR
- typing.Any

**Functions:**

### `def __go(lcls: Any) -> None`

**Line:** 275

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.__init__
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/__init__.py`

**Imports:**
- __future__.annotations
- engine.interfaces.Dialect
- typing.Callable
- typing.Optional
- typing.TYPE_CHECKING
- typing.Type

**Functions:**

### `def _auto_fn(name: str) -> Optional[Callable[([], Type[Dialect])]]`

**Description:**
default dialect importer.

plugs into the :class:`.PluginLoader`
as a first-hit system.

**Line:** 23

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.mssql.base
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/mssql/base.py`

**Imports:**
- __future__.annotations
- codecs
- datetime
- engine.cursor
- engine.default
- engine.reflection
- engine.reflection.ReflectionDefaults
- json.JSON
- json.JSONIndexType
- json.JSONPathType
- operator
- re
- sql._typing.is_sql_compiler
- sql.coercions
- sql.compiler
- sql.compiler.InsertmanyvaluesSentinelOpts
- sql.dml.DMLState
- sql.elements
- sql.elements.TryCast
- sql.expression
- sql.func
- sql.quoted_name
- sql.roles
- sql.selectable.TableClause
- sql.sqltypes
- sql.try_cast
- sql.util
- types.BIGINT
- types.BINARY
- types.CHAR
- types.DATE
- types.DATETIME
- types.DECIMAL
- types.FLOAT
- types.INTEGER
- types.NCHAR
- types.NUMERIC
- types.NVARCHAR
- types.SMALLINT
- types.TEXT
- types.VARCHAR
- typing.TYPE_CHECKING
- typing.overload
- util.typing.Literal
- util.update_wrapper
- uuid.UUID

**Functions:**

### `def _db_plus_owner_listing(fn)`

**Line:** 2871

---

### `def _db_plus_owner(fn)`

**Line:** 2889

---

### `def _switch_db(dbname, connection, fn, *arg, **kw)`

**Line:** 2908

---

### `def _owner_plus_db(dialect, schema)`

**Line:** 2925

---

### `def _schema_elements(schema)`

**Line:** 2935

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.mssql.information_schema
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/mssql/information_schema.py`

**Imports:**
- ext.compiler.compiles
- sql.expression
- types.Boolean
- types.Integer
- types.NVARCHAR
- types.Numeric
- types.String
- types.TypeDecorator
- types.Unicode

**Functions:**

### `def _compile(element, compiler, **kw)`

**Decorators:**
- `@compiles(...)`

**Line:** 41

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.mssql.provision
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/mssql/provision.py`

**Imports:**
- schema.Column
- schema.DropConstraint
- schema.ForeignKeyConstraint
- schema.MetaData
- schema.Table
- sqlalchemy.Integer
- sqlalchemy.inspect
- testing.provision.create_db
- testing.provision.drop_all_schema_objects_pre_tables
- testing.provision.drop_db
- testing.provision.generate_driver_url
- testing.provision.get_temp_table_name
- testing.provision.log
- testing.provision.normalize_sequence
- testing.provision.run_reap_dbs
- testing.provision.temp_table_keyword_args

**Functions:**

### `def generate_driver_url(url, driver, query_str)`

**Decorators:**
- `@generate_driver_url.for_db(...)`

**Line:** 24

---

### `def _mssql_create_db(cfg, eng, ident)`

**Decorators:**
- `@create_db.for_db(...)`

**Line:** 44

---

### `def _mssql_drop_db(cfg, eng, ident)`

**Decorators:**
- `@drop_db.for_db(...)`

**Line:** 59

---

### `def _mssql_drop_ignore(conn, ident)`

**Line:** 64

---

### `def _reap_mssql_dbs(url, idents)`

**Decorators:**
- `@run_reap_dbs.for_db(...)`

**Line:** 82

---

### `def _mssql_temp_table_keyword_args(cfg, eng)`

**Decorators:**
- `@temp_table_keyword_args.for_db(...)`

**Line:** 110

---

### `def _mssql_get_temp_table_name(cfg, eng, base_name)`

**Decorators:**
- `@get_temp_table_name.for_db(...)`

**Line:** 115

---

### `def drop_all_schema_objects_pre_tables(cfg, eng)`

**Decorators:**
- `@drop_all_schema_objects_pre_tables.for_db(...)`

**Line:** 120

---

### `def normalize_sequence(cfg, sequence)`

**Decorators:**
- `@normalize_sequence.for_db(...)`

**Line:** 143

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.mysql.asyncmy
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/asyncmy.py`

**Imports:**
- asyncmy.constants.CLIENT
- contextlib.asynccontextmanager
- engine.AdaptedConnection
- pymysql.MySQLDialect_pymysql
- util.concurrency.asyncio
- util.concurrency.await_fallback
- util.concurrency.await_only

**Functions:**

### `def _Binary(x)`

**Description:**
Return x as a binary type.

**Line:** 235

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.mysql.dml
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/dml.py`

**Imports:**
- __future__.annotations
- sql._typing._DMLTableArgument
- sql.base.ColumnCollection
- sql.base.ReadOnlyColumnCollection
- sql.base._exclusive_against
- sql.base._generative
- sql.dml.Insert
- sql.elements.ClauseElement
- sql.elements.KeyedColumnElement
- sql.expression.alias
- sql.selectable.NamedFromClause
- typing.Any
- typing.List
- typing.Mapping
- typing.Optional
- typing.Tuple
- typing.Union
- util.typing.Self

**Functions:**

### `def insert(table: _DMLTableArgument) -> Insert`

**Description:**
Construct a MySQL/MariaDB-specific variant :class:`_mysql.Insert`
construct.

.. container:: inherited_member

The :func:`sqlalchemy.dialects.mysql.insert` function creates
a :class:`sqlalchemy.dialects.mysql.Insert`.  This class is based
on the dialect-agnostic :class:`_sql.Insert` construct which may
be constructed using the :func:`_sql.insert` function in
SQLAlchemy Core.

The :class:`_mysql.Insert` construct includes additional methods
:meth:`_mysql.Insert.on_duplicate_key_update`.

**Line:** 34

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.mysql.mariadb
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mariadb.py`

**Imports:**
- base.MariaDBIdentifierPreparer
- base.MySQLDialect

**Functions:**

### `def loader(driver)`

**Line:** 19

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.mysql.provision
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/provision.py`

**Imports:**
- sqlalchemy.dialects.mysql.insert
- testing.provision.configure_follower
- testing.provision.create_db
- testing.provision.drop_db
- testing.provision.generate_driver_url
- testing.provision.temp_table_keyword_args
- testing.provision.upsert

**Functions:**

### `def generate_driver_url(url, driver, query_str)`

**Decorators:**
- `@generate_driver_url.for_db(...)`

**Line:** 13

---

### `def _mysql_create_db(cfg, eng, ident)`

**Decorators:**
- `@create_db.for_db(...)`

**Line:** 46

---

### `def _mysql_configure_follower(config, ident)`

**Decorators:**
- `@configure_follower.for_db(...)`

**Line:** 66

---

### `def _mysql_drop_db(cfg, eng, ident)`

**Decorators:**
- `@drop_db.for_db(...)`

**Line:** 72

---

### `def _mysql_temp_table_keyword_args(cfg, eng)`

**Decorators:**
- `@temp_table_keyword_args.for_db(...)`

**Line:** 80

---

### `def _upsert(cfg, table, returning, set_lambda = None, sort_by_parameter_order = False)`

**Decorators:**
- `@upsert.for_db(...)`

**Line:** 85

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.mysql.reflection
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/reflection.py`

**Imports:**
- enumerated.ENUM
- enumerated.SET
- re
- types.DATETIME
- types.TIME
- types.TIMESTAMP

**Functions:**

### `def _pr_compile(regex, cleanup = None)`

**Description:**
Prepare a 2-tuple of compiled regex and callable.

**Line:** 627

---

### `def _re_compile(regex)`

**Description:**
Compile a string to regex, I and UNICODE.

**Line:** 633

---

### `def _strip_values(values)`

**Description:**
Strip reflected values quotes

**Line:** 639

---

### `def cleanup_text(raw_text: str) -> str`

**Line:** 650

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.oracle.provision
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/oracle/provision.py`

**Imports:**
- engine.url
- sqlalchemy.event
- testing.provision.configure_follower
- testing.provision.create_db
- testing.provision.drop_all_schema_objects_post_tables
- testing.provision.drop_all_schema_objects_pre_tables
- testing.provision.drop_db
- testing.provision.follower_url_from_main
- testing.provision.log
- testing.provision.post_configure_engine
- testing.provision.run_reap_dbs
- testing.provision.set_default_schema_on_connection
- testing.provision.stop_test_class_outside_fixtures
- testing.provision.temp_table_keyword_args
- testing.provision.update_db_opts

**Functions:**

### `def _oracle_create_db(cfg, eng, ident)`

**Decorators:**
- `@create_db.for_db(...)`

**Line:** 23

---

### `def _oracle_configure_follower(config, ident)`

**Decorators:**
- `@configure_follower.for_db(...)`

**Line:** 42

---

### `def _ora_drop_ignore(conn, dbname)`

**Line:** 47

---

### `def _ora_drop_all_schema_objects_pre_tables(cfg, eng)`

**Decorators:**
- `@drop_all_schema_objects_pre_tables.for_db(...)`

**Line:** 58

---

### `def _ora_drop_all_schema_objects_post_tables(cfg, eng)`

**Decorators:**
- `@drop_all_schema_objects_post_tables.for_db(...)`

**Line:** 64

---

### `def _oracle_drop_db(cfg, eng, ident)`

**Decorators:**
- `@drop_db.for_db(...)`

**Line:** 81

---

### `def _ora_stop_test_class_outside_fixtures(config, db, cls)`

**Decorators:**
- `@stop_test_class_outside_fixtures.for_db(...)`

**Line:** 94

---

### `def _purge_recyclebin(eng, schema = None)`

**Line:** 115

---

### `def _oracle_post_configure_engine(url, engine, follower_ident)`

**Decorators:**
- `@post_configure_engine.for_db(...)`

**Line:** 135

---

### `def _reap_oracle_dbs(url, idents)`

**Decorators:**
- `@run_reap_dbs.for_db(...)`

**Line:** 152

---

### `def _oracle_follower_url_from_main(url, ident)`

**Decorators:**
- `@follower_url_from_main.for_db(...)`

**Line:** 185

---

### `def _oracle_temp_table_keyword_args(cfg, eng)`

**Decorators:**
- `@temp_table_keyword_args.for_db(...)`

**Line:** 191

---

### `def _oracle_set_default_schema_on_connection(cfg, dbapi_connection, schema_name)`

**Decorators:**
- `@set_default_schema_on_connection.for_db(...)`

**Line:** 199

---

### `def _update_db_opts(db_url, db_opts, options)`

**Decorators:**
- `@update_db_opts.for_db(...)`

**Description:**
Set database options (db_opts) for a test database that we created.

**Line:** 208

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.postgresql.array
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/array.py`

**Imports:**
- __future__.annotations
- operators.CONTAINED_BY
- operators.CONTAINS
- operators.OVERLAP
- re
- sql._typing._TypeEngineArgument
- sql.expression
- sql.operators
- typing.Any
- typing.Optional
- typing.TypeVar

**Functions:**

### `def Any(other, arrexpr, operator = operators.eq)`

**Description:**
A synonym for the ARRAY-level :meth:`.ARRAY.Comparator.any` method.
See that method for details.

**Line:** 30

---

### `def All(other, arrexpr, operator = operators.eq)`

**Description:**
A synonym for the ARRAY-level :meth:`.ARRAY.Comparator.all` method.
See that method for details.

**Line:** 39

---

### `def _split_enum_values(array_string)`

**Line:** 405

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.postgresql.dml
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/dml.py`

**Imports:**
- __future__.annotations
- _typing._OnConflictConstraintT
- _typing._OnConflictIndexElementsT
- _typing._OnConflictIndexWhereT
- _typing._OnConflictSetT
- _typing._OnConflictWhereT
- sql._typing._DMLTableArgument
- sql.base.ColumnCollection
- sql.base.ReadOnlyColumnCollection
- sql.base._exclusive_against
- sql.base._generative
- sql.coercions
- sql.dml.Insert
- sql.elements.ClauseElement
- sql.elements.KeyedColumnElement
- sql.expression.alias
- sql.roles
- sql.schema
- typing.Any
- typing.Optional
- util.typing.Self

**Functions:**

### `def insert(table: _DMLTableArgument) -> Insert`

**Description:**
Construct a PostgreSQL-specific variant :class:`_postgresql.Insert`
construct.

.. container:: inherited_member

The :func:`sqlalchemy.dialects.postgresql.insert` function creates
a :class:`sqlalchemy.dialects.postgresql.Insert`.  This class is based
on the dialect-agnostic :class:`_sql.Insert` construct which may
be constructed using the :func:`_sql.insert` function in
SQLAlchemy Core.

The :class:`_postgresql.Insert` construct includes additional methods
:meth:`_postgresql.Insert.on_conflict_do_update`,
:meth:`_postgresql.Insert.on_conflict_do_nothing`.

**Line:** 37

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.postgresql.ext
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/ext.py`

**Imports:**
- __future__.annotations
- array.ARRAY
- sql.coercions
- sql.elements
- sql.expression
- sql.functions
- sql.roles
- sql.schema
- sql.schema.ColumnCollectionConstraint
- sql.sqltypes.TEXT
- sql.visitors.InternalTraversal
- sql.visitors._TraverseInternalsType
- typing.Any
- typing.TYPE_CHECKING
- typing.TypeVar

**Functions:**

### `def array_agg(*arg, **kw)`

**Description:**
PostgreSQL-specific form of :class:`_functions.array_agg`, ensures
return type is :class:`_postgresql.ARRAY` and not
the plain :class:`_types.ARRAY`, unless an explicit ``type_``
is passed.

**Line:** 287

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.postgresql.hstore
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/hstore.py`

**Imports:**
- array.ARRAY
- operators.CONTAINED_BY
- operators.CONTAINS
- operators.GETITEM
- operators.HAS_ALL
- operators.HAS_ANY
- operators.HAS_KEY
- re
- sql.functions

**Functions:**

### `def _parse_error(hstore_str, pos)`

**Description:**
format an unmarshalling error.

**Line:** 316

---

### `def _parse_hstore(hstore_str)`

**Description:**
Parse an hstore from its literal string representation.

Attempts to approximate PG's hstore input parsing rules as closely as
possible. Although currently this is not strictly necessary, since the
current implementation of hstore's output syntax is stricter than what it
accepts as input, the documentation makes no guarantees that will always
be the case.

**Line:** 337

---

### `def _serialize_hstore(val)`

**Description:**
Serialize a dictionary into an hstore literal.  Keys and values must
both be strings (except None for values).

**Line:** 379

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.postgresql.provision
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/provision.py`

**Imports:**
- sqlalchemy.dialects.postgresql
- sqlalchemy.dialects.postgresql.insert
- testing.provision.create_db
- testing.provision.drop_all_schema_objects_post_tables
- testing.provision.drop_all_schema_objects_pre_tables
- testing.provision.drop_db
- testing.provision.log
- testing.provision.post_configure_engine
- testing.provision.prepare_for_drop_tables
- testing.provision.set_default_schema_on_connection
- testing.provision.temp_table_keyword_args
- testing.provision.upsert
- testing.warn_test_suite
- time

**Functions:**

### `def _pg_create_db(cfg, eng, ident)`

**Decorators:**
- `@create_db.for_db(...)`

**Line:** 22

---

### `def _pg_drop_db(cfg, eng, ident)`

**Decorators:**
- `@drop_db.for_db(...)`

**Line:** 57

---

### `def _postgresql_temp_table_keyword_args(cfg, eng)`

**Decorators:**
- `@temp_table_keyword_args.for_db(...)`

**Line:** 72

---

### `def _postgresql_set_default_schema_on_connection(cfg, dbapi_connection, schema_name)`

**Decorators:**
- `@set_default_schema_on_connection.for_db(...)`

**Line:** 77

---

### `def drop_all_schema_objects_pre_tables(cfg, eng)`

**Decorators:**
- `@drop_all_schema_objects_pre_tables.for_db(...)`

**Line:** 89

---

### `def drop_all_schema_objects_post_tables(cfg, eng)`

**Decorators:**
- `@drop_all_schema_objects_post_tables.for_db(...)`

**Line:** 98

---

### `def prepare_for_drop_tables(config, connection)`

**Decorators:**
- `@prepare_for_drop_tables.for_db(...)`

**Description:**
Ensure there are no locks on the current username/database.

**Line:** 112

---

### `def _upsert(cfg, table, returning, set_lambda = None, sort_by_parameter_order = False)`

**Decorators:**
- `@upsert.for_db(...)`

**Line:** 133

---

### `def _create_citext_extension(url, engine, follower_ident)`

**Decorators:**
- `@post_configure_engine.for_db(...)`

**Line:** 162

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.postgresql.psycopg
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg.py`

**Imports:**
- __future__.annotations
- _psycopg_common._PGDialect_common_psycopg
- _psycopg_common._PGExecutionContext_common_psycopg
- base.INTERVAL
- base.PGCompiler
- base.PGIdentifierPreparer
- base.REGCONFIG
- engine.AdaptedConnection
- json.JSON
- json.JSONB
- json.JSONPathType
- logging
- psycopg
- psycopg.adapt.AdaptersMap
- psycopg.pq.ExecStatus
- psycopg.pq.TransactionStatus
- psycopg.types.TypeInfo
- psycopg.types.hstore.register_hstore
- psycopg.types.json
- psycopg.types.json.set_json_dumps
- psycopg.types.json.set_json_loads
- psycopg.types.multirange.Multirange
- psycopg.types.range.Range
- psycopg.types.string
- re
- sql.sqltypes
- types.CITEXT
- typing.Iterable
- typing.TYPE_CHECKING
- typing.cast
- util.concurrency.await_fallback
- util.concurrency.await_only

**Functions:**

### `def _log_notices(diagnostic)`

**Line:** 249

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.sqlite.dml
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/sqlite/dml.py`

**Imports:**
- __future__.annotations
- _typing._OnConflictIndexElementsT
- _typing._OnConflictIndexWhereT
- _typing._OnConflictSetT
- _typing._OnConflictWhereT
- sql._typing._DMLTableArgument
- sql.base.ColumnCollection
- sql.base.ReadOnlyColumnCollection
- sql.base._exclusive_against
- sql.base._generative
- sql.coercions
- sql.dml.Insert
- sql.elements.ClauseElement
- sql.elements.KeyedColumnElement
- sql.expression.alias
- sql.roles
- typing.Any
- util.typing.Self

**Functions:**

### `def insert(table: _DMLTableArgument) -> Insert`

**Description:**
Construct a sqlite-specific variant :class:`_sqlite.Insert`
construct.

.. container:: inherited_member

The :func:`sqlalchemy.dialects.sqlite.insert` function creates
a :class:`sqlalchemy.dialects.sqlite.Insert`.  This class is based
on the dialect-agnostic :class:`_sql.Insert` construct which may
be constructed using the :func:`_sql.insert` function in
SQLAlchemy Core.

The :class:`_sqlite.Insert` construct includes additional methods
:meth:`_sqlite.Insert.on_conflict_do_update`,
:meth:`_sqlite.Insert.on_conflict_do_nothing`.

**Line:** 32

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.dialects.sqlite.provision
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/dialects/sqlite/provision.py`

**Imports:**
- engine.url
- os
- re
- sqlalchemy.dialects.sqlite.insert
- sqlalchemy.event
- testing.provision.create_db
- testing.provision.drop_db
- testing.provision.follower_url_from_main
- testing.provision.generate_driver_url
- testing.provision.log
- testing.provision.post_configure_engine
- testing.provision.run_reap_dbs
- testing.provision.stop_test_class_outside_fixtures
- testing.provision.temp_table_keyword_args
- testing.provision.upsert

**Functions:**

### `def _format_url(url, driver, ident)`

**Description:**
given a sqlite url + desired driver + ident, make a canonical
URL out of it

**Line:** 30

---

### `def generate_driver_url(url, driver, query_str)`

**Decorators:**
- `@generate_driver_url.for_db(...)`

**Line:** 80

---

### `def _sqlite_follower_url_from_main(url, ident)`

**Decorators:**
- `@follower_url_from_main.for_db(...)`

**Line:** 92

---

### `def _sqlite_post_configure_engine(url, engine, follower_ident)`

**Decorators:**
- `@post_configure_engine.for_db(...)`

**Line:** 97

---

### `def _sqlite_create_db(cfg, eng, ident)`

**Decorators:**
- `@create_db.for_db(...)`

**Line:** 139

---

### `def _sqlite_drop_db(cfg, eng, ident)`

**Decorators:**
- `@drop_db.for_db(...)`

**Line:** 144

---

### `def _drop_dbs_w_ident(databasename, driver, ident)`

**Line:** 148

---

### `def stop_test_class_outside_fixtures(config, db, cls)`

**Decorators:**
- `@stop_test_class_outside_fixtures.for_db(...)`

**Line:** 157

---

### `def _sqlite_temp_table_keyword_args(cfg, eng)`

**Decorators:**
- `@temp_table_keyword_args.for_db(...)`

**Line:** 162

---

### `def _reap_sqlite_dbs(url, idents)`

**Decorators:**
- `@run_reap_dbs.for_db(...)`

**Line:** 167

---

### `def _upsert(cfg, table, returning, set_lambda = None, sort_by_parameter_order = False)`

**Decorators:**
- `@upsert.for_db(...)`

**Line:** 177

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.engine._py_processors
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/engine/_py_processors.py`

**Imports:**
- __future__.annotations
- datetime
- datetime.date
- datetime.datetime
- datetime.time
- decimal.Decimal
- typing
- typing.Any
- typing.Callable
- typing.Optional
- typing.Type
- typing.TypeVar
- typing.Union

**Functions:**

### `def str_to_datetime_processor_factory(regexp: typing.Pattern[str], type_: Callable[(..., _DT)]) -> Callable[([Optional[str]], Optional[_DT])]`

**Line:** 37

---

### `def to_decimal_processor_factory(target_class: Type[Decimal], scale: int) -> Callable[([Optional[float]], Optional[Decimal])]`

**Line:** 80

---

### `def to_float(value: Optional[Union[(int, float)]]) -> Optional[float]`

**Line:** 94

---

### `def to_str(value: Optional[Any]) -> Optional[str]`

**Line:** 101

---

### `def int_to_boolean(value: Optional[int]) -> Optional[bool]`

**Line:** 108

---

### `def str_to_datetime(value: Optional[str]) -> Optional[datetime.datetime]`

**Line:** 115

---

### `def str_to_time(value: Optional[str]) -> Optional[datetime.time]`

**Line:** 123

---

### `def str_to_date(value: Optional[str]) -> Optional[datetime.date]`

**Line:** 131

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.engine._py_row
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/engine/_py_row.py`

**Imports:**
- __future__.annotations
- operator
- result.ResultMetaData
- result._KeyType
- result._ProcessorsType
- result._RawRowType
- result._TupleGetterType
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.Iterator
- typing.List
- typing.Mapping
- typing.Optional
- typing.Tuple
- typing.Type

**Functions:**

### `def rowproxy_reconstructor(cls: Type[BaseRow], state: Dict[(str, Any)]) -> BaseRow`

**Line:** 108

---

### `def tuplegetter(*indexes: int) -> _TupleGetterType`

**Line:** 116

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.engine._py_util
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/engine/_py_util.py`

**Imports:**
- __future__.annotations
- interfaces._CoreAnyExecuteParams
- interfaces._CoreMultiExecuteParams
- interfaces._DBAPIAnyExecuteParams
- interfaces._DBAPIMultiExecuteParams
- typing
- typing.Any
- typing.Mapping
- typing.Optional
- typing.Tuple

**Functions:**

### `def _distill_params_20(params: Optional[_CoreAnyExecuteParams]) -> _CoreMultiExecuteParams`

**Line:** 21

---

### `def _distill_raw_params(params: Optional[_DBAPIAnyExecuteParams]) -> _DBAPIMultiExecuteParams`

**Line:** 46

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.engine.create
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/engine/create.py`

**Imports:**
- __future__.annotations
- base.Engine
- inspect
- interfaces.DBAPIConnection
- interfaces.IsolationLevel
- interfaces._ExecuteOptions
- interfaces._ParamStyle
- log._EchoFlagType
- mock.create_mock_engine
- pool.ConnectionPoolEntry
- pool.Pool
- pool._AdhocProxiedConnection
- pool._CreatorFnType
- pool._CreatorWRecFnType
- pool._ResetStyleArgType
- sql.compiler
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.List
- typing.Optional
- typing.Type
- typing.Union
- typing.cast
- typing.overload
- url.URL
- util.immutabledict
- util.typing.Literal

**Functions:**

### `def create_engine(url: Union[(str, URL)], connect_args: Dict[(Any, Any)] = Ellipsis, convert_unicode: bool = Ellipsis, creator: Union[(_CreatorFnType, _CreatorWRecFnType)] = Ellipsis, echo: _EchoFlagType = Ellipsis, echo_pool: _EchoFlagType = Ellipsis, enable_from_linting: bool = Ellipsis, execution_options: _ExecuteOptions = Ellipsis, future: Literal[True], hide_parameters: bool = Ellipsis, implicit_returning: Literal[True] = Ellipsis, insertmanyvalues_page_size: int = Ellipsis, isolation_level: IsolationLevel = Ellipsis, json_deserializer: Callable[(..., Any)] = Ellipsis, json_serializer: Callable[(..., Any)] = Ellipsis, label_length: Optional[int] = Ellipsis, logging_name: str = Ellipsis, max_identifier_length: Optional[int] = Ellipsis, max_overflow: int = Ellipsis, module: Optional[Any] = Ellipsis, paramstyle: Optional[_ParamStyle] = Ellipsis, pool: Optional[Pool] = Ellipsis, poolclass: Optional[Type[Pool]] = Ellipsis, pool_logging_name: str = Ellipsis, pool_pre_ping: bool = Ellipsis, pool_size: int = Ellipsis, pool_recycle: int = Ellipsis, pool_reset_on_return: Optional[_ResetStyleArgType] = Ellipsis, pool_timeout: float = Ellipsis, pool_use_lifo: bool = Ellipsis, plugins: List[str] = Ellipsis, query_cache_size: int = Ellipsis, use_insertmanyvalues: bool = Ellipsis, **kwargs: Any) -> Engine`

**Decorators:**
- `@overload`

**Line:** 49

---

### `def create_engine(url: Union[(str, URL)], **kwargs: Any) -> Engine`

**Decorators:**
- `@overload`

**Line:** 90

---

### `def create_engine(url: Union[(str, _url.URL)], **kwargs: Any) -> Engine`

**Decorators:**
- `@util.deprecated_params(...)`

**Description:**
Create a new :class:`_engine.Engine` instance.

The standard calling form is to send the :ref:`URL <database_urls>` as the
first positional argument, usually a string
that indicates database dialect and connection arguments::

engine = create_engine("postgresql+psycopg2://scott:tiger@localhost/test")

.. note::

Please review :ref:`database_urls` for general guidelines in composing
URL strings.  In particular, special characters, such as those often
part of passwords, must be URL encoded to be properly parsed.

Additional keyword arguments may then follow it which
establish various options on the resulting :class:`_engine.Engine`
and its underlying :class:`.Dialect` and :class:`_pool.Pool`
constructs::

engine = create_engine("mysql+mysqldb://scott:tiger@hostname/dbname",
pool_recycle=3600, echo=True)

The string form of the URL is
``dialect[+driver]://user:password@host/dbname[?key=value..]``, where
``dialect`` is a database name such as ``mysql``, ``oracle``,
``postgresql``, etc., and ``driver`` the name of a DBAPI, such as
``psycopg2``, ``pyodbc``, ``cx_oracle``, etc.  Alternatively,
the URL can be an instance of :class:`~sqlalchemy.engine.url.URL`.

``**kwargs`` takes a wide variety of options which are routed
towards their appropriate components.  Arguments may be specific to
the :class:`_engine.Engine`, the underlying :class:`.Dialect`,
as well as the
:class:`_pool.Pool`.  Specific dialects also accept keyword arguments that
are unique to that dialect.   Here, we describe the parameters
that are common to most :func:`_sa.create_engine()` usage.

Once established, the newly resulting :class:`_engine.Engine` will
request a connection from the underlying :class:`_pool.Pool` once
:meth:`_engine.Engine.connect` is called, or a method which depends on it
such as :meth:`_engine.Engine.execute` is invoked.   The
:class:`_pool.Pool` in turn
will establish the first actual DBAPI connection when this request
is received.   The :func:`_sa.create_engine` call itself does **not**
establish any actual DBAPI connections directly.

.. seealso::

:doc:`/core/engines`

:doc:`/dialects/index`

:ref:`connections_toplevel`

:param connect_args: a dictionary of options which will be
passed directly to the DBAPI's ``connect()`` method as
additional keyword arguments.  See the example
at :ref:`custom_dbapi_args`.

:param creator: a callable which returns a DBAPI connection.
This creation function will be passed to the underlying
connection pool and will be used to create all new database
connections. Usage of this function causes connection
parameters specified in the URL argument to be bypassed.

This hook is not as flexible as the newer
:meth:`_events.DialectEvents.do_connect` hook which allows complete
control over how a connection is made to the database, given the full
set of URL arguments and state beforehand.

.. seealso::

:meth:`_events.DialectEvents.do_connect` - event hook that allows
full control over DBAPI connection mechanics.

:ref:`custom_dbapi_args`

:param echo=False: if True, the Engine will log all statements
as well as a ``repr()`` of their parameter lists to the default log
handler, which defaults to ``sys.stdout`` for output.   If set to the
string ``"debug"``, result rows will be printed to the standard output
as well. The ``echo`` attribute of ``Engine`` can be modified at any
time to turn logging on and off; direct control of logging is also
available using the standard Python ``logging`` module.

.. seealso::

:ref:`dbengine_logging` - further detail on how to configure
logging.


:param echo_pool=False: if True, the connection pool will log
informational output such as when connections are invalidated
as well as when connections are recycled to the default log handler,
which defaults to ``sys.stdout`` for output.   If set to the string
``"debug"``, the logging will include pool checkouts and checkins.
Direct control of logging is also available using the standard Python
``logging`` module.

.. seealso::

:ref:`dbengine_logging` - further detail on how to configure
logging.


:param empty_in_strategy:   No longer used; SQLAlchemy now uses
"empty set" behavior for IN in all cases.

:param enable_from_linting: defaults to True.  Will emit a warning
if a given SELECT statement is found to have un-linked FROM elements
which would cause a cartesian product.

.. versionadded:: 1.4

.. seealso::

:ref:`change_4737`

:param execution_options: Dictionary execution options which will
be applied to all connections.  See
:meth:`~sqlalchemy.engine.Connection.execution_options`

:param future: Use the 2.0 style :class:`_engine.Engine` and
:class:`_engine.Connection` API.

As of SQLAlchemy 2.0, this parameter is present for backwards
compatibility only and must remain at its default value of ``True``.

The :paramref:`_sa.create_engine.future` parameter will be
deprecated in a subsequent 2.x release and eventually removed.

.. versionadded:: 1.4

.. versionchanged:: 2.0 All :class:`_engine.Engine` objects are
"future" style engines and there is no longer a ``future=False``
mode of operation.

.. seealso::

:ref:`migration_20_toplevel`

:param hide_parameters: Boolean, when set to True, SQL statement parameters
will not be displayed in INFO logging nor will they be formatted into
the string representation of :class:`.StatementError` objects.

.. versionadded:: 1.3.8

.. seealso::

:ref:`dbengine_logging` - further detail on how to configure
logging.

:param implicit_returning=True:  Legacy parameter that may only be set
to True. In SQLAlchemy 2.0, this parameter does nothing. In order to
disable "implicit returning" for statements invoked by the ORM,
configure this on a per-table basis using the
:paramref:`.Table.implicit_returning` parameter.


:param insertmanyvalues_page_size: number of rows to format into an
INSERT statement when the statement uses "insertmanyvalues" mode, which is
a paged form of bulk insert that is used for many backends when using
:term:`executemany` execution typically in conjunction with RETURNING.
Defaults to 1000, but may also be subject to dialect-specific limiting
factors which may override this value on a per-statement basis.

.. versionadded:: 2.0

.. seealso::

:ref:`engine_insertmanyvalues`

:ref:`engine_insertmanyvalues_page_size`

:paramref:`_engine.Connection.execution_options.insertmanyvalues_page_size`

:param isolation_level: optional string name of an isolation level
which will be set on all new connections unconditionally.
Isolation levels are typically some subset of the string names
``"SERIALIZABLE"``, ``"REPEATABLE READ"``,
``"READ COMMITTED"``, ``"READ UNCOMMITTED"`` and ``"AUTOCOMMIT"``
based on backend.

The :paramref:`_sa.create_engine.isolation_level` parameter is
in contrast to the
:paramref:`.Connection.execution_options.isolation_level`
execution option, which may be set on an individual
:class:`.Connection`, as well as the same parameter passed to
:meth:`.Engine.execution_options`, where it may be used to create
multiple engines with different isolation levels that share a common
connection pool and dialect.

.. versionchanged:: 2.0 The
:paramref:`_sa.create_engine.isolation_level`
parameter has been generalized to work on all dialects which support
the concept of isolation level, and is provided as a more succinct,
up front configuration switch in contrast to the execution option
which is more of an ad-hoc programmatic option.

.. seealso::

:ref:`dbapi_autocommit`

:param json_deserializer: for dialects that support the
:class:`_types.JSON`
datatype, this is a Python callable that will convert a JSON string
to a Python object.  By default, the Python ``json.loads`` function is
used.

.. versionchanged:: 1.3.7  The SQLite dialect renamed this from
``_json_deserializer``.

:param json_serializer: for dialects that support the :class:`_types.JSON`
datatype, this is a Python callable that will render a given object
as JSON.   By default, the Python ``json.dumps`` function is used.

.. versionchanged:: 1.3.7  The SQLite dialect renamed this from
``_json_serializer``.


:param label_length=None: optional integer value which limits
the size of dynamically generated column labels to that many
characters. If less than 6, labels are generated as
"_(counter)". If ``None``, the value of
``dialect.max_identifier_length``, which may be affected via the
:paramref:`_sa.create_engine.max_identifier_length` parameter,
is used instead.   The value of
:paramref:`_sa.create_engine.label_length`
may not be larger than that of
:paramref:`_sa.create_engine.max_identfier_length`.

.. seealso::

:paramref:`_sa.create_engine.max_identifier_length`

:param logging_name:  String identifier which will be used within
the "name" field of logging records generated within the
"sqlalchemy.engine" logger. Defaults to a hexstring of the
object's id.

.. seealso::

:ref:`dbengine_logging` - further detail on how to configure
logging.

:paramref:`_engine.Connection.execution_options.logging_token`

:param max_identifier_length: integer; override the max_identifier_length
determined by the dialect.  if ``None`` or zero, has no effect.  This
is the database's configured maximum number of characters that may be
used in a SQL identifier such as a table name, column name, or label
name. All dialects determine this value automatically, however in the
case of a new database version for which this value has changed but
SQLAlchemy's dialect has not been adjusted, the value may be passed
here.

.. versionadded:: 1.3.9

.. seealso::

:paramref:`_sa.create_engine.label_length`

:param max_overflow=10: the number of connections to allow in
connection pool "overflow", that is connections that can be
opened above and beyond the pool_size setting, which defaults
to five. this is only used with :class:`~sqlalchemy.pool.QueuePool`.

:param module=None: reference to a Python module object (the module
itself, not its string name).  Specifies an alternate DBAPI module to
be used by the engine's dialect.  Each sub-dialect references a
specific DBAPI which will be imported before first connect.  This
parameter causes the import to be bypassed, and the given module to
be used instead. Can be used for testing of DBAPIs as well as to
inject "mock" DBAPI implementations into the :class:`_engine.Engine`.

:param paramstyle=None: The `paramstyle <https://legacy.python.org/dev/peps/pep-0249/#paramstyle>`_
to use when rendering bound parameters.  This style defaults to the
one recommended by the DBAPI itself, which is retrieved from the
``.paramstyle`` attribute of the DBAPI.  However, most DBAPIs accept
more than one paramstyle, and in particular it may be desirable
to change a "named" paramstyle into a "positional" one, or vice versa.
When this attribute is passed, it should be one of the values
``"qmark"``, ``"numeric"``, ``"named"``, ``"format"`` or
``"pyformat"``, and should correspond to a parameter style known
to be supported by the DBAPI in use.

:param pool=None: an already-constructed instance of
:class:`~sqlalchemy.pool.Pool`, such as a
:class:`~sqlalchemy.pool.QueuePool` instance. If non-None, this
pool will be used directly as the underlying connection pool
for the engine, bypassing whatever connection parameters are
present in the URL argument. For information on constructing
connection pools manually, see :ref:`pooling_toplevel`.

:param poolclass=None: a :class:`~sqlalchemy.pool.Pool`
subclass, which will be used to create a connection pool
instance using the connection parameters given in the URL. Note
this differs from ``pool`` in that you don't actually
instantiate the pool in this case, you just indicate what type
of pool to be used.

:param pool_logging_name:  String identifier which will be used within
the "name" field of logging records generated within the
"sqlalchemy.pool" logger. Defaults to a hexstring of the object's
id.

.. seealso::

:ref:`dbengine_logging` - further detail on how to configure
logging.

:param pool_pre_ping: boolean, if True will enable the connection pool
"pre-ping" feature that tests connections for liveness upon
each checkout.

.. versionadded:: 1.2

.. seealso::

:ref:`pool_disconnects_pessimistic`

:param pool_size=5: the number of connections to keep open
inside the connection pool. This used with
:class:`~sqlalchemy.pool.QueuePool` as
well as :class:`~sqlalchemy.pool.SingletonThreadPool`.  With
:class:`~sqlalchemy.pool.QueuePool`, a ``pool_size`` setting
of 0 indicates no limit; to disable pooling, set ``poolclass`` to
:class:`~sqlalchemy.pool.NullPool` instead.

:param pool_recycle=-1: this setting causes the pool to recycle
connections after the given number of seconds has passed. It
defaults to -1, or no timeout. For example, setting to 3600
means connections will be recycled after one hour. Note that
MySQL in particular will disconnect automatically if no
activity is detected on a connection for eight hours (although
this is configurable with the MySQLDB connection itself and the
server configuration as well).

.. seealso::

:ref:`pool_setting_recycle`

:param pool_reset_on_return='rollback': set the
:paramref:`_pool.Pool.reset_on_return` parameter of the underlying
:class:`_pool.Pool` object, which can be set to the values
``"rollback"``, ``"commit"``, or ``None``.

.. seealso::

:ref:`pool_reset_on_return`

:param pool_timeout=30: number of seconds to wait before giving
up on getting a connection from the pool. This is only used
with :class:`~sqlalchemy.pool.QueuePool`. This can be a float but is
subject to the limitations of Python time functions which may not be
reliable in the tens of milliseconds.

.. note: don't use 30.0 above, it seems to break with the :param tag

:param pool_use_lifo=False: use LIFO (last-in-first-out) when retrieving
connections from :class:`.QueuePool` instead of FIFO
(first-in-first-out). Using LIFO, a server-side timeout scheme can
reduce the number of connections used during non- peak   periods of
use.   When planning for server-side timeouts, ensure that a recycle or
pre-ping strategy is in use to gracefully   handle stale connections.

.. versionadded:: 1.3

.. seealso::

:ref:`pool_use_lifo`

:ref:`pool_disconnects`

:param plugins: string list of plugin names to load.  See
:class:`.CreateEnginePlugin` for background.

.. versionadded:: 1.2.3

:param query_cache_size: size of the cache used to cache the SQL string
form of queries.  Set to zero to disable caching.

The cache is pruned of its least recently used items when its size reaches
N * 1.5.  Defaults to 500, meaning the cache will always store at least
500 SQL statements when filled, and will grow up to 750 items at which
point it is pruned back down to 500 by removing the 250 least recently
used items.

Caching is accomplished on a per-statement basis by generating a
cache key that represents the statement's structure, then generating
string SQL for the current dialect only if that key is not present
in the cache.   All statements support caching, however some features
such as an INSERT with a large set of parameters will intentionally
bypass the cache.   SQL logging will indicate statistics for each
statement whether or not it were pull from the cache.

.. note:: some ORM functions related to unit-of-work persistence as well
as some attribute loading strategies will make use of individual
per-mapper caches outside of the main cache.


.. seealso::

:ref:`sql_caching`

.. versionadded:: 1.4

:param use_insertmanyvalues: True by default, use the "insertmanyvalues"
execution style for INSERT..RETURNING statements by default.

.. versionadded:: 2.0

.. seealso::

:ref:`engine_insertmanyvalues`

**Line:** 118

---

### `def engine_from_config(configuration: Dict[(str, Any)], prefix: str = 'sqlalchemy.', **kwargs: Any) -> Engine`

**Description:**
Create a new Engine instance using a configuration dictionary.

The dictionary is typically produced from a config file.

The keys of interest to ``engine_from_config()`` should be prefixed, e.g.
``sqlalchemy.url``, ``sqlalchemy.echo``, etc.  The 'prefix' argument
indicates the prefix to be searched for.  Each matching key (after the
prefix is stripped) is treated as though it were the corresponding keyword
argument to a :func:`_sa.create_engine` call.

The only required key is (assuming the default prefix) ``sqlalchemy.url``,
which provides the :ref:`database URL <database_urls>`.

A select set of keyword arguments will be "coerced" to their
expected type based on string values.    The set of arguments
is extensible per-dialect using the ``engine_config_types`` accessor.

:param configuration: A dictionary (typically produced from a config file,
but this is not a requirement).  Items whose keys start with the value
of 'prefix' will have that prefix stripped, and will then be passed to
:func:`_sa.create_engine`.

:param prefix: Prefix to match and then strip from keys
in 'configuration'.

:param kwargs: Each keyword argument to ``engine_from_config()`` itself
overrides the corresponding item taken from the 'configuration'
dictionary.  Keyword arguments should *not* be prefixed.

**Line:** 761

---

### `def create_pool_from_url(url: Union[(str, URL)], poolclass: Optional[Type[Pool]] = Ellipsis, logging_name: str = Ellipsis, pre_ping: bool = Ellipsis, size: int = Ellipsis, recycle: int = Ellipsis, reset_on_return: Optional[_ResetStyleArgType] = Ellipsis, timeout: float = Ellipsis, use_lifo: bool = Ellipsis, **kwargs: Any) -> Pool`

**Decorators:**
- `@overload`

**Line:** 807

---

### `def create_pool_from_url(url: Union[(str, URL)], **kwargs: Any) -> Pool`

**Decorators:**
- `@overload`

**Line:** 824

---

### `def create_pool_from_url(url: Union[(str, URL)], **kwargs: Any) -> Pool`

**Description:**
Create a pool instance from the given url.

If ``poolclass`` is not provided the pool class used
is selected using the dialect specified in the URL.

The arguments passed to :func:`_sa.create_pool_from_url` are
identical to the pool argument passed to the :func:`_sa.create_engine`
function.

.. versionadded:: 2.0.10

**Line:** 828

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.engine.cursor
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/engine/cursor.py`

**Imports:**
- __future__.annotations
- base.Connection
- collections
- default.DefaultExecutionContext
- functools
- interfaces.DBAPICursor
- interfaces.Dialect
- interfaces.ExecutionContext
- interfaces._DBAPICursorDescription
- operator
- result.IteratorResult
- result.MergedResult
- result.Result
- result.ResultMetaData
- result.SimpleResultMetaData
- result._KeyIndexType
- result._KeyMapRecType
- result._KeyMapType
- result._KeyType
- result._ProcessorsType
- result._TupleGetterType
- result.tuplegetter
- row.Row
- sql.base._generative
- sql.compiler.RM_NAME
- sql.compiler.RM_OBJECTS
- sql.compiler.RM_RENDERED_NAME
- sql.compiler.RM_TYPE
- sql.compiler.ResultColumnsEntry
- sql.elements
- sql.sqltypes
- sql.type_api.TypeEngine
- sql.type_api._ResultProcessorType
- sql.util
- typing
- typing.Any
- typing.ClassVar
- typing.Dict
- typing.Iterator
- typing.List
- typing.Mapping
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.cast
- util.compat
- util.typing.Literal
- util.typing.Self

**Functions:**

### `def null_dml_result() -> IteratorResult[Any]`

**Line:** 1372

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.engine.mock
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/engine/mock.py`

**Imports:**
- __future__.annotations
- base.Engine
- interfaces.CoreExecuteOptionsParameter
- interfaces.Dialect
- interfaces._CoreAnyExecuteParams
- operator.attrgetter
- sql.base.Executable
- sql.ddl.SchemaDropper
- sql.ddl.SchemaGenerator
- sql.schema.HasSchemaAttr
- sql.schema.SchemaItem
- typing
- typing.Any
- typing.Callable
- typing.Optional
- typing.Type
- typing.Union
- typing.cast
- url.URL

**Functions:**

### `def create_mock_engine(url: Union[(str, URL)], executor: Any, **kw: Any) -> MockConnection`

**Description:**
Create a "mock" engine used for echoing DDL.

This is a utility function used for debugging or storing the output of DDL
sequences as generated by :meth:`_schema.MetaData.create_all`
and related methods.

The function accepts a URL which is used only to determine the kind of
dialect to be used, as well as an "executor" callable function which
will receive a SQL expression object and parameters, which can then be
echoed or otherwise printed.   The executor's return value is not handled,
nor does the engine allow regular string statements to be invoked, and
is therefore only useful for DDL that is sent to the database without
receiving any results.

E.g.::

from sqlalchemy import create_mock_engine

def dump(sql, *multiparams, **params):
print(sql.compile(dialect=engine.dialect))

engine = create_mock_engine('postgresql+psycopg2://', dump)
metadata.create_all(engine, checkfirst=False)

:param url: A string URL which typically needs to contain only the
database backend name.

:param executor: a callable which receives the arguments ``sql``,
``*multiparams`` and ``**params``.  The ``sql`` parameter is typically
an instance of :class:`.ExecutableDDLElement`, which can then be compiled
into a string using :meth:`.ExecutableDDLElement.compile`.

.. versionadded:: 1.4 - the :func:`.create_mock_engine` function replaces
the previous "mock" engine strategy used with
:func:`_sa.create_engine`.

.. seealso::

:ref:`faq_ddl_as_string`

**Line:** 72

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.engine.processors
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/engine/processors.py`

**Imports:**
- __future__.annotations
- _py_processors.int_to_boolean
- _py_processors.str_to_date
- _py_processors.str_to_datetime
- _py_processors.str_to_datetime_processor_factory
- _py_processors.str_to_time
- _py_processors.to_decimal_processor_factory
- _py_processors.to_float
- _py_processors.to_str
- sqlalchemy.cyextension.processors.DecimalResultProcessor
- sqlalchemy.cyextension.processors.int_to_boolean
- sqlalchemy.cyextension.processors.str_to_date
- sqlalchemy.cyextension.processors.str_to_datetime
- sqlalchemy.cyextension.processors.str_to_time
- sqlalchemy.cyextension.processors.to_float
- sqlalchemy.cyextension.processors.to_str
- typing
- util._has_cy.HAS_CYEXTENSION

**Functions:**

### `def to_decimal_processor_factory(target_class, scale)`

**Line:** 55

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.engine.reflection
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/engine/reflection.py`

**Imports:**
- __future__.annotations
- base.Connection
- base.Engine
- contextlib
- dataclasses.dataclass
- enum.Flag
- enum.auto
- enum.unique
- interfaces.Dialect
- interfaces.ReflectedCheckConstraint
- interfaces.ReflectedColumn
- interfaces.ReflectedForeignKeyConstraint
- interfaces.ReflectedIndex
- interfaces.ReflectedPrimaryKeyConstraint
- interfaces.ReflectedTableComment
- interfaces.ReflectedUniqueConstraint
- interfaces.TableKey
- sql.cache_key._ad_hoc_cache_key_from_args
- sql.elements.TextClause
- sql.operators
- sql.schema
- sql.type_api.TypeEngine
- sql.visitors.InternalTraversal
- typing.Any
- typing.Callable
- typing.Collection
- typing.Dict
- typing.Generator
- typing.Iterable
- typing.List
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- util.topological
- util.typing.final

**Functions:**

### `def cache(fn: Callable[(..., _R)], self: Dialect, con: Connection, *args: Any, **kw: Any) -> _R`

**Decorators:**
- `@util.decorator`

**Line:** 79

---

### `def flexi_cache(*traverse_args: Tuple[(str, InternalTraversal)]) -> Callable[([Callable[..., _R]], Callable[..., _R])]`

**Line:** 102

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.engine.result
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/engine/result.py`

**Imports:**
- __future__.annotations
- _py_row.tuplegetter
- enum.Enum
- functools
- itertools
- operator
- row.Row
- row.RowMapping
- sql.base.HasMemoized
- sql.base.InPlaceGenerative
- sql.base._generative
- sql.schema.Column
- sql.type_api._ResultProcessorType
- sqlalchemy.cyextension.resultproxy.tuplegetter
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.HasMemoized_ro_memoized_attribute
- util.NONE_SET
- util._has_cy.HAS_CYEXTENSION
- util.typing.Literal
- util.typing.Self

**Functions:**

### `def result_tuple(fields: Sequence[str], extra: Optional[Any] = None) -> Callable[([Iterable[Any]], Row[Any])]`

**Line:** 395

---

### `def null_result() -> IteratorResult[Any]`

**Line:** 2306

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.engine.url
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/engine/url.py`

**Imports:**
- __future__.annotations
- collections.abc
- dialects.plugins
- dialects.registry
- interfaces.Dialect
- re
- typing.Any
- typing.Dict
- typing.Iterable
- typing.List
- typing.Mapping
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.Tuple
- typing.Type
- typing.Union
- typing.cast
- typing.overload
- urllib.parse.parse_qsl
- urllib.parse.quote_plus
- urllib.parse.unquote

**Functions:**

### `def make_url(name_or_url: Union[(str, URL)]) -> URL`

**Description:**
Given a string, produce a new URL instance.

The format of the URL generally follows `RFC-1738
<https://www.ietf.org/rfc/rfc1738.txt>`_, with some exceptions, including
that underscores, and not dashes or periods, are accepted within the
"scheme" portion.

If a :class:`.URL` object is passed, it is returned as is.

.. seealso::

:ref:`database_urls`

**Line:** 821

---

### `def _parse_url(name: str) -> URL`

**Line:** 849

---

### `def _sqla_url_quote(text: str) -> str`

**Line:** 909

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.engine.util
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/engine/util.py`

**Imports:**
- __future__.annotations
- _py_util._distill_params_20
- _py_util._distill_raw_params
- sqlalchemy.cyextension.util._distill_params_20
- sqlalchemy.cyextension.util._distill_raw_params
- typing
- typing.Any
- typing.Callable
- typing.Optional
- typing.TypeVar
- util._has_cy.HAS_CYEXTENSION
- util.typing.Protocol

**Functions:**

### `def connection_memoize(key: str) -> Callable[([_C], _C)]`

**Description:**
Decorator, memoize a function in a connection.info stash.

Only applicable to functions which take no arguments other than a
connection.  The memo will be stored in ``connection.info[key]``.

**Line:** 35

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.event.api
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/event/api.py`

**Imports:**
- __future__.annotations
- base._registrars
- registry._ET
- registry._EventKey
- registry._ListenerFnType
- typing.Any
- typing.Callable

**Functions:**

### `def _event_key(target: _ET, identifier: str, fn: _ListenerFnType) -> _EventKey[_ET]`

**Line:** 28

---

### `def listen(target: Any, identifier: str, fn: Callable[(..., Any)], *args: Any, **kw: Any) -> None`

**Description:**
Register a listener function for the given target.

The :func:`.listen` function is part of the primary interface for the
SQLAlchemy event system, documented at :ref:`event_toplevel`.

e.g.::

from sqlalchemy import event
from sqlalchemy.schema import UniqueConstraint

def unique_constraint_name(const, table):
const.name = "uq_%s_%s" % (
table.name,
list(const.columns)[0].name
)
event.listen(
UniqueConstraint,
"after_parent_attach",
unique_constraint_name)

:param bool insert: The default behavior for event handlers is to append
the decorated user defined function to an internal list of registered
event listeners upon discovery. If a user registers a function with
``insert=True``, SQLAlchemy will insert (prepend) the function to the
internal list upon discovery. This feature is not typically used or
recommended by the SQLAlchemy maintainers, but is provided to ensure
certain user defined functions can run before others, such as when
:ref:`Changing the sql_mode in MySQL <mysql_sql_mode>`.

:param bool named: When using named argument passing, the names listed in
the function argument specification will be used as keys in the
dictionary.
See :ref:`event_named_argument_styles`.

:param bool once: Private/Internal API usage. Deprecated.  This parameter
would provide that an event function would run only once per given
target. It does not however imply automatic de-registration of the
listener function; associating an arbitrarily high number of listeners
without explicitly removing them will cause memory to grow unbounded even
if ``once=True`` is specified.

:param bool propagate: The ``propagate`` kwarg is available when working
with ORM instrumentation and mapping events.
See :class:`_ormevent.MapperEvents` and
:meth:`_ormevent.MapperEvents.before_mapper_configured` for examples.

:param bool retval: This flag applies only to specific event listeners,
each of which includes documentation explaining when it should be used.
By default, no listener ever requires a return value.
However, some listeners do support special behaviors for return values,
and include in their documentation that the ``retval=True`` flag is
necessary for a return value to be processed.

Event listener suites that make use of :paramref:`_event.listen.retval`
include :class:`_events.ConnectionEvents` and
:class:`_ormevent.AttributeEvents`.

.. note::

The :func:`.listen` function cannot be called at the same time
that the target event is being run.   This has implications
for thread safety, and also means an event cannot be added
from inside the listener function for itself.  The list of
events to be run are present inside of a mutable collection
that can't be changed during iteration.

Event registration and removal is not intended to be a "high
velocity" operation; it is a configurational operation.  For
systems that need to quickly associate and deassociate with
events at high scale, use a mutable structure that is handled
from inside of a single listener.

.. seealso::

:func:`.listens_for`

:func:`.remove`

**Line:** 41

---

### `def listens_for(target: Any, identifier: str, *args: Any, **kw: Any) -> Callable[([Callable[..., Any]], Callable[..., Any])]`

**Description:**
Decorate a function as a listener for the given target + identifier.

The :func:`.listens_for` decorator is part of the primary interface for the
SQLAlchemy event system, documented at :ref:`event_toplevel`.

This function generally shares the same kwargs as :func:`.listens`.

e.g.::

from sqlalchemy import event
from sqlalchemy.schema import UniqueConstraint

@event.listens_for(UniqueConstraint, "after_parent_attach")
def unique_constraint_name(const, table):
const.name = "uq_%s_%s" % (
table.name,
list(const.columns)[0].name
)

A given function can also be invoked for only the first invocation
of the event using the ``once`` argument::

@event.listens_for(Mapper, "before_configure", once=True)
def on_config():
do_config()


.. warning:: The ``once`` argument does not imply automatic de-registration
of the listener function after it has been invoked a first time; a
listener entry will remain associated with the target object.
Associating an arbitrarily high number of listeners without explicitly
removing them will cause memory to grow unbounded even if ``once=True``
is specified.

.. seealso::

:func:`.listen` - general description of event listening

**Line:** 127

---

### `def remove(target: Any, identifier: str, fn: Callable[(..., Any)]) -> None`

**Description:**
Remove an event listener.

The arguments here should match exactly those which were sent to
:func:`.listen`; all the event registration which proceeded as a result
of this call will be reverted by calling :func:`.remove` with the same
arguments.

e.g.::

# if a function was registered like this...
@event.listens_for(SomeMappedClass, "before_insert", propagate=True)
def my_listener_function(*arg):
pass

# ... it's removed like this
event.remove(SomeMappedClass, "before_insert", my_listener_function)

Above, the listener function associated with ``SomeMappedClass`` was also
propagated to subclasses of ``SomeMappedClass``; the :func:`.remove`
function will revert all of these operations.

.. note::

The :func:`.remove` function cannot be called at the same time
that the target event is being run.   This has implications
for thread safety, and also means an event cannot be removed
from inside the listener function for itself.  The list of
events to be run are present inside of a mutable collection
that can't be changed during iteration.

Event registration and removal is not intended to be a "high
velocity" operation; it is a configurational operation.  For
systems that need to quickly associate and deassociate with
events at high scale, use a mutable structure that is handled
from inside of a single listener.

.. seealso::

:func:`.listen`

**Line:** 177

---

### `def contains(target: Any, identifier: str, fn: Callable[(..., Any)]) -> bool`

**Description:**
Return True if the given target/ident/fn is set up to listen.

**Line:** 222

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.event.base
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/event/base.py`

**Imports:**
- __future__.annotations
- attr._ClsLevelDispatch
- attr._EmptyListener
- attr._InstanceLevelDispatch
- attr._JoinedListener
- registry._ET
- registry._EventKey
- typing
- typing.Any
- typing.Dict
- typing.Generic
- typing.Iterator
- typing.List
- typing.Mapping
- typing.MutableMapping
- typing.Optional
- typing.Tuple
- typing.Type
- typing.Union
- typing.cast
- typing.overload
- util.typing.Literal
- weakref

**Functions:**

### `def _is_event_name(name: str) -> bool`

**Line:** 50

---

### `def _remove_dispatcher(cls: Type[_HasEventsDispatch[_ET]]) -> None`

**Line:** 223

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.event.legacy
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/event/legacy.py`

**Imports:**
- __future__.annotations
- attr._ClsLevelDispatch
- base._HasEventsDispatch
- registry._ET
- registry._ListenerFnType
- typing
- typing.Any
- typing.Callable
- typing.List
- typing.Optional
- typing.Tuple
- typing.Type
- util.compat.FullArgSpec

**Functions:**

### `def _legacy_signature(since: str, argnames: List[str], converter: Optional[Callable[(..., Any)]] = None) -> Callable[([Callable[..., Any]], Callable[..., Any])]`

**Description:**
legacy sig decorator


:param since: string version for deprecation warning
:param argnames: list of strings, which is *all* arguments that the legacy
version accepted, including arguments that are still there
:param converter: lambda that will accept tuple of this full arg signature
and return tuple of new arg signature.

**Line:** 35

---

### `def _wrap_fn_for_legacy(dispatch_collection: _ClsLevelDispatch[_ET], fn: _ListenerFnType, argspec: FullArgSpec) -> _ListenerFnType`

**Line:** 60

---

### `def _indent(text: str, indent: str) -> str`

**Line:** 117

---

### `def _standard_listen_example(dispatch_collection: _ClsLevelDispatch[_ET], sample_target: Any, fn: _ListenerFnType) -> str`

**Line:** 121

---

### `def _legacy_listen_examples(dispatch_collection: _ClsLevelDispatch[_ET], sample_target: str, fn: _ListenerFnType) -> str`

**Line:** 162

---

### `def _version_signature_changes(parent_dispatch_cls: Type[_HasEventsDispatch[_ET]], dispatch_collection: _ClsLevelDispatch[_ET]) -> str`

**Line:** 190

---

### `def _augment_fn_docs(dispatch_collection: _ClsLevelDispatch[_ET], parent_dispatch_cls: Type[_HasEventsDispatch[_ET]], fn: _ListenerFnType) -> str`

**Line:** 220

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.event.registry
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/event/registry.py`

**Imports:**
- __future__.annotations
- attr.RefCollection
- base.dispatcher
- collections
- types
- typing
- typing.Any
- typing.Callable
- typing.Deque
- typing.Dict
- typing.Generic
- typing.Iterable
- typing.Optional
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.cast
- weakref

**Functions:**

### `def _collection_gced(ref: weakref.ref[Any]) -> None`

**Line:** 103

---

### `def _stored_in_collection(event_key: _EventKey[_ET], owner: RefCollection[_ET]) -> bool`

**Line:** 120

---

### `def _removed_from_collection(event_key: _EventKey[_ET], owner: RefCollection[_ET]) -> None`

**Line:** 141

---

### `def _stored_in_collection_multi(newowner: RefCollection[_ET], oldowner: RefCollection[_ET], elements: Iterable[_ListenerFnType]) -> None`

**Line:** 160

---

### `def _clear(owner: RefCollection[_ET], elements: Iterable[_ListenerFnType]) -> None`

**Line:** 196

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.associationproxy
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/associationproxy.py`

**Imports:**
- __future__.annotations
- operator
- orm.InspectionAttrExtensionType
- orm.ORMDescriptor
- orm.base.SQLORMOperations
- orm.collections
- orm.interfaces
- orm.interfaces.MapperProperty
- orm.interfaces.PropComparator
- orm.interfaces._AttributeOptions
- orm.interfaces._DCAttributeOptions
- orm.interfaces._DEFAULT_ATTRIBUTE_OPTIONS
- orm.mapper.Mapper
- sql._typing._ColumnExpressionArgument
- sql._typing._InfoType
- sql.base._NoArg
- sql.operators
- sql.or_
- typing
- typing.AbstractSet
- typing.Any
- typing.Callable
- typing.Collection
- typing.Dict
- typing.Generic
- typing.ItemsView
- typing.Iterable
- typing.Iterator
- typing.KeysView
- typing.List
- typing.Mapping
- typing.MutableMapping
- typing.MutableSequence
- typing.MutableSet
- typing.NoReturn
- typing.Optional
- typing.Set
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.ValuesView
- typing.cast
- typing.overload
- util.typing.Literal
- util.typing.Protocol
- util.typing.Self
- util.typing.SupportsIndex
- util.typing.SupportsKeysAndGetItem

**Functions:**

### `def association_proxy(target_collection: str, attr: str, creator: Optional[_CreatorProtocol] = None, getset_factory: Optional[_GetSetFactoryProtocol] = None, proxy_factory: Optional[_ProxyFactoryProtocol] = None, proxy_bulk_set: Optional[_ProxyBulkSetProtocol] = None, info: Optional[_InfoType] = None, cascade_scalar_deletes: bool = False, create_on_none_assignment: bool = False, init: Union[(_NoArg, bool)] = _NoArg.NO_ARG, repr: Union[(_NoArg, bool)] = _NoArg.NO_ARG, default: Optional[Any] = _NoArg.NO_ARG, default_factory: Union[(_NoArg, Callable[[], _T])] = _NoArg.NO_ARG, compare: Union[(_NoArg, bool)] = _NoArg.NO_ARG, kw_only: Union[(_NoArg, bool)] = _NoArg.NO_ARG) -> AssociationProxy[Any]`

**Description:**
Return a Python property implementing a view of a target
attribute which references an attribute on members of the
target.

The returned value is an instance of :class:`.AssociationProxy`.

Implements a Python property representing a relationship as a collection
of simpler values, or a scalar value.  The proxied property will mimic
the collection type of the target (list, dict or set), or, in the case of
a one to one relationship, a simple scalar value.

:param target_collection: Name of the attribute that is the immediate
target.  This attribute is typically mapped by
:func:`~sqlalchemy.orm.relationship` to link to a target collection, but
can also be a many-to-one or non-scalar relationship.

:param attr: Attribute on the associated instance or instances that
are available on instances of the target object.

:param creator: optional.

Defines custom behavior when new items are added to the proxied
collection.

By default, adding new items to the collection will trigger a
construction of an instance of the target object, passing the given
item as a positional argument to the target constructor.  For cases
where this isn't sufficient, :paramref:`.association_proxy.creator`
can supply a callable that will construct the object in the
appropriate way, given the item that was passed.

For list- and set- oriented collections, a single argument is
passed to the callable. For dictionary oriented collections, two
arguments are passed, corresponding to the key and value.

The :paramref:`.association_proxy.creator` callable is also invoked
for scalar (i.e. many-to-one, one-to-one) relationships. If the
current value of the target relationship attribute is ``None``, the
callable is used to construct a new object.  If an object value already
exists, the given attribute value is populated onto that object.

.. seealso::

:ref:`associationproxy_creator`

:param cascade_scalar_deletes: when True, indicates that setting
the proxied value to ``None``, or deleting it via ``del``, should
also remove the source object.  Only applies to scalar attributes.
Normally, removing the proxied target will not remove the proxy
source, as this object may have other state that is still to be
kept.

.. versionadded:: 1.3

.. seealso::

:ref:`cascade_scalar_deletes` - complete usage example

:param create_on_none_assignment: when True, indicates that setting
the proxied value to ``None`` should **create** the source object
if it does not exist, using the creator.  Only applies to scalar
attributes.  This is mutually exclusive
vs. the :paramref:`.assocation_proxy.cascade_scalar_deletes`.

.. versionadded:: 2.0.18

:param init: Specific to :ref:`orm_declarative_native_dataclasses`,
specifies if the mapped attribute should be part of the ``__init__()``
method as generated by the dataclass process.

.. versionadded:: 2.0.0b4

:param repr: Specific to :ref:`orm_declarative_native_dataclasses`,
specifies if the attribute established by this :class:`.AssociationProxy`
should be part of the ``__repr__()`` method as generated by the dataclass
process.

.. versionadded:: 2.0.0b4

:param default_factory: Specific to
:ref:`orm_declarative_native_dataclasses`, specifies a default-value
generation function that will take place as part of the ``__init__()``
method as generated by the dataclass process.

.. versionadded:: 2.0.0b4

:param compare: Specific to
:ref:`orm_declarative_native_dataclasses`, indicates if this field
should be included in comparison operations when generating the
``__eq__()`` and ``__ne__()`` methods for the mapped class.

.. versionadded:: 2.0.0b4

:param kw_only: Specific to :ref:`orm_declarative_native_dataclasses`,
indicates if this field should be marked as keyword-only when generating
the ``__init__()`` method as generated by the dataclass process.

.. versionadded:: 2.0.0b4

:param info: optional, will be assigned to
:attr:`.AssociationProxy.info` if present.


The following additional parameters involve injection of custom behaviors
within the :class:`.AssociationProxy` object and are for advanced use
only:

:param getset_factory: Optional.  Proxied attribute access is
automatically handled by routines that get and set values based on
the `attr` argument for this proxy.

If you would like to customize this behavior, you may supply a
`getset_factory` callable that produces a tuple of `getter` and
`setter` functions.  The factory is called with two arguments, the
abstract type of the underlying collection and this proxy instance.

:param proxy_factory: Optional.  The type of collection to emulate is
determined by sniffing the target collection.  If your collection
type can't be determined by duck typing or you'd like to use a
different collection implementation, you may supply a factory
function to produce those collections.  Only applicable to
non-scalar relationships.

:param proxy_bulk_set: Optional, use with proxy_factory.

**Line:** 84

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.asyncio.base
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/base.py`

**Imports:**
- __future__.annotations
- abc
- functools
- typing.Any
- typing.AsyncGenerator
- typing.AsyncIterator
- typing.Awaitable
- typing.Callable
- typing.ClassVar
- typing.Dict
- typing.Generator
- typing.Generic
- typing.NoReturn
- typing.Optional
- typing.Tuple
- typing.TypeVar
- typing.overload
- util.typing.Literal
- util.typing.Self
- weakref

**Functions:**

### `def asyncstartablecontext(func: Callable[(..., AsyncIterator[_T_co])]) -> Callable[(..., GeneratorStartableContext[_T_co])]`

**Description:**
@asyncstartablecontext decorator.

the decorated function can be called either as ``async with fn()``, **or**
``await fn()``.   This is decidedly different from what
``@contextlib.asynccontextmanager`` supports, and the usage pattern
is different as well.

Typical usage::

@asyncstartablecontext
async def some_async_generator(<arguments>):
<setup>
try:
yield <value>
except GeneratorExit:
# return value was awaited, no context manager is present
# and caller will .close() the resource explicitly
pass
else:
<context manager cleanup>


Above, ``GeneratorExit`` is caught if the function were used as an
``await``.  In this case, it's essential that the cleanup does **not**
occur, so there should not be a ``finally`` block.

If ``GeneratorExit`` is not invoked, this means we're in ``__aexit__``
and we were invoked as a context manager, and cleanup should proceed.

**Line:** 221

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.asyncio.engine
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/engine.py`

**Imports:**
- __future__.annotations
- asyncio
- base.GeneratorStartableContext
- base.ProxyComparable
- base.StartableContext
- base.asyncstartablecontext
- contextlib
- engine.Connection
- engine.Engine
- engine.base.NestedTransaction
- engine.base.Transaction
- engine.create_engine
- engine.create_pool_from_url
- engine.cursor.CursorResult
- engine.interfaces.CompiledCacheType
- engine.interfaces.CoreExecuteOptionsParameter
- engine.interfaces.Dialect
- engine.interfaces.IsolationLevel
- engine.interfaces.SchemaTranslateMapType
- engine.interfaces._CoreAnyExecuteParams
- engine.interfaces._CoreSingleExecuteParams
- engine.interfaces._DBAPIAnyExecuteParams
- engine.interfaces._ExecuteOptions
- engine.result.ScalarResult
- engine.url.URL
- exc.ArgumentError
- pool.Pool
- pool.PoolProxiedConnection
- result.AsyncResult
- result.AsyncScalarResult
- result._ensure_sync_result
- sql._typing._InfoType
- sql.base.Executable
- sql.selectable.TypedReturnsRows
- typing.Any
- typing.AsyncIterator
- typing.Callable
- typing.Dict
- typing.Generator
- typing.NoReturn
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.overload
- util.concurrency.greenlet_spawn

**Functions:**

### `def create_async_engine(url: Union[(str, URL)], **kw: Any) -> AsyncEngine`

**Description:**
Create a new async engine instance.

Arguments passed to :func:`_asyncio.create_async_engine` are mostly
identical to those passed to the :func:`_sa.create_engine` function.
The specified dialect must be an asyncio-compatible dialect
such as :ref:`dialect-postgresql-asyncpg`.

.. versionadded:: 1.4

:param async_creator: an async callable which returns a driver-level
asyncio connection. If given, the function should take no arguments,
and return a new asyncio connection from the underlying asyncio
database driver; the connection will be wrapped in the appropriate
structures to be used with the :class:`.AsyncEngine`.   Note that the
parameters specified in the URL are not applied here, and the creator
function should use its own connection parameters.

This parameter is the asyncio equivalent of the
:paramref:`_sa.create_engine.creator` parameter of the
:func:`_sa.create_engine` function.

.. versionadded:: 2.0.16

**Line:** 67

---

### `def async_engine_from_config(configuration: Dict[(str, Any)], prefix: str = 'sqlalchemy.', **kwargs: Any) -> AsyncEngine`

**Description:**
Create a new AsyncEngine instance using a configuration dictionary.

This function is analogous to the :func:`_sa.engine_from_config` function
in SQLAlchemy Core, except that the requested dialect must be an
asyncio-compatible dialect such as :ref:`dialect-postgresql-asyncpg`.
The argument signature of the function is identical to that
of :func:`_sa.engine_from_config`.

.. versionadded:: 1.4.29

**Line:** 121

---

### `def create_async_pool_from_url(url: Union[(str, URL)], **kwargs: Any) -> Pool`

**Description:**
Create a new async engine instance.

Arguments passed to :func:`_asyncio.create_async_pool_from_url` are mostly
identical to those passed to the :func:`_sa.create_pool_from_url` function.
The specified dialect must be an asyncio-compatible dialect
such as :ref:`dialect-postgresql-asyncpg`.

.. versionadded:: 2.0.10

**Line:** 146

---

### `def _get_sync_engine_or_connection(async_engine: AsyncEngine) -> Engine`

**Decorators:**
- `@overload`

**Line:** 1421

---

### `def _get_sync_engine_or_connection(async_engine: AsyncConnection) -> Connection`

**Decorators:**
- `@overload`

**Line:** 1426

---

### `def _get_sync_engine_or_connection(async_engine: Union[(AsyncEngine, AsyncConnection)]) -> Union[(Engine, Connection)]`

**Line:** 1432

---

### `def _no_insp_for_async_conn_yet(subject: AsyncConnection) -> NoReturn`

**Decorators:**
- `@inspection._inspects(...)`

**Line:** 1447

---

### `def _no_insp_for_async_engine_xyet(subject: AsyncEngine) -> NoReturn`

**Decorators:**
- `@inspection._inspects(...)`

**Line:** 1459

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.asyncio.result
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/result.py`

**Imports:**
- __future__.annotations
- engine.CursorResult
- engine.Result
- engine.result.FilterResult
- engine.result.FrozenResult
- engine.result.ResultMetaData
- engine.result._KeyIndexType
- engine.result._NO_ROW
- engine.result._R
- engine.result._UniqueFilterType
- engine.result._WithKeys
- engine.row.Row
- engine.row.RowMapping
- operator
- sql.base._generative
- typing.Any
- typing.AsyncIterator
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.overload
- util.concurrency.greenlet_spawn
- util.typing.Literal
- util.typing.Self

**Functions:**

### `async def _ensure_sync_result(result: _RT, calling_method: Any) -> _RT`

**Line:** 950

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.asyncio.session
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/session.py`

**Imports:**
- __future__.annotations
- asyncio
- base.ReversibleProxy
- base.StartableContext
- engine.AsyncConnection
- engine.AsyncEngine
- engine.Connection
- engine.CursorResult
- engine.Engine
- engine.Result
- engine.Row
- engine.RowMapping
- engine.ScalarResult
- engine.interfaces.CoreExecuteOptionsParameter
- engine.interfaces._CoreAnyExecuteParams
- event.dispatcher
- orm.Session
- orm.SessionTransaction
- orm._typing.OrmExecuteOptionsParameter
- orm._typing._IdentityKeyType
- orm._typing._O
- orm.close_all_sessions
- orm.identity.IdentityMap
- orm.interfaces.ORMOption
- orm.object_session
- orm.session._BindArguments
- orm.session._EntityBindKey
- orm.session._PKIdentityArgument
- orm.session._SessionBind
- orm.session._SessionBindKey
- orm.state
- result.AsyncResult
- result.AsyncScalarResult
- result._ensure_sync_result
- sql._typing._InfoType
- sql.base.Executable
- sql.dml.UpdateBase
- sql.elements.ClauseElement
- sql.selectable.ForUpdateParameter
- sql.selectable.TypedReturnsRows
- typing.Any
- typing.Awaitable
- typing.Callable
- typing.Dict
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.concurrency.greenlet_spawn

**Functions:**

### `def async_object_session(instance: object) -> Optional[AsyncSession]`

**Description:**
Return the :class:`_asyncio.AsyncSession` to which the given instance
belongs.

This function makes use of the sync-API function
:class:`_orm.object_session` to retrieve the :class:`_orm.Session` which
refers to the given instance, and from there links it to the original
:class:`_asyncio.AsyncSession`.

If the :class:`_asyncio.AsyncSession` has been garbage collected, the
return value is ``None``.

This functionality is also available from the
:attr:`_orm.InstanceState.async_session` accessor.

:param instance: an ORM mapped instance
:return: an :class:`_asyncio.AsyncSession` object, or ``None``.

.. versionadded:: 1.4.18

**Line:** 1885

---

### `def async_session(session: Session) -> Optional[AsyncSession]`

**Description:**
Return the :class:`_asyncio.AsyncSession` which is proxying the given
:class:`_orm.Session` object, if any.

:param session: a :class:`_orm.Session` instance.
:return: a :class:`_asyncio.AsyncSession` instance, or ``None``.

.. versionadded:: 1.4.18

**Line:** 1914

---

### `async def close_all_sessions() -> None`

**Description:**
Close all :class:`_asyncio.AsyncSession` sessions.

.. versionadded:: 2.0.23

.. seealso::

:func:`.session.close_all_sessions`

**Line:** 1927

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.automap
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/automap.py`

**Imports:**
- __future__.annotations
- dataclasses
- engine.base.Engine
- orm.backref
- orm.base.RelationshipDirection
- orm.decl_base._DeferredMapperConfig
- orm.declarative_base
- orm.exc
- orm.interfaces
- orm.mapper._CONFIGURE_MUTEX
- orm.relationship
- orm.relationships.ORMBackrefArgument
- orm.relationships.Relationship
- schema.ForeignKeyConstraint
- sql.and_
- sql.schema.Column
- sql.schema.MetaData
- sql.schema.Table
- typing.Any
- typing.Callable
- typing.ClassVar
- typing.Dict
- typing.List
- typing.NoReturn
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.Properties
- util.immutabledict
- util.typing.Protocol

**Functions:**

### `def classname_for_table(base: Type[Any], tablename: str, table: Table) -> str`

**Description:**
Return the class name that should be used, given the name
of a table.

The default implementation is::

return str(tablename)

Alternate implementations can be specified using the
:paramref:`.AutomapBase.prepare.classname_for_table`
parameter.

:param base: the :class:`.AutomapBase` class doing the prepare.

:param tablename: string name of the :class:`_schema.Table`.

:param table: the :class:`_schema.Table` object itself.

:return: a string class name.

.. note::

In Python 2, the string used for the class name **must** be a
non-Unicode object, e.g. a ``str()`` object.  The ``.name`` attribute
of :class:`_schema.Table` is typically a Python unicode subclass,
so the
``str()`` function should be applied to this name, after accounting for
any non-ASCII characters.

**Line:** 722

---

### `def name_for_scalar_relationship(base: Type[Any], local_cls: Type[Any], referred_cls: Type[Any], constraint: ForeignKeyConstraint) -> str`

**Description:**
Return the attribute name that should be used to refer from one
class to another, for a scalar object reference.

The default implementation is::

return referred_cls.__name__.lower()

Alternate implementations can be specified using the
:paramref:`.AutomapBase.prepare.name_for_scalar_relationship`
parameter.

:param base: the :class:`.AutomapBase` class doing the prepare.

:param local_cls: the class to be mapped on the local side.

:param referred_cls: the class to be mapped on the referring side.

:param constraint: the :class:`_schema.ForeignKeyConstraint` that is being
inspected to produce this relationship.

**Line:** 770

---

### `def name_for_collection_relationship(base: Type[Any], local_cls: Type[Any], referred_cls: Type[Any], constraint: ForeignKeyConstraint) -> str`

**Description:**
Return the attribute name that should be used to refer from one
class to another, for a collection reference.

The default implementation is::

return referred_cls.__name__.lower() + "_collection"

Alternate implementations
can be specified using the
:paramref:`.AutomapBase.prepare.name_for_collection_relationship`
parameter.

:param base: the :class:`.AutomapBase` class doing the prepare.

:param local_cls: the class to be mapped on the local side.

:param referred_cls: the class to be mapped on the referring side.

:param constraint: the :class:`_schema.ForeignKeyConstraint` that is being
inspected to produce this relationship.

**Line:** 811

---

### `def generate_relationship(base: Type[Any], direction: RelationshipDirection, return_fn: Callable[(..., Relationship[Any])], attrname: str, local_cls: Type[Any], referred_cls: Type[Any], **kw: Any) -> Relationship[Any]`

**Decorators:**
- `@overload`

**Line:** 885

---

### `def generate_relationship(base: Type[Any], direction: RelationshipDirection, return_fn: Callable[(..., ORMBackrefArgument)], attrname: str, local_cls: Type[Any], referred_cls: Type[Any], **kw: Any) -> ORMBackrefArgument`

**Decorators:**
- `@overload`

**Line:** 898

---

### `def generate_relationship(base: Type[Any], direction: RelationshipDirection, return_fn: Union[(Callable[..., Relationship[Any]], Callable[..., ORMBackrefArgument])], attrname: str, local_cls: Type[Any], referred_cls: Type[Any], **kw: Any) -> Union[(Relationship[Any], ORMBackrefArgument)]`

**Description:**
Generate a :func:`_orm.relationship` or :func:`.backref`
on behalf of two
mapped classes.

An alternate implementation of this function can be specified using the
:paramref:`.AutomapBase.prepare.generate_relationship` parameter.

The default implementation of this function is as follows::

if return_fn is backref:
return return_fn(attrname, **kw)
elif return_fn is relationship:
return return_fn(referred_cls, **kw)
else:
raise TypeError("Unknown relationship function: %s" % return_fn)

:param base: the :class:`.AutomapBase` class doing the prepare.

:param direction: indicate the "direction" of the relationship; this will
be one of :data:`.ONETOMANY`, :data:`.MANYTOONE`, :data:`.MANYTOMANY`.

:param return_fn: the function that is used by default to create the
relationship.  This will be either :func:`_orm.relationship` or
:func:`.backref`.  The :func:`.backref` function's result will be used to
produce a new :func:`_orm.relationship` in a second step,
so it is critical
that user-defined implementations correctly differentiate between the two
functions, if a custom relationship function is being used.

:param attrname: the attribute name to which this relationship is being
assigned. If the value of :paramref:`.generate_relationship.return_fn` is
the :func:`.backref` function, then this name is the name that is being
assigned to the backref.

:param local_cls: the "local" class to which this relationship or backref
will be locally present.

:param referred_cls: the "referred" class to which the relationship or
backref refers to.

:param \**kw: all additional keyword arguments are passed along to the
function.

:return: a :func:`_orm.relationship` or :func:`.backref` construct,
as dictated
by the :paramref:`.generate_relationship.return_fn` parameter.

**Line:** 910

---

### `def automap_base(declarative_base: Optional[Type[Any]] = None, **kw: Any) -> Any`

**Description:**
Produce a declarative automap base.

This function produces a new base class that is a product of the
:class:`.AutomapBase` class as well a declarative base produced by
:func:`.declarative.declarative_base`.

All parameters other than ``declarative_base`` are keyword arguments
that are passed directly to the :func:`.declarative.declarative_base`
function.

:param declarative_base: an existing class produced by
:func:`.declarative.declarative_base`.  When this is passed, the function
no longer invokes :func:`.declarative.declarative_base` itself, and all
other keyword arguments are ignored.

:param \**kw: keyword arguments are passed along to
:func:`.declarative.declarative_base`.

**Line:** 1378

---

### `def _is_many_to_many(automap_base: Type[Any], table: Table) -> Tuple[(Optional[Table], Optional[Table], Optional[list[ForeignKeyConstraint]])]`

**Line:** 1417

---

### `def _relationships_for_fks(automap_base: Type[Any], map_config: _DeferredMapperConfig, table_to_map_config: Union[(Dict[Optional[Table], _DeferredMapperConfig], Dict[Table, _DeferredMapperConfig])], collection_class: type, name_for_scalar_relationship: NameForScalarRelationshipType, name_for_collection_relationship: NameForCollectionRelationshipType, generate_relationship: GenerateRelationshipType) -> None`

**Line:** 1448

---

### `def _m2m_relationship(automap_base: Type[Any], lcl_m2m: Table, rem_m2m: Table, m2m_const: List[ForeignKeyConstraint], table: Table, table_to_map_config: Union[(Dict[Optional[Table], _DeferredMapperConfig], Dict[Table, _DeferredMapperConfig])], collection_class: type, name_for_scalar_relationship: NameForCollectionRelationshipType, name_for_collection_relationship: NameForCollectionRelationshipType, generate_relationship: GenerateRelationshipType) -> None`

**Line:** 1558

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.compiler
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/compiler.py`

**Imports:**
- sql.sqltypes

**Functions:**

### `def compiles(class_, *specs)`

**Description:**
Register a function as a compiler for a
given :class:`_expression.ClauseElement` type.

**Line:** 459

---

### `def deregister(class_)`

**Description:**
Remove all custom compilers associated with a given
:class:`_expression.ClauseElement` type.

**Line:** 508

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.declarative.__init__
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/declarative/__init__.py`

**Imports:**
- extensions.AbstractConcreteBase
- extensions.ConcreteBase
- extensions.DeferredReflection
- orm.decl_api.DeclarativeMeta
- orm.decl_api.as_declarative
- orm.decl_api.declarative_base
- orm.decl_api.declared_attr
- orm.decl_api.has_inherited_table
- orm.decl_api.synonym_for

**Functions:**

### `def declarative_base(*arg, **kw)`

**Decorators:**
- `@util.moved_20(...)`

**Line:** 26

---

### `def as_declarative(*arg, **kw)`

**Decorators:**
- `@util.moved_20(...)`

**Line:** 34

---

### `def has_inherited_table(*arg, **kw)`

**Decorators:**
- `@util.moved_20(...)`

**Line:** 42

---

### `def synonym_for(*arg, **kw)`

**Decorators:**
- `@util.moved_20(...)`

**Line:** 50

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.horizontal_shard
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/horizontal_shard.py`

**Imports:**
- __future__.annotations
- engine.base.Connection
- engine.base.Engine
- engine.base.OptionEngine
- engine.result.IteratorResult
- engine.result.Result
- orm.LoaderCallableStatus
- orm.PassiveFlag
- orm._typing.OrmExecuteOptionsParameter
- orm._typing._O
- orm.bulk_persistence.BulkUDCompileState
- orm.context.QueryContext
- orm.interfaces.ORMOption
- orm.mapper.Mapper
- orm.query.Query
- orm.session.ORMExecuteState
- orm.session.Session
- orm.session._BindArguments
- orm.session._EntityBindKey
- orm.session._PKIdentityArgument
- orm.session._SessionBind
- orm.state.InstanceState
- sql.Executable
- sql._typing._TP
- sql.elements.ClauseElement
- typing.Any
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- util.typing.Protocol
- util.typing.Self

**Functions:**

### `def execute_and_instances(orm_context: ORMExecuteState) -> Union[(Result[_T], IteratorResult[_TP])]`

**Line:** 428

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.hybrid
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/hybrid.py`

**Imports:**
- __future__.annotations
- orm.InspectionAttrExtensionType
- orm.ORMDescriptor
- orm.attributes
- orm.attributes.QueryableAttribute
- orm.interfaces
- orm.interfaces.MapperProperty
- orm.util.AliasedInsp
- sql.SQLColumnExpression
- sql._typing._ColumnExpressionArgument
- sql._typing._DMLColumnArgument
- sql._typing._HasClauseElement
- sql._typing._InfoType
- sql._typing.is_has_clause_element
- sql.elements.ColumnElement
- sql.elements.SQLCoreOperations
- sql.operators.OperatorType
- sql.roles
- typing.Any
- typing.Callable
- typing.Generic
- typing.List
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.typing.Concatenate
- util.typing.Literal
- util.typing.ParamSpec
- util.typing.Protocol
- util.typing.Self

**Functions:**

### `def _unwrap_classmethod(meth: _T) -> _T`

**Line:** 1057

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.instrumentation
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/instrumentation.py`

**Imports:**
- orm.attributes
- orm.base
- orm.collections
- orm.exc
- orm.instrumentation
- orm.instrumentation.ClassManager
- orm.instrumentation.InstrumentationFactory
- orm.instrumentation._default_dict_getter
- orm.instrumentation._default_manager_getter
- orm.instrumentation._default_opt_manager_getter
- orm.instrumentation._default_state_getter
- orm.util
- weakref

**Functions:**

### `def find_native_user_instrumentation_hook(cls)`

**Description:**
Find user-specified instrumentation management for a class.

**Line:** 69

---

### `def _install_instrumented_lookups()`

**Description:**
Replace global class/object management functions
with ExtendedInstrumentationRegistry implementations, which
allow multiple types of class managers to be present,
at the cost of performance.

This function is called only by ExtendedInstrumentationRegistry
and unit tests specific to this behavior.

The _reinstall_default_lookups() function can be called
after this one to re-establish the default functions.

**Line:** 396

---

### `def _reinstall_default_lookups()`

**Description:**
Restore simplified lookups.

**Line:** 419

---

### `def _install_lookups(lookups)`

**Line:** 432

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.mutable
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/mutable.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- orm.Mapper
- orm._typing._ExternalEntityType
- orm._typing._O
- orm._typing._T
- orm.attributes.AttributeEventToken
- orm.attributes.InstrumentedAttribute
- orm.attributes.QueryableAttribute
- orm.attributes.flag_modified
- orm.context.QueryContext
- orm.decl_api.DeclarativeAttributeIntercept
- orm.state.InstanceState
- orm.unitofwork.UOWTransaction
- sql.base.SchemaEventTarget
- sql.schema.Column
- sql.type_api.TypeEngine
- typing.AbstractSet
- typing.Any
- typing.Dict
- typing.Iterable
- typing.List
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.overload
- util.memoized_property
- util.typing.SupportsIndex
- util.typing.TypeGuard
- weakref
- weakref.WeakKeyDictionary

**Functions:**

### `def _setup_composite_listener() -> None`

**Line:** 749

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.mypy.apply
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/mypy/apply.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ARG_NAMED_OPT
- mypy.nodes.Argument
- mypy.nodes.AssignmentStmt
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.MDEF
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.RefExpr
- mypy.nodes.StrExpr
- mypy.nodes.SymbolTableNode
- mypy.nodes.TempNode
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.plugin.SemanticAnalyzerPluginInterface
- mypy.plugins.common.add_method_to_class
- mypy.types.AnyType
- mypy.types.Instance
- mypy.types.NoneTyp
- mypy.types.ProperType
- mypy.types.TypeOfAny
- mypy.types.UnboundType
- mypy.types.UnionType
- mypy.types.get_proper_type
- names.NAMED_TYPE_SQLA_MAPPED
- names.expr_to_mapped_constructor
- typing.List
- typing.Optional
- typing.Union

**Functions:**

### `def apply_mypy_mapped_attr(cls: ClassDef, api: SemanticAnalyzerPluginInterface, item: Union[(NameExpr, StrExpr)], attributes: List[util.SQLAlchemyAttribute]) -> None`

**Line:** 45

---

### `def re_apply_declarative_assignments(cls: ClassDef, api: SemanticAnalyzerPluginInterface, attributes: List[util.SQLAlchemyAttribute]) -> None`

**Description:**
For multiple class passes, re-apply our left-hand side types as mypy
seems to reset them in place.

**Line:** 98

---

### `def apply_type_to_mapped_statement(api: SemanticAnalyzerPluginInterface, stmt: AssignmentStmt, lvalue: NameExpr, left_hand_explicit_type: Optional[ProperType], python_type_for_type: Optional[ProperType]) -> None`

**Description:**
Apply the Mapped[<type>] annotation and right hand object to a
declarative assignment statement.

This converts a Python declarative class statement such as::

class User(Base):
# ...

attrname = Column(Integer)

To one that describes the final Python behavior to Mypy::

class User(Base):
# ...

attrname : Mapped[Optional[int]] = <meaningless temp node>

**Line:** 183

---

### `def add_additional_orm_attributes(cls: ClassDef, api: SemanticAnalyzerPluginInterface, attributes: List[util.SQLAlchemyAttribute]) -> None`

**Description:**
Apply __init__, __table__ and other attributes to the mapped class.

**Line:** 249

---

### `def _apply_placeholder_attr_to_class(api: SemanticAnalyzerPluginInterface, cls: ClassDef, qualified_name: str, attrname: str) -> None`

**Line:** 302

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.mypy.decl_class
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/mypy/decl_class.py`

**Imports:**
- __future__.annotations
- mypy.nodes.AssignmentStmt
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.Decorator
- mypy.nodes.LambdaExpr
- mypy.nodes.ListExpr
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.PlaceholderNode
- mypy.nodes.RefExpr
- mypy.nodes.StrExpr
- mypy.nodes.SymbolNode
- mypy.nodes.SymbolTableNode
- mypy.nodes.TempNode
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.plugin.SemanticAnalyzerPluginInterface
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.NoneType
- mypy.types.ProperType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.UnboundType
- mypy.types.UnionType
- mypy.types.get_proper_type
- typing.List
- typing.Optional
- typing.Union

**Functions:**

### `def scan_declarative_assignments_and_apply_types(cls: ClassDef, api: SemanticAnalyzerPluginInterface, is_mixin_scan: bool = False) -> Optional[List[util.SQLAlchemyAttribute]]`

**Line:** 48

---

### `def _scan_symbol_table_entry(cls: ClassDef, api: SemanticAnalyzerPluginInterface, name: str, value: SymbolTableNode, attributes: List[util.SQLAlchemyAttribute]) -> None`

**Description:**
Extract mapping information from a SymbolTableNode that's in the
type.names dictionary.

**Line:** 114

---

### `def _scan_declarative_decorator_stmt(cls: ClassDef, api: SemanticAnalyzerPluginInterface, stmt: Decorator, attributes: List[util.SQLAlchemyAttribute]) -> None`

**Description:**
Extract mapping information from a @declared_attr in a declarative
class.

E.g.::

@reg.mapped
class MyClass:
# ...

@declared_attr
def updated_at(cls) -> Column[DateTime]:
return Column(DateTime)

Will resolve in mypy as::

@reg.mapped
class MyClass:
# ...

updated_at: Mapped[Optional[datetime.datetime]]

**Line:** 203

---

### `def _scan_declarative_assignment_stmt(cls: ClassDef, api: SemanticAnalyzerPluginInterface, stmt: AssignmentStmt, attributes: List[util.SQLAlchemyAttribute]) -> None`

**Description:**
Extract mapping information from an assignment statement in a
declarative class.

**Line:** 359

---

### `def _scan_for_mapped_bases(cls: ClassDef, api: SemanticAnalyzerPluginInterface) -> None`

**Description:**
Given a class, iterate through its superclass hierarchy to find
all other classes that are considered as ORM-significant.

Locates non-mapped mixins and scans them for mapped attributes to be
applied to subclasses.

**Line:** 489

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.mypy.infer
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/mypy/infer.py`

**Imports:**
- __future__.annotations
- mypy.maptype.map_instance_to_supertype
- mypy.nodes.AssignmentStmt
- mypy.nodes.CallExpr
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.LambdaExpr
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.RefExpr
- mypy.nodes.StrExpr
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.plugin.SemanticAnalyzerPluginInterface
- mypy.subtypes.is_subtype
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.NoneType
- mypy.types.ProperType
- mypy.types.TypeOfAny
- mypy.types.UnionType
- mypy.types.get_proper_type
- typing.Optional
- typing.Sequence

**Functions:**

### `def infer_type_from_right_hand_nameexpr(api: SemanticAnalyzerPluginInterface, stmt: AssignmentStmt, node: Var, left_hand_explicit_type: Optional[ProperType], infer_from_right_side: RefExpr) -> Optional[ProperType]`

**Line:** 40

---

### `def _infer_type_from_relationship(api: SemanticAnalyzerPluginInterface, stmt: AssignmentStmt, node: Var, left_hand_explicit_type: Optional[ProperType]) -> Optional[ProperType]`

**Description:**
Infer the type of mapping from a relationship.

E.g.::

@reg.mapped
class MyClass:
# ...

addresses = relationship(Address, uselist=True)

order: Mapped["Order"] = relationship("Order")

Will resolve in mypy as::

@reg.mapped
class MyClass:
# ...

addresses: Mapped[List[Address]]

order: Mapped["Order"]

**Line:** 80

---

### `def _infer_type_from_decl_composite_property(api: SemanticAnalyzerPluginInterface, stmt: AssignmentStmt, node: Var, left_hand_explicit_type: Optional[ProperType]) -> Optional[ProperType]`

**Description:**
Infer the type of mapping from a Composite.

**Line:** 246

---

### `def _infer_type_from_mapped(api: SemanticAnalyzerPluginInterface, stmt: AssignmentStmt, node: Var, left_hand_explicit_type: Optional[ProperType], infer_from_right_side: RefExpr) -> Optional[ProperType]`

**Description:**
Infer the type of mapping from a right side expression
that returns Mapped.

**Line:** 278

---

### `def _infer_type_from_decl_column_property(api: SemanticAnalyzerPluginInterface, stmt: AssignmentStmt, node: Var, left_hand_explicit_type: Optional[ProperType]) -> Optional[ProperType]`

**Description:**
Infer the type of mapping from a ColumnProperty.

This includes mappings against ``column_property()`` as well as the
``deferred()`` function.

**Line:** 310

---

### `def _infer_type_from_decl_column(api: SemanticAnalyzerPluginInterface, stmt: AssignmentStmt, node: Var, left_hand_explicit_type: Optional[ProperType], right_hand_expression: Optional[CallExpr] = None) -> Optional[ProperType]`

**Description:**
Infer the type of mapping from a Column.

E.g.::

@reg.mapped
class MyClass:
# ...

a = Column(Integer)

b = Column("b", String)

c: Mapped[int] = Column(Integer)

d: bool = Column(Boolean)

Will resolve in MyPy as::

@reg.mapped
class MyClass:
# ...

a : Mapped[int]

b : Mapped[str]

c: Mapped[int]

d: Mapped[bool]

**Line:** 359

---

### `def _infer_type_from_left_and_inferred_right(api: SemanticAnalyzerPluginInterface, node: Var, left_hand_explicit_type: ProperType, python_type_for_type: ProperType, orig_left_hand_type: Optional[ProperType] = None, orig_python_type_for_type: Optional[ProperType] = None) -> Optional[ProperType]`

**Description:**
Validate type when a left hand annotation is present and we also
could infer the right hand side::

attrname: SomeType = Column(SomeDBType)

**Line:** 458

---

### `def _infer_collection_type_from_left_and_inferred_right(api: SemanticAnalyzerPluginInterface, node: Var, left_hand_explicit_type: Instance, python_type_for_type: Instance) -> Optional[ProperType]`

**Line:** 500

---

### `def infer_type_from_left_hand_type_only(api: SemanticAnalyzerPluginInterface, node: Var, left_hand_explicit_type: Optional[ProperType]) -> Optional[ProperType]`

**Description:**
Determine the type based on explicit annotation only.

if no annotation were present, note that we need one there to know
the type.

**Line:** 529

---

### `def extract_python_type_from_typeengine(api: SemanticAnalyzerPluginInterface, node: TypeInfo, type_args: Sequence[Expression]) -> ProperType`

**Line:** 558

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.mypy.names
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/mypy/names.py`

**Imports:**
- __future__.annotations
- mypy.nodes.ARG_POS
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.Decorator
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.OverloadedFuncDef
- mypy.nodes.SymbolNode
- mypy.nodes.TypeAlias
- mypy.nodes.TypeInfo
- mypy.plugin.SemanticAnalyzerPluginInterface
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.UnboundType
- mypy.types.get_proper_type
- typing.Dict
- typing.List
- typing.Optional
- typing.Set
- typing.Tuple
- typing.Union

**Functions:**

### `def has_base_type_id(info: TypeInfo, type_id: int) -> bool`

**Line:** 219

---

### `def mro_has_id(mro: List[TypeInfo], type_id: int) -> bool`

**Line:** 233

---

### `def type_id_for_unbound_type(type_: UnboundType, cls: ClassDef, api: SemanticAnalyzerPluginInterface) -> Optional[int]`

**Line:** 247

---

### `def type_id_for_callee(callee: Expression) -> Optional[int]`

**Line:** 262

---

### `def type_id_for_named_node(node: Union[(NameExpr, MemberExpr, SymbolNode)]) -> Optional[int]`

**Line:** 306

---

### `def type_id_for_fullname(fullname: str) -> Optional[int]`

**Line:** 319

---

### `def expr_to_mapped_constructor(expr: Expression) -> CallExpr`

**Line:** 333

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.mypy.plugin
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/mypy/plugin.py`

**Imports:**
- __future__.annotations
- mypy.mro.MroError
- mypy.mro.calculate_mro
- mypy.nodes
- mypy.nodes.Block
- mypy.nodes.ClassDef
- mypy.nodes.GDEF
- mypy.nodes.MypyFile
- mypy.nodes.NameExpr
- mypy.nodes.SymbolTable
- mypy.nodes.SymbolTableNode
- mypy.nodes.TypeInfo
- mypy.plugin.AttributeContext
- mypy.plugin.ClassDefContext
- mypy.plugin.DynamicClassDefContext
- mypy.plugin.Plugin
- mypy.plugin.SemanticAnalyzerPluginInterface
- mypy.types.Instance
- mypy.types.Type
- mypy.types.get_proper_type
- typing.Callable
- typing.List
- typing.Optional
- typing.Tuple
- typing.Type
- typing.Union

**Functions:**

### `def plugin(version: str) -> TypingType[SQLAlchemyPlugin]`

**Line:** 136

---

### `def _dynamic_class_hook(ctx: DynamicClassDefContext) -> None`

**Description:**
Generate a declarative Base class when the declarative_base() function
is encountered.

**Line:** 140

---

### `def _fill_in_decorators(ctx: ClassDefContext) -> None`

**Line:** 179

---

### `def _cls_decorator_hook(ctx: ClassDefContext) -> None`

**Line:** 233

---

### `def _base_cls_decorator_hook(ctx: ClassDefContext) -> None`

**Line:** 250

---

### `def _declarative_mixin_hook(ctx: ClassDefContext) -> None`

**Line:** 263

---

### `def _metaclass_cls_hook(ctx: ClassDefContext) -> None`

**Line:** 271

---

### `def _base_cls_hook(ctx: ClassDefContext) -> None`

**Line:** 275

---

### `def _queryable_getattr_hook(ctx: AttributeContext) -> Type`

**Line:** 280

---

### `def _add_globals(ctx: Union[(ClassDefContext, DynamicClassDefContext)]) -> None`

**Description:**
Add __sa_DeclarativeMeta and __sa_Mapped symbol to the global space
for all class defs

**Line:** 286

---

### `def _set_declarative_metaclass(api: SemanticAnalyzerPluginInterface, target_cls: ClassDef) -> None`

**Line:** 295

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.mypy.util
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/mypy/util.py`

**Imports:**
- __future__.annotations
- mypy.messages.format_type
- mypy.nodes.CLASSDEF_NO_INFO
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.Context
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.IfStmt
- mypy.nodes.JsonDict
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.Statement
- mypy.nodes.SymbolTableNode
- mypy.nodes.TypeAlias
- mypy.nodes.TypeInfo
- mypy.options.Options
- mypy.plugin.ClassDefContext
- mypy.plugin.DynamicClassDefContext
- mypy.plugin.SemanticAnalyzerPluginInterface
- mypy.plugins.common.deserialize_and_fixup_type
- mypy.typeops.map_type_from_supertype
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.NoneType
- mypy.types.Type
- mypy.types.TypeVarType
- mypy.types.UnboundType
- mypy.types.UnionType
- mypy.types.get_proper_type
- mypy.version
- re
- typing.Any
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Optional
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.overload

**Functions:**

### `def name_is_dunder(name: str) -> bool`

**Line:** 107

---

### `def _set_info_metadata(info: TypeInfo, key: str, data: Any) -> None`

**Line:** 111

---

### `def _get_info_metadata(info: TypeInfo, key: str) -> Optional[Any]`

**Line:** 115

---

### `def _get_info_mro_metadata(info: TypeInfo, key: str) -> Optional[Any]`

**Line:** 119

---

### `def establish_as_sqlalchemy(info: TypeInfo) -> None`

**Line:** 128

---

### `def set_is_base(info: TypeInfo) -> None`

**Line:** 132

---

### `def get_is_base(info: TypeInfo) -> bool`

**Line:** 136

---

### `def has_declarative_base(info: TypeInfo) -> bool`

**Line:** 141

---

### `def set_has_table(info: TypeInfo) -> None`

**Line:** 146

---

### `def get_has_table(info: TypeInfo) -> bool`

**Line:** 150

---

### `def get_mapped_attributes(info: TypeInfo, api: SemanticAnalyzerPluginInterface) -> Optional[List[SQLAlchemyAttribute]]`

**Line:** 155

---

### `def format_type(typ_: Type, options: Options) -> str`

**Line:** 174

---

### `def set_mapped_attributes(info: TypeInfo, attributes: List[SQLAlchemyAttribute]) -> None`

**Line:** 181

---

### `def fail(api: SemanticAnalyzerPluginInterface, msg: str, ctx: Context) -> None`

**Line:** 191

---

### `def add_global(ctx: Union[(ClassDefContext, DynamicClassDefContext)], module: str, symbol_name: str, asname: str) -> None`

**Line:** 196

---

### `def get_callexpr_kwarg(callexpr: CallExpr, name: str, expr_types: None = Ellipsis) -> Optional[Union[(CallExpr, NameExpr)]]`

**Decorators:**
- `@overload`

**Line:** 213

---

### `def get_callexpr_kwarg(callexpr: CallExpr, name: str, expr_types: Tuple[(TypingType[_TArgType], ...)]) -> Optional[_TArgType]`

**Decorators:**
- `@overload`

**Line:** 220

---

### `def get_callexpr_kwarg(callexpr: CallExpr, name: str, expr_types: Optional[Tuple[(TypingType[Any], ...)]] = None) -> Optional[Any]`

**Line:** 229

---

### `def flatten_typechecking(stmts: Iterable[Statement]) -> Iterator[Statement]`

**Line:** 249

---

### `def type_for_callee(callee: Expression) -> Optional[Union[(Instance, TypeInfo)]]`

**Line:** 261

---

### `def unbound_to_instance(api: SemanticAnalyzerPluginInterface, typ: Type) -> Type`

**Description:**
Take the UnboundType that we seem to get as the ret_type from a FuncDef
and convert it into an Instance/TypeInfo kind of structure that seems
to work as the left-hand type of an AssignmentStatement.

**Line:** 280

---

### `def info_for_cls(cls: ClassDef, api: SemanticAnalyzerPluginInterface) -> Optional[TypeInfo]`

**Line:** 328

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.orderinglist
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/orderinglist.py`

**Imports:**
- __future__.annotations
- orm.collections.collection
- orm.collections.collection_adapter
- typing.Callable
- typing.List
- typing.Optional
- typing.Sequence
- typing.TypeVar

**Functions:**

### `def ordering_list(attr: str, count_from: Optional[int] = None, ordering_func: Optional[OrderingFunc] = None, reorder_on_append: bool = False) -> Callable[([], OrderingList)]`

**Description:**
Prepares an :class:`OrderingList` factory for use in mapper definitions.

Returns an object suitable for use as an argument to a Mapper
relationship's ``collection_class`` option.  e.g.::

from sqlalchemy.ext.orderinglist import ordering_list

class Slide(Base):
__tablename__ = 'slide'

id = Column(Integer, primary_key=True)
name = Column(String)

bullets = relationship("Bullet", order_by="Bullet.position",
collection_class=ordering_list('position'))

:param attr:
Name of the mapped attribute to use for storage and retrieval of
ordering information

:param count_from:
Set up an integer-based ordering, starting at ``count_from``.  For
example, ``ordering_list('pos', count_from=1)`` would create a 1-based
list in SQL, storing the value in the 'pos' column.  Ignored if
``ordering_func`` is supplied.

Additional arguments are passed to the :class:`.OrderingList` constructor.

**Line:** 141

---

### `def count_from_0(index, collection)`

**Description:**
Numbering function: consecutive integers starting at 0.

**Line:** 188

---

### `def count_from_1(index, collection)`

**Description:**
Numbering function: consecutive integers starting at 1.

**Line:** 194

---

### `def count_from_n_factory(start)`

**Description:**
Numbering function: consecutive integers starting at arbitrary start.

**Line:** 200

---

### `def _unsugar_count_from(**kw)`

**Description:**
Builds counting functions from keyword arguments.

Keyword argument filter, prepares a simple ``ordering_func`` from a
``count_from`` argument, otherwise passes ``ordering_func`` on unchanged.

**Line:** 213

---

### `def _reconstitute(cls, dict_, items)`

**Description:**
Reconstitute an :class:`.OrderingList`.

This is the adjoint to :meth:`.OrderingList.__reduce__`.  It is used for
unpickling :class:`.OrderingList` objects.

**Line:** 406

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.ext.serializer
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/ext/serializer.py`

**Imports:**
- engine.Engine
- io.BytesIO
- orm.class_mapper
- orm.interfaces.MapperProperty
- orm.mapper.Mapper
- orm.session.Session
- pickle
- re
- util.b64decode
- util.b64encode

**Functions:**

### `def Serializer(*args, **kw)`

**Line:** 85

---

### `def Deserializer(file, metadata = None, scoped_session = None, engine = None)`

**Line:** 126

---

### `def dumps(obj, protocol = pickle.HIGHEST_PROTOCOL)`

**Line:** 175

---

### `def loads(data, metadata = None, scoped_session = None, engine = None)`

**Line:** 182

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.inspection
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/inspection.py`

**Imports:**
- __future__.annotations
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generic
- typing.Optional
- typing.Type
- typing.TypeVar
- typing.Union
- typing.overload
- util.typing.Literal
- util.typing.Protocol

**Functions:**

### `def inspect(subject: Type[_InspectableTypeProtocol[_IN]], raiseerr: bool = True) -> _IN`

**Decorators:**
- `@overload`

**Line:** 92

---

### `def inspect(subject: _InspectableProtocol[_IN], raiseerr: bool = True) -> _IN`

**Decorators:**
- `@overload`

**Line:** 99

---

### `def inspect(subject: Inspectable[_IN], raiseerr: bool = True) -> _IN`

**Decorators:**
- `@overload`

**Line:** 104

---

### `def inspect(subject: Any, raiseerr: Literal[False] = Ellipsis) -> Optional[Any]`

**Decorators:**
- `@overload`

**Line:** 109

---

### `def inspect(subject: Any, raiseerr: bool = True) -> Any`

**Decorators:**
- `@overload`

**Line:** 114

---

### `def inspect(subject: Any, raiseerr: bool = True) -> Any`

**Description:**
Produce an inspection object for the given target.

The returned value in some cases may be the
same object as the one given, such as if a
:class:`_orm.Mapper` object is passed.   In other
cases, it will be an instance of the registered
inspection type for the given object, such as
if an :class:`_engine.Engine` is passed, an
:class:`_reflection.Inspector` object is returned.

:param subject: the subject to be inspected.
:param raiseerr: When ``True``, if the given subject
does not
correspond to a known SQLAlchemy inspected type,
:class:`sqlalchemy.exc.NoInspectionAvailable`
is raised.  If ``False``, ``None`` is returned.

**Line:** 118

---

### `def _inspects(*types: Type[Any]) -> Callable[([_F], _F)]`

**Line:** 159

---

### `def _self_inspects(cls: _TT) -> _TT`

**Line:** 177

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.log
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/log.py`

**Imports:**
- __future__.annotations
- logging
- sys
- typing.Any
- typing.Optional
- typing.Set
- typing.Type
- typing.TypeVar
- typing.Union
- typing.overload
- util.py311
- util.py38
- util.typing.Literal

**Functions:**

### `def _add_default_handler(logger: logging.Logger) -> None`

**Line:** 58

---

### `def _qual_logger_name_for_cls(cls: Type[Identified]) -> str`

**Line:** 69

---

### `def class_logger(cls: Type[_IT]) -> Type[_IT]`

**Line:** 76

---

### `def instance_logger(instance: Identified, echoflag: _EchoFlagType = None) -> None`

**Description:**
create a logger for an instance that implements :class:`.Identified`.

**Line:** 228

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.__init__
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/__init__.py`

**Imports:**
- __future__.annotations
- _orm_constructors._mapper_fn
- _orm_constructors.aliased
- _orm_constructors.backref
- _orm_constructors.clear_mappers
- _orm_constructors.column_property
- _orm_constructors.composite
- _orm_constructors.contains_alias
- _orm_constructors.create_session
- _orm_constructors.deferred
- _orm_constructors.dynamic_loader
- _orm_constructors.join
- _orm_constructors.mapped_column
- _orm_constructors.orm_insert_sentinel
- _orm_constructors.outerjoin
- _orm_constructors.query_expression
- _orm_constructors.relationship
- _orm_constructors.synonym
- _orm_constructors.with_loader_criteria
- _orm_constructors.with_polymorphic
- attributes.AttributeEventToken
- attributes.InstrumentedAttribute
- attributes.QueryableAttribute
- base.DynamicMapped
- base.InspectionAttrExtensionType
- base.LoaderCallableStatus
- base.Mapped
- base.NotExtension
- base.ORMDescriptor
- base.PassiveFlag
- base.SQLORMExpression
- base.WriteOnlyMapped
- base.class_mapper
- context.FromStatement
- context.QueryContext
- decl_api.DeclarativeBase
- decl_api.DeclarativeBaseNoMeta
- decl_api.DeclarativeMeta
- decl_api.MappedAsDataclass
- decl_api.add_mapped_attribute
- decl_api.as_declarative
- decl_api.declarative_base
- decl_api.declarative_mixin
- decl_api.declared_attr
- decl_api.has_inherited_table
- decl_api.registry
- decl_api.synonym_for
- decl_base.MappedClassProtocol
- descriptor_props.Composite
- descriptor_props.CompositeProperty
- descriptor_props.Synonym
- descriptor_props.SynonymProperty
- dynamic.AppenderQuery
- events.AttributeEvents
- events.InstanceEvents
- events.InstrumentationEvents
- events.MapperEvents
- events.QueryEvents
- events.SessionEvents
- identity.IdentityMap
- instrumentation.ClassManager
- interfaces.EXT_CONTINUE
- interfaces.EXT_SKIP
- interfaces.EXT_STOP
- interfaces.InspectionAttr
- interfaces.InspectionAttrInfo
- interfaces.MANYTOMANY
- interfaces.MANYTOONE
- interfaces.MapperProperty
- interfaces.NO_KEY
- interfaces.NO_VALUE
- interfaces.ONETOMANY
- interfaces.PropComparator
- interfaces.RelationshipDirection
- interfaces.UserDefinedOption
- loading.merge_frozen_result
- loading.merge_result
- mapped_collection.KeyFuncDict
- mapped_collection.MappedCollection
- mapped_collection.attribute_keyed_dict
- mapped_collection.attribute_mapped_collection
- mapped_collection.column_keyed_dict
- mapped_collection.column_mapped_collection
- mapped_collection.keyfunc_mapping
- mapped_collection.mapped_collection
- mapper.Mapper
- mapper.configure_mappers
- mapper.reconstructor
- mapper.validates
- properties.ColumnProperty
- properties.MappedColumn
- properties.MappedSQLExpression
- query.AliasOption
- query.Query
- relationships.Relationship
- relationships.RelationshipProperty
- relationships.foreign
- relationships.remote
- scoping.QueryPropertyDescriptor
- scoping.scoped_session
- session.ORMExecuteState
- session.Session
- session.SessionTransaction
- session.SessionTransactionOrigin
- session.close_all_sessions
- session.make_transient
- session.make_transient_to_detached
- session.object_session
- session.sessionmaker
- state.AttributeState
- state.InstanceState
- strategy_options.Load
- strategy_options.contains_eager
- strategy_options.defaultload
- strategy_options.defer
- strategy_options.immediateload
- strategy_options.joinedload
- strategy_options.lazyload
- strategy_options.load_only
- strategy_options.noload
- strategy_options.raiseload
- strategy_options.selectin_polymorphic
- strategy_options.selectinload
- strategy_options.subqueryload
- strategy_options.undefer
- strategy_options.undefer_group
- strategy_options.with_expression
- typing.Any
- unitofwork.UOWTransaction
- util.Bundle
- util.CascadeOptions
- util.LoaderCriteriaOption
- util.object_mapper
- util.polymorphic_union
- util.was_deleted
- util.with_parent
- writeonly.WriteOnlyCollection

**Functions:**

### `def __go(lcls: Any) -> None`

**Line:** 165

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm._orm_constructors
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/_orm_constructors.py`

**Imports:**
- __future__.annotations
- _typing._EntityType
- _typing._O
- _typing._ORMColumnExprArgument
- descriptor_props.Composite
- descriptor_props.Synonym
- descriptor_props._CC
- descriptor_props._CompositeAttrType
- exc.InvalidRequestError
- interfaces.PropComparator
- interfaces._AttributeOptions
- mapper.Mapper
- properties.MappedColumn
- properties.MappedSQLExpression
- query.AliasOption
- query.Query
- relationships.ORMBackrefArgument
- relationships.Relationship
- relationships.RelationshipProperty
- relationships._LazyLoadArgumentType
- relationships._ORMColCollectionArgument
- relationships._ORMOrderByArgument
- relationships._RelationshipArgumentType
- relationships._RelationshipJoinConditionArgument
- relationships._RelationshipSecondaryArgument
- session.Session
- session._SessionBind
- sql._typing._AutoIncrementType
- sql._typing._ColumnExpressionArgument
- sql._typing._FromClauseArgument
- sql._typing._InfoType
- sql._typing._OnClauseArgument
- sql._typing._TypeEngineArgument
- sql._typing._no_kw
- sql.base.SchemaEventTarget
- sql.base._NoArg
- sql.elements.ColumnElement
- sql.schema.FetchedValue
- sql.schema.SchemaConst
- sql.schema._InsertSentinelColumnDefault
- sql.schema._ServerDefaultArgument
- sql.selectable.Alias
- sql.selectable.FromClause
- sql.selectable.Subquery
- typing
- typing.Any
- typing.Callable
- typing.Collection
- typing.Iterable
- typing.NoReturn
- typing.Optional
- typing.TYPE_CHECKING
- typing.Type
- typing.Union
- typing.overload
- util.AliasedClass
- util.AliasedInsp
- util.LoaderCriteriaOption
- util._ORMJoin
- util.typing.Annotated
- util.typing.Literal

**Functions:**

### `def contains_alias(alias: Union[(Alias, Subquery)]) -> AliasOption`

**Decorators:**
- `@util.deprecated(...)`

**Description:**
Return a :class:`.MapperOption` that will indicate to the
:class:`_query.Query`
that the main table has been aliased.

**Line:** 88

---

### `def mapped_column(__name_pos: Optional[Union[(str, _TypeEngineArgument[Any], SchemaEventTarget)]] = None, __type_pos: Optional[Union[(_TypeEngineArgument[Any], SchemaEventTarget)]] = None, init: Union[(_NoArg, bool)] = _NoArg.NO_ARG, repr: Union[(_NoArg, bool)] = _NoArg.NO_ARG, default: Optional[Any] = _NoArg.NO_ARG, default_factory: Union[(_NoArg, Callable[[], _T])] = _NoArg.NO_ARG, compare: Union[(_NoArg, bool)] = _NoArg.NO_ARG, kw_only: Union[(_NoArg, bool)] = _NoArg.NO_ARG, nullable: Optional[Union[(bool, Literal[SchemaConst.NULL_UNSPECIFIED])]] = SchemaConst.NULL_UNSPECIFIED, primary_key: Optional[bool] = False, deferred: Union[(_NoArg, bool)] = _NoArg.NO_ARG, deferred_group: Optional[str] = None, deferred_raiseload: Optional[bool] = None, use_existing_column: bool = False, name: Optional[str] = None, type_: Optional[_TypeEngineArgument[Any]] = None, autoincrement: _AutoIncrementType = 'auto', doc: Optional[str] = None, key: Optional[str] = None, index: Optional[bool] = None, unique: Optional[bool] = None, info: Optional[_InfoType] = None, onupdate: Optional[Any] = None, insert_default: Optional[Any] = _NoArg.NO_ARG, server_default: Optional[_ServerDefaultArgument] = None, server_onupdate: Optional[FetchedValue] = None, active_history: bool = False, quote: Optional[bool] = None, system: bool = False, comment: Optional[str] = None, sort_order: Union[(_NoArg, int)] = _NoArg.NO_ARG, *args: SchemaEventTarget, **kw: Any) -> MappedColumn[Any]`

**Description:**
declare a new ORM-mapped :class:`_schema.Column` construct
for use within :ref:`Declarative Table <orm_declarative_table>`
configuration.

The :func:`_orm.mapped_column` function provides an ORM-aware and
Python-typing-compatible construct which is used with
:ref:`declarative <orm_declarative_mapping>` mappings to indicate an
attribute that's mapped to a Core :class:`_schema.Column` object.  It
provides the equivalent feature as mapping an attribute to a
:class:`_schema.Column` object directly when using Declarative,
specifically when using :ref:`Declarative Table <orm_declarative_table>`
configuration.

.. versionadded:: 2.0

:func:`_orm.mapped_column` is normally used with explicit typing along with
the :class:`_orm.Mapped` annotation type, where it can derive the SQL
type and nullability for the column based on what's present within the
:class:`_orm.Mapped` annotation.   It also may be used without annotations
as a drop-in replacement for how :class:`_schema.Column` is used in
Declarative mappings in SQLAlchemy 1.x style.

For usage examples of :func:`_orm.mapped_column`, see the documentation
at :ref:`orm_declarative_table`.

.. seealso::

:ref:`orm_declarative_table` - complete documentation

:ref:`whatsnew_20_orm_declarative_typing` - migration notes for
Declarative mappings using 1.x style mappings

:param __name: String name to give to the :class:`_schema.Column`.  This
is an optional, positional only argument that if present must be the
first positional argument passed.  If omitted, the attribute name to
which the :func:`_orm.mapped_column`  is mapped will be used as the SQL
column name.
:param __type: :class:`_types.TypeEngine` type or instance which will
indicate the datatype to be associated with the :class:`_schema.Column`.
This is an optional, positional-only argument that if present must
immediately follow the ``__name`` parameter if present also, or otherwise
be the first positional parameter.  If omitted, the ultimate type for
the column may be derived either from the annotated type, or if a
:class:`_schema.ForeignKey` is present, from the datatype of the
referenced column.
:param \*args: Additional positional arguments include constructs such
as :class:`_schema.ForeignKey`, :class:`_schema.CheckConstraint`,
and :class:`_schema.Identity`, which are passed through to the constructed
:class:`_schema.Column`.
:param nullable: Optional bool, whether the column should be "NULL" or
"NOT NULL". If omitted, the nullability is derived from the type
annotation based on whether or not ``typing.Optional`` is present.
``nullable`` defaults to ``True`` otherwise for non-primary key columns,
and ``False`` for primary key columns.
:param primary_key: optional bool, indicates the :class:`_schema.Column`
would be part of the table's primary key or not.
:param deferred: Optional bool - this keyword argument is consumed by the
ORM declarative process, and is not part of the :class:`_schema.Column`
itself; instead, it indicates that this column should be "deferred" for
loading as though mapped by :func:`_orm.deferred`.

.. seealso::

:ref:`orm_queryguide_deferred_declarative`

:param deferred_group: Implies :paramref:`_orm.mapped_column.deferred`
to ``True``, and set the :paramref:`_orm.deferred.group` parameter.

.. seealso::

:ref:`orm_queryguide_deferred_group`

:param deferred_raiseload: Implies :paramref:`_orm.mapped_column.deferred`
to ``True``, and set the :paramref:`_orm.deferred.raiseload` parameter.

.. seealso::

:ref:`orm_queryguide_deferred_raiseload`

:param use_existing_column: if True, will attempt to locate the given
column name on an inherited superclass (typically single inheriting
superclass), and if present, will not produce a new column, mapping
to the superclass column as though it were omitted from this class.
This is used for mixins that add new columns to an inherited superclass.

.. seealso::

:ref:`orm_inheritance_column_conflicts`

.. versionadded:: 2.0.0b4

:param default: Passed directly to the
:paramref:`_schema.Column.default` parameter if the
:paramref:`_orm.mapped_column.insert_default` parameter is not present.
Additionally, when used with :ref:`orm_declarative_native_dataclasses`,
indicates a default Python value that should be applied to the keyword
constructor within the generated ``__init__()`` method.

Note that in the case of dataclass generation when
:paramref:`_orm.mapped_column.insert_default` is not present, this means
the :paramref:`_orm.mapped_column.default` value is used in **two**
places, both the ``__init__()`` method as well as the
:paramref:`_schema.Column.default` parameter. While this behavior may
change in a future release, for the moment this tends to "work out"; a
default of ``None`` will mean that the :class:`_schema.Column` gets no
default generator, whereas a default that refers to a non-``None`` Python
or SQL expression value will be assigned up front on the object when
``__init__()`` is called, which is the same value that the Core
:class:`_sql.Insert` construct would use in any case, leading to the same
end result.

.. note:: When using Core level column defaults that are callables to
be interpreted by the underlying :class:`_schema.Column` in conjunction
with :ref:`ORM-mapped dataclasses
<orm_declarative_native_dataclasses>`, especially those that are
:ref:`context-aware default functions <context_default_functions>`,
**the** :paramref:`_orm.mapped_column.insert_default` **parameter must
be used instead**.  This is necessary to disambiguate the callable from
being interpreted as a dataclass level default.

:param insert_default: Passed directly to the
:paramref:`_schema.Column.default` parameter; will supersede the value
of :paramref:`_orm.mapped_column.default` when present, however
:paramref:`_orm.mapped_column.default` will always apply to the
constructor default for a dataclasses mapping.

:param sort_order: An integer that indicates how this mapped column
should be sorted compared to the others when the ORM is creating a
:class:`_schema.Table`. Among mapped columns that have the same
value the default ordering is used, placing first the mapped columns
defined in the main class, then the ones in the super classes.
Defaults to 0. The sort is ascending.

.. versionadded:: 2.0.4

:param active_history=False:

When ``True``, indicates that the "previous" value for a
scalar attribute should be loaded when replaced, if not
already loaded. Normally, history tracking logic for
simple non-primary-key scalar values only needs to be
aware of the "new" value in order to perform a flush. This
flag is available for applications that make use of
:func:`.attributes.get_history` or :meth:`.Session.is_modified`
which also need to know the "previous" value of the attribute.

.. versionadded:: 2.0.10


:param init: Specific to :ref:`orm_declarative_native_dataclasses`,
specifies if the mapped attribute should be part of the ``__init__()``
method as generated by the dataclass process.
:param repr: Specific to :ref:`orm_declarative_native_dataclasses`,
specifies if the mapped attribute should be part of the ``__repr__()``
method as generated by the dataclass process.
:param default_factory: Specific to
:ref:`orm_declarative_native_dataclasses`,
specifies a default-value generation function that will take place
as part of the ``__init__()``
method as generated by the dataclass process.
:param compare: Specific to
:ref:`orm_declarative_native_dataclasses`, indicates if this field
should be included in comparison operations when generating the
``__eq__()`` and ``__ne__()`` methods for the mapped class.

.. versionadded:: 2.0.0b4

:param kw_only: Specific to
:ref:`orm_declarative_native_dataclasses`, indicates if this field
should be marked as keyword-only when generating the ``__init__()``.

:param \**kw: All remaining keyword arguments are passed through to the
constructor for the :class:`_schema.Column`.

**Line:** 97

---

### `def orm_insert_sentinel(name: Optional[str] = None, type_: Optional[_TypeEngineArgument[Any]] = None, default: Optional[Any] = None, omit_from_statements: bool = True) -> MappedColumn[Any]`

**Description:**
Provides a surrogate :func:`_orm.mapped_column` that generates
a so-called :term:`sentinel` column, allowing efficient bulk
inserts with deterministic RETURNING sorting for tables that don't
otherwise have qualifying primary key configurations.

Use of :func:`_orm.orm_insert_sentinel` is analogous to the use of the
:func:`_schema.insert_sentinel` construct within a Core
:class:`_schema.Table` construct.

Guidelines for adding this construct to a Declarative mapped class
are the same as that of the :func:`_schema.insert_sentinel` construct;
the database table itself also needs to have a column with this name
present.

For background on how this object is used, see the section
:ref:`engine_insertmanyvalues_sentinel_columns` as part of the
section :ref:`engine_insertmanyvalues`.

.. seealso::

:func:`_schema.insert_sentinel`

:ref:`engine_insertmanyvalues`

:ref:`engine_insertmanyvalues_sentinel_columns`


.. versionadded:: 2.0.10

**Line:** 348

---

### `def column_property(column: _ORMColumnExprArgument[_T], group: Optional[str] = None, deferred: bool = False, raiseload: bool = False, comparator_factory: Optional[Type[PropComparator[_T]]] = None, init: Union[(_NoArg, bool)] = _NoArg.NO_ARG, repr: Union[(_NoArg, bool)] = _NoArg.NO_ARG, default: Optional[Any] = _NoArg.NO_ARG, default_factory: Union[(_NoArg, Callable[[], _T])] = _NoArg.NO_ARG, compare: Union[(_NoArg, bool)] = _NoArg.NO_ARG, kw_only: Union[(_NoArg, bool)] = _NoArg.NO_ARG, active_history: bool = False, expire_on_flush: bool = True, info: Optional[_InfoType] = None, doc: Optional[str] = None, *additional_columns: _ORMColumnExprArgument[Any]) -> MappedSQLExpression[_T]`

**Decorators:**
- `@util.deprecated_params(...)`

**Description:**
Provide a column-level property for use with a mapping.

With Declarative mappings, :func:`_orm.column_property` is used to
map read-only SQL expressions to a mapped class.

When using Imperative mappings, :func:`_orm.column_property` also
takes on the role of mapping table columns with additional features.
When using fully Declarative mappings, the :func:`_orm.mapped_column`
construct should be used for this purpose.

With Declarative Dataclass mappings, :func:`_orm.column_property`
is considered to be **read only**, and will not be included in the
Dataclass ``__init__()`` constructor.

The :func:`_orm.column_property` function returns an instance of
:class:`.ColumnProperty`.

.. seealso::

:ref:`mapper_column_property_sql_expressions` - general use of
:func:`_orm.column_property` to map SQL expressions

:ref:`orm_imperative_table_column_options` - usage of
:func:`_orm.column_property` with Imperative Table mappings to apply
additional options to a plain :class:`_schema.Column` object

:param \*cols:
list of Column objects to be mapped.

:param active_history=False:

Used only for Imperative Table mappings, or legacy-style Declarative
mappings (i.e. which have not been upgraded to
:func:`_orm.mapped_column`), for column-based attributes that are
expected to be writeable; use :func:`_orm.mapped_column` with
:paramref:`_orm.mapped_column.active_history` for Declarative mappings.
See that parameter for functional details.

:param comparator_factory: a class which extends
:class:`.ColumnProperty.Comparator` which provides custom SQL
clause generation for comparison operations.

:param group:
a group name for this property when marked as deferred.

:param deferred:
when True, the column property is "deferred", meaning that
it does not load immediately, and is instead loaded when the
attribute is first accessed on an instance.  See also
:func:`~sqlalchemy.orm.deferred`.

:param doc:
optional string that will be applied as the doc on the
class-bound descriptor.

:param expire_on_flush=True:
Disable expiry on flush.   A column_property() which refers
to a SQL expression (and not a single table-bound column)
is considered to be a "read only" property; populating it
has no effect on the state of data, and it can only return
database state.   For this reason a column_property()'s value
is expired whenever the parent object is involved in a
flush, that is, has any kind of "dirty" state within a flush.
Setting this parameter to ``False`` will have the effect of
leaving any existing value present after the flush proceeds.
Note that the :class:`.Session` with default expiration
settings still expires
all attributes after a :meth:`.Session.commit` call, however.

:param info: Optional data dictionary which will be populated into the
:attr:`.MapperProperty.info` attribute of this object.

:param raiseload: if True, indicates the column should raise an error
when undeferred, rather than loading the value.  This can be
altered at query time by using the :func:`.deferred` option with
raiseload=False.

.. versionadded:: 1.4

.. seealso::

:ref:`orm_queryguide_deferred_raiseload`

:param init:

:param default:

:param default_factory:

:param kw_only:

**Line:** 411

---

### `def composite(_class_or_attr: _CompositeAttrType[Any], group: Optional[str] = None, deferred: bool = False, raiseload: bool = False, comparator_factory: Optional[Type[Composite.Comparator[_T]]] = None, active_history: bool = False, init: Union[(_NoArg, bool)] = _NoArg.NO_ARG, repr: Union[(_NoArg, bool)] = _NoArg.NO_ARG, default: Optional[Any] = _NoArg.NO_ARG, default_factory: Union[(_NoArg, Callable[[], _T])] = _NoArg.NO_ARG, compare: Union[(_NoArg, bool)] = _NoArg.NO_ARG, kw_only: Union[(_NoArg, bool)] = _NoArg.NO_ARG, info: Optional[_InfoType] = None, doc: Optional[str] = None, *attrs: _CompositeAttrType[Any], **__kw: Any) -> Composite[Any]`

**Decorators:**
- `@overload`

**Line:** 545

---

### `def composite(_class_or_attr: Type[_CC], group: Optional[str] = None, deferred: bool = False, raiseload: bool = False, comparator_factory: Optional[Type[Composite.Comparator[_T]]] = None, active_history: bool = False, init: Union[(_NoArg, bool)] = _NoArg.NO_ARG, repr: Union[(_NoArg, bool)] = _NoArg.NO_ARG, default: Optional[Any] = _NoArg.NO_ARG, default_factory: Union[(_NoArg, Callable[[], _T])] = _NoArg.NO_ARG, compare: Union[(_NoArg, bool)] = _NoArg.NO_ARG, kw_only: Union[(_NoArg, bool)] = _NoArg.NO_ARG, info: Optional[_InfoType] = None, doc: Optional[str] = None, *attrs: _CompositeAttrType[Any], **__kw: Any) -> Composite[_CC]`

**Decorators:**
- `@overload`

**Line:** 567

---

### `def composite(_class_or_attr: Callable[(..., _CC)], group: Optional[str] = None, deferred: bool = False, raiseload: bool = False, comparator_factory: Optional[Type[Composite.Comparator[_T]]] = None, active_history: bool = False, init: Union[(_NoArg, bool)] = _NoArg.NO_ARG, repr: Union[(_NoArg, bool)] = _NoArg.NO_ARG, default: Optional[Any] = _NoArg.NO_ARG, default_factory: Union[(_NoArg, Callable[[], _T])] = _NoArg.NO_ARG, compare: Union[(_NoArg, bool)] = _NoArg.NO_ARG, kw_only: Union[(_NoArg, bool)] = _NoArg.NO_ARG, info: Optional[_InfoType] = None, doc: Optional[str] = None, *attrs: _CompositeAttrType[Any], **__kw: Any) -> Composite[_CC]`

**Decorators:**
- `@overload`

**Line:** 589

---

### `def composite(_class_or_attr: Union[(None, Type[_CC], Callable[..., _CC], _CompositeAttrType[Any])] = None, group: Optional[str] = None, deferred: bool = False, raiseload: bool = False, comparator_factory: Optional[Type[Composite.Comparator[_T]]] = None, active_history: bool = False, init: Union[(_NoArg, bool)] = _NoArg.NO_ARG, repr: Union[(_NoArg, bool)] = _NoArg.NO_ARG, default: Optional[Any] = _NoArg.NO_ARG, default_factory: Union[(_NoArg, Callable[[], _T])] = _NoArg.NO_ARG, compare: Union[(_NoArg, bool)] = _NoArg.NO_ARG, kw_only: Union[(_NoArg, bool)] = _NoArg.NO_ARG, info: Optional[_InfoType] = None, doc: Optional[str] = None, *attrs: _CompositeAttrType[Any], **__kw: Any) -> Composite[Any]`

**Description:**
Return a composite column-based property for use with a Mapper.

See the mapping documentation section :ref:`mapper_composite` for a
full usage example.

The :class:`.MapperProperty` returned by :func:`.composite`
is the :class:`.Composite`.

:param class\_:
The "composite type" class, or any classmethod or callable which
will produce a new instance of the composite object given the
column values in order.

:param \*attrs:
List of elements to be mapped, which may include:

* :class:`_schema.Column` objects
* :func:`_orm.mapped_column` constructs
* string names of other attributes on the mapped class, which may be
any other SQL or object-mapped attribute.  This can for
example allow a composite that refers to a many-to-one relationship

:param active_history=False:
When ``True``, indicates that the "previous" value for a
scalar attribute should be loaded when replaced, if not
already loaded.  See the same flag on :func:`.column_property`.

:param group:
A group name for this property when marked as deferred.

:param deferred:
When True, the column property is "deferred", meaning that it does
not load immediately, and is instead loaded when the attribute is
first accessed on an instance.  See also
:func:`~sqlalchemy.orm.deferred`.

:param comparator_factory:  a class which extends
:class:`.Composite.Comparator` which provides custom SQL
clause generation for comparison operations.

:param doc:
optional string that will be applied as the doc on the
class-bound descriptor.

:param info: Optional data dictionary which will be populated into the
:attr:`.MapperProperty.info` attribute of this object.

:param init: Specific to :ref:`orm_declarative_native_dataclasses`,
specifies if the mapped attribute should be part of the ``__init__()``
method as generated by the dataclass process.
:param repr: Specific to :ref:`orm_declarative_native_dataclasses`,
specifies if the mapped attribute should be part of the ``__repr__()``
method as generated by the dataclass process.
:param default_factory: Specific to
:ref:`orm_declarative_native_dataclasses`,
specifies a default-value generation function that will take place
as part of the ``__init__()``
method as generated by the dataclass process.

:param compare: Specific to
:ref:`orm_declarative_native_dataclasses`, indicates if this field
should be included in comparison operations when generating the
``__eq__()`` and ``__ne__()`` methods for the mapped class.

.. versionadded:: 2.0.0b4

:param kw_only: Specific to
:ref:`orm_declarative_native_dataclasses`, indicates if this field
should be marked as keyword-only when generating the ``__init__()``.

**Line:** 610

---

### `def with_loader_criteria(entity_or_base: _EntityType[Any], where_criteria: _ColumnExpressionArgument[bool], loader_only: bool = False, include_aliases: bool = False, propagate_to_loaders: bool = True, track_closure_variables: bool = True) -> LoaderCriteriaOption`

**Description:**
Add additional WHERE criteria to the load for all occurrences of
a particular entity.

.. versionadded:: 1.4

The :func:`_orm.with_loader_criteria` option is intended to add
limiting criteria to a particular kind of entity in a query,
**globally**, meaning it will apply to the entity as it appears
in the SELECT query as well as within any subqueries, join
conditions, and relationship loads, including both eager and lazy
loaders, without the need for it to be specified in any particular
part of the query.    The rendering logic uses the same system used by
single table inheritance to ensure a certain discriminator is applied
to a table.

E.g., using :term:`2.0-style` queries, we can limit the way the
``User.addresses`` collection is loaded, regardless of the kind
of loading used::

from sqlalchemy.orm import with_loader_criteria

stmt = select(User).options(
selectinload(User.addresses),
with_loader_criteria(Address, Address.email_address != 'foo'))
)

Above, the "selectinload" for ``User.addresses`` will apply the
given filtering criteria to the WHERE clause.

Another example, where the filtering will be applied to the
ON clause of the join, in this example using :term:`1.x style`
queries::

q = session.query(User).outerjoin(User.addresses).options(
with_loader_criteria(Address, Address.email_address != 'foo'))
)

The primary purpose of :func:`_orm.with_loader_criteria` is to use
it in the :meth:`_orm.SessionEvents.do_orm_execute` event handler
to ensure that all occurrences of a particular entity are filtered
in a certain way, such as filtering for access control roles.    It
also can be used to apply criteria to relationship loads.  In the
example below, we can apply a certain set of rules to all queries
emitted by a particular :class:`_orm.Session`::

session = Session(bind=engine)

@event.listens_for("do_orm_execute", session)
def _add_filtering_criteria(execute_state):

if (
execute_state.is_select
and not execute_state.is_column_load
and not execute_state.is_relationship_load
):
execute_state.statement = execute_state.statement.options(
with_loader_criteria(
SecurityRole,
lambda cls: cls.role.in_(['some_role']),
include_aliases=True
)
)

In the above example, the :meth:`_orm.SessionEvents.do_orm_execute`
event will intercept all queries emitted using the
:class:`_orm.Session`. For those queries which are SELECT statements
and are not attribute or relationship loads a custom
:func:`_orm.with_loader_criteria` option is added to the query.    The
:func:`_orm.with_loader_criteria` option will be used in the given
statement and will also be automatically propagated to all relationship
loads that descend from this query.

The criteria argument given is a ``lambda`` that accepts a ``cls``
argument.  The given class will expand to include all mapped subclass
and need not itself be a mapped class.

.. tip::

When using :func:`_orm.with_loader_criteria` option in
conjunction with the :func:`_orm.contains_eager` loader option,
it's important to note that :func:`_orm.with_loader_criteria` only
affects the part of the query that determines what SQL is rendered
in terms of the WHERE and FROM clauses. The
:func:`_orm.contains_eager` option does not affect the rendering of
the SELECT statement outside of the columns clause, so does not have
any interaction with the :func:`_orm.with_loader_criteria` option.
However, the way things "work" is that :func:`_orm.contains_eager`
is meant to be used with a query that is already selecting from the
additional entities in some way, where
:func:`_orm.with_loader_criteria` can apply it's additional
criteria.

In the example below, assuming a mapping relationship as
``A -> A.bs -> B``, the given :func:`_orm.with_loader_criteria`
option will affect the way in which the JOIN is rendered::

stmt = select(A).join(A.bs).options(
contains_eager(A.bs),
with_loader_criteria(B, B.flag == 1)
)

Above, the given :func:`_orm.with_loader_criteria` option will
affect the ON clause of the JOIN that is specified by
``.join(A.bs)``, so is applied as expected. The
:func:`_orm.contains_eager` option has the effect that columns from
``B`` are added to the columns clause::

SELECT
b.id, b.a_id, b.data, b.flag,
a.id AS id_1,
a.data AS data_1
FROM a JOIN b ON a.id = b.a_id AND b.flag = :flag_1


The use of the :func:`_orm.contains_eager` option within the above
statement has no effect on the behavior of the
:func:`_orm.with_loader_criteria` option. If the
:func:`_orm.contains_eager` option were omitted, the SQL would be
the same as regards the FROM and WHERE clauses, where
:func:`_orm.with_loader_criteria` continues to add its criteria to
the ON clause of the JOIN. The addition of
:func:`_orm.contains_eager` only affects the columns clause, in that
additional columns against ``b`` are added which are then consumed
by the ORM to produce ``B`` instances.

.. warning:: The use of a lambda inside of the call to
:func:`_orm.with_loader_criteria` is only invoked **once per unique
class**. Custom functions should not be invoked within this lambda.
See :ref:`engine_lambda_caching` for an overview of the "lambda SQL"
feature, which is for advanced use only.

:param entity_or_base: a mapped class, or a class that is a super
class of a particular set of mapped classes, to which the rule
will apply.

:param where_criteria: a Core SQL expression that applies limiting
criteria.   This may also be a "lambda:" or Python function that
accepts a target class as an argument, when the given class is
a base with many different mapped subclasses.

.. note:: To support pickling, use a module-level Python function to
produce the SQL expression instead of a lambda or a fixed SQL
expression, which tend to not be picklable.

:param include_aliases: if True, apply the rule to :func:`_orm.aliased`
constructs as well.

:param propagate_to_loaders: defaults to True, apply to relationship
loaders such as lazy loaders.   This indicates that the
option object itself including SQL expression is carried along with
each loaded instance.  Set to ``False`` to prevent the object from
being assigned to individual instances.


.. seealso::

:ref:`examples_session_orm_events` - includes examples of using
:func:`_orm.with_loader_criteria`.

:ref:`do_orm_execute_global_criteria` - basic example on how to
combine :func:`_orm.with_loader_criteria` with the
:meth:`_orm.SessionEvents.do_orm_execute` event.

:param track_closure_variables: when False, closure variables inside
of a lambda expression will not be used as part of
any cache key.    This allows more complex expressions to be used
inside of a lambda expression but requires that the lambda ensures
it returns the identical SQL every time given a particular class.

.. versionadded:: 1.4.0b2

**Line:** 720

---

### `def relationship(argument: Optional[_RelationshipArgumentType[Any]] = None, secondary: Optional[_RelationshipSecondaryArgument] = None, uselist: Optional[bool] = None, collection_class: Optional[Union[(Type[Collection[Any]], Callable[[], Collection[Any]])]] = None, primaryjoin: Optional[_RelationshipJoinConditionArgument] = None, secondaryjoin: Optional[_RelationshipJoinConditionArgument] = None, back_populates: Optional[str] = None, order_by: _ORMOrderByArgument = False, backref: Optional[ORMBackrefArgument] = None, overlaps: Optional[str] = None, post_update: bool = False, cascade: str = 'save-update, merge', viewonly: bool = False, init: Union[(_NoArg, bool)] = _NoArg.NO_ARG, repr: Union[(_NoArg, bool)] = _NoArg.NO_ARG, default: Union[(_NoArg, _T)] = _NoArg.NO_ARG, default_factory: Union[(_NoArg, Callable[[], _T])] = _NoArg.NO_ARG, compare: Union[(_NoArg, bool)] = _NoArg.NO_ARG, kw_only: Union[(_NoArg, bool)] = _NoArg.NO_ARG, lazy: _LazyLoadArgumentType = 'select', passive_deletes: Union[(Literal['all'], bool)] = False, passive_updates: bool = True, active_history: bool = False, enable_typechecks: bool = True, foreign_keys: Optional[_ORMColCollectionArgument] = None, remote_side: Optional[_ORMColCollectionArgument] = None, join_depth: Optional[int] = None, comparator_factory: Optional[Type[RelationshipProperty.Comparator[Any]]] = None, single_parent: bool = False, innerjoin: bool = False, distinct_target_key: Optional[bool] = None, load_on_pending: bool = False, query_class: Optional[Type[Query[Any]]] = None, info: Optional[_InfoType] = None, omit_join: Literal[(None, False)] = None, sync_backref: Optional[bool] = None, **kw: Any) -> Relationship[Any]`

**Description:**
Provide a relationship between two mapped classes.

This corresponds to a parent-child or associative table relationship.
The constructed class is an instance of :class:`.Relationship`.

.. seealso::

:ref:`tutorial_orm_related_objects` - tutorial introduction
to :func:`_orm.relationship` in the :ref:`unified_tutorial`

:ref:`relationship_config_toplevel` - narrative documentation

:param argument:
This parameter refers to the class that is to be related.   It
accepts several forms, including a direct reference to the target
class itself, the :class:`_orm.Mapper` instance for the target class,
a Python callable / lambda that will return a reference to the
class or :class:`_orm.Mapper` when called, and finally a string
name for the class, which will be resolved from the
:class:`_orm.registry` in use in order to locate the class, e.g.::

class SomeClass(Base):
# ...

related = relationship("RelatedClass")

The :paramref:`_orm.relationship.argument` may also be omitted from the
:func:`_orm.relationship` construct entirely, and instead placed inside
a :class:`_orm.Mapped` annotation on the left side, which should
include a Python collection type if the relationship is expected
to be a collection, such as::

class SomeClass(Base):
# ...

related_items: Mapped[List["RelatedItem"]] = relationship()

Or for a many-to-one or one-to-one relationship::

class SomeClass(Base):
# ...

related_item: Mapped["RelatedItem"] = relationship()

.. seealso::

:ref:`orm_declarative_properties` - further detail
on relationship configuration when using Declarative.

:param secondary:
For a many-to-many relationship, specifies the intermediary
table, and is typically an instance of :class:`_schema.Table`.
In less common circumstances, the argument may also be specified
as an :class:`_expression.Alias` construct, or even a
:class:`_expression.Join` construct.

:paramref:`_orm.relationship.secondary` may
also be passed as a callable function which is evaluated at
mapper initialization time.  When using Declarative, it may also
be a string argument noting the name of a :class:`_schema.Table`
that is
present in the :class:`_schema.MetaData`
collection associated with the
parent-mapped :class:`_schema.Table`.

.. warning:: When passed as a Python-evaluable string, the
argument is interpreted using Python's ``eval()`` function.
**DO NOT PASS UNTRUSTED INPUT TO THIS STRING**.
See :ref:`declarative_relationship_eval` for details on
declarative evaluation of :func:`_orm.relationship` arguments.

The :paramref:`_orm.relationship.secondary` keyword argument is
typically applied in the case where the intermediary
:class:`_schema.Table`
is not otherwise expressed in any direct class mapping. If the
"secondary" table is also explicitly mapped elsewhere (e.g. as in
:ref:`association_pattern`), one should consider applying the
:paramref:`_orm.relationship.viewonly` flag so that this
:func:`_orm.relationship`
is not used for persistence operations which
may conflict with those of the association object pattern.

.. seealso::

:ref:`relationships_many_to_many` - Reference example of "many
to many".

:ref:`self_referential_many_to_many` - Specifics on using
many-to-many in a self-referential case.

:ref:`declarative_many_to_many` - Additional options when using
Declarative.

:ref:`association_pattern` - an alternative to
:paramref:`_orm.relationship.secondary`
when composing association
table relationships, allowing additional attributes to be
specified on the association table.

:ref:`composite_secondary_join` - a lesser-used pattern which
in some cases can enable complex :func:`_orm.relationship` SQL
conditions to be used.

:param active_history=False:
When ``True``, indicates that the "previous" value for a
many-to-one reference should be loaded when replaced, if
not already loaded. Normally, history tracking logic for
simple many-to-ones only needs to be aware of the "new"
value in order to perform a flush. This flag is available
for applications that make use of
:func:`.attributes.get_history` which also need to know
the "previous" value of the attribute.

:param backref:
A reference to a string relationship name, or a :func:`_orm.backref`
construct, which will be used to automatically generate a new
:func:`_orm.relationship` on the related class, which then refers to this
one using a bi-directional :paramref:`_orm.relationship.back_populates`
configuration.

In modern Python, explicit use of :func:`_orm.relationship`
with :paramref:`_orm.relationship.back_populates` should be preferred,
as it is more robust in terms of mapper configuration as well as
more conceptually straightforward.  It also integrates with
new :pep:`484` typing features introduced in SQLAlchemy 2.0 which
is not possible with dynamically generated attributes.

.. seealso::

:ref:`relationships_backref` - notes on using
:paramref:`_orm.relationship.backref`

:ref:`tutorial_orm_related_objects` - in the :ref:`unified_tutorial`,
presents an overview of bi-directional relationship configuration
and behaviors using :paramref:`_orm.relationship.back_populates`

:func:`.backref` - allows control over :func:`_orm.relationship`
configuration when using :paramref:`_orm.relationship.backref`.


:param back_populates:
Indicates the name of a :func:`_orm.relationship` on the related
class that will be synchronized with this one.   It is usually
expected that the :func:`_orm.relationship` on the related class
also refer to this one.  This allows objects on both sides of
each :func:`_orm.relationship` to synchronize in-Python state
changes and also provides directives to the :term:`unit of work`
flush process how changes along these relationships should
be persisted.

.. seealso::

:ref:`tutorial_orm_related_objects` - in the :ref:`unified_tutorial`,
presents an overview of bi-directional relationship configuration
and behaviors.

:ref:`relationship_patterns` - includes many examples of
:paramref:`_orm.relationship.back_populates`.

:paramref:`_orm.relationship.backref` - legacy form which allows
more succinct configuration, but does not support explicit typing

:param overlaps:
A string name or comma-delimited set of names of other relationships
on either this mapper, a descendant mapper, or a target mapper with
which this relationship may write to the same foreign keys upon
persistence.   The only effect this has is to eliminate the
warning that this relationship will conflict with another upon
persistence.   This is used for such relationships that are truly
capable of conflicting with each other on write, but the application
will ensure that no such conflicts occur.

.. versionadded:: 1.4

.. seealso::

:ref:`error_qzyx` - usage example

:param cascade:
A comma-separated list of cascade rules which determines how
Session operations should be "cascaded" from parent to child.
This defaults to ``False``, which means the default cascade
should be used - this default cascade is ``"save-update, merge"``.

The available cascades are ``save-update``, ``merge``,
``expunge``, ``delete``, ``delete-orphan``, and ``refresh-expire``.
An additional option, ``all`` indicates shorthand for
``"save-update, merge, refresh-expire,
expunge, delete"``, and is often used as in ``"all, delete-orphan"``
to indicate that related objects should follow along with the
parent object in all cases, and be deleted when de-associated.

.. seealso::

:ref:`unitofwork_cascades` - Full detail on each of the available
cascade options.

:param cascade_backrefs=False:
Legacy; this flag is always False.

.. versionchanged:: 2.0 "cascade_backrefs" functionality has been
removed.

:param collection_class:
A class or callable that returns a new list-holding object. will
be used in place of a plain list for storing elements.

.. seealso::

:ref:`custom_collections` - Introductory documentation and
examples.

:param comparator_factory:
A class which extends :class:`.Relationship.Comparator`
which provides custom SQL clause generation for comparison
operations.

.. seealso::

:class:`.PropComparator` - some detail on redefining comparators
at this level.

:ref:`custom_comparators` - Brief intro to this feature.


:param distinct_target_key=None:
Indicate if a "subquery" eager load should apply the DISTINCT
keyword to the innermost SELECT statement.  When left as ``None``,
the DISTINCT keyword will be applied in those cases when the target
columns do not comprise the full primary key of the target table.
When set to ``True``, the DISTINCT keyword is applied to the
innermost SELECT unconditionally.

It may be desirable to set this flag to False when the DISTINCT is
reducing performance of the innermost subquery beyond that of what
duplicate innermost rows may be causing.

.. seealso::

:ref:`loading_toplevel` - includes an introduction to subquery
eager loading.

:param doc:
Docstring which will be applied to the resulting descriptor.

:param foreign_keys:

A list of columns which are to be used as "foreign key"
columns, or columns which refer to the value in a remote
column, within the context of this :func:`_orm.relationship`
object's :paramref:`_orm.relationship.primaryjoin` condition.
That is, if the :paramref:`_orm.relationship.primaryjoin`
condition of this :func:`_orm.relationship` is ``a.id ==
b.a_id``, and the values in ``b.a_id`` are required to be
present in ``a.id``, then the "foreign key" column of this
:func:`_orm.relationship` is ``b.a_id``.

In normal cases, the :paramref:`_orm.relationship.foreign_keys`
parameter is **not required.** :func:`_orm.relationship` will
automatically determine which columns in the
:paramref:`_orm.relationship.primaryjoin` condition are to be
considered "foreign key" columns based on those
:class:`_schema.Column` objects that specify
:class:`_schema.ForeignKey`,
or are otherwise listed as referencing columns in a
:class:`_schema.ForeignKeyConstraint` construct.
:paramref:`_orm.relationship.foreign_keys` is only needed when:

1. There is more than one way to construct a join from the local
table to the remote table, as there are multiple foreign key
references present.  Setting ``foreign_keys`` will limit the
:func:`_orm.relationship`
to consider just those columns specified
here as "foreign".

2. The :class:`_schema.Table` being mapped does not actually have
:class:`_schema.ForeignKey` or
:class:`_schema.ForeignKeyConstraint`
constructs present, often because the table
was reflected from a database that does not support foreign key
reflection (MySQL MyISAM).

3. The :paramref:`_orm.relationship.primaryjoin`
argument is used to
construct a non-standard join condition, which makes use of
columns or expressions that do not normally refer to their
"parent" column, such as a join condition expressed by a
complex comparison using a SQL function.

The :func:`_orm.relationship` construct will raise informative
error messages that suggest the use of the
:paramref:`_orm.relationship.foreign_keys` parameter when
presented with an ambiguous condition.   In typical cases,
if :func:`_orm.relationship` doesn't raise any exceptions, the
:paramref:`_orm.relationship.foreign_keys` parameter is usually
not needed.

:paramref:`_orm.relationship.foreign_keys` may also be passed as a
callable function which is evaluated at mapper initialization time,
and may be passed as a Python-evaluable string when using
Declarative.

.. warning:: When passed as a Python-evaluable string, the
argument is interpreted using Python's ``eval()`` function.
**DO NOT PASS UNTRUSTED INPUT TO THIS STRING**.
See :ref:`declarative_relationship_eval` for details on
declarative evaluation of :func:`_orm.relationship` arguments.

.. seealso::

:ref:`relationship_foreign_keys`

:ref:`relationship_custom_foreign`

:func:`.foreign` - allows direct annotation of the "foreign"
columns within a :paramref:`_orm.relationship.primaryjoin`
condition.

:param info: Optional data dictionary which will be populated into the
:attr:`.MapperProperty.info` attribute of this object.

:param innerjoin=False:
When ``True``, joined eager loads will use an inner join to join
against related tables instead of an outer join.  The purpose
of this option is generally one of performance, as inner joins
generally perform better than outer joins.

This flag can be set to ``True`` when the relationship references an
object via many-to-one using local foreign keys that are not
nullable, or when the reference is one-to-one or a collection that
is guaranteed to have one or at least one entry.

The option supports the same "nested" and "unnested" options as
that of :paramref:`_orm.joinedload.innerjoin`.  See that flag
for details on nested / unnested behaviors.

.. seealso::

:paramref:`_orm.joinedload.innerjoin` - the option as specified by
loader option, including detail on nesting behavior.

:ref:`what_kind_of_loading` - Discussion of some details of
various loader options.


:param join_depth:
When non-``None``, an integer value indicating how many levels
deep "eager" loaders should join on a self-referring or cyclical
relationship.  The number counts how many times the same Mapper
shall be present in the loading condition along a particular join
branch.  When left at its default of ``None``, eager loaders
will stop chaining when they encounter a the same target mapper
which is already higher up in the chain.  This option applies
both to joined- and subquery- eager loaders.

.. seealso::

:ref:`self_referential_eager_loading` - Introductory documentation
and examples.

:param lazy='select': specifies
How the related items should be loaded.  Default value is
``select``.  Values include:

* ``select`` - items should be loaded lazily when the property is
first accessed, using a separate SELECT statement, or identity map
fetch for simple many-to-one references.

* ``immediate`` - items should be loaded as the parents are loaded,
using a separate SELECT statement, or identity map fetch for
simple many-to-one references.

* ``joined`` - items should be loaded "eagerly" in the same query as
that of the parent, using a JOIN or LEFT OUTER JOIN.  Whether
the join is "outer" or not is determined by the
:paramref:`_orm.relationship.innerjoin` parameter.

* ``subquery`` - items should be loaded "eagerly" as the parents are
loaded, using one additional SQL statement, which issues a JOIN to
a subquery of the original statement, for each collection
requested.

* ``selectin`` - items should be loaded "eagerly" as the parents
are loaded, using one or more additional SQL statements, which
issues a JOIN to the immediate parent object, specifying primary
key identifiers using an IN clause.

* ``noload`` - no loading should occur at any time.  The related
collection will remain empty.   The ``noload`` strategy is not
recommended for general use.  For a general use "never load"
approach, see :ref:`write_only_relationship`

* ``raise`` - lazy loading is disallowed; accessing
the attribute, if its value were not already loaded via eager
loading, will raise an :exc:`~sqlalchemy.exc.InvalidRequestError`.
This strategy can be used when objects are to be detached from
their attached :class:`.Session` after they are loaded.

* ``raise_on_sql`` - lazy loading that emits SQL is disallowed;
accessing the attribute, if its value were not already loaded via
eager loading, will raise an
:exc:`~sqlalchemy.exc.InvalidRequestError`, **if the lazy load
needs to emit SQL**.  If the lazy load can pull the related value
from the identity map or determine that it should be None, the
value is loaded.  This strategy can be used when objects will
remain associated with the attached :class:`.Session`, however
additional SELECT statements should be blocked.

* ``write_only`` - the attribute will be configured with a special
"virtual collection" that may receive
:meth:`_orm.WriteOnlyCollection.add` and
:meth:`_orm.WriteOnlyCollection.remove` commands to add or remove
individual objects, but will not under any circumstances load or
iterate the full set of objects from the database directly. Instead,
methods such as :meth:`_orm.WriteOnlyCollection.select`,
:meth:`_orm.WriteOnlyCollection.insert`,
:meth:`_orm.WriteOnlyCollection.update` and
:meth:`_orm.WriteOnlyCollection.delete` are provided which generate SQL
constructs that may be used to load and modify rows in bulk. Used for
large collections that are never appropriate to load at once into
memory.

The ``write_only`` loader style is configured automatically when
the :class:`_orm.WriteOnlyMapped` annotation is provided on the
left hand side within a Declarative mapping.  See the section
:ref:`write_only_relationship` for examples.

.. versionadded:: 2.0

.. seealso::

:ref:`write_only_relationship` - in the :ref:`queryguide_toplevel`

* ``dynamic`` - the attribute will return a pre-configured
:class:`_query.Query` object for all read
operations, onto which further filtering operations can be
applied before iterating the results.

The ``dynamic`` loader style is configured automatically when
the :class:`_orm.DynamicMapped` annotation is provided on the
left hand side within a Declarative mapping.  See the section
:ref:`dynamic_relationship` for examples.

.. legacy::  The "dynamic" lazy loader strategy is the legacy form of
what is now the "write_only" strategy described in the section
:ref:`write_only_relationship`.

.. seealso::

:ref:`dynamic_relationship` - in the :ref:`queryguide_toplevel`

:ref:`write_only_relationship` - more generally useful approach
for large collections that should not fully load into memory

* True - a synonym for 'select'

* False - a synonym for 'joined'

* None - a synonym for 'noload'

.. seealso::

:ref:`orm_queryguide_relationship_loaders` - Full documentation on
relationship loader configuration in the :ref:`queryguide_toplevel`.


:param load_on_pending=False:
Indicates loading behavior for transient or pending parent objects.

When set to ``True``, causes the lazy-loader to
issue a query for a parent object that is not persistent, meaning it
has never been flushed.  This may take effect for a pending object
when autoflush is disabled, or for a transient object that has been
"attached" to a :class:`.Session` but is not part of its pending
collection.

The :paramref:`_orm.relationship.load_on_pending`
flag does not improve
behavior when the ORM is used normally - object references should be
constructed at the object level, not at the foreign key level, so
that they are present in an ordinary way before a flush proceeds.
This flag is not not intended for general use.

.. seealso::

:meth:`.Session.enable_relationship_loading` - this method
establishes "load on pending" behavior for the whole object, and
also allows loading on objects that remain transient or
detached.

:param order_by:
Indicates the ordering that should be applied when loading these
items.  :paramref:`_orm.relationship.order_by`
is expected to refer to
one of the :class:`_schema.Column`
objects to which the target class is
mapped, or the attribute itself bound to the target class which
refers to the column.

:paramref:`_orm.relationship.order_by`
may also be passed as a callable
function which is evaluated at mapper initialization time, and may
be passed as a Python-evaluable string when using Declarative.

.. warning:: When passed as a Python-evaluable string, the
argument is interpreted using Python's ``eval()`` function.
**DO NOT PASS UNTRUSTED INPUT TO THIS STRING**.
See :ref:`declarative_relationship_eval` for details on
declarative evaluation of :func:`_orm.relationship` arguments.

:param passive_deletes=False:
Indicates loading behavior during delete operations.

A value of True indicates that unloaded child items should not
be loaded during a delete operation on the parent.  Normally,
when a parent item is deleted, all child items are loaded so
that they can either be marked as deleted, or have their
foreign key to the parent set to NULL.  Marking this flag as
True usually implies an ON DELETE <CASCADE|SET NULL> rule is in
place which will handle updating/deleting child rows on the
database side.

Additionally, setting the flag to the string value 'all' will
disable the "nulling out" of the child foreign keys, when the parent
object is deleted and there is no delete or delete-orphan cascade
enabled.  This is typically used when a triggering or error raise
scenario is in place on the database side.  Note that the foreign
key attributes on in-session child objects will not be changed after
a flush occurs so this is a very special use-case setting.
Additionally, the "nulling out" will still occur if the child
object is de-associated with the parent.

.. seealso::

:ref:`passive_deletes` - Introductory documentation
and examples.

:param passive_updates=True:
Indicates the persistence behavior to take when a referenced
primary key value changes in place, indicating that the referencing
foreign key columns will also need their value changed.

When True, it is assumed that ``ON UPDATE CASCADE`` is configured on
the foreign key in the database, and that the database will
handle propagation of an UPDATE from a source column to
dependent rows.  When False, the SQLAlchemy
:func:`_orm.relationship`
construct will attempt to emit its own UPDATE statements to
modify related targets.  However note that SQLAlchemy **cannot**
emit an UPDATE for more than one level of cascade.  Also,
setting this flag to False is not compatible in the case where
the database is in fact enforcing referential integrity, unless
those constraints are explicitly "deferred", if the target backend
supports it.

It is highly advised that an application which is employing
mutable primary keys keeps ``passive_updates`` set to True,
and instead uses the referential integrity features of the database
itself in order to handle the change efficiently and fully.

.. seealso::

:ref:`passive_updates` - Introductory documentation and
examples.

:paramref:`.mapper.passive_updates` - a similar flag which
takes effect for joined-table inheritance mappings.

:param post_update:
This indicates that the relationship should be handled by a
second UPDATE statement after an INSERT or before a
DELETE. This flag is used to handle saving bi-directional
dependencies between two individual rows (i.e. each row
references the other), where it would otherwise be impossible to
INSERT or DELETE both rows fully since one row exists before the
other. Use this flag when a particular mapping arrangement will
incur two rows that are dependent on each other, such as a table
that has a one-to-many relationship to a set of child rows, and
also has a column that references a single child row within that
list (i.e. both tables contain a foreign key to each other). If
a flush operation returns an error that a "cyclical
dependency" was detected, this is a cue that you might want to
use :paramref:`_orm.relationship.post_update` to "break" the cycle.

.. seealso::

:ref:`post_update` - Introductory documentation and examples.

:param primaryjoin:
A SQL expression that will be used as the primary
join of the child object against the parent object, or in a
many-to-many relationship the join of the parent object to the
association table. By default, this value is computed based on the
foreign key relationships of the parent and child tables (or
association table).

:paramref:`_orm.relationship.primaryjoin` may also be passed as a
callable function which is evaluated at mapper initialization time,
and may be passed as a Python-evaluable string when using
Declarative.

.. warning:: When passed as a Python-evaluable string, the
argument is interpreted using Python's ``eval()`` function.
**DO NOT PASS UNTRUSTED INPUT TO THIS STRING**.
See :ref:`declarative_relationship_eval` for details on
declarative evaluation of :func:`_orm.relationship` arguments.

.. seealso::

:ref:`relationship_primaryjoin`

:param remote_side:
Used for self-referential relationships, indicates the column or
list of columns that form the "remote side" of the relationship.

:paramref:`_orm.relationship.remote_side` may also be passed as a
callable function which is evaluated at mapper initialization time,
and may be passed as a Python-evaluable string when using
Declarative.

.. warning:: When passed as a Python-evaluable string, the
argument is interpreted using Python's ``eval()`` function.
**DO NOT PASS UNTRUSTED INPUT TO THIS STRING**.
See :ref:`declarative_relationship_eval` for details on
declarative evaluation of :func:`_orm.relationship` arguments.

.. seealso::

:ref:`self_referential` - in-depth explanation of how
:paramref:`_orm.relationship.remote_side`
is used to configure self-referential relationships.

:func:`.remote` - an annotation function that accomplishes the
same purpose as :paramref:`_orm.relationship.remote_side`,
typically
when a custom :paramref:`_orm.relationship.primaryjoin` condition
is used.

:param query_class:
A :class:`_query.Query`
subclass that will be used internally by the
``AppenderQuery`` returned by a "dynamic" relationship, that
is, a relationship that specifies ``lazy="dynamic"`` or was
otherwise constructed using the :func:`_orm.dynamic_loader`
function.

.. seealso::

:ref:`dynamic_relationship` - Introduction to "dynamic"
relationship loaders.

:param secondaryjoin:
A SQL expression that will be used as the join of
an association table to the child object. By default, this value is
computed based on the foreign key relationships of the association
and child tables.

:paramref:`_orm.relationship.secondaryjoin` may also be passed as a
callable function which is evaluated at mapper initialization time,
and may be passed as a Python-evaluable string when using
Declarative.

.. warning:: When passed as a Python-evaluable string, the
argument is interpreted using Python's ``eval()`` function.
**DO NOT PASS UNTRUSTED INPUT TO THIS STRING**.
See :ref:`declarative_relationship_eval` for details on
declarative evaluation of :func:`_orm.relationship` arguments.

.. seealso::

:ref:`relationship_primaryjoin`

:param single_parent:
When True, installs a validator which will prevent objects
from being associated with more than one parent at a time.
This is used for many-to-one or many-to-many relationships that
should be treated either as one-to-one or one-to-many.  Its usage
is optional, except for :func:`_orm.relationship` constructs which
are many-to-one or many-to-many and also
specify the ``delete-orphan`` cascade option.  The
:func:`_orm.relationship` construct itself will raise an error
instructing when this option is required.

.. seealso::

:ref:`unitofwork_cascades` - includes detail on when the
:paramref:`_orm.relationship.single_parent`
flag may be appropriate.

:param uselist:
A boolean that indicates if this property should be loaded as a
list or a scalar. In most cases, this value is determined
automatically by :func:`_orm.relationship` at mapper configuration
time.  When using explicit :class:`_orm.Mapped` annotations,
:paramref:`_orm.relationship.uselist` may be derived from the
whether or not the annotation within :class:`_orm.Mapped` contains
a collection class.
Otherwise, :paramref:`_orm.relationship.uselist` may be derived from
the type and direction
of the relationship - one to many forms a list, many to one
forms a scalar, many to many is a list. If a scalar is desired
where normally a list would be present, such as a bi-directional
one-to-one relationship, use an appropriate :class:`_orm.Mapped`
annotation or set :paramref:`_orm.relationship.uselist` to False.

The :paramref:`_orm.relationship.uselist`
flag is also available on an
existing :func:`_orm.relationship`
construct as a read-only attribute,
which can be used to determine if this :func:`_orm.relationship`
deals
with collections or scalar attributes::

>>> User.addresses.property.uselist
True

.. seealso::

:ref:`relationships_one_to_one` - Introduction to the "one to
one" relationship pattern, which is typically when an alternate
setting for :paramref:`_orm.relationship.uselist` is involved.

:param viewonly=False:
When set to ``True``, the relationship is used only for loading
objects, and not for any persistence operation.  A
:func:`_orm.relationship` which specifies
:paramref:`_orm.relationship.viewonly` can work
with a wider range of SQL operations within the
:paramref:`_orm.relationship.primaryjoin` condition, including
operations that feature the use of a variety of comparison operators
as well as SQL functions such as :func:`_expression.cast`.  The
:paramref:`_orm.relationship.viewonly`
flag is also of general use when defining any kind of
:func:`_orm.relationship` that doesn't represent
the full set of related objects, to prevent modifications of the
collection from resulting in persistence operations.

When using the :paramref:`_orm.relationship.viewonly` flag in
conjunction with backrefs, the originating relationship for a
particular state change will not produce state changes within the
viewonly relationship.   This is the behavior implied by
:paramref:`_orm.relationship.sync_backref` being set to False.

.. versionchanged:: 1.3.17 - the
:paramref:`_orm.relationship.sync_backref` flag is set to False
when using viewonly in conjunction with backrefs.

.. seealso::

:paramref:`_orm.relationship.sync_backref`

:param sync_backref:
A boolean that enables the events used to synchronize the in-Python
attributes when this relationship is target of either
:paramref:`_orm.relationship.backref` or
:paramref:`_orm.relationship.back_populates`.

Defaults to ``None``, which indicates that an automatic value should
be selected based on the value of the
:paramref:`_orm.relationship.viewonly` flag.  When left at its
default, changes in state will be back-populated only if neither
sides of a relationship is viewonly.

.. versionadded:: 1.3.17

.. versionchanged:: 1.4 - A relationship that specifies
:paramref:`_orm.relationship.viewonly` automatically implies
that :paramref:`_orm.relationship.sync_backref` is ``False``.

.. seealso::

:paramref:`_orm.relationship.viewonly`

:param omit_join:
Allows manual control over the "selectin" automatic join
optimization.  Set to ``False`` to disable the "omit join" feature
added in SQLAlchemy 1.3; or leave as ``None`` to leave automatic
optimization in place.

.. note:: This flag may only be set to ``False``.   It is not
necessary to set it to ``True`` as the "omit_join" optimization is
automatically detected; if it is not detected, then the
optimization is not supported.

.. versionchanged:: 1.3.11  setting ``omit_join`` to True will now
emit a warning as this was not the intended use of this flag.

.. versionadded:: 1.3

:param init: Specific to :ref:`orm_declarative_native_dataclasses`,
specifies if the mapped attribute should be part of the ``__init__()``
method as generated by the dataclass process.
:param repr: Specific to :ref:`orm_declarative_native_dataclasses`,
specifies if the mapped attribute should be part of the ``__repr__()``
method as generated by the dataclass process.
:param default_factory: Specific to
:ref:`orm_declarative_native_dataclasses`,
specifies a default-value generation function that will take place
as part of the ``__init__()``
method as generated by the dataclass process.
:param compare: Specific to
:ref:`orm_declarative_native_dataclasses`, indicates if this field
should be included in comparison operations when generating the
``__eq__()`` and ``__ne__()`` methods for the mapped class.

.. versionadded:: 2.0.0b4

:param kw_only: Specific to
:ref:`orm_declarative_native_dataclasses`, indicates if this field
should be marked as keyword-only when generating the ``__init__()``.

**Line:** 910

---

### `def synonym(name: str, map_column: Optional[bool] = None, descriptor: Optional[Any] = None, comparator_factory: Optional[Type[PropComparator[_T]]] = None, init: Union[(_NoArg, bool)] = _NoArg.NO_ARG, repr: Union[(_NoArg, bool)] = _NoArg.NO_ARG, default: Union[(_NoArg, _T)] = _NoArg.NO_ARG, default_factory: Union[(_NoArg, Callable[[], _T])] = _NoArg.NO_ARG, compare: Union[(_NoArg, bool)] = _NoArg.NO_ARG, kw_only: Union[(_NoArg, bool)] = _NoArg.NO_ARG, info: Optional[_InfoType] = None, doc: Optional[str] = None) -> Synonym[Any]`

**Description:**
Denote an attribute name as a synonym to a mapped property,
in that the attribute will mirror the value and expression behavior
of another attribute.

e.g.::

class MyClass(Base):
__tablename__ = 'my_table'

id = Column(Integer, primary_key=True)
job_status = Column(String(50))

status = synonym("job_status")


:param name: the name of the existing mapped property.  This
can refer to the string name ORM-mapped attribute
configured on the class, including column-bound attributes
and relationships.

:param descriptor: a Python :term:`descriptor` that will be used
as a getter (and potentially a setter) when this attribute is
accessed at the instance level.

:param map_column: **For classical mappings and mappings against
an existing Table object only**.  if ``True``, the :func:`.synonym`
construct will locate the :class:`_schema.Column`
object upon the mapped
table that would normally be associated with the attribute name of
this synonym, and produce a new :class:`.ColumnProperty` that instead
maps this :class:`_schema.Column`
to the alternate name given as the "name"
argument of the synonym; in this way, the usual step of redefining
the mapping of the :class:`_schema.Column`
to be under a different name is
unnecessary. This is usually intended to be used when a
:class:`_schema.Column`
is to be replaced with an attribute that also uses a
descriptor, that is, in conjunction with the
:paramref:`.synonym.descriptor` parameter::

my_table = Table(
"my_table", metadata,
Column('id', Integer, primary_key=True),
Column('job_status', String(50))
)

class MyClass:
@property
def _job_status_descriptor(self):
return "Status: %s" % self._job_status


mapper(
MyClass, my_table, properties={
"job_status": synonym(
"_job_status", map_column=True,
descriptor=MyClass._job_status_descriptor)
}
)

Above, the attribute named ``_job_status`` is automatically
mapped to the ``job_status`` column::

>>> j1 = MyClass()
>>> j1._job_status = "employed"
>>> j1.job_status
Status: employed

When using Declarative, in order to provide a descriptor in
conjunction with a synonym, use the
:func:`sqlalchemy.ext.declarative.synonym_for` helper.  However,
note that the :ref:`hybrid properties <mapper_hybrids>` feature
should usually be preferred, particularly when redefining attribute
behavior.

:param info: Optional data dictionary which will be populated into the
:attr:`.InspectionAttr.info` attribute of this object.

:param comparator_factory: A subclass of :class:`.PropComparator`
that will provide custom comparison behavior at the SQL expression
level.

.. note::

For the use case of providing an attribute which redefines both
Python-level and SQL-expression level behavior of an attribute,
please refer to the Hybrid attribute introduced at
:ref:`mapper_hybrids` for a more effective technique.

.. seealso::

:ref:`synonyms` - Overview of synonyms

:func:`.synonym_for` - a helper oriented towards Declarative

:ref:`mapper_hybrids` - The Hybrid Attribute extension provides an
updated approach to augmenting attribute behavior more flexibly
than can be achieved with synonyms.

**Line:** 1806

---

### `def create_session(bind: Optional[_SessionBind] = None, **kwargs: Any) -> Session`

**Description:**
Create a new :class:`.Session`
with no automation enabled by default.

This function is used primarily for testing.   The usual
route to :class:`.Session` creation is via its constructor
or the :func:`.sessionmaker` function.

:param bind: optional, a single Connectable to use for all
database access in the created
:class:`~sqlalchemy.orm.session.Session`.

:param \*\*kwargs: optional, passed through to the
:class:`.Session` constructor.

:returns: an :class:`~sqlalchemy.orm.session.Session` instance

The defaults of create_session() are the opposite of that of
:func:`sessionmaker`; ``autoflush`` and ``expire_on_commit`` are
False.

Usage::

>>> from sqlalchemy.orm import create_session
>>> session = create_session()

It is recommended to use :func:`sessionmaker` instead of
create_session().

**Line:** 1935

---

### `def _mapper_fn(*arg: Any, **kw: Any) -> NoReturn`

**Description:**
Placeholder for the now-removed ``mapper()`` function.

Classical mappings should be performed using the
:meth:`_orm.registry.map_imperatively` method.

This symbol remains in SQLAlchemy 2.0 to suit the deprecated use case
of using the ``mapper()`` function as a target for ORM event listeners,
which failed to be marked as deprecated in the 1.4 series.

Global ORM mapper listeners should instead use the :class:`_orm.Mapper`
class as the target.

.. versionchanged:: 2.0  The ``mapper()`` function was removed; the
symbol remains temporarily as a placeholder for the event listening
use case.

**Line:** 1973

---

### `def dynamic_loader(argument: Optional[_RelationshipArgumentType[Any]] = None, **kw: Any) -> RelationshipProperty[Any]`

**Description:**
Construct a dynamically-loading mapper property.

This is essentially the same as
using the ``lazy='dynamic'`` argument with :func:`relationship`::

dynamic_loader(SomeClass)

# is the same as

relationship(SomeClass, lazy="dynamic")

See the section :ref:`dynamic_relationship` for more details
on dynamic loading.

**Line:** 2000

---

### `def backref(name: str, **kwargs: Any) -> ORMBackrefArgument`

**Description:**
When using the :paramref:`_orm.relationship.backref` parameter,
provides specific parameters to be used when the new
:func:`_orm.relationship` is generated.

E.g.::

'items':relationship(
SomeItem, backref=backref('parent', lazy='subquery'))

The :paramref:`_orm.relationship.backref` parameter is generally
considered to be legacy; for modern applications, using
explicit :func:`_orm.relationship` constructs linked together using
the :paramref:`_orm.relationship.back_populates` parameter should be
preferred.

.. seealso::

:ref:`relationships_backref` - background on backrefs

**Line:** 2022

---

### `def deferred(column: _ORMColumnExprArgument[_T], group: Optional[str] = None, raiseload: bool = False, comparator_factory: Optional[Type[PropComparator[_T]]] = None, init: Union[(_NoArg, bool)] = _NoArg.NO_ARG, repr: Union[(_NoArg, bool)] = _NoArg.NO_ARG, default: Optional[Any] = _NoArg.NO_ARG, default_factory: Union[(_NoArg, Callable[[], _T])] = _NoArg.NO_ARG, compare: Union[(_NoArg, bool)] = _NoArg.NO_ARG, kw_only: Union[(_NoArg, bool)] = _NoArg.NO_ARG, active_history: bool = False, expire_on_flush: bool = True, info: Optional[_InfoType] = None, doc: Optional[str] = None, *additional_columns: _ORMColumnExprArgument[Any]) -> MappedSQLExpression[_T]`

**Description:**
Indicate a column-based mapped attribute that by default will
not load unless accessed.

When using :func:`_orm.mapped_column`, the same functionality as
that of :func:`_orm.deferred` construct is provided by using the
:paramref:`_orm.mapped_column.deferred` parameter.

:param \*columns: columns to be mapped.  This is typically a single
:class:`_schema.Column` object,
however a collection is supported in order
to support multiple columns mapped under the same attribute.

:param raiseload: boolean, if True, indicates an exception should be raised
if the load operation is to take place.

.. versionadded:: 1.4


Additional arguments are the same as that of :func:`_orm.column_property`.

.. seealso::

:ref:`orm_queryguide_deferred_imperative`

**Line:** 2047

---

### `def query_expression(default_expr: _ORMColumnExprArgument[_T] = sql.null(), repr: Union[(_NoArg, bool)] = _NoArg.NO_ARG, compare: Union[(_NoArg, bool)] = _NoArg.NO_ARG, expire_on_flush: bool = True, info: Optional[_InfoType] = None, doc: Optional[str] = None) -> MappedSQLExpression[_T]`

**Description:**
Indicate an attribute that populates from a query-time SQL expression.

:param default_expr: Optional SQL expression object that will be used in
all cases if not assigned later with :func:`_orm.with_expression`.

.. versionadded:: 1.2

.. seealso::

:ref:`orm_queryguide_with_expression` - background and usage examples

**Line:** 2106

---

### `def clear_mappers() -> None`

**Description:**
Remove all mappers from all classes.

.. versionchanged:: 1.4  This function now locates all
:class:`_orm.registry` objects and calls upon the
:meth:`_orm.registry.dispose` method of each.

This function removes all instrumentation from classes and disposes
of their associated mappers.  Once called, the classes are unmapped
and can be later re-mapped with new mappers.

:func:`.clear_mappers` is *not* for normal use, as there is literally no
valid usage for it outside of very specific testing scenarios. Normally,
mappers are permanent structural components of user-defined classes, and
are never discarded independently of their class.  If a mapped class
itself is garbage collected, its mapper is automatically disposed of as
well. As such, :func:`.clear_mappers` is only for usage in test suites
that re-use the same classes with different mappings, which is itself an
extremely rare use case - the only such use case is in fact SQLAlchemy's
own test suite, and possibly the test suites of other ORM extension
libraries which intend to test various combinations of mapper construction
upon a fixed set of classes.

**Line:** 2147

---

### `def aliased(element: Type[_O], alias: Optional[FromClause] = None, name: Optional[str] = None, flat: bool = False, adapt_on_names: bool = False) -> AliasedType[_O]`

**Decorators:**
- `@overload`

**Line:** 2183

---

### `def aliased(element: Union[(AliasedClass[_O], Mapper[_O], AliasedInsp[_O])], alias: Optional[FromClause] = None, name: Optional[str] = None, flat: bool = False, adapt_on_names: bool = False) -> AliasedClass[_O]`

**Decorators:**
- `@overload`

**Line:** 2194

---

### `def aliased(element: FromClause, alias: None = None, name: Optional[str] = None, flat: bool = False, adapt_on_names: bool = False) -> FromClause`

**Decorators:**
- `@overload`

**Line:** 2205

---

### `def aliased(element: Union[(_EntityType[_O], FromClause)], alias: Optional[FromClause] = None, name: Optional[str] = None, flat: bool = False, adapt_on_names: bool = False) -> Union[(AliasedClass[_O], FromClause, AliasedType[_O])]`

**Description:**
Produce an alias of the given element, usually an :class:`.AliasedClass`
instance.

E.g.::

my_alias = aliased(MyClass)

stmt = select(MyClass, my_alias).filter(MyClass.id > my_alias.id)
result = session.execute(stmt)

The :func:`.aliased` function is used to create an ad-hoc mapping of a
mapped class to a new selectable.  By default, a selectable is generated
from the normally mapped selectable (typically a :class:`_schema.Table`
) using the
:meth:`_expression.FromClause.alias` method. However, :func:`.aliased`
can also be
used to link the class to a new :func:`_expression.select` statement.
Also, the :func:`.with_polymorphic` function is a variant of
:func:`.aliased` that is intended to specify a so-called "polymorphic
selectable", that corresponds to the union of several joined-inheritance
subclasses at once.

For convenience, the :func:`.aliased` function also accepts plain
:class:`_expression.FromClause` constructs, such as a
:class:`_schema.Table` or
:func:`_expression.select` construct.   In those cases, the
:meth:`_expression.FromClause.alias`
method is called on the object and the new
:class:`_expression.Alias` object returned.  The returned
:class:`_expression.Alias` is not
ORM-mapped in this case.

.. seealso::

:ref:`tutorial_orm_entity_aliases` - in the :ref:`unified_tutorial`

:ref:`orm_queryguide_orm_aliases` - in the :ref:`queryguide_toplevel`

:param element: element to be aliased.  Is normally a mapped class,
but for convenience can also be a :class:`_expression.FromClause`
element.

:param alias: Optional selectable unit to map the element to.  This is
usually used to link the object to a subquery, and should be an aliased
select construct as one would produce from the
:meth:`_query.Query.subquery` method or
the :meth:`_expression.Select.subquery` or
:meth:`_expression.Select.alias` methods of the :func:`_expression.select`
construct.

:param name: optional string name to use for the alias, if not specified
by the ``alias`` parameter.  The name, among other things, forms the
attribute name that will be accessible via tuples returned by a
:class:`_query.Query` object.  Not supported when creating aliases
of :class:`_sql.Join` objects.

:param flat: Boolean, will be passed through to the
:meth:`_expression.FromClause.alias` call so that aliases of
:class:`_expression.Join` objects will alias the individual tables
inside the join, rather than creating a subquery.  This is generally
supported by all modern databases with regards to right-nested joins
and generally produces more efficient queries.

:param adapt_on_names: if True, more liberal "matching" will be used when
mapping the mapped columns of the ORM entity to those of the
given selectable - a name-based match will be performed if the
given selectable doesn't otherwise have a column that corresponds
to one on the entity.  The use case for this is when associating
an entity with some derived selectable such as one that uses
aggregate functions::

class UnitPrice(Base):
__tablename__ = 'unit_price'
...
unit_id = Column(Integer)
price = Column(Numeric)

aggregated_unit_price = Session.query(
func.sum(UnitPrice.price).label('price')
).group_by(UnitPrice.unit_id).subquery()

aggregated_unit_price = aliased(UnitPrice,
alias=aggregated_unit_price, adapt_on_names=True)

Above, functions on ``aggregated_unit_price`` which refer to
``.price`` will return the
``func.sum(UnitPrice.price).label('price')`` column, as it is
matched on the name "price".  Ordinarily, the "price" function
wouldn't have any "column correspondence" to the actual
``UnitPrice.price`` column as it is not a proxy of the original.

**Line:** 2215

---

### `def with_polymorphic(base: Union[(Type[_O], Mapper[_O])], classes: Union[(Literal['*'], Iterable[Type[Any]])], selectable: Union[(Literal[False, None], FromClause)] = False, flat: bool = False, polymorphic_on: Optional[ColumnElement[Any]] = None, aliased: bool = False, innerjoin: bool = False, adapt_on_names: bool = False, _use_mapper_path: bool = False) -> AliasedClass[_O]`

**Description:**
Produce an :class:`.AliasedClass` construct which specifies
columns for descendant mappers of the given base.

Using this method will ensure that each descendant mapper's
tables are included in the FROM clause, and will allow filter()
criterion to be used against those tables.  The resulting
instances will also have those columns already loaded so that
no "post fetch" of those columns will be required.

.. seealso::

:ref:`with_polymorphic` - full discussion of
:func:`_orm.with_polymorphic`.

:param base: Base class to be aliased.

:param classes: a single class or mapper, or list of
class/mappers, which inherit from the base class.
Alternatively, it may also be the string ``'*'``, in which case
all descending mapped classes will be added to the FROM clause.

:param aliased: when True, the selectable will be aliased.   For a
JOIN, this means the JOIN will be SELECTed from inside of a subquery
unless the :paramref:`_orm.with_polymorphic.flat` flag is set to
True, which is recommended for simpler use cases.

:param flat: Boolean, will be passed through to the
:meth:`_expression.FromClause.alias` call so that aliases of
:class:`_expression.Join` objects will alias the individual tables
inside the join, rather than creating a subquery.  This is generally
supported by all modern databases with regards to right-nested joins
and generally produces more efficient queries.  Setting this flag is
recommended as long as the resulting SQL is functional.

:param selectable: a table or subquery that will
be used in place of the generated FROM clause. This argument is
required if any of the desired classes use concrete table
inheritance, since SQLAlchemy currently cannot generate UNIONs
among tables automatically. If used, the ``selectable`` argument
must represent the full set of tables and columns mapped by every
mapped class. Otherwise, the unaccounted mapped columns will
result in their table being appended directly to the FROM clause
which will usually lead to incorrect results.

When left at its default value of ``False``, the polymorphic
selectable assigned to the base mapper is used for selecting rows.
However, it may also be passed as ``None``, which will bypass the
configured polymorphic selectable and instead construct an ad-hoc
selectable for the target classes given; for joined table inheritance
this will be a join that includes all target mappers and their
subclasses.

:param polymorphic_on: a column to be used as the "discriminator"
column for the given selectable. If not given, the polymorphic_on
attribute of the base classes' mapper will be used, if any. This
is useful for mappings that don't have polymorphic loading
behavior by default.

:param innerjoin: if True, an INNER JOIN will be used.  This should
only be specified if querying for one specific subtype only

:param adapt_on_names: Passes through the
:paramref:`_orm.aliased.adapt_on_names`
parameter to the aliased object.  This may be useful in situations where
the given selectable is not directly related to the existing mapped
selectable.

.. versionadded:: 1.4.33

**Line:** 2323

---

### `def join(left: _FromClauseArgument, right: _FromClauseArgument, onclause: Optional[_OnClauseArgument] = None, isouter: bool = False, full: bool = False) -> _ORMJoin`

**Description:**
Produce an inner join between left and right clauses.

:func:`_orm.join` is an extension to the core join interface
provided by :func:`_expression.join()`, where the
left and right selectable may be not only core selectable
objects such as :class:`_schema.Table`, but also mapped classes or
:class:`.AliasedClass` instances.   The "on" clause can
be a SQL expression or an ORM mapped attribute
referencing a configured :func:`_orm.relationship`.

:func:`_orm.join` is not commonly needed in modern usage,
as its functionality is encapsulated within that of the
:meth:`_sql.Select.join` and :meth:`_query.Query.join`
methods. which feature a
significant amount of automation beyond :func:`_orm.join`
by itself.  Explicit use of :func:`_orm.join`
with ORM-enabled SELECT statements involves use of the
:meth:`_sql.Select.select_from` method, as in::

from sqlalchemy.orm import join
stmt = select(User).\
select_from(join(User, Address, User.addresses)).\
filter(Address.email_address=='foo@bar.com')

In modern SQLAlchemy the above join can be written more
succinctly as::

stmt = select(User).\
join(User.addresses).\
filter(Address.email_address=='foo@bar.com')

.. warning:: using :func:`_orm.join` directly may not work properly
with modern ORM options such as :func:`_orm.with_loader_criteria`.
It is strongly recommended to use the idiomatic join patterns
provided by methods such as :meth:`.Select.join` and
:meth:`.Select.join_from` when creating ORM joins.

.. seealso::

:ref:`orm_queryguide_joins` - in the :ref:`queryguide_toplevel` for
background on idiomatic ORM join patterns

**Line:** 2417

---

### `def outerjoin(left: _FromClauseArgument, right: _FromClauseArgument, onclause: Optional[_OnClauseArgument] = None, full: bool = False) -> _ORMJoin`

**Description:**
Produce a left outer join between left and right clauses.

This is the "outer join" version of the :func:`_orm.join` function,
featuring the same behavior except that an OUTER JOIN is generated.
See that function's documentation for other usage details.

**Line:** 2470

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm._typing
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/_typing.py`

**Imports:**
- __future__.annotations
- attributes.AttributeImpl
- attributes.CollectionAttributeImpl
- attributes.HasCollectionAdapter
- attributes.QueryableAttribute
- base.PassiveFlag
- decl_api.registry
- engine.interfaces._CoreKnownExecutionOptions
- interfaces.InspectionAttr
- interfaces.MapperProperty
- interfaces.ORMOption
- interfaces.UserDefinedOption
- mapper.Mapper
- operator
- relationships.RelationshipProperty
- sql._orm_types.DMLStrategyArgument
- sql._orm_types.SynchronizeSessionArgument
- sql._typing._CE
- sql._typing._HasClauseElement
- sql.base.ExecutableOption
- sql.elements.ColumnElement
- sql.roles
- state.InstanceState
- typing.Any
- typing.Dict
- typing.Mapping
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- util.AliasedClass
- util.AliasedInsp
- util.typing.Protocol
- util.typing.TypeGuard

**Functions:**

### `def is_orm_option(opt: ExecutableOption) -> TypeGuard[ORMOption]`

**Line:** 120

---

### `def is_user_defined_option(opt: ExecutableOption) -> TypeGuard[UserDefinedOption]`

**Line:** 126

---

### `def is_composite_class(obj: Any) -> bool`

**Line:** 132

---

### `def insp_is_mapper_property(obj: Any) -> TypeGuard[MapperProperty[Any]]`

**Line:** 141

---

### `def insp_is_mapper(obj: Any) -> TypeGuard[Mapper[Any]]`

**Line:** 144

---

### `def insp_is_aliased_class(obj: Any) -> TypeGuard[AliasedInsp[Any]]`

**Line:** 147

---

### `def insp_is_attribute(obj: InspectionAttr) -> TypeGuard[QueryableAttribute[Any]]`

**Line:** 150

---

### `def attr_is_internal_proxy(obj: InspectionAttr) -> TypeGuard[QueryableAttribute[Any]]`

**Line:** 155

---

### `def prop_is_relationship(prop: MapperProperty[Any]) -> TypeGuard[RelationshipProperty[Any]]`

**Line:** 160

---

### `def is_collection_impl(impl: AttributeImpl) -> TypeGuard[CollectionAttributeImpl]`

**Line:** 165

---

### `def is_has_collection_adapter(impl: AttributeImpl) -> TypeGuard[HasCollectionAdapter]`

**Line:** 170

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.attributes
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/attributes.py`

**Imports:**
- __future__.annotations
- _typing._EntityType
- _typing._ExternalEntityType
- _typing._InstanceDict
- _typing._InternalEntityType
- _typing._LoaderCallable
- _typing._O
- _typing.insp_is_aliased_class
- base.ATTR_EMPTY
- base.ATTR_WAS_SET
- base.CALLABLES_OK
- base.DEFERRED_HISTORY_LOAD
- base.INCLUDE_PENDING_MUTATIONS
- base.INIT_OK
- base.LOAD_AGAINST_COMMITTED
- base.LoaderCallableStatus
- base.Mapped
- base.NEVER_SET
- base.NON_PERSISTENT_OK
- base.NO_AUTOFLUSH
- base.NO_CHANGE
- base.NO_KEY
- base.NO_RAISE
- base.NO_VALUE
- base.PASSIVE_CLASS_MISMATCH
- base.PASSIVE_NO_FETCH
- base.PASSIVE_NO_FETCH_RELATED
- base.PASSIVE_NO_INITIALIZE
- base.PASSIVE_NO_RESULT
- base.PASSIVE_OFF
- base.PASSIVE_ONLY_PERSISTENT
- base.PASSIVE_RETURN_NO_VALUE
- base.PassiveFlag
- base.RELATED_OBJECT_OK
- base.SQLORMExpression
- base.SQL_OK
- base._DeclarativeMapped
- base.instance_dict
- base.instance_state
- base.instance_str
- base.manager_of_class
- base.opt_manager_of_class
- base.state_str
- collections.CollectionAdapter
- collections._AdaptedCollectionProtocol
- dataclasses
- event.EventTarget
- event.base._Dispatch
- event.dispatcher
- interfaces.MapperProperty
- operator
- relationships.RelationshipProperty
- sql._typing._ColumnExpressionArgument
- sql._typing._DMLColumnArgument
- sql._typing._InfoType
- sql._typing._PropagateAttrsType
- sql.annotation._AnnotationDict
- sql.base
- sql.cache_key
- sql.cache_key.HasCacheKey
- sql.coercions
- sql.elements.ColumnElement
- sql.elements.Label
- sql.operators.OperatorType
- sql.roles
- sql.selectable.FromClause
- sql.visitors
- sql.visitors.InternalTraversal
- sql.visitors._TraverseInternalsType
- state.InstanceState
- typing.Any
- typing.Callable
- typing.ClassVar
- typing.Dict
- typing.Iterable
- typing.List
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.AliasedInsp
- util.typing.Literal
- util.typing.Self
- util.typing.TypeGuard
- writeonly.WriteOnlyAttributeImpl

**Functions:**

### `def _queryable_attribute_unreduce(key: str, mapped_class: Type[_O], parententity: _InternalEntityType[_O], entity: _ExternalEntityType[Any]) -> Any`

**Line:** 492

---

### `def create_proxied_attribute(descriptor: Any) -> Callable[(..., QueryableAttribute[Any])]`

**Description:**
Create an QueryableAttribute / user descriptor hybrid.

Returns a new QueryableAttribute type that delegates descriptor
behavior and getattr() to the given descriptor.

**Line:** 586

---

### `def _is_collection_attribute_impl(impl: AttributeImpl) -> TypeGuard[CollectionAttributeImpl]`

**Line:** 1593

---

### `def backref_listeners(attribute: QueryableAttribute[Any], key: str, uselist: bool) -> None`

**Description:**
Apply listeners to synchronize a two-way relationship.

**Line:** 2103

---

### `def get_history(obj: object, key: str, passive: PassiveFlag = PASSIVE_OFF) -> History`

**Description:**
Return a :class:`.History` record for the given object
and attribute key.

This is the **pre-flush** history for a given attribute, which is
reset each time the :class:`.Session` flushes changes to the
current database transaction.

.. note::

Prefer to use the :attr:`.AttributeState.history` and
:meth:`.AttributeState.load_history` accessors to retrieve the
:class:`.History` for instance attributes.


:param obj: an object whose class is instrumented by the
attributes package.

:param key: string attribute name.

:param passive: indicates loading behavior for the attribute
if the value is not already present.   This is a
bitflag attribute, which defaults to the symbol
:attr:`.PASSIVE_OFF` indicating all necessary SQL
should be emitted.

.. seealso::

:attr:`.AttributeState.history`

:meth:`.AttributeState.load_history` - retrieve history
using loader callables if the value is not locally present.

**Line:** 2521

---

### `def get_state_history(state: InstanceState[Any], key: str, passive: PassiveFlag = PASSIVE_OFF) -> History`

**Line:** 2561

---

### `def has_parent(cls: Type[_O], obj: _O, key: str, optimistic: bool = False) -> bool`

**Description:**
TODO

**Line:** 2567

---

### `def register_attribute(class_: Type[_O], key: str, comparator: interfaces.PropComparator[_T], parententity: _InternalEntityType[_O], doc: Optional[str] = None, **kw: Any) -> InstrumentedAttribute[_T]`

**Line:** 2576

---

### `def register_attribute_impl(class_: Type[_O], key: str, uselist: bool = False, callable_: Optional[_LoaderCallable] = None, useobject: bool = False, impl_class: Optional[Type[AttributeImpl]] = None, backref: Optional[str] = None, **kw: Any) -> QueryableAttribute[Any]`

**Line:** 2592

---

### `def register_descriptor(class_: Type[Any], key: str, comparator: interfaces.PropComparator[_T], parententity: _InternalEntityType[Any], doc: Optional[str] = None) -> InstrumentedAttribute[_T]`

**Line:** 2643

---

### `def unregister_attribute(class_: Type[Any], key: str) -> None`

**Line:** 2663

---

### `def init_collection(obj: object, key: str) -> CollectionAdapter`

**Description:**
Initialize a collection attribute and return the collection adapter.

This function is used to provide direct access to collection internals
for a previously unloaded attribute.  e.g.::

collection_adapter = init_collection(someobject, 'elements')
for elem in values:
collection_adapter.append_without_event(elem)

For an easier way to do the above, see
:func:`~sqlalchemy.orm.attributes.set_committed_value`.

:param obj: a mapped object

:param key: string attribute name where the collection is located.

**Line:** 2667

---

### `def init_state_collection(state: InstanceState[Any], dict_: _InstanceDict, key: str) -> CollectionAdapter`

**Description:**
Initialize a collection attribute and return the collection adapter.

Discards any existing collection which may be there.

**Line:** 2690

---

### `def set_committed_value(instance, key, value)`

**Description:**
Set the value of an attribute with no history events.

Cancels any previous history present.  The value should be
a scalar value for scalar-holding attributes, or
an iterable for any collection-holding attribute.

This is the same underlying method used when a lazy loader
fires off and loads additional data from the database.
In particular, this method can be used by application code
which has loaded additional attributes or collections through
separate queries, which can then be attached to an instance
as though it were part of its original loaded state.

**Line:** 2717

---

### `def set_attribute(instance: object, key: str, value: Any, initiator: Optional[AttributeEventToken] = None) -> None`

**Description:**
Set the value of an attribute, firing history events.

This function may be used regardless of instrumentation
applied directly to the class, i.e. no descriptors are required.
Custom attribute management schemes will need to make usage
of this method to establish attribute state as understood
by SQLAlchemy.

:param instance: the object that will be modified

:param key: string name of the attribute

:param value: value to assign

:param initiator: an instance of :class:`.Event` that would have
been propagated from a previous event listener.  This argument
is used when the :func:`.set_attribute` function is being used within
an existing event listening function where an :class:`.Event` object
is being supplied; the object may be used to track the origin of the
chain of events.

.. versionadded:: 1.2.3

**Line:** 2736

---

### `def get_attribute(instance: object, key: str) -> Any`

**Description:**
Get the value of an attribute, firing any callables required.

This function may be used regardless of instrumentation
applied directly to the class, i.e. no descriptors are required.
Custom attribute management schemes will need to make usage
of this method to make usage of attribute state as understood
by SQLAlchemy.

**Line:** 2770

---

### `def del_attribute(instance: object, key: str) -> None`

**Description:**
Delete the value of an attribute, firing history events.

This function may be used regardless of instrumentation
applied directly to the class, i.e. no descriptors are required.
Custom attribute management schemes will need to make usage
of this method to establish attribute state as understood
by SQLAlchemy.

**Line:** 2784

---

### `def flag_modified(instance: object, key: str) -> None`

**Description:**
Mark an attribute on an instance as 'modified'.

This sets the 'modified' flag on the instance and
establishes an unconditional change event for the given attribute.
The attribute must have a value present, else an
:class:`.InvalidRequestError` is raised.

To mark an object "dirty" without referring to any specific attribute
so that it is considered within a flush, use the
:func:`.attributes.flag_dirty` call.

.. seealso::

:func:`.attributes.flag_dirty`

**Line:** 2798

---

### `def flag_dirty(instance: object) -> None`

**Description:**
Mark an instance as 'dirty' without any specific attribute mentioned.

This is a special operation that will allow the object to travel through
the flush process for interception by events such as
:meth:`.SessionEvents.before_flush`.   Note that no SQL will be emitted in
the flush process for an object that has no changes, even if marked dirty
via this method.  However, a :meth:`.SessionEvents.before_flush` handler
will be able to see the object in the :attr:`.Session.dirty` collection and
may establish changes on it, which will then be included in the SQL
emitted.

.. versionadded:: 1.2

.. seealso::

:func:`.attributes.flag_modified`

**Line:** 2821

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.base
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/base.py`

**Imports:**
- __future__.annotations
- _typing._EntityType
- _typing._ExternalEntityType
- _typing._InternalEntityType
- _typing.insp_is_mapper
- attributes.InstrumentedAttribute
- dynamic.AppenderQuery
- enum.Enum
- instrumentation.ClassManager
- interfaces.PropComparator
- mapper.Mapper
- operator
- sql._typing._ColumnExpressionArgument
- sql._typing._InfoType
- sql.elements.ColumnElement
- sql.elements.SQLColumnExpression
- sql.elements.SQLCoreOperations
- sql.operators.OperatorType
- sql.roles
- state.InstanceState
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generic
- typing.Optional
- typing.TYPE_CHECKING
- typing.Type
- typing.TypeVar
- typing.Union
- typing.no_type_check
- typing.overload
- util.AliasedClass
- util.FastIntFlag
- util.langhelpers.TypingOnly
- util.typing.Literal
- writeonly.WriteOnlyCollection

**Functions:**

### `def _assertions(*assertions: Any) -> Callable[([_F], _F)]`

**Line:** 296

---

### `def manager_of_class(cls: Type[_O]) -> ClassManager[_O]`

**Line:** 311

---

### `def opt_manager_of_class(cls: AliasedClass[Any]) -> None`

**Decorators:**
- `@overload`

**Line:** 315

---

### `def opt_manager_of_class(cls: _ExternalEntityType[_O]) -> Optional[ClassManager[_O]]`

**Decorators:**
- `@overload`

**Line:** 319

---

### `def opt_manager_of_class(cls: _ExternalEntityType[_O]) -> Optional[ClassManager[_O]]`

**Line:** 324

---

### `def instance_state(instance: _O) -> InstanceState[_O]`

**Line:** 329

---

### `def instance_dict(instance: object) -> Dict[(str, Any)]`

**Line:** 332

---

### `def manager_of_class(cls)`

**Line:** 339

---

### `def opt_manager_of_class(cls)`

**Line:** 347

---

### `def instance_str(instance: object) -> str`

**Description:**
Return a string describing an instance.

**Line:** 355

---

### `def state_str(state: InstanceState[Any]) -> str`

**Description:**
Return a string describing an instance via its InstanceState.

**Line:** 361

---

### `def state_class_str(state: InstanceState[Any]) -> str`

**Description:**
Return a string describing an instance's class via its
InstanceState.

**Line:** 370

---

### `def attribute_str(instance: object, attribute: str) -> str`

**Line:** 381

---

### `def state_attribute_str(state: InstanceState[Any], attribute: str) -> str`

**Line:** 385

---

### `def object_mapper(instance: _T) -> Mapper[_T]`

**Description:**
Given an object, return the primary Mapper associated with the object
instance.

Raises :class:`sqlalchemy.orm.exc.UnmappedInstanceError`
if no mapping is configured.

This function is available via the inspection system as::

inspect(instance).mapper

Using the inspection system will raise
:class:`sqlalchemy.exc.NoInspectionAvailable` if the instance is
not part of a mapping.

**Line:** 389

---

### `def object_state(instance: _T) -> InstanceState[_T]`

**Description:**
Given an object, return the :class:`.InstanceState`
associated with the object.

Raises :class:`sqlalchemy.orm.exc.UnmappedInstanceError`
if no mapping is configured.

Equivalent functionality is available via the :func:`_sa.inspect`
function as::

inspect(instance)

Using the inspection system will raise
:class:`sqlalchemy.exc.NoInspectionAvailable` if the instance is
not part of a mapping.

**Line:** 408

---

### `def _inspect_mapped_object(instance: _T) -> Optional[InstanceState[_T]]`

**Decorators:**
- `@inspection._inspects(...)`

**Line:** 433

---

### `def _class_to_mapper(class_or_mapper: Union[(Mapper[_T], Type[_T])]) -> Mapper[_T]`

**Line:** 440

---

### `def _mapper_or_none(entity: Union[(Type[_T], _InternalEntityType[_T])]) -> Optional[Mapper[_T]]`

**Description:**
Return the :class:`_orm.Mapper` for the given class or None if the
class is not mapped.

**Line:** 452

---

### `def _is_mapped_class(entity: Any) -> bool`

**Description:**
Return True if the given object is a mapped class,
:class:`_orm.Mapper`, or :class:`.AliasedClass`.

**Line:** 467

---

### `def _is_aliased_class(entity: Any) -> bool`

**Line:** 480

---

### `def _entity_descriptor(entity: _EntityType[Any], key: str) -> Any`

**Decorators:**
- `@no_type_check`

**Description:**
Return a class attribute given an entity and string name.

May return :class:`.InstrumentedAttribute` or user-defined
attribute.

**Line:** 486

---

### `def _state_mapper(state: InstanceState[_O]) -> Mapper[_O]`

**Line:** 515

---

### `def _inspect_mapped_class(class_: Type[_O], configure: bool = False) -> Optional[Mapper[_O]]`

**Line:** 522

---

### `def _parse_mapper_argument(arg: Union[(Mapper[_O], Type[_O])]) -> Mapper[_O]`

**Line:** 538

---

### `def class_mapper(class_: Type[_O], configure: bool = True) -> Mapper[_O]`

**Description:**
Given a class, return the primary :class:`_orm.Mapper` associated
with the key.

Raises :exc:`.UnmappedClassError` if no mapping is configured
on the given class, or :exc:`.ArgumentError` if a non-class
object is passed.

Equivalent functionality is available via the :func:`_sa.inspect`
function as::

inspect(some_mapped_class)

Using the inspection system will raise
:class:`sqlalchemy.exc.NoInspectionAvailable` if the class is not mapped.

**Line:** 546

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.bulk_persistence
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/bulk_persistence.py`

**Imports:**
- __future__.annotations
- _typing.DMLStrategyArgument
- _typing.OrmExecuteOptionsParameter
- _typing.SynchronizeSessionArgument
- base.NO_VALUE
- context.AbstractORMCompileState
- context.FromStatement
- context.ORMFromStatementCompileState
- context.QueryContext
- engine.Connection
- engine.Dialect
- engine.cursor
- engine.interfaces._CoreAnyExecuteParams
- engine.result
- mapper.Mapper
- session.ORMExecuteState
- session.Session
- session.SessionTransaction
- session._BindArguments
- sql.base.CompileState
- sql.base.Options
- sql.base._entity_namespace_key
- sql.coercions
- sql.dml
- sql.dml.DeleteDMLState
- sql.dml.InsertDMLState
- sql.dml.UpdateDMLState
- sql.expression
- sql.roles
- sql.select
- sql.sqltypes
- state.InstanceState
- typing.Any
- typing.Dict
- typing.Iterable
- typing.Optional
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.EMPTY_DICT
- util.typing.Literal

**Functions:**

### `def _bulk_insert(mapper: Mapper[_O], mappings: Union[(Iterable[InstanceState[_O]], Iterable[Dict[str, Any]])], session_transaction: SessionTransaction, isstates: bool, return_defaults: bool, render_nulls: bool, use_orm_insert_stmt: Literal[None] = Ellipsis, execution_options: Optional[OrmExecuteOptionsParameter] = Ellipsis) -> None`

**Decorators:**
- `@overload`

**Line:** 75

---

### `def _bulk_insert(mapper: Mapper[_O], mappings: Union[(Iterable[InstanceState[_O]], Iterable[Dict[str, Any]])], session_transaction: SessionTransaction, isstates: bool, return_defaults: bool, render_nulls: bool, use_orm_insert_stmt: Optional[dml.Insert] = Ellipsis, execution_options: Optional[OrmExecuteOptionsParameter] = Ellipsis) -> cursor.CursorResult[Any]`

**Decorators:**
- `@overload`

**Line:** 89

---

### `def _bulk_insert(mapper: Mapper[_O], mappings: Union[(Iterable[InstanceState[_O]], Iterable[Dict[str, Any]])], session_transaction: SessionTransaction, isstates: bool, return_defaults: bool, render_nulls: bool, use_orm_insert_stmt: Optional[dml.Insert] = None, execution_options: Optional[OrmExecuteOptionsParameter] = None) -> Optional[cursor.CursorResult[Any]]`

**Line:** 102

---

### `def _bulk_update(mapper: Mapper[Any], mappings: Union[(Iterable[InstanceState[_O]], Iterable[Dict[str, Any]])], session_transaction: SessionTransaction, isstates: bool, update_changed_only: bool, use_orm_update_stmt: Literal[None] = Ellipsis, enable_check_rowcount: bool = True) -> None`

**Decorators:**
- `@overload`

**Line:** 231

---

### `def _bulk_update(mapper: Mapper[Any], mappings: Union[(Iterable[InstanceState[_O]], Iterable[Dict[str, Any]])], session_transaction: SessionTransaction, isstates: bool, update_changed_only: bool, use_orm_update_stmt: Optional[dml.Update] = Ellipsis, enable_check_rowcount: bool = True) -> _result.Result[Any]`

**Decorators:**
- `@overload`

**Line:** 244

---

### `def _bulk_update(mapper: Mapper[Any], mappings: Union[(Iterable[InstanceState[_O]], Iterable[Dict[str, Any]])], session_transaction: SessionTransaction, isstates: bool, update_changed_only: bool, use_orm_update_stmt: Optional[dml.Update] = None, enable_check_rowcount: bool = True) -> Optional[_result.Result[Any]]`

**Line:** 256

---

### `def _expand_composites(mapper, mappings)`

**Line:** 347

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.clsregistry
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/clsregistry.py`

**Imports:**
- __future__.annotations
- descriptor_props.SynonymProperty
- properties.ColumnProperty
- re
- relationships.RelationshipProperty
- sql.schema.MetaData
- sql.schema.Table
- sql.schema._get_table_key
- sqlalchemy
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generator
- typing.Iterable
- typing.List
- typing.Mapping
- typing.MutableMapping
- typing.NoReturn
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- util.class_mapper
- util.typing.CallableReference
- weakref

**Functions:**

### `def add_class(classname: str, cls: Type[_T], decl_class_registry: _ClsRegistryType) -> None`

**Description:**
Add a class to the _decl_class_registry associated with the
given declarative class.

**Line:** 64

---

### `def remove_class(classname: str, cls: Type[Any], decl_class_registry: _ClsRegistryType) -> None`

**Line:** 118

---

### `def _key_is_empty(key: str, decl_class_registry: _ClsRegistryType, test: Callable[([Any], bool)]) -> bool`

**Description:**
test if a key is empty of a certain object.

used for unit tests against the registry to see if garbage collection
is working.

"test" is a callable that will be passed an object should return True
if the given object is the one we were looking for.

We can't pass the actual object itself b.c. this is for testing garbage
collection; the caller will have to have removed references to the
object itself.

**Line:** 151

---

### `def _determine_container(key: str, value: Any) -> _GetColumns`

**Line:** 406

---

### `def _resolver(cls: Type[Any], prop: RelationshipProperty[Any]) -> Tuple[(Callable[[str], Callable[[], Union[Type[Any], Table, _ModNS]]], Callable[[str, bool], _class_resolver])]`

**Line:** 545

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.collections
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/collections.py`

**Imports:**
- __future__.annotations
- attributes.AttributeEventToken
- attributes.CollectionAttributeImpl
- base.NO_KEY
- mapped_collection.KeyFuncDict
- mapped_collection.MappedCollection
- mapped_collection.attribute_keyed_dict
- mapped_collection.attribute_mapped_collection
- mapped_collection.column_keyed_dict
- mapped_collection.column_mapped_collection
- mapped_collection.keyfunc_mapping
- mapped_collection.mapped_collection
- operator
- sql.base.NO_ARG
- state.InstanceState
- threading
- typing
- typing.Any
- typing.Callable
- typing.Collection
- typing.Dict
- typing.Iterable
- typing.List
- typing.NoReturn
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- util.compat.inspect_getfullargspec
- util.typing.Protocol
- weakref

**Functions:**

### `def collection_adapter(collection: Collection[Any]) -> CollectionAdapter`

**Description:**
Fetch the :class:`.CollectionAdapter` for a collection.

**Line:** 448

---

### `def bulk_replace(values, existing_adapter, new_adapter, initiator = None)`

**Description:**
Load a new collection, firing events based on prior like membership.

Appends instances in ``values`` onto the ``new_adapter``. Events will be
fired for any instance not present in the ``existing_adapter``.  Any
instances in ``existing_adapter`` not present in ``values`` will have
remove events fired upon them.

:param values: An iterable of collection member instances

:param existing_adapter: A :class:`.CollectionAdapter` of
instances to be replaced

:param new_adapter: An empty :class:`.CollectionAdapter`
to load with ``values``

**Line:** 772

---

### `def prepare_instrumentation(factory: Union[(Type[Collection[Any]], _CollectionFactoryType)]) -> _CollectionFactoryType`

**Description:**
Prepare a callable for future use as a collection class factory.

Given a collection class factory (either a type or no-arg callable),
return another factory that will produce compatible instances when
called.

This function is responsible for converting collection_class=list
into the run-time behavior of collection_class=InstrumentedList.

**Line:** 814

---

### `def _instrument_class(cls)`

**Description:**
Modify methods in a class and install instrumentation.

**Line:** 862

---

### `def _locate_roles_and_methods(cls)`

**Description:**
search for _sa_instrument_role-decorated methods in
method resolution order, assign to roles.

**Line:** 883

---

### `def _setup_canned_roles(cls, roles, methods)`

**Description:**
see if this class has "canned" roles based on a known
collection type (dict, set, list).  Apply those roles
as needed to the "roles" dictionary, and also
prepare "decorator" methods

**Line:** 928

---

### `def _assert_required_roles(cls, roles, methods)`

**Description:**
ensure all roles are present, and apply implicit instrumentation if
needed

**Line:** 953

---

### `def _set_collection_attributes(cls, roles, methods)`

**Description:**
apply ad-hoc instrumentation from decorators, class-level defaults
and implicit role declarations

**Line:** 985

---

### `def _instrument_membership_mutator(method, before, argument, after)`

**Description:**
Route method args and/or return value through the collection
adapter.

**Line:** 1009

---

### `def __set_wo_mutation(collection, item, _sa_initiator = None)`

**Description:**
Run set wo mutation events.

The collection is not mutated.

**Line:** 1071

---

### `def __set(collection, item, _sa_initiator, key)`

**Description:**
Run set events.

This event always occurs before the collection is actually mutated.

**Line:** 1085

---

### `def __del(collection, item, _sa_initiator, key)`

**Description:**
Run del events.

This event occurs before the collection is actually mutated, *except*
in the case of a pop operation, in which case it occurs afterwards.
For pop operations, the __before_pop hook is called before the
operation occurs.

**Line:** 1099

---

### `def __before_pop(collection, _sa_initiator = None)`

**Description:**
An event which occurs on a before a pop() operation occurs.

**Line:** 1114

---

### `def _list_decorators() -> Dict[(str, Callable[[_FN], _FN])]`

**Description:**
Tailored instrumentation wrappers for any list-like class.

**Line:** 1121

---

### `def _dict_decorators() -> Dict[(str, Callable[[_FN], _FN])]`

**Description:**
Tailored instrumentation wrappers for any dict-like mapping class.

**Line:** 1262

---

### `def _set_binops_check_strict(self: Any, obj: Any) -> bool`

**Description:**
Allow only set, frozenset and self.__class__-derived
objects in binops.

**Line:** 1369

---

### `def _set_binops_check_loose(self: Any, obj: Any) -> bool`

**Description:**
Allow anything set-like to participate in set binops.

**Line:** 1375

---

### `def _set_decorators() -> Dict[(str, Callable[[_FN], _FN])]`

**Description:**
Tailored instrumentation wrappers for any set-like class.

**Line:** 1383

---

### `def __go(lcls)`

**Line:** 1593

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.context
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/context.py`

**Imports:**
- __future__.annotations
- _typing.OrmExecuteOptionsParameter
- _typing._InternalEntityType
- base._is_aliased_class
- engine.Result
- engine.interfaces._CoreSingleExecuteParams
- interfaces.ORMColumnDescription
- interfaces.ORMColumnsClauseRole
- itertools
- loading.PostLoad
- mapper.Mapper
- path_registry.PathRegistry
- query.Query
- session.Session
- session._BindArguments
- sql._typing._ColumnsClauseArgument
- sql._typing._TP
- sql._typing.is_dml
- sql._typing.is_insert_update
- sql._typing.is_select_base
- sql.base.CacheableOptions
- sql.base.CompileState
- sql.base.Executable
- sql.base.Generative
- sql.base.Options
- sql.base._select_iterables
- sql.coercions
- sql.compiler.SQLCompiler
- sql.dml.UpdateBase
- sql.dml._DMLTableElement
- sql.elements.ColumnElement
- sql.elements.GroupedElement
- sql.elements.TextClause
- sql.expression
- sql.roles
- sql.selectable.CompoundSelectState
- sql.selectable.ExecutableReturnsRows
- sql.selectable.LABEL_STYLE_DISAMBIGUATE_ONLY
- sql.selectable.LABEL_STYLE_NONE
- sql.selectable.LABEL_STYLE_TABLENAME_PLUS_COL
- sql.selectable.Select
- sql.selectable.SelectBase
- sql.selectable.SelectLabelStyle
- sql.selectable.SelectState
- sql.selectable.TypedReturnsRows
- sql.selectable._JoinTargetElement
- sql.selectable._LabelConventionCallable
- sql.selectable._SetupJoinsElement
- sql.type_api.TypeEngine
- sql.util
- sql.visitors
- sql.visitors.InternalTraversal
- typing.Any
- typing.Dict
- typing.Iterable
- typing.List
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- util.AliasedClass
- util.Bundle
- util.ORMAdapter
- util.ORMStatementAdapter
- util._ORMJoin
- util._TraceAdaptRole
- util._entity_corresponds_to

**Functions:**

### `def _column_descriptions(query_or_select_stmt: Union[(Query, Select, FromStatement)], compile_state: Optional[ORMSelectCompileState] = None, legacy: bool = False) -> List[ORMColumnDescription]`

**Line:** 2409

---

### `def _legacy_filter_by_entity_zero(query_or_augmented_select: Union[(Query[Any], Select[Any])]) -> Optional[_InternalEntityType[Any]]`

**Line:** 2436

---

### `def _entity_from_pre_ent_zero(query_or_augmented_select: Union[(Query[Any], Select[Any])]) -> Optional[_InternalEntityType[Any]]`

**Line:** 2451

---

### `def _determine_last_joined_entity(setup_joins: Tuple[(_SetupJoinsElement, ...)], entity_zero: Optional[_InternalEntityType[Any]] = None) -> Optional[Union[(_InternalEntityType[Any], _JoinTargetElement)]]`

**Line:** 2470

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.decl_api
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/decl_api.py`

**Imports:**
- __future__.annotations
- _orm_constructors.composite
- _orm_constructors.deferred
- _orm_constructors.mapped_column
- _orm_constructors.relationship
- _orm_constructors.synonym
- _typing._O
- _typing._RegistryType
- attributes.InstrumentedAttribute
- base.Mapped
- base.ORMDescriptor
- base._inspect_mapped_class
- base._is_mapped_class
- decl_base._ClassScanMapperConfig
- decl_base._DataclassArguments
- decl_base._DeferredMapperConfig
- decl_base._add_attribute
- decl_base._as_declarative
- decl_base._declarative_constructor
- decl_base._del_attribute
- decl_base._mapper
- descriptor_props.Composite
- descriptor_props.Synonym
- instrumentation.ClassManager
- interfaces.MapperProperty
- itertools
- mapper.Mapper
- properties.MappedColumn
- re
- relationships.RelationshipProperty
- sql._typing._TypeEngineArgument
- sql.base._NoArg
- sql.elements.SQLCoreOperations
- sql.schema.MetaData
- sql.selectable.FromClause
- sql.sqltypes
- sql.type_api._MatchedOnType
- state.InstanceState
- typing
- typing.Any
- typing.Callable
- typing.ClassVar
- typing.Dict
- typing.FrozenSet
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.Mapping
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.hybridmethod
- util.hybridproperty
- util.typing
- util.typing.CallableReference
- util.typing.Literal
- util.typing.Self
- util.typing.flatten_newtype
- util.typing.is_generic
- util.typing.is_literal
- util.typing.is_newtype
- weakref

**Functions:**

### `def has_inherited_table(cls: Type[_O]) -> bool`

**Description:**
Given a class, return True if any of the classes it inherits from has a
mapped table, otherwise return False.

This is used in declarative mixins to build attributes that behave
differently for the base class vs. a subclass in an inheritance
hierarchy.

.. seealso::

:ref:`decl_mixin_inheritance`

**Line:** 107

---

### `def synonym_for(name: str, map_column: bool = False) -> Callable[([Callable[..., Any]], Synonym[Any])]`

**Description:**
Decorator that produces an :func:`_orm.synonym`
attribute in conjunction with a Python descriptor.

The function being decorated is passed to :func:`_orm.synonym` as the
:paramref:`.orm.synonym.descriptor` parameter::

class MyClass(Base):
__tablename__ = 'my_table'

id = Column(Integer, primary_key=True)
_job_status = Column("job_status", String(50))

@synonym_for("job_status")
@property
def job_status(self):
return "Status: %s" % self._job_status

The :ref:`hybrid properties <mapper_hybrids>` feature of SQLAlchemy
is typically preferred instead of synonyms, which is a more legacy
feature.

.. seealso::

:ref:`synonyms` - Overview of synonyms

:func:`_orm.synonym` - the mapper-level function

:ref:`mapper_hybrids` - The Hybrid Attribute extension provides an
updated approach to augmenting attribute behavior more flexibly than
can be achieved with synonyms.

**Line:** 199

---

### `def declarative_mixin(cls: Type[_T]) -> Type[_T]`

**Description:**
Mark a class as providing the feature of "declarative mixin".

E.g.::

from sqlalchemy.orm import declared_attr
from sqlalchemy.orm import declarative_mixin

@declarative_mixin
class MyMixin:

@declared_attr
def __tablename__(cls):
return cls.__name__.lower()

__table_args__ = {'mysql_engine': 'InnoDB'}
__mapper_args__= {'always_refresh': True}

id =  Column(Integer, primary_key=True)

class MyModel(MyMixin, Base):
name = Column(String(1000))

The :func:`_orm.declarative_mixin` decorator currently does not modify
the given class in any way; it's current purpose is strictly to assist
the :ref:`Mypy plugin <mypy_toplevel>` in being able to identify
SQLAlchemy declarative mixin classes when no other context is present.

.. versionadded:: 1.4.6

.. seealso::

:ref:`orm_mixins_toplevel`

:ref:`mypy_declarative_mixins` - in the
:ref:`Mypy plugin documentation <mypy_toplevel>`

**Line:** 489

---

### `def _setup_declarative_base(cls: Type[Any]) -> None`

**Line:** 531

---

### `def _check_not_declarative(cls: Type[Any], base: Type[Any]) -> None`

**Line:** 851

---

### `def add_mapped_attribute(target: Type[_O], key: str, attr: MapperProperty[Any]) -> None`

**Description:**
Add a new mapped attribute to an ORM mapped class.

E.g.::

add_mapped_attribute(User, "addresses", relationship(Address))

This may be used for ORM mappings that aren't using a declarative
metaclass that intercepts attribute set operations.

.. versionadded:: 2.0

**Line:** 975

---

### `def declarative_base(metadata: Optional[MetaData] = None, mapper: Optional[Callable[(..., Mapper[Any])]] = None, cls: Type[Any] = object, name: str = 'Base', class_registry: Optional[clsregistry._ClsRegistryType] = None, type_annotation_map: Optional[_TypeAnnotationMapType] = None, constructor: Callable[(..., None)] = _declarative_constructor, metaclass: Type[Any] = DeclarativeMeta) -> Any`

**Description:**
Construct a base class for declarative class definitions.

The new base class will be given a metaclass that produces
appropriate :class:`~sqlalchemy.schema.Table` objects and makes
the appropriate :class:`_orm.Mapper` calls based on the
information provided declaratively in the class and any subclasses
of the class.

.. versionchanged:: 2.0 Note that the :func:`_orm.declarative_base`
function is superseded by the new :class:`_orm.DeclarativeBase` class,
which generates a new "base" class using subclassing, rather than
return value of a function.  This allows an approach that is compatible
with :pep:`484` typing tools.

The :func:`_orm.declarative_base` function is a shorthand version
of using the :meth:`_orm.registry.generate_base`
method.  That is, the following::

from sqlalchemy.orm import declarative_base

Base = declarative_base()

Is equivalent to::

from sqlalchemy.orm import registry

mapper_registry = registry()
Base = mapper_registry.generate_base()

See the docstring for :class:`_orm.registry`
and :meth:`_orm.registry.generate_base`
for more details.

.. versionchanged:: 1.4  The :func:`_orm.declarative_base`
function is now a specialization of the more generic
:class:`_orm.registry` class.  The function also moves to the
``sqlalchemy.orm`` package from the ``declarative.ext`` package.


:param metadata:
An optional :class:`~sqlalchemy.schema.MetaData` instance.  All
:class:`~sqlalchemy.schema.Table` objects implicitly declared by
subclasses of the base will share this MetaData.  A MetaData instance
will be created if none is provided.  The
:class:`~sqlalchemy.schema.MetaData` instance will be available via the
``metadata`` attribute of the generated declarative base class.

:param mapper:
An optional callable, defaults to :class:`_orm.Mapper`. Will
be used to map subclasses to their Tables.

:param cls:
Defaults to :class:`object`. A type to use as the base for the generated
declarative base class. May be a class or tuple of classes.

:param name:
Defaults to ``Base``.  The display name for the generated
class.  Customizing this is not required, but can improve clarity in
tracebacks and debugging.

:param constructor:
Specify the implementation for the ``__init__`` function on a mapped
class that has no ``__init__`` of its own.  Defaults to an
implementation that assigns \**kwargs for declared
fields and relationships to an instance.  If ``None`` is supplied,
no __init__ will be provided and construction will fall back to
cls.__init__ by way of the normal Python semantics.

:param class_registry: optional dictionary that will serve as the
registry of class names-> mapped classes when string names
are used to identify classes inside of :func:`_orm.relationship`
and others.  Allows two or more declarative base classes
to share the same registry of class names for simplified
inter-base relationships.

:param type_annotation_map: optional dictionary of Python types to
SQLAlchemy :class:`_types.TypeEngine` classes or instances.  This
is used exclusively by the :class:`_orm.MappedColumn` construct
to produce column types based on annotations within the
:class:`_orm.Mapped` type.


.. versionadded:: 2.0

.. seealso::

:ref:`orm_declarative_mapped_column_type_map`

:param metaclass:
Defaults to :class:`.DeclarativeMeta`.  A metaclass or __metaclass__
compatible callable to use as the meta type of the generated
declarative base class.

.. seealso::

:class:`_orm.registry`

**Line:** 994

---

### `def as_declarative(**kw: Any) -> Callable[([Type[_T]], Type[_T])]`

**Description:**
Class decorator which will adapt a given class into a
:func:`_orm.declarative_base`.

This function makes use of the :meth:`_orm.registry.as_declarative_base`
method, by first creating a :class:`_orm.registry` automatically
and then invoking the decorator.

E.g.::

from sqlalchemy.orm import as_declarative

@as_declarative()
class Base:
@declared_attr
def __tablename__(cls):
return cls.__name__.lower()
id = Column(Integer, primary_key=True)

class MyMappedClass(Base):
# ...

.. seealso::

:meth:`_orm.registry.as_declarative_base`

**Line:** 1840

---

### `def _inspect_decl_meta(cls: Type[Any]) -> Optional[Mapper[Any]]`

**Decorators:**
- `@inspection._inspects(...)`

**Line:** 1881

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.decl_base
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/decl_base.py`

**Imports:**
- __future__.annotations
- _typing._ClassDict
- _typing._O
- _typing._RegistryType
- _typing.attr_is_internal_proxy
- attributes.InstrumentedAttribute
- attributes.QueryableAttribute
- base.InspectionAttr
- base.Mapped
- base._is_mapped_class
- collections
- dataclasses
- decl_api.declared_attr
- descriptor_props.CompositeProperty
- descriptor_props.SynonymProperty
- instrumentation.ClassManager
- interfaces.MapperProperty
- interfaces._AttributeOptions
- interfaces._DCAttributeOptions
- interfaces._IntrospectsAnnotations
- interfaces._MappedAttribute
- interfaces._MapsColumns
- mapper.Mapper
- properties.ColumnProperty
- properties.MappedColumn
- re
- sql.base._NoArg
- sql.elements.NamedColumn
- sql.expression
- sql.schema.Column
- sql.schema.MetaData
- sql.schema.Table
- sql.selectable.FromClause
- typing.Any
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.List
- typing.Mapping
- typing.NamedTuple
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- util._extract_mapped_subtype
- util._is_mapped_annotation
- util.class_mapper
- util.de_stringify_annotation
- util.topological
- util.typing.Protocol
- util.typing.TypedDict
- util.typing._AnnotationScanType
- util.typing.is_fwd_ref
- util.typing.is_literal
- util.typing.typing_get_args
- weakref

**Functions:**

### `def _declared_mapping_info(cls: Type[Any]) -> Optional[Union[(_DeferredMapperConfig, Mapper[Any])]]`

**Line:** 132

---

### `def _is_supercls_for_inherits(cls: Type[Any]) -> bool`

**Description:**
return True if this class will be used as a superclass to set in
'inherits'.

This includes deferred mapper configs that aren't mapped yet, however does
not include classes with _sa_decl_prepare_nocascade (e.g.
``AbstractConcreteBase``); these concrete-only classes are not set up as
"inherits" until after mappers are configured using
mapper._set_concrete_base()

**Line:** 145

---

### `def _resolve_for_abstract_or_classical(cls: Type[Any]) -> Optional[Type[Any]]`

**Line:** 167

---

### `def _get_immediate_cls_attr(cls: Type[Any], attrname: str, strict: bool = False) -> Optional[Any]`

**Description:**
return an attribute of the class that is either present directly
on the class, e.g. not on a superclass, or is from a superclass but
this superclass is a non-mapped mixin, that is, not a descendant of
the declarative base and is also not classically mapped.

This is used to detect attributes that indicate something about
a mapped class independently from any mapped classes that it may
inherit from.

**Line:** 189

---

### `def _dive_for_cls_manager(cls: Type[_O]) -> Optional[ClassManager[_O]]`

**Line:** 228

---

### `def _as_declarative(registry: _RegistryType, cls: Type[Any], dict_: _ClassDict) -> Optional[_MapperConfig]`

**Line:** 242

---

### `def _mapper(registry: _RegistryType, cls: Type[_O], table: Optional[FromClause], mapper_kw: _MapperKwArgs) -> Mapper[_O]`

**Line:** 250

---

### `def _is_declarative_props(obj: Any) -> bool`

**Decorators:**
- `@util.preload_module(...)`

**Line:** 261

---

### `def _check_declared_props_nocascade(obj: Any, name: str, cls: Type[_O]) -> bool`

**Line:** 267

---

### `def _as_dc_declaredattr(field_metadata: Mapping[(str, Any)], sa_dataclass_metadata_key: str) -> Any`

**Decorators:**
- `@util.preload_module(...)`

**Line:** 1962

---

### `def _add_attribute(cls: Type[Any], key: str, value: MapperProperty[Any]) -> None`

**Description:**
add an attribute to an existing declarative class.

This runs through the logic to determine MapperProperty,
adds it to the Mapper, adds a column to the mapped Table, etc.

**Line:** 2053

---

### `def _del_attribute(cls: Type[Any], key: str) -> None`

**Line:** 2105

---

### `def _declarative_constructor(self: Any, **kwargs: Any) -> None`

**Description:**
A simple constructor that allows initialization from kwargs.

Sets attributes on the constructed instance using the names and
values in ``kwargs``.

Only keys that are present as
attributes of the instance's class are allowed. These could be,
for example, any mapped columns or relationships.

**Line:** 2129

---

### `def _undefer_column_name(key: str, column: Column[Any]) -> None`

**Line:** 2151

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.dynamic
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/dynamic.py`

**Imports:**
- __future__.annotations
- base.PassiveFlag
- engine.result
- event._Dispatch
- mapper.Mapper
- query.Query
- relationships._RelationshipOrderByArg
- session.Session
- session.object_session
- sql.elements.ColumnElement
- state.InstanceState
- typing.Any
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- util.AliasedClass
- writeonly.AbstractCollectionWriter
- writeonly.WriteOnlyAttributeImpl
- writeonly.WriteOnlyHistory
- writeonly.WriteOnlyLoader

**Functions:**

### `def mixin_user_query(cls: Any) -> type[AppenderMixin[Any]]`

**Description:**
Return a new class with AppenderQuery functionality layered over.

**Line:** 296

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.evaluator
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/evaluator.py`

**Imports:**
- __future__.annotations
- base.LoaderCallableStatus
- base.PassiveFlag
- sql.and_
- sql.operators
- sql.sqltypes.Integer
- sql.sqltypes.Numeric
- typing.Type
- util.warn_deprecated

**Functions:**

### `def __getattr__(name: str) -> Type[_EvaluatorCompiler]`

**Line:** 358

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.exc
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/exc.py`

**Imports:**
- __future__.annotations
- exc.MultipleResultsFound
- exc.NoResultFound
- interfaces.LoaderStrategy
- interfaces.MapperProperty
- state.InstanceState
- typing.Any
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar

**Functions:**

### `def _safe_cls_name(cls: Type[Any]) -> str`

**Line:** 200

---

### `def _default_unmapped(cls: Type[Any]) -> Optional[str]`

**Decorators:**
- `@util.preload_module(...)`

**Line:** 212

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.identity
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/identity.py`

**Imports:**
- __future__.annotations
- _typing._IdentityKeyType
- state.InstanceState
- typing.Any
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.NoReturn
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.cast
- weakref

**Functions:**

### `def _killed(state: InstanceState[Any], key: _IdentityKeyType[Any]) -> NoReturn`

**Line:** 294

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.instrumentation
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/instrumentation.py`

**Imports:**
- __future__.annotations
- _typing._O
- _typing._RegistryType
- attributes.AttributeImpl
- attributes.QueryableAttribute
- attributes._is_collection_attribute_impl
- collections._AdaptedCollectionProtocol
- collections._CollectionFactoryType
- decl_base._MapperConfig
- event.EventTarget
- event.dispatcher
- events.InstanceEvents
- mapper.Mapper
- state.InstanceState
- typing.Any
- typing.Callable
- typing.Collection
- typing.Dict
- typing.Generic
- typing.Iterable
- typing.List
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- util.HasMemoized
- util.typing.Literal
- util.typing.Protocol
- weakref

**Functions:**

### `def register_class(class_: Type[_O], finalize: bool = True, mapper: Optional[Mapper[_O]] = None, registry: Optional[_RegistryType] = None, declarative_scan: Optional[_MapperConfig] = None, expired_attribute_loader: Optional[_ExpiredAttributeLoaderProto] = None, init_method: Optional[Callable[(..., None)]] = None) -> ClassManager[_O]`

**Description:**
Register class instrumentation.

Returns the existing or newly created class manager.

**Line:** 666

---

### `def unregister_class(class_)`

**Description:**
Unregister class instrumentation.

**Line:** 696

---

### `def is_instrumented(instance, key)`

**Description:**
Return True if the given attribute on the given instance is
instrumented by the attributes package.

This function may be used regardless of instrumentation
applied directly to the class, i.e. no descriptors are required.

**Line:** 702

---

### `def _generate_init(class_, class_manager, original_init)`

**Description:**
Build an __init__ decorator that triggers ClassManager events.

**Line:** 715

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.loading
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/loading.py`

**Imports:**
- __future__.annotations
- _typing._IdentityKeyType
- base.LoaderCallableStatus
- base.PassiveFlag
- base._DEFER_FOR_STATE
- base._RAISE_FOR_STATE
- base._SET_DEFERRED_EXPIRED
- context.FromStatement
- context.ORMCompileState
- context.QueryContext
- engine.cursor.CursorResult
- engine.interfaces._ExecuteOptions
- engine.result.ChunkedIteratorResult
- engine.result.FrozenResult
- engine.result.Result
- engine.result.SimpleResultMetaData
- engine.result_tuple
- interfaces.ORMOption
- mapper.Mapper
- query.Query
- session.Session
- sql.Select
- sql.select
- sql.selectable.ForUpdateArg
- sql.selectable.LABEL_STYLE_TABLENAME_PLUS_COL
- sql.selectable.SelectState
- sql.util
- state.InstanceState
- typing.Any
- typing.Dict
- typing.Iterable
- typing.List
- typing.Mapping
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- util.EMPTY_DICT
- util._none_set
- util.state_str

**Functions:**

### `def instances(cursor: CursorResult[Any], context: QueryContext) -> Result[Any]`

**Description:**
Return a :class:`.Result` given an ORM query context.

:param cursor: a :class:`.CursorResult`, generated by a statement
which came from :class:`.ORMCompileState`

:param context: a :class:`.QueryContext` object

:return: a :class:`.Result` object representing ORM results

.. versionchanged:: 1.4 The instances() function now uses
:class:`.Result` objects and has an all new interface.

**Line:** 78

---

### `def merge_frozen_result(session, statement, frozen_result, load = True)`

**Decorators:**
- `@util.preload_module(...)`

**Description:**
Merge a :class:`_engine.FrozenResult` back into a :class:`_orm.Session`,
returning a new :class:`_engine.Result` object with :term:`persistent`
objects.

See the section :ref:`do_orm_execute_re_executing` for an example.

.. seealso::

:ref:`do_orm_execute_re_executing`

:meth:`_engine.Result.freeze`

:class:`_engine.FrozenResult`

**Line:** 296

---

### `def merge_result(query: Query[Any], iterator: Union[(FrozenResult, Iterable[Sequence[Any]], Iterable[object])], load: bool = True) -> Union[(FrozenResult, Iterable[Any])]`

**Decorators:**
- `@util.became_legacy_20(...)`
- `@util.preload_module(...)`

**Description:**
Merge a result into the given :class:`.Query` object's Session.

See :meth:`_orm.Query.merge_result` for top-level documentation on this
function.

**Line:** 361

---

### `def get_from_identity(session: Session, mapper: Mapper[_O], key: _IdentityKeyType[_O], passive: PassiveFlag) -> Union[(LoaderCallableStatus, Optional[_O])]`

**Description:**
Look up the given key in the given session's identity map,
check the object for expired state if found.

**Line:** 445

---

### `def load_on_ident(session: Session, statement: Union[(Select, FromStatement)], key: Optional[_IdentityKeyType], load_options: Optional[Sequence[ORMOption]] = None, refresh_state: Optional[InstanceState[Any]] = None, with_for_update: Optional[ForUpdateArg] = None, only_load_props: Optional[Iterable[str]] = None, no_autoflush: bool = False, bind_arguments: Mapping[(str, Any)] = util.EMPTY_DICT, execution_options: _ExecuteOptions = util.EMPTY_DICT, require_pk_cols: bool = False, is_user_refresh: bool = False)`

**Description:**
Load the given identity key from the database.

**Line:** 483

---

### `def load_on_pk_identity(session: Session, statement: Union[(Select, FromStatement)], primary_key_identity: Optional[Tuple[(Any, ...)]], load_options: Optional[Sequence[ORMOption]] = None, refresh_state: Optional[InstanceState[Any]] = None, with_for_update: Optional[ForUpdateArg] = None, only_load_props: Optional[Iterable[str]] = None, identity_token: Optional[Any] = None, no_autoflush: bool = False, bind_arguments: Mapping[(str, Any)] = util.EMPTY_DICT, execution_options: _ExecuteOptions = util.EMPTY_DICT, require_pk_cols: bool = False, is_user_refresh: bool = False)`

**Description:**
Load the given primary key identity from the database.

**Line:** 522

---

### `def _set_get_options(compile_opt, load_opt, populate_existing = None, version_check = None, only_load_props = None, refresh_state = None, identity_token = None, is_user_refresh = None)`

**Line:** 706

---

### `def _setup_entity_query(compile_state, mapper, query_entity, path, adapter, column_collection, with_polymorphic = None, only_load_props = None, polymorphic_discriminator = None, **kw)`

**Line:** 740

---

### `def _warn_for_runid_changed(state)`

**Line:** 795

---

### `def _instance_processor(query_entity, mapper, context, result, path, adapter, only_load_props = None, refresh_state = None, polymorphic_discriminator = None, _polymorphic_from = None)`

**Description:**
Produce a mapper level row processor callable
which processes rows into mapped instances.

**Line:** 807

---

### `def _load_subclass_via_in(context, path, entity, polymorphic_from, option_entities)`

**Line:** 1235

---

### `def _populate_full(context, row, state, dict_, isnew, load_path, loaded_instance, populate_existing, populators)`

**Line:** 1304

---

### `def _populate_partial(context, row, state, dict_, isnew, load_path, unloaded, populators)`

**Line:** 1361

---

### `def _validate_version_id(mapper, state, dict_, row, getter)`

**Line:** 1398

---

### `def _decorate_polymorphic_switch(instance_fn, context, query_entity, mapper, result, path, polymorphic_discriminator, adapter, ensure_no_pk)`

**Line:** 1415

---

### `def load_scalar_attributes(mapper, state, attribute_names, passive)`

**Description:**
initiate a column-based attribute refresh operation.

**Line:** 1576

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.mapped_collection
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/mapped_collection.py`

**Imports:**
- __future__.annotations
- collections.CollectionAdapter
- collections.collection
- collections.collection_adapter
- operator
- sql.coercions
- sql.elements.ColumnElement
- sql.expression
- sql.roles
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generic
- typing.List
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- util.typing.Literal

**Functions:**

### `def column_keyed_dict(mapping_spec: Union[(Type[_KT], Callable[[_KT], _VT])], ignore_unpopulated_attribute: bool = False) -> Type[KeyFuncDict[(_KT, _KT)]]`

**Description:**
A dictionary-based collection type with column-based keying.

.. versionchanged:: 2.0 Renamed :data:`.column_mapped_collection` to
:class:`.column_keyed_dict`.

Returns a :class:`.KeyFuncDict` factory which will produce new
dictionary keys based on the value of a particular :class:`.Column`-mapped
attribute on ORM mapped instances to be added to the dictionary.

.. note:: the value of the target attribute must be assigned with its
value at the time that the object is being added to the
dictionary collection.   Additionally, changes to the key attribute
are **not tracked**, which means the key in the dictionary is not
automatically synchronized with the key value on the target object
itself.  See :ref:`key_collections_mutations` for further details.

.. seealso::

:ref:`orm_dictionary_collection` - background on use

:param mapping_spec: a :class:`_schema.Column` object that is expected
to be mapped by the target mapper to a particular attribute on the
mapped class, the value of which on a particular instance is to be used
as the key for a new dictionary entry for that instance.
:param ignore_unpopulated_attribute:  if True, and the mapped attribute
indicated by the given :class:`_schema.Column` target attribute
on an object is not populated at all, the operation will be silently
skipped.  By default, an error is raised.

.. versionadded:: 2.0 an error is raised by default if the attribute
being used for the dictionary key is determined that it was never
populated with any value.  The
:paramref:`_orm.column_keyed_dict.ignore_unpopulated_attribute`
parameter may be set which will instead indicate that this condition
should be ignored, and the append operation silently skipped.
This is in contrast to the behavior of the 1.x series which would
erroneously populate the value in the dictionary with an arbitrary key
value of ``None``.

**Line:** 146

---

### `def attribute_keyed_dict(attr_name: str, ignore_unpopulated_attribute: bool = False) -> Type[KeyFuncDict[(_KT, _KT)]]`

**Description:**
A dictionary-based collection type with attribute-based keying.

.. versionchanged:: 2.0 Renamed :data:`.attribute_mapped_collection` to
:func:`.attribute_keyed_dict`.

Returns a :class:`.KeyFuncDict` factory which will produce new
dictionary keys based on the value of a particular named attribute on
ORM mapped instances to be added to the dictionary.

.. note:: the value of the target attribute must be assigned with its
value at the time that the object is being added to the
dictionary collection.   Additionally, changes to the key attribute
are **not tracked**, which means the key in the dictionary is not
automatically synchronized with the key value on the target object
itself.  See :ref:`key_collections_mutations` for further details.

.. seealso::

:ref:`orm_dictionary_collection` - background on use

:param attr_name: string name of an ORM-mapped attribute
on the mapped class, the value of which on a particular instance
is to be used as the key for a new dictionary entry for that instance.
:param ignore_unpopulated_attribute:  if True, and the target attribute
on an object is not populated at all, the operation will be silently
skipped.  By default, an error is raised.

.. versionadded:: 2.0 an error is raised by default if the attribute
being used for the dictionary key is determined that it was never
populated with any value.  The
:paramref:`_orm.attribute_keyed_dict.ignore_unpopulated_attribute`
parameter may be set which will instead indicate that this condition
should be ignored, and the append operation silently skipped.
This is in contrast to the behavior of the 1.x series which would
erroneously populate the value in the dictionary with an arbitrary key
value of ``None``.

**Line:** 232

---

### `def keyfunc_mapping(keyfunc: _F, ignore_unpopulated_attribute: bool = False) -> Type[KeyFuncDict[(_KT, Any)]]`

**Description:**
A dictionary-based collection type with arbitrary keying.

.. versionchanged:: 2.0 Renamed :data:`.mapped_collection` to
:func:`.keyfunc_mapping`.

Returns a :class:`.KeyFuncDict` factory with a keying function
generated from keyfunc, a callable that takes an entity and returns a
key value.

.. note:: the given keyfunc is called only once at the time that the
target object is being added to the collection.   Changes to the
effective value returned by the function are not tracked.


.. seealso::

:ref:`orm_dictionary_collection` - background on use

:param keyfunc: a callable that will be passed the ORM-mapped instance
which should then generate a new key to use in the dictionary.
If the value returned is :attr:`.LoaderCallableStatus.NO_VALUE`, an error
is raised.
:param ignore_unpopulated_attribute:  if True, and the callable returns
:attr:`.LoaderCallableStatus.NO_VALUE` for a particular instance, the
operation will be silently skipped.  By default, an error is raised.

.. versionadded:: 2.0 an error is raised by default if the callable
being used for the dictionary key returns
:attr:`.LoaderCallableStatus.NO_VALUE`, which in an ORM attribute
context indicates an attribute that was never populated with any value.
The :paramref:`_orm.mapped_collection.ignore_unpopulated_attribute`
parameter may be set which will instead indicate that this condition
should be ignored, and the append operation silently skipped. This is
in contrast to the behavior of the 1.x series which would erroneously
populate the value in the dictionary with an arbitrary key value of
``None``.

**Line:** 281

---

### `def _mapped_collection_cls(keyfunc: _F, ignore_unpopulated_attribute: bool) -> Type[KeyFuncDict[(_KT, _KT)]]`

**Line:** 518

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.mapper
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/mapper.py`

**Imports:**
- __future__.annotations
- _typing._IdentityKeyType
- _typing._InstanceDict
- _typing._O
- _typing._ORMColumnExprArgument
- _typing._RegistryType
- base.PassiveFlag
- base._class_to_mapper
- base._parse_mapper_argument
- base._state_mapper
- base.state_str
- collections.deque
- decl_api.registry
- dependency.DependencyProcessor
- descriptor_props.CompositeProperty
- descriptor_props.SynonymProperty
- engine.Row
- engine.RowMapping
- event.EventTarget
- event.dispatcher
- events.MapperEvents
- functools.reduce
- instrumentation.ClassManager
- interfaces.EXT_SKIP
- interfaces.InspectionAttr
- interfaces.MapperProperty
- interfaces.ORMEntityColumnsClauseRole
- interfaces.ORMFromClauseRole
- interfaces.StrategizedProperty
- interfaces._MappedAttribute
- itertools.chain
- path_registry.CachingEntityRegistry
- path_registry.PathRegistry
- properties.ColumnProperty
- relationships.RelationshipProperty
- sql.TableClause
- sql._typing._ColumnExpressionArgument
- sql._typing._EquivalentColumnMap
- sql.base
- sql.base.ReadOnlyColumnCollection
- sql.cache_key.MemoizedHasCacheKey
- sql.coercions
- sql.elements.ColumnClause
- sql.elements.ColumnElement
- sql.elements.KeyedColumnElement
- sql.expression
- sql.operators
- sql.roles
- sql.schema.Column
- sql.schema.Table
- sql.selectable.FromClause
- sql.selectable.LABEL_STYLE_TABLENAME_PLUS_COL
- sql.util
- sql.visitors
- state.InstanceState
- sys
- threading
- typing.Any
- typing.Callable
- typing.Collection
- typing.Deque
- typing.Dict
- typing.FrozenSet
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- util.HasMemoized
- util.HasMemoized_ro_memoized_attribute
- util.ORMAdapter
- util.OrderedSet
- util.typing.Literal
- weakref

**Functions:**

### `def _all_registries() -> Set[registry]`

**Line:** 140

---

### `def _unconfigured_mappers() -> Iterator[Mapper[Any]]`

**Line:** 145

---

### `def configure_mappers() -> None`

**Description:**
Initialize the inter-mapper relationships of all mappers that
have been constructed thus far across all :class:`_orm.registry`
collections.

The configure step is used to reconcile and initialize the
:func:`_orm.relationship` linkages between mapped classes, as well as to
invoke configuration events such as the
:meth:`_orm.MapperEvents.before_configured` and
:meth:`_orm.MapperEvents.after_configured`, which may be used by ORM
extensions or user-defined extension hooks.

Mapper configuration is normally invoked automatically, the first time
mappings from a particular :class:`_orm.registry` are used, as well as
whenever mappings are used and additional not-yet-configured mappers have
been constructed. The automatic configuration process however is local only
to the :class:`_orm.registry` involving the target mapper and any related
:class:`_orm.registry` objects which it may depend on; this is
equivalent to invoking the :meth:`_orm.registry.configure` method
on a particular :class:`_orm.registry`.

By contrast, the :func:`_orm.configure_mappers` function will invoke the
configuration process on all :class:`_orm.registry` objects that
exist in memory, and may be useful for scenarios where many individual
:class:`_orm.registry` objects that are nonetheless interrelated are
in use.

.. versionchanged:: 1.4

As of SQLAlchemy 1.4.0b2, this function works on a
per-:class:`_orm.registry` basis, locating all :class:`_orm.registry`
objects present and invoking the :meth:`_orm.registry.configure` method
on each. The :meth:`_orm.registry.configure` method may be preferred to
limit the configuration of mappers to those local to a particular
:class:`_orm.registry` and/or declarative base class.

Points at which automatic configuration is invoked include when a mapped
class is instantiated into an instance, as well as when ORM queries
are emitted using :meth:`.Session.query` or :meth:`_orm.Session.execute`
with an ORM-enabled statement.

The mapper configure process, whether invoked by
:func:`_orm.configure_mappers` or from :meth:`_orm.registry.configure`,
provides several event hooks that can be used to augment the mapper
configuration step. These hooks include:

* :meth:`.MapperEvents.before_configured` - called once before
:func:`.configure_mappers` or :meth:`_orm.registry.configure` does any
work; this can be used to establish additional options, properties, or
related mappings before the operation proceeds.

* :meth:`.MapperEvents.mapper_configured` - called as each individual
:class:`_orm.Mapper` is configured within the process; will include all
mapper state except for backrefs set up by other mappers that are still
to be configured.

* :meth:`.MapperEvents.after_configured` - called once after
:func:`.configure_mappers` or :meth:`_orm.registry.configure` is
complete; at this stage, all :class:`_orm.Mapper` objects that fall
within the scope of the configuration operation will be fully configured.
Note that the calling application may still have other mappings that
haven't been produced yet, such as if they are in modules as yet
unimported, and may also have mappings that are still to be configured,
if they are in other :class:`_orm.registry` collections not part of the
current scope of configuration.

**Line:** 4100

---

### `def _configure_registries(registries: Set[_RegistryType], cascade: bool) -> None`

**Line:** 4171

---

### `def _do_configure_registries(registries: Set[_RegistryType], cascade: bool) -> None`

**Decorators:**
- `@util.preload_module(...)`

**Line:** 4206

---

### `def _dispose_registries(registries: Set[_RegistryType], cascade: bool) -> None`

**Decorators:**
- `@util.preload_module(...)`

**Line:** 4259

---

### `def reconstructor(fn)`

**Description:**
Decorate a method as the 'reconstructor' hook.

Designates a single method as the "reconstructor", an ``__init__``-like
method that will be called by the ORM after the instance has been
loaded from the database or otherwise reconstituted.

.. tip::

The :func:`_orm.reconstructor` decorator makes use of the
:meth:`_orm.InstanceEvents.load` event hook, which can be
used directly.

The reconstructor will be invoked with no arguments.  Scalar
(non-collection) database-mapped attributes of the instance will
be available for use within the function.  Eagerly-loaded
collections are generally not yet available and will usually only
contain the first element.  ORM state changes made to objects at
this stage will not be recorded for the next flush() operation, so
the activity within a reconstructor should be conservative.

.. seealso::

:meth:`.InstanceEvents.load`

**Line:** 4292

---

### `def validates(include_removes: bool = False, include_backrefs: bool = True, *names: str) -> Callable[([_Fn], _Fn)]`

**Description:**
Decorate a method as a 'validator' for one or more named properties.

Designates a method as a validator, a method which receives the
name of the attribute as well as a value to be assigned, or in the
case of a collection, the value to be added to the collection.
The function can then raise validation exceptions to halt the
process from continuing (where Python's built-in ``ValueError``
and ``AssertionError`` exceptions are reasonable choices), or can
modify or replace the value before proceeding. The function should
otherwise return the given value.

Note that a validator for a collection **cannot** issue a load of that
collection within the validation routine - this usage raises
an assertion to avoid recursion overflows.  This is a reentrant
condition which is not supported.

:param \*names: list of attribute names to be validated.
:param include_removes: if True, "remove" events will be
sent as well - the validation function must accept an additional
argument "is_remove" which will be a boolean.

:param include_backrefs: defaults to ``True``; if ``False``, the
validation function will not emit if the originator is an attribute
event related via a backref.  This can be used for bi-directional
:func:`.validates` usage where only one validator should emit per
attribute operation.

.. versionchanged:: 2.0.16 This paramter inadvertently defaulted to
``False`` for releases 2.0.0 through 2.0.15.  Its correct default
of ``True`` is restored in 2.0.16.

.. seealso::

:ref:`simple_validators` - usage examples for :func:`.validates`

**Line:** 4322

---

### `def _event_on_load(state, ctx)`

**Line:** 4373

---

### `def _event_on_init(state, args, kwargs)`

**Description:**
Run init_instance hooks.

This also includes mapper compilation, normally not needed
here but helps with some piecemeal configuration
scenarios (such as in the ORM tutorial).

**Line:** 4380

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.path_registry
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/path_registry.py`

**Imports:**
- __future__.annotations
- _typing._InternalEntityType
- _typing.insp_is_mapper_property
- functools.reduce
- interfaces.MapperProperty
- itertools.chain
- logging
- mapper.Mapper
- operator
- relationships.RelationshipProperty
- sql.cache_key.HasCacheKey
- sql.cache_key._CacheKeyTraversalType
- sql.elements.BindParameter
- sql.visitors
- sql.visitors.anon_map
- typing.Any
- typing.Dict
- typing.Iterator
- typing.List
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- typing.cast
- typing.overload
- util.AliasedInsp
- util.typing.TypeGuard
- util.typing._LiteralStar

**Functions:**

### `def is_root(path: PathRegistry) -> TypeGuard[RootRegistry]`

**Line:** 48

---

### `def is_entity(path: PathRegistry) -> TypeGuard[AbstractEntityRegistry]`

**Line:** 51

---

### `def _unreduce_path(path: _SerializedPath) -> PathRegistry`

**Line:** 82

---

### `def path_is_entity(path: PathRegistry) -> TypeGuard[AbstractEntityRegistry]`

**Line:** 809

---

### `def path_is_property(path: PathRegistry) -> TypeGuard[PropRegistry]`

**Line:** 814

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.persistence
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py`

**Imports:**
- __future__.annotations
- base.state_str
- engine.cursor
- itertools.chain
- itertools.groupby
- itertools.zip_longest
- operator
- sql.elements.BooleanClauseList
- sql.operators
- sql.selectable.LABEL_STYLE_TABLENAME_PLUS_COL

**Functions:**

### `def save_obj(base_mapper, states, uowtransaction, single = False)`

**Description:**
Issue ``INSERT`` and/or ``UPDATE`` statements for a list
of objects.

This is called within the context of a UOWTransaction during a
flush operation, given a list of states to be flushed.  The
base mapper in an inheritance hierarchy handles the inserts/
updates for all descendant mappers.

**Line:** 40

---

### `def post_update(base_mapper, states, uowtransaction, post_update_cols)`

**Description:**
Issue UPDATE statements on behalf of a relationship() which
specifies post_update.

**Line:** 123

---

### `def delete_obj(base_mapper, states, uowtransaction)`

**Description:**
Issue ``DELETE`` statements for a list of objects.

This is called within the context of a UOWTransaction during a
flush operation.

**Line:** 166

---

### `def _organize_states_for_save(base_mapper, states, uowtransaction)`

**Description:**
Make an initial pass across a set of states for INSERT or
UPDATE.

This includes splitting out into distinct lists for
each, calling before_insert/before_update, obtaining
key information for each state including its dictionary,
mapper, the connection to use for the execution per state,
and the identity flag.

**Line:** 209

---

### `def _organize_states_for_post_update(base_mapper, states, uowtransaction)`

**Description:**
Make an initial pass across a set of states for UPDATE
corresponding to post_update.

This includes obtaining key information for each state
including its dictionary, mapper, the connection to use for
the execution per state.

**Line:** 289

---

### `def _organize_states_for_delete(base_mapper, states, uowtransaction)`

**Description:**
Make an initial pass across a set of states for DELETE.

This includes calling out before_delete and obtaining
key information for each state including its dictionary,
mapper, the connection to use for the execution per state.

**Line:** 301

---

### `def _collect_insert_commands(table, states_to_insert, bulk = False, return_defaults = False, render_nulls = False, include_bulk_keys = ())`

**Description:**
Identify sets of values to use in INSERT statements for a
list of states.

**Line:** 324

---

### `def _collect_update_commands(uowtransaction, table, states_to_update, bulk = False, use_orm_update_stmt = None, include_bulk_keys = ())`

**Description:**
Identify sets of values to use in UPDATE statements for a
list of states.

This function works intricately with the history system
to determine exactly what values should be updated
as well as how the row should be matched within an UPDATE
statement.  Includes some tricky scenarios where the primary
key of an object might have been changed.

**Line:** 425

---

### `def _collect_post_update_commands(base_mapper, uowtransaction, table, states_to_update, post_update_cols)`

**Description:**
Identify sets of values to use in UPDATE statements for a
list of states within a post_update operation.

**Line:** 633

---

### `def _collect_delete_commands(base_mapper, uowtransaction, table, states_to_delete)`

**Description:**
Identify values to use in DELETE statements for a list of
states to be deleted.

**Line:** 687

---

### `def _emit_update_statements(base_mapper, uowtransaction, mapper, table, update, bookkeeping = True, use_orm_update_stmt = None, enable_check_rowcount = True)`

**Description:**
Emit UPDATE statements corresponding to value lists collected
by _collect_update_commands().

**Line:** 725

---

### `def _emit_insert_statements(base_mapper, uowtransaction, mapper, table, insert, bookkeeping = True, use_orm_insert_stmt = None, execution_options = None)`

**Description:**
Emit INSERT statements corresponding to value lists collected
by _collect_insert_commands().

**Line:** 957

---

### `def _emit_post_update_statements(base_mapper, uowtransaction, mapper, table, update)`

**Description:**
Emit UPDATE statements corresponding to value lists collected
by _collect_post_update_commands().

**Line:** 1277

---

### `def _emit_delete_statements(base_mapper, uowtransaction, mapper, table, delete)`

**Description:**
Emit DELETE statements corresponding to value lists collected
by _collect_delete_commands().

**Line:** 1395

---

### `def _finalize_insert_update_commands(base_mapper, uowtransaction, states)`

**Description:**
finalize state on states that have been inserted or updated,
including calling after_insert/after_update events.

**Line:** 1494

---

### `def _postfetch_post_update(mapper, uowtransaction, table, state, dict_, result, params)`

**Line:** 1569

---

### `def _postfetch(mapper, uowtransaction, table, state, dict_, result, params, value_params, isupdate, returned_defaults)`

**Description:**
Expire attributes in need of newly persisted database state,
after an INSERT or UPDATE statement has proceeded for that
state.

**Line:** 1610

---

### `def _postfetch_bulk_save(mapper, dict_, table)`

**Line:** 1707

---

### `def _connections_for_states(base_mapper, uowtransaction, states)`

**Description:**
Return an iterator of (state, state.dict, mapper, connection).

The states are sorted according to _sort_states, then paired
with the connection they should be using for the given
unit of work transaction.

**Line:** 1712

---

### `def _sort_states(mapper, states)`

**Line:** 1738

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.relationships
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/relationships.py`

**Imports:**
- __future__.annotations
- _typing._EntityType
- _typing._ExternalEntityType
- _typing._IdentityKeyType
- _typing._InstanceDict
- _typing._InternalEntityType
- _typing._O
- _typing._RegistryType
- _typing.insp_is_aliased_class
- _typing.is_has_collection_adapter
- base.DynamicMapped
- base.LoaderCallableStatus
- base.Mapped
- base.PassiveFlag
- base.WriteOnlyMapped
- base._DeclarativeMapped
- base._is_mapped_class
- base.class_mapper
- base.state_str
- clsregistry._ModNS
- clsregistry._class_resolver
- collections
- collections.abc
- dataclasses
- decl_base._ClassScanMapperConfig
- dependency.DependencyProcessor
- inspect
- inspection.inspect
- interfaces.MANYTOMANY
- interfaces.MANYTOONE
- interfaces.ONETOMANY
- interfaces.PropComparator
- interfaces.RelationshipDirection
- interfaces.StrategizedProperty
- interfaces._AttributeOptions
- interfaces._IntrospectsAnnotations
- mapper.Mapper
- query.Query
- re
- session.Session
- sql._typing._ColumnExpressionArgument
- sql._typing._CoreAdapterProto
- sql._typing._EquivalentColumnMap
- sql._typing._HasClauseElement
- sql._typing._InfoType
- sql.annotation.SupportsAnnotations
- sql.annotation._AnnotationDict
- sql.annotation._safe_annotate
- sql.coercions
- sql.elements.BinaryExpression
- sql.elements.BindParameter
- sql.elements.ClauseElement
- sql.elements.ColumnClause
- sql.elements.ColumnElement
- sql.expression
- sql.operators
- sql.roles
- sql.schema.Table
- sql.selectable.FromClause
- sql.util.ClauseAdapter
- sql.util._deep_annotate
- sql.util._deep_deannotate
- sql.util._shallow_annotate
- sql.util.adapt_criterion_to_null
- sql.util.join_condition
- sql.util.selectables_overlap
- sql.util.visit_binary_product
- sql.visitors
- state.InstanceState
- strategies.LazyLoader
- typing
- typing.Any
- typing.Callable
- typing.Collection
- typing.Dict
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.List
- typing.NamedTuple
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.Set
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- util.AliasedClass
- util.AliasedInsp
- util.CascadeOptions
- util._orm_annotate
- util._orm_deannotate
- util.typing.Literal
- util.typing.RODescriptorReference
- util.typing._AnnotationScanType
- util.typing.de_optionalize_union_types
- util.typing.resolve_name_to_real_class_name
- weakref

**Functions:**

### `def remote(expr: _CEA) -> _CEA`

**Description:**
Annotate a portion of a primaryjoin expression
with a 'remote' annotation.

See the section :ref:`relationship_custom_foreign` for a
description of use.

.. seealso::

:ref:`relationship_custom_foreign`

:func:`.foreign`

**Line:** 205

---

### `def foreign(expr: _CEA) -> _CEA`

**Description:**
Annotate a portion of a primaryjoin expression
with a 'foreign' annotation.

See the section :ref:`relationship_custom_foreign` for a
description of use.

.. seealso::

:ref:`relationship_custom_foreign`

:func:`.remote`

**Line:** 224

---

### `def _annotate_columns(element: _CE, annotations: _AnnotationDict) -> _CE`

**Line:** 2238

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.session
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/session.py`

**Imports:**
- __future__.annotations
- _typing.OrmExecuteOptionsParameter
- _typing._EntityType
- _typing._IdentityKeyType
- _typing._InstanceDict
- _typing._O
- _typing.insp_is_mapper
- _typing.is_composite_class
- _typing.is_orm_option
- _typing.is_user_defined_option
- base.LoaderCallableStatus
- base.PassiveFlag
- base._class_to_mapper
- base._none_set
- base._state_mapper
- base.instance_str
- base.object_mapper
- base.object_state
- base.state_str
- context.FromStatement
- context.ORMCompileState
- contextlib
- engine.Connection
- engine.CursorResult
- engine.Engine
- engine.Result
- engine.Row
- engine.RowMapping
- engine.base.Transaction
- engine.base.TwoPhaseTransaction
- engine.interfaces.CoreExecuteOptionsParameter
- engine.interfaces._CoreAnyExecuteParams
- engine.interfaces._CoreSingleExecuteParams
- engine.interfaces._ExecuteOptions
- engine.result.ScalarResult
- engine.util.TransactionalContext
- enum.Enum
- event.EventTarget
- event._InstanceLevelDispatch
- event.dispatcher
- identity.IdentityMap
- inspection.Inspectable
- inspection.inspect
- interfaces.ORMOption
- interfaces.UserDefinedOption
- itertools
- mapper.Mapper
- path_registry.PathRegistry
- query.Query
- query.RowReturningQuery
- sql.Select
- sql.TableClause
- sql._typing._ColumnsClauseArgument
- sql._typing._InfoType
- sql._typing._T0
- sql._typing._T1
- sql._typing._T2
- sql._typing._T3
- sql._typing._T4
- sql._typing._T5
- sql._typing._T6
- sql._typing._T7
- sql._typing._TypedColumnClauseArgument
- sql.base.CompileState
- sql.base.Executable
- sql.base.ExecutableOption
- sql.base._NoArg
- sql.coercions
- sql.dml
- sql.dml.UpdateBase
- sql.elements.ClauseElement
- sql.roles
- sql.roles.TypedColumnsClauseRole
- sql.schema.Table
- sql.selectable.ForUpdateArg
- sql.selectable.ForUpdateParameter
- sql.selectable.LABEL_STYLE_TABLENAME_PLUS_COL
- sql.selectable.TypedReturnsRows
- sql.visitors
- state.InstanceState
- state_changes._StateChange
- state_changes._StateChangeState
- state_changes._StateChangeStates
- sys
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.List
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- unitofwork.UOWTransaction
- util.IdentitySet
- util.typing.Literal
- util.typing.Protocol
- weakref

**Functions:**

### `def _state_session(state: InstanceState[Any]) -> Optional[Session]`

**Description:**
Given an :class:`.InstanceState`, return the :class:`.Session`
associated, if any.

**Line:** 195

---

### `def close_all_sessions() -> None`

**Description:**
Close all sessions in memory.

This function consults a global registry of all :class:`.Session` objects
and calls :meth:`.Session.close` on them, which resets them to a clean
state.

This function is not for general use but may be useful for test suites
within the teardown scheme.

.. versionadded:: 1.3

**Line:** 5118

---

### `def make_transient(instance: object) -> None`

**Description:**
Alter the state of the given instance so that it is :term:`transient`.

.. note::

:func:`.make_transient` is a special-case function for
advanced use cases only.

The given mapped instance is assumed to be in the :term:`persistent` or
:term:`detached` state.   The function will remove its association with any
:class:`.Session` as well as its :attr:`.InstanceState.identity`. The
effect is that the object will behave as though it were newly constructed,
except retaining any attribute / collection values that were loaded at the
time of the call.   The :attr:`.InstanceState.deleted` flag is also reset
if this object had been deleted as a result of using
:meth:`.Session.delete`.

.. warning::

:func:`.make_transient` does **not** "unexpire" or otherwise eagerly
load ORM-mapped attributes that are not currently loaded at the time
the function is called.   This includes attributes which:

* were expired via :meth:`.Session.expire`

* were expired as the natural effect of committing a session
transaction, e.g. :meth:`.Session.commit`

* are normally :term:`lazy loaded` but are not currently loaded

* are "deferred" (see :ref:`orm_queryguide_column_deferral`) and are
not yet loaded

* were not present in the query which loaded this object, such as that
which is common in joined table inheritance and other scenarios.

After :func:`.make_transient` is called, unloaded attributes such
as those above will normally resolve to the value ``None`` when
accessed, or an empty collection for a collection-oriented attribute.
As the object is transient and un-associated with any database
identity, it will no longer retrieve these values.

.. seealso::

:func:`.make_transient_to_detached`

**Line:** 5136

---

### `def make_transient_to_detached(instance: object) -> None`

**Description:**
Make the given transient instance :term:`detached`.

.. note::

:func:`.make_transient_to_detached` is a special-case function for
advanced use cases only.

All attribute history on the given instance
will be reset as though the instance were freshly loaded
from a query.  Missing attributes will be marked as expired.
The primary key attributes of the object, which are required, will be made
into the "key" of the instance.

The object can then be added to a session, or merged
possibly with the load=False flag, at which point it will look
as if it were loaded that way, without emitting SQL.

This is a special use case function that differs from a normal
call to :meth:`.Session.merge` in that a given persistent state
can be manufactured without any SQL calls.

.. seealso::

:func:`.make_transient`

:meth:`.Session.enable_relationship_loading`

**Line:** 5201

---

### `def object_session(instance: object) -> Optional[Session]`

**Description:**
Return the :class:`.Session` to which the given instance belongs.

This is essentially the same as the :attr:`.InstanceState.session`
accessor.  See that attribute for details.

**Line:** 5240

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.strategies
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/strategies.py`

**Imports:**
- __future__.annotations
- base.ATTR_WAS_SET
- base.LoaderCallableStatus
- base.PASSIVE_OFF
- base.PassiveFlag
- base._DEFER_FOR_STATE
- base._RAISE_FOR_STATE
- base._SET_DEFERRED_EXPIRED
- collections
- context.ORMCompileState
- context.ORMSelectCompileState
- context.QueryContext
- context._column_descriptions
- interfaces.LoaderStrategy
- interfaces.StrategizedProperty
- itertools
- relationships.RelationshipProperty
- session._state_session
- sql.elements.ColumnElement
- sql.selectable.LABEL_STYLE_TABLENAME_PLUS_COL
- sql.selectable.Select
- sql.util
- sql.visitors
- state.InstanceState
- strategy_options.Load
- typing.Any
- typing.Dict
- typing.TYPE_CHECKING
- typing.Tuple
- util.AliasedClass
- util._none_set

**Functions:**

### `def _register_attribute(prop, mapper, useobject, compare_function = None, typecallable = None, callable_ = None, proxy_property = None, active_history = False, impl_class = None, **kw)`

**Line:** 66

---

### `def single_parent_validator(desc, prop)`

**Line:** 3315

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.strategy_options
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/strategy_options.py`

**Imports:**
- __future__.annotations
- _typing._EntityType
- _typing._InternalEntityType
- _typing.insp_is_aliased_class
- _typing.insp_is_attribute
- _typing.insp_is_mapper
- _typing.insp_is_mapper_property
- attributes.QueryableAttribute
- base.InspectionAttr
- context.ORMCompileState
- context.QueryContext
- context._MapperEntity
- interfaces.LoaderOption
- interfaces.MapperProperty
- interfaces.ORMOption
- interfaces._StrategyKey
- mapper.Mapper
- path_registry.AbstractEntityRegistry
- path_registry.PathRegistry
- path_registry.TokenRegistry
- path_registry._DEFAULT_TOKEN
- path_registry._PathRepresentation
- path_registry._StrPathToken
- path_registry._WILDCARD_TOKEN
- path_registry.path_is_property
- sql._typing._ColumnExpressionArgument
- sql._typing._FromClauseArgument
- sql.and_
- sql.base._generative
- sql.cache_key
- sql.cache_key.CacheKey
- sql.cache_key._CacheKeyTraversalType
- sql.coercions
- sql.roles
- sql.traversals
- sql.visitors
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.Optional
- typing.Sequence
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.AliasedInsp
- util._orm_full_deannotate
- util.typing.Final
- util.typing.Literal
- util.typing.Self

**Functions:**

### `def _generate_from_keys(meth: Callable[(..., _AbstractLoad)], keys: Tuple[(_AttrType, ...)], chained: bool, kw: Any) -> _AbstractLoad`

**Line:** 2257

---

### `def _parse_attr_argument(attr: _AttrType) -> Tuple[(InspectionAttr, _InternalEntityType[Any], MapperProperty[Any])]`

**Description:**
parse an attribute or wildcard argument to produce an
:class:`._AbstractLoad` instance.

This is used by the standalone loader strategy functions like
``joinedload()``, ``defer()``, etc. to produce :class:`_orm.Load` or
:class:`._WildcardLoad` objects.

**Line:** 2321

---

### `def loader_unbound_fn(fn: _FN) -> _FN`

**Description:**
decorator that applies docstrings between standalone loader functions
and the loader methods on :class:`._AbstractLoad`.

**Line:** 2358

---

### `def contains_eager(*keys: _AttrType, **kw: Any) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2381

---

### `def load_only(raiseload: bool = False, *attrs: _AttrType) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2386

---

### `def joinedload(*keys: _AttrType, **kw: Any) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2394

---

### `def subqueryload(*keys: _AttrType) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2399

---

### `def selectinload(recursion_depth: Optional[int] = None, *keys: _AttrType) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2404

---

### `def lazyload(*keys: _AttrType) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2413

---

### `def immediateload(recursion_depth: Optional[int] = None, *keys: _AttrType) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2418

---

### `def noload(*keys: _AttrType) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2427

---

### `def raiseload(*keys: _AttrType, **kw: Any) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2432

---

### `def defaultload(*keys: _AttrType) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2437

---

### `def defer(key: _AttrType, raiseload: bool = False, *addl_attrs: _AttrType) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2442

---

### `def undefer(key: _AttrType, *addl_attrs: _AttrType) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2462

---

### `def undefer_group(name: str) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2474

---

### `def with_expression(key: _AttrType, expression: _ColumnExpressionArgument[Any]) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2480

---

### `def selectin_polymorphic(base_cls: _EntityType[Any], classes: Iterable[Type[Any]]) -> _AbstractLoad`

**Decorators:**
- `@loader_unbound_fn`

**Line:** 2489

---

### `def _raise_for_does_not_link(path, attrname, parent_entity)`

**Line:** 2496

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.sync
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/sync.py`

**Imports:**
- __future__.annotations
- base.PassiveFlag

**Functions:**

### `def populate(source, source_mapper, dest, dest_mapper, synchronize_pairs, uowcommit, flag_cascaded_pks)`

**Line:** 22

---

### `def bulk_populate_inherit_keys(source_dict, source_mapper, synchronize_pairs)`

**Line:** 65

---

### `def clear(dest, dest_mapper, synchronize_pairs)`

**Line:** 81

---

### `def update(source, source_mapper, dest, old_prefix, synchronize_pairs)`

**Line:** 98

---

### `def populate_dict(source, source_mapper, dict_, synchronize_pairs)`

**Line:** 113

---

### `def source_modified(uowcommit, source, source_mapper, synchronize_pairs)`

**Description:**
return true if the source object has changes from an old to a
new value on the given synchronize pairs

**Line:** 125

---

### `def _raise_col_to_prop(isdest, source_mapper, source_column, dest_mapper, dest_column, err)`

**Line:** 144

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.unitofwork
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py`

**Imports:**
- __future__.annotations
- dependency.DependencyProcessor
- interfaces.MapperProperty
- mapper.Mapper
- session.Session
- session.SessionTransaction
- state.InstanceState
- typing.Any
- typing.Dict
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- util.topological

**Functions:**

### `def track_cascade_events(descriptor, prop)`

**Description:**
Establish event listeners on object attributes which handle
cascade-on-set/append.

**Line:** 43

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.orm.util
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/orm/util.py`

**Imports:**
- __future__.annotations
- _typing._EntityType
- _typing._IdentityKeyType
- _typing._InternalEntityType
- _typing._O
- _typing._ORMCOLEXPR
- _typing.insp_is_aliased_class
- _typing.insp_is_mapper
- _typing.prop_is_relationship
- base.DynamicMapped
- base.InspectionAttr
- base.Mapped
- base.ORMDescriptor
- base.WriteOnlyMapped
- base._MappedAnnotationBase
- base._class_to_mapper
- base._never_set
- base._none_set
- base.attribute_str
- base.class_mapper
- base.instance_str
- base.object_mapper
- base.object_state
- base.opt_manager_of_class
- base.state_attribute_str
- base.state_class_str
- base.state_str
- context.ORMCompileState
- context._MapperEntity
- engine.Row
- engine.RowMapping
- engine.result.result_tuple
- enum
- functools
- interfaces.CriteriaOption
- interfaces.MapperProperty
- interfaces.ORMColumnsClauseRole
- interfaces.ORMEntityColumnsClauseRole
- interfaces.ORMFromClauseRole
- mapper.Mapper
- path_registry.AbstractEntityRegistry
- path_registry.PathRegistry
- query.Query
- re
- relationships.RelationshipProperty
- sql._typing._CE
- sql._typing._ColumnExpressionArgument
- sql._typing._EquivalentColumnMap
- sql._typing._FromClauseArgument
- sql._typing._OnClauseArgument
- sql._typing._PropagateAttrsType
- sql._typing.is_selectable
- sql.annotation.SupportsCloneAnnotations
- sql.annotation._SA
- sql.base.ColumnCollection
- sql.base.ReadOnlyColumnCollection
- sql.cache_key.HasCacheKey
- sql.cache_key.MemoizedHasCacheKey
- sql.coercions
- sql.elements.BindParameter
- sql.elements.ColumnElement
- sql.elements.KeyedColumnElement
- sql.expression
- sql.lambdas
- sql.roles
- sql.selectable.FromClause
- sql.selectable.Select
- sql.selectable.Selectable
- sql.selectable._ColumnsClauseElement
- sql.util
- sql.visitors
- sql.visitors.anon_map
- types
- typing
- typing.AbstractSet
- typing.Any
- typing.Callable
- typing.Dict
- typing.FrozenSet
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Match
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- util.langhelpers.MemoizedSlots
- util.typing.ArgsTypeProcotol
- util.typing.Literal
- util.typing.Protocol
- util.typing._AnnotationScanType
- util.typing.de_stringify_annotation
- util.typing.de_stringify_union_elements
- util.typing.eval_name_only
- util.typing.is_origin_of_cls
- util.typing.typing_get_origin
- weakref

**Functions:**

### `def _validator_events(desc, key, validator, include_removes, include_backrefs)`

**Description:**
Runs a validation method on an attribute value to be set or
appended.

**Line:** 276

---

### `def polymorphic_union(table_map, typecolname, aliasname = 'p_union', cast_nulls = True)`

**Description:**
Create a ``UNION`` statement used by a polymorphic mapper.

See  :ref:`concrete_inheritance` for an example of how
this is used.

:param table_map: mapping of polymorphic identities to
:class:`_schema.Table` objects.
:param typecolname: string name of a "discriminator" column, which will be
derived from the query, producing the polymorphic identity for
each row.  If ``None``, no polymorphic discriminator is generated.
:param aliasname: name of the :func:`~sqlalchemy.sql.expression.alias()`
construct generated.
:param cast_nulls: if True, non-existent columns, which are represented
as labeled NULLs, will be passed into CAST.   This is a legacy behavior
that is problematic on some backends such as Oracle - in which case it
can be set to False.

**Line:** 342

---

### `def identity_key(class_: Optional[Type[_T]] = None, ident: Union[(Any, Tuple[Any, ...])] = None, instance: Optional[_T] = None, row: Optional[Union[(Row[Any], RowMapping)]] = None, identity_token: Optional[Any] = None) -> _IdentityKeyType[_T]`

**Description:**
Generate "identity key" tuples, as are used as keys in the
:attr:`.Session.identity_map` dictionary.

This function has several call styles:

* ``identity_key(class, ident, identity_token=token)``

This form receives a mapped class and a primary key scalar or
tuple as an argument.

E.g.::

>>> identity_key(MyClass, (1, 2))
(<class '__main__.MyClass'>, (1, 2), None)

:param class: mapped class (must be a positional argument)
:param ident: primary key, may be a scalar or tuple argument.
:param identity_token: optional identity token

.. versionadded:: 1.2 added identity_token


* ``identity_key(instance=instance)``

This form will produce the identity key for a given instance.  The
instance need not be persistent, only that its primary key attributes
are populated (else the key will contain ``None`` for those missing
values).

E.g.::

>>> instance = MyClass(1, 2)
>>> identity_key(instance=instance)
(<class '__main__.MyClass'>, (1, 2), None)

In this form, the given instance is ultimately run though
:meth:`_orm.Mapper.identity_key_from_instance`, which will have the
effect of performing a database check for the corresponding row
if the object is expired.

:param instance: object instance (must be given as a keyword arg)

* ``identity_key(class, row=row, identity_token=token)``

This form is similar to the class/tuple form, except is passed a
database result row as a :class:`.Row` or :class:`.RowMapping` object.

E.g.::

>>> row = engine.execute(\
text("select * from table where a=1 and b=2")\
).first()
>>> identity_key(MyClass, row=row)
(<class '__main__.MyClass'>, (1, 2), None)

:param class: mapped class (must be a positional argument)
:param row: :class:`.Row` row returned by a :class:`_engine.CursorResult`
(must be given as a keyword arg)
:param identity_token: optional identity token

.. versionadded:: 1.2 added identity_token

**Line:** 424

---

### `def _inspect_mc(class_: Type[_O]) -> Optional[Mapper[_O]]`

**Decorators:**
- `@inspection._inspects(...)`

**Line:** 1521

---

### `def _inspect_generic_alias(class_: Type[_O]) -> Optional[Mapper[_O]]`

**Decorators:**
- `@inspection._inspects(...)`

**Line:** 1539

---

### `def _orm_annotate(element: _SA, exclude: Optional[Any] = None) -> _SA`

**Description:**
Deep copy the given ClauseElement, annotating each element with the
"_orm_adapt" flag.

Elements within the exclude collection will be cloned but not annotated.

**Line:** 1769

---

### `def _orm_deannotate(element: _SA) -> _SA`

**Description:**
Remove annotations that link a column to a particular mapping.

Note this doesn't affect "remote" and "foreign" annotations
passed by the :func:`_orm.foreign` and :func:`_orm.remote`
annotators.

**Line:** 1779

---

### `def _orm_full_deannotate(element: _SA) -> _SA`

**Line:** 1793

---

### `def with_parent(instance: object, prop: attributes.QueryableAttribute[Any], from_entity: Optional[_EntityType[Any]] = None) -> ColumnElement[bool]`

**Description:**
Create filtering criterion that relates this query's primary entity
to the given related instance, using established
:func:`_orm.relationship()`
configuration.

E.g.::

stmt = select(Address).where(with_parent(some_user, User.addresses))


The SQL rendered is the same as that rendered when a lazy loader
would fire off from the given parent on that attribute, meaning
that the appropriate state is taken from the parent object in
Python without the need to render joins to the parent table
in the rendered statement.

The given property may also make use of :meth:`_orm.PropComparator.of_type`
to indicate the left side of the criteria::


a1 = aliased(Address)
a2 = aliased(Address)
stmt = select(a1, a2).where(
with_parent(u1, User.addresses.of_type(a2))
)

The above use is equivalent to using the
:func:`_orm.with_parent.from_entity` argument::

a1 = aliased(Address)
a2 = aliased(Address)
stmt = select(a1, a2).where(
with_parent(u1, User.addresses, from_entity=a2)
)

:param instance:
An instance which has some :func:`_orm.relationship`.

:param property:
Class-bound attribute, which indicates
what relationship from the instance should be used to reconcile the
parent/child relationship.

:param from_entity:
Entity in which to consider as the left side.  This defaults to the
"zero" entity of the :class:`_query.Query` itself.

.. versionadded:: 1.2

**Line:** 1972

---

### `def has_identity(object_: object) -> bool`

**Description:**
Return True if the given object has a database
identity.

This typically corresponds to the object being
in either the persistent or detached state.

.. seealso::

:func:`.was_deleted`

**Line:** 2051

---

### `def was_deleted(object_: object) -> bool`

**Description:**
Return True if the given object was deleted
within a session flush.

This is regardless of whether or not the object is
persistent or detached.

.. seealso::

:attr:`.InstanceState.was_deleted`

**Line:** 2067

---

### `def _entity_corresponds_to(given: _InternalEntityType[Any], entity: _InternalEntityType[Any]) -> bool`

**Description:**
determine if 'given' corresponds to 'entity', in terms
of an entity passed to Query that would match the same entity
being referred to elsewhere in the query.

**Line:** 2084

---

### `def _entity_corresponds_to_use_path_impl(given: _InternalEntityType[Any], entity: _InternalEntityType[Any]) -> bool`

**Description:**
determine if 'given' corresponds to 'entity', in terms
of a path of loader options where a mapped attribute is taken to
be a member of a parent entity.

e.g.::

someoption(A).someoption(A.b)  # -> fn(A, A) -> True
someoption(A).someoption(C.d)  # -> fn(A, C) -> False

a1 = aliased(A)
someoption(a1).someoption(A.b) # -> fn(a1, A) -> False
someoption(a1).someoption(a1.b) # -> fn(a1, a1) -> True

wp = with_polymorphic(A, [A1, A2])
someoption(wp).someoption(A1.foo)  # -> fn(wp, A1) -> False
someoption(wp).someoption(wp.A1.foo)  # -> fn(wp, wp.A1) -> True

**Line:** 2107

---

### `def _entity_isa(given: _InternalEntityType[Any], mapper: Mapper[Any]) -> bool`

**Description:**
determine if 'given' "is a" mapper, in terms of the given
would load rows of type 'mapper'.

**Line:** 2144

---

### `def _getitem(iterable_query: Query[Any], item: Any) -> Any`

**Description:**
calculate __getitem__ in terms of an iterable query object
that also has a slice() method.

**Line:** 2159

---

### `def _is_mapped_annotation(raw_annotation: _AnnotationScanType, cls: Type[Any], originating_cls: Type[Any]) -> bool`

**Line:** 2198

---

### `def _cleanup_mapped_str_annotation(annotation: str, originating_module: str) -> str`

**Line:** 2223

---

### `def _extract_mapped_subtype(raw_annotation: Optional[_AnnotationScanType], cls: type, originating_module: str, key: str, attr_cls: Type[Any], required: bool, is_dataclass_field: bool, expect_mapped: bool = True, raiseerr: bool = True) -> Optional[Tuple[(Union[type, str], Optional[type])]]`

**Description:**
given an annotation, figure out if it's ``Mapped[something]`` and if
so, return the ``something`` part.

Includes error raise scenarios and other options.

**Line:** 2311

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.pool.base
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/pool/base.py`

**Imports:**
- __future__.annotations
- collections.deque
- dataclasses
- engine.interfaces.DBAPIConnection
- engine.interfaces.DBAPICursor
- engine.interfaces.Dialect
- enum.Enum
- event._DispatchCommon
- event._ListenerFnType
- event.dispatcher
- sql._typing._InfoType
- threading
- time
- typing
- typing.Any
- typing.Callable
- typing.Deque
- typing.Dict
- typing.List
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- typing.cast
- util.typing.Literal
- util.typing.Protocol
- weakref

**Functions:**

### `def _finalize_fairy(dbapi_connection: Optional[DBAPIConnection], connection_record: Optional[_ConnectionRecord], pool: Pool, ref: Optional[weakref.ref[_ConnectionFairy]], echo: Optional[log._EchoFlagType], transaction_was_reset: bool = False, fairy: Optional[_ConnectionFairy] = None) -> None`

**Description:**
Cleanup for a :class:`._ConnectionFairy` whether or not it's already
been garbage collected.

When using an async dialect no IO can happen here (without using
a dedicated thread), since this is called outside the greenlet
context and with an already running loop. In this case function
will only log a message and raise a warning.

**Line:** 919

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.__init__
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/__init__.py`

**Imports:**
- _typing.ColumnExpressionArgument
- _typing.NotNullable
- _typing.Nullable
- annotation.Annotated
- annotation._prepare_annotations
- base.Executable
- compiler.COLLECT_CARTESIAN_PRODUCTS
- compiler.FROM_LINTING
- compiler.NO_LINTING
- compiler.WARN_LINTING
- ddl.BaseDDLElement
- ddl.DDL
- ddl.DDLElement
- ddl.ExecutableDDLElement
- elements.AnnotatedColumnElement
- elements.ClauseList
- expression.Alias
- expression.ClauseElement
- expression.ColumnCollection
- expression.ColumnElement
- expression.CompoundSelect
- expression.Delete
- expression.False_
- expression.FromClause
- expression.Insert
- expression.Join
- expression.LABEL_STYLE_DEFAULT
- expression.LABEL_STYLE_DISAMBIGUATE_ONLY
- expression.LABEL_STYLE_NONE
- expression.LABEL_STYLE_TABLENAME_PLUS_COL
- expression.LambdaElement
- expression.SQLColumnExpression
- expression.Select
- expression.SelectLabelStyle
- expression.Selectable
- expression.StatementLambdaElement
- expression.Subquery
- expression.TableClause
- expression.TableSample
- expression.True_
- expression.Update
- expression.Values
- expression.alias
- expression.all_
- expression.and_
- expression.any_
- expression.asc
- expression.between
- expression.bindparam
- expression.case
- expression.cast
- expression.collate
- expression.column
- expression.cte
- expression.delete
- expression.desc
- expression.distinct
- expression.except_
- expression.except_all
- expression.exists
- expression.extract
- expression.false
- expression.func
- expression.funcfilter
- expression.insert
- expression.intersect
- expression.intersect_all
- expression.join
- expression.label
- expression.lambda_stmt
- expression.lateral
- expression.literal
- expression.literal_column
- expression.modifier
- expression.not_
- expression.null
- expression.nulls_first
- expression.nulls_last
- expression.nullsfirst
- expression.nullslast
- expression.or_
- expression.outerjoin
- expression.outparam
- expression.over
- expression.quoted_name
- expression.select
- expression.table
- expression.tablesample
- expression.text
- expression.true
- expression.try_cast
- expression.tuple_
- expression.type_coerce
- expression.union
- expression.union_all
- expression.update
- expression.values
- expression.within_group
- selectable.AnnotatedFromClause
- typing.Any
- typing.TYPE_CHECKING
- visitors.ClauseVisitor

**Functions:**

### `def __go(lcls: Any) -> None`

**Line:** 111

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql._dml_constructors
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/_dml_constructors.py`

**Imports:**
- __future__.annotations
- _typing._DMLTableArgument
- dml.Delete
- dml.Insert
- dml.Update
- typing.TYPE_CHECKING

**Functions:**

### `def insert(table: _DMLTableArgument) -> Insert`

**Description:**
Construct an :class:`_expression.Insert` object.

E.g.::

from sqlalchemy import insert

stmt = (
insert(user_table).
values(name='username', fullname='Full Username')
)

Similar functionality is available via the
:meth:`_expression.TableClause.insert` method on
:class:`_schema.Table`.

.. seealso::

:ref:`tutorial_core_insert` - in the :ref:`unified_tutorial`


:param table: :class:`_expression.TableClause`
which is the subject of the
insert.

:param values: collection of values to be inserted; see
:meth:`_expression.Insert.values`
for a description of allowed formats here.
Can be omitted entirely; a :class:`_expression.Insert` construct
will also dynamically render the VALUES clause at execution time
based on the parameters passed to :meth:`_engine.Connection.execute`.

:param inline: if True, no attempt will be made to retrieve the
SQL-generated default values to be provided within the statement;
in particular,
this allows SQL expressions to be rendered 'inline' within the
statement without the need to pre-execute them beforehand; for
backends that support "returning", this turns off the "implicit
returning" feature for the statement.

If both :paramref:`_expression.insert.values` and compile-time bind
parameters are present, the compile-time bind parameters override the
information specified within :paramref:`_expression.insert.values` on a
per-key basis.

The keys within :paramref:`_expression.Insert.values` can be either
:class:`~sqlalchemy.schema.Column` objects or their string
identifiers. Each key may reference one of:

* a literal data value (i.e. string, number, etc.);
* a Column object;
* a SELECT statement.

If a ``SELECT`` statement is specified which references this
``INSERT`` statement's table, the statement will be correlated
against the ``INSERT`` statement.

.. seealso::

:ref:`tutorial_core_insert` - in the :ref:`unified_tutorial`

**Line:** 20

---

### `def update(table: _DMLTableArgument) -> Update`

**Description:**
Construct an :class:`_expression.Update` object.

E.g.::

from sqlalchemy import update

stmt = (
update(user_table).
where(user_table.c.id == 5).
values(name='user #5')
)

Similar functionality is available via the
:meth:`_expression.TableClause.update` method on
:class:`_schema.Table`.

:param table: A :class:`_schema.Table`
object representing the database
table to be updated.


.. seealso::

:ref:`tutorial_core_update_delete` - in the :ref:`unified_tutorial`

**Line:** 85

---

### `def delete(table: _DMLTableArgument) -> Delete`

**Description:**
Construct :class:`_expression.Delete` object.

E.g.::

from sqlalchemy import delete

stmt = (
delete(user_table).
where(user_table.c.id == 5)
)

Similar functionality is available via the
:meth:`_expression.TableClause.delete` method on
:class:`_schema.Table`.

:param table: The table to delete rows from.

.. seealso::

:ref:`tutorial_core_update_delete` - in the :ref:`unified_tutorial`

**Line:** 116

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql._elements_constructors
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/_elements_constructors.py`

**Imports:**
- __future__.annotations
- _typing._ColumnExpressionArgument
- _typing._ColumnExpressionOrLiteralArgument
- _typing._ColumnExpressionOrStrLabelArgument
- _typing._TypeEngineArgument
- base._NoArg
- coercions._document_text_coercion
- elements.BinaryExpression
- elements.BindParameter
- elements.BooleanClauseList
- elements.Case
- elements.Cast
- elements.CollationClause
- elements.CollectionAggregate
- elements.ColumnClause
- elements.ColumnElement
- elements.Extract
- elements.False_
- elements.FunctionFilter
- elements.Label
- elements.Null
- elements.Over
- elements.TextClause
- elements.True_
- elements.TryCast
- elements.Tuple
- elements.TypeCoerce
- elements.UnaryExpression
- elements.WithinGroup
- functions.FunctionElement
- selectable.FromClause
- type_api.TypeEngine
- typing
- typing.Any
- typing.Callable
- typing.Iterable
- typing.Mapping
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.overload
- util.typing.Literal

**Functions:**

### `def all_(expr: _ColumnExpressionArgument[_T]) -> CollectionAggregate[bool]`

**Description:**
Produce an ALL expression.

For dialects such as that of PostgreSQL, this operator applies
to usage of the :class:`_types.ARRAY` datatype, for that of
MySQL, it may apply to a subquery.  e.g.::

# renders on PostgreSQL:
# '5 = ALL (somearray)'
expr = 5 == all_(mytable.c.somearray)

# renders on MySQL:
# '5 = ALL (SELECT value FROM table)'
expr = 5 == all_(select(table.c.value))

Comparison to NULL may work using ``None``::

None == all_(mytable.c.somearray)

The any_() / all_() operators also feature a special "operand flipping"
behavior such that if any_() / all_() are used on the left side of a
comparison using a standalone operator such as ``==``, ``!=``, etc.
(not including operator methods such as
:meth:`_sql.ColumnOperators.is_`) the rendered expression is flipped::

# would render '5 = ALL (column)`
all_(mytable.c.column) == 5

Or with ``None``, which note will not perform
the usual step of rendering "IS" as is normally the case for NULL::

# would render 'NULL = ALL(somearray)'
all_(mytable.c.somearray) == None

.. versionchanged:: 1.4.26  repaired the use of any_() / all_()
comparing to NULL on the right side to be flipped to the left.

The column-level :meth:`_sql.ColumnElement.all_` method (not to be
confused with :class:`_types.ARRAY` level
:meth:`_types.ARRAY.Comparator.all`) is shorthand for
``all_(col)``::

5 == mytable.c.somearray.all_()

.. seealso::

:meth:`_sql.ColumnOperators.all_`

:func:`_expression.any_`

**Line:** 63

---

### `def and_(initial_clause: Union[(Literal[True], _ColumnExpressionArgument[bool])], *clauses: _ColumnExpressionArgument[bool]) -> ColumnElement[bool]`

**Description:**
Produce a conjunction of expressions joined by ``AND``.

E.g.::

from sqlalchemy import and_

stmt = select(users_table).where(
and_(
users_table.c.name == 'wendy',
users_table.c.enrolled == True
)
)

The :func:`.and_` conjunction is also available using the
Python ``&`` operator (though note that compound expressions
need to be parenthesized in order to function with Python
operator precedence behavior)::

stmt = select(users_table).where(
(users_table.c.name == 'wendy') &
(users_table.c.enrolled == True)
)

The :func:`.and_` operation is also implicit in some cases;
the :meth:`_expression.Select.where`
method for example can be invoked multiple
times against a statement, which will have the effect of each
clause being combined using :func:`.and_`::

stmt = select(users_table).\
where(users_table.c.name == 'wendy').\
where(users_table.c.enrolled == True)

The :func:`.and_` construct must be given at least one positional
argument in order to be valid; a :func:`.and_` construct with no
arguments is ambiguous.   To produce an "empty" or dynamically
generated :func:`.and_`  expression, from a given list of expressions,
a "default" element of :func:`_sql.true` (or just ``True``) should be
specified::

from sqlalchemy import true
criteria = and_(true(), *expressions)

The above expression will compile to SQL as the expression ``true``
or ``1 = 1``, depending on backend, if no other expressions are
present.  If expressions are present, then the :func:`_sql.true` value is
ignored as it does not affect the outcome of an AND expression that
has other elements.

.. deprecated:: 1.4  The :func:`.and_` element now requires that at
least one argument is passed; creating the :func:`.and_` construct
with no arguments is deprecated, and will emit a deprecation warning
while continuing to produce a blank SQL string.

.. seealso::

:func:`.or_`

**Line:** 117

---

### `def and_(*clauses)`

**Description:**
Produce a conjunction of expressions joined by ``AND``.

E.g.::

from sqlalchemy import and_

stmt = select(users_table).where(
and_(
users_table.c.name == 'wendy',
users_table.c.enrolled == True
)
)

The :func:`.and_` conjunction is also available using the
Python ``&`` operator (though note that compound expressions
need to be parenthesized in order to function with Python
operator precedence behavior)::

stmt = select(users_table).where(
(users_table.c.name == 'wendy') &
(users_table.c.enrolled == True)
)

The :func:`.and_` operation is also implicit in some cases;
the :meth:`_expression.Select.where`
method for example can be invoked multiple
times against a statement, which will have the effect of each
clause being combined using :func:`.and_`::

stmt = select(users_table).\
where(users_table.c.name == 'wendy').\
where(users_table.c.enrolled == True)

The :func:`.and_` construct must be given at least one positional
argument in order to be valid; a :func:`.and_` construct with no
arguments is ambiguous.   To produce an "empty" or dynamically
generated :func:`.and_`  expression, from a given list of expressions,
a "default" element of :func:`_sql.true` (or just ``True``) should be
specified::

from sqlalchemy import true
criteria = and_(true(), *expressions)

The above expression will compile to SQL as the expression ``true``
or ``1 = 1``, depending on backend, if no other expressions are
present.  If expressions are present, then the :func:`_sql.true` value
is ignored as it does not affect the outcome of an AND expression that
has other elements.

.. deprecated:: 1.4  The :func:`.and_` element now requires that at
least one argument is passed; creating the :func:`.and_` construct
with no arguments is deprecated, and will emit a deprecation warning
while continuing to produce a blank SQL string.

.. seealso::

:func:`.or_`

**Line:** 185

---

### `def any_(expr: _ColumnExpressionArgument[_T]) -> CollectionAggregate[bool]`

**Description:**
Produce an ANY expression.

For dialects such as that of PostgreSQL, this operator applies
to usage of the :class:`_types.ARRAY` datatype, for that of
MySQL, it may apply to a subquery.  e.g.::

# renders on PostgreSQL:
# '5 = ANY (somearray)'
expr = 5 == any_(mytable.c.somearray)

# renders on MySQL:
# '5 = ANY (SELECT value FROM table)'
expr = 5 == any_(select(table.c.value))

Comparison to NULL may work using ``None`` or :func:`_sql.null`::

None == any_(mytable.c.somearray)

The any_() / all_() operators also feature a special "operand flipping"
behavior such that if any_() / all_() are used on the left side of a
comparison using a standalone operator such as ``==``, ``!=``, etc.
(not including operator methods such as
:meth:`_sql.ColumnOperators.is_`) the rendered expression is flipped::

# would render '5 = ANY (column)`
any_(mytable.c.column) == 5

Or with ``None``, which note will not perform
the usual step of rendering "IS" as is normally the case for NULL::

# would render 'NULL = ANY(somearray)'
any_(mytable.c.somearray) == None

.. versionchanged:: 1.4.26  repaired the use of any_() / all_()
comparing to NULL on the right side to be flipped to the left.

The column-level :meth:`_sql.ColumnElement.any_` method (not to be
confused with :class:`_types.ARRAY` level
:meth:`_types.ARRAY.Comparator.any`) is shorthand for
``any_(col)``::

5 = mytable.c.somearray.any_()

.. seealso::

:meth:`_sql.ColumnOperators.any_`

:func:`_expression.all_`

**Line:** 248

---

### `def asc(column: _ColumnExpressionOrStrLabelArgument[_T]) -> UnaryExpression[_T]`

**Description:**
Produce an ascending ``ORDER BY`` clause element.

e.g.::

from sqlalchemy import asc
stmt = select(users_table).order_by(asc(users_table.c.name))

will produce SQL as::

SELECT id, name FROM user ORDER BY name ASC

The :func:`.asc` function is a standalone version of the
:meth:`_expression.ColumnElement.asc`
method available on all SQL expressions,
e.g.::


stmt = select(users_table).order_by(users_table.c.name.asc())

:param column: A :class:`_expression.ColumnElement` (e.g.
scalar SQL expression)
with which to apply the :func:`.asc` operation.

.. seealso::

:func:`.desc`

:func:`.nulls_first`

:func:`.nulls_last`

:meth:`_expression.Select.order_by`

**Line:** 302

---

### `def collate(expression: _ColumnExpressionArgument[str], collation: str) -> BinaryExpression[str]`

**Description:**
Return the clause ``expression COLLATE collation``.

e.g.::

collate(mycolumn, 'utf8_bin')

produces::

mycolumn COLLATE utf8_bin

The collation expression is also quoted if it is a case sensitive
identifier, e.g. contains uppercase characters.

.. versionchanged:: 1.2 quoting is automatically applied to COLLATE
expressions if they are case sensitive.

**Line:** 342

---

### `def between(expr: _ColumnExpressionOrLiteralArgument[_T], lower_bound: Any, upper_bound: Any, symmetric: bool = False) -> BinaryExpression[bool]`

**Description:**
Produce a ``BETWEEN`` predicate clause.

E.g.::

from sqlalchemy import between
stmt = select(users_table).where(between(users_table.c.id, 5, 7))

Would produce SQL resembling::

SELECT id, name FROM user WHERE id BETWEEN :id_1 AND :id_2

The :func:`.between` function is a standalone version of the
:meth:`_expression.ColumnElement.between` method available on all
SQL expressions, as in::

stmt = select(users_table).where(users_table.c.id.between(5, 7))

All arguments passed to :func:`.between`, including the left side
column expression, are coerced from Python scalar values if a
the value is not a :class:`_expression.ColumnElement` subclass.
For example,
three fixed values can be compared as in::

print(between(5, 3, 7))

Which would produce::

:param_1 BETWEEN :param_2 AND :param_3

:param expr: a column expression, typically a
:class:`_expression.ColumnElement`
instance or alternatively a Python scalar expression to be coerced
into a column expression, serving as the left side of the ``BETWEEN``
expression.

:param lower_bound: a column or Python scalar expression serving as the
lower bound of the right side of the ``BETWEEN`` expression.

:param upper_bound: a column or Python scalar expression serving as the
upper bound of the right side of the ``BETWEEN`` expression.

:param symmetric: if True, will render " BETWEEN SYMMETRIC ". Note
that not all databases support this syntax.

.. seealso::

:meth:`_expression.ColumnElement.between`

**Line:** 365

---

### `def outparam(key: str, type_: Optional[TypeEngine[_T]] = None) -> BindParameter[_T]`

**Description:**
Create an 'OUT' parameter for usage in functions (stored procedures),
for databases which support them.

The ``outparam`` can be used like a regular function parameter.
The "output" value will be available from the
:class:`~sqlalchemy.engine.CursorResult` object via its ``out_parameters``
attribute, which returns a dictionary containing the values.

**Line:** 424

---

### `def not_(clause: BinaryExpression[_T]) -> BinaryExpression[_T]`

**Decorators:**
- `@overload`

**Line:** 442

---

### `def not_(clause: _ColumnExpressionArgument[_T]) -> ColumnElement[_T]`

**Decorators:**
- `@overload`

**Line:** 447

---

### `def not_(clause: _ColumnExpressionArgument[_T]) -> ColumnElement[_T]`

**Description:**
Return a negation of the given clause, i.e. ``NOT(clause)``.

The ``~`` operator is also overloaded on all
:class:`_expression.ColumnElement` subclasses to produce the
same result.

**Line:** 451

---

### `def bindparam(key: Optional[str], value: Any = _NoArg.NO_ARG, type_: Optional[_TypeEngineArgument[_T]] = None, unique: bool = False, required: Union[(bool, Literal[_NoArg.NO_ARG])] = _NoArg.NO_ARG, quote: Optional[bool] = None, callable_: Optional[Callable[([], Any)]] = None, expanding: bool = False, isoutparam: bool = False, literal_execute: bool = False) -> BindParameter[_T]`

**Description:**
Produce a "bound expression".

The return value is an instance of :class:`.BindParameter`; this
is a :class:`_expression.ColumnElement`
subclass which represents a so-called
"placeholder" value in a SQL expression, the value of which is
supplied at the point at which the statement in executed against a
database connection.

In SQLAlchemy, the :func:`.bindparam` construct has
the ability to carry along the actual value that will be ultimately
used at expression time.  In this way, it serves not just as
a "placeholder" for eventual population, but also as a means of
representing so-called "unsafe" values which should not be rendered
directly in a SQL statement, but rather should be passed along
to the :term:`DBAPI` as values which need to be correctly escaped
and potentially handled for type-safety.

When using :func:`.bindparam` explicitly, the use case is typically
one of traditional deferment of parameters; the :func:`.bindparam`
construct accepts a name which can then be referred to at execution
time::

from sqlalchemy import bindparam

stmt = select(users_table).\
where(users_table.c.name == bindparam('username'))

The above statement, when rendered, will produce SQL similar to::

SELECT id, name FROM user WHERE name = :username

In order to populate the value of ``:username`` above, the value
would typically be applied at execution time to a method
like :meth:`_engine.Connection.execute`::

result = connection.execute(stmt, username='wendy')

Explicit use of :func:`.bindparam` is also common when producing
UPDATE or DELETE statements that are to be invoked multiple times,
where the WHERE criterion of the statement is to change on each
invocation, such as::

stmt = (users_table.update().
where(user_table.c.name == bindparam('username')).
values(fullname=bindparam('fullname'))
)

connection.execute(
stmt, [{"username": "wendy", "fullname": "Wendy Smith"},
{"username": "jack", "fullname": "Jack Jones"},
]
)

SQLAlchemy's Core expression system makes wide use of
:func:`.bindparam` in an implicit sense.   It is typical that Python
literal values passed to virtually all SQL expression functions are
coerced into fixed :func:`.bindparam` constructs.  For example, given
a comparison operation such as::

expr = users_table.c.name == 'Wendy'

The above expression will produce a :class:`.BinaryExpression`
construct, where the left side is the :class:`_schema.Column` object
representing the ``name`` column, and the right side is a
:class:`.BindParameter` representing the literal value::

print(repr(expr.right))
BindParameter('%(4327771088 name)s', 'Wendy', type_=String())

The expression above will render SQL such as::

user.name = :name_1

Where the ``:name_1`` parameter name is an anonymous name.  The
actual string ``Wendy`` is not in the rendered string, but is carried
along where it is later used within statement execution.  If we
invoke a statement like the following::

stmt = select(users_table).where(users_table.c.name == 'Wendy')
result = connection.execute(stmt)

We would see SQL logging output as::

SELECT "user".id, "user".name
FROM "user"
WHERE "user".name = %(name_1)s
{'name_1': 'Wendy'}

Above, we see that ``Wendy`` is passed as a parameter to the database,
while the placeholder ``:name_1`` is rendered in the appropriate form
for the target database, in this case the PostgreSQL database.

Similarly, :func:`.bindparam` is invoked automatically when working
with :term:`CRUD` statements as far as the "VALUES" portion is
concerned.   The :func:`_expression.insert` construct produces an
``INSERT`` expression which will, at statement execution time, generate
bound placeholders based on the arguments passed, as in::

stmt = users_table.insert()
result = connection.execute(stmt, name='Wendy')

The above will produce SQL output as::

INSERT INTO "user" (name) VALUES (%(name)s)
{'name': 'Wendy'}

The :class:`_expression.Insert` construct, at
compilation/execution time, rendered a single :func:`.bindparam`
mirroring the column name ``name`` as a result of the single ``name``
parameter we passed to the :meth:`_engine.Connection.execute` method.

:param key:
the key (e.g. the name) for this bind param.
Will be used in the generated
SQL statement for dialects that use named parameters.  This
value may be modified when part of a compilation operation,
if other :class:`BindParameter` objects exist with the same
key, or if its length is too long and truncation is
required.

If omitted, an "anonymous" name is generated for the bound parameter;
when given a value to bind, the end result is equivalent to calling upon
the :func:`.literal` function with a value to bind, particularly
if the :paramref:`.bindparam.unique` parameter is also provided.

:param value:
Initial value for this bind param.  Will be used at statement
execution time as the value for this parameter passed to the
DBAPI, if no other value is indicated to the statement execution
method for this particular parameter name.  Defaults to ``None``.

:param callable\_:
A callable function that takes the place of "value".  The function
will be called at statement execution time to determine the
ultimate value.   Used for scenarios where the actual bind
value cannot be determined at the point at which the clause
construct is created, but embedded bind values are still desirable.

:param type\_:
A :class:`.TypeEngine` class or instance representing an optional
datatype for this :func:`.bindparam`.  If not passed, a type
may be determined automatically for the bind, based on the given
value; for example, trivial Python types such as ``str``,
``int``, ``bool``
may result in the :class:`.String`, :class:`.Integer` or
:class:`.Boolean` types being automatically selected.

The type of a :func:`.bindparam` is significant especially in that
the type will apply pre-processing to the value before it is
passed to the database.  For example, a :func:`.bindparam` which
refers to a datetime value, and is specified as holding the
:class:`.DateTime` type, may apply conversion needed to the
value (such as stringification on SQLite) before passing the value
to the database.

:param unique:
if True, the key name of this :class:`.BindParameter` will be
modified if another :class:`.BindParameter` of the same name
already has been located within the containing
expression.  This flag is used generally by the internals
when producing so-called "anonymous" bound expressions, it
isn't generally applicable to explicitly-named :func:`.bindparam`
constructs.

:param required:
If ``True``, a value is required at execution time.  If not passed,
it defaults to ``True`` if neither :paramref:`.bindparam.value`
or :paramref:`.bindparam.callable` were passed.  If either of these
parameters are present, then :paramref:`.bindparam.required`
defaults to ``False``.

:param quote:
True if this parameter name requires quoting and is not
currently known as a SQLAlchemy reserved word; this currently
only applies to the Oracle backend, where bound names must
sometimes be quoted.

:param isoutparam:
if True, the parameter should be treated like a stored procedure
"OUT" parameter.  This applies to backends such as Oracle which
support OUT parameters.

:param expanding:
if True, this parameter will be treated as an "expanding" parameter
at execution time; the parameter value is expected to be a sequence,
rather than a scalar value, and the string SQL statement will
be transformed on a per-execution basis to accommodate the sequence
with a variable number of parameter slots passed to the DBAPI.
This is to allow statement caching to be used in conjunction with
an IN clause.

.. seealso::

:meth:`.ColumnOperators.in_`

:ref:`baked_in` - with baked queries

.. note:: The "expanding" feature does not support "executemany"-
style parameter sets.

.. versionadded:: 1.2

.. versionchanged:: 1.3 the "expanding" bound parameter feature now
supports empty lists.

:param literal_execute:
if True, the bound parameter will be rendered in the compile phase
with a special "POSTCOMPILE" token, and the SQLAlchemy compiler will
render the final value of the parameter into the SQL statement at
statement execution time, omitting the value from the parameter
dictionary / list passed to DBAPI ``cursor.execute()``.  This
produces a similar effect as that of using the ``literal_binds``,
compilation flag,  however takes place as the statement is sent to
the DBAPI ``cursor.execute()`` method, rather than when the statement
is compiled.   The primary use of this
capability is for rendering LIMIT / OFFSET clauses for database
drivers that can't accommodate for bound parameters in these
contexts, while allowing SQL constructs to be cacheable at the
compilation level.

.. versionadded:: 1.4 Added "post compile" bound parameters

.. seealso::

:ref:`change_4808`.

.. seealso::

:ref:`tutorial_sending_parameters` - in the
:ref:`unified_tutorial`

**Line:** 463

---

### `def case(value: Optional[Any] = None, else_: Optional[Any] = None, *whens: Union[(typing_Tuple[_ColumnExpressionArgument[bool], Any], Mapping[Any, Any])]) -> Case[Any]`

**Description:**
Produce a ``CASE`` expression.

The ``CASE`` construct in SQL is a conditional object that
acts somewhat analogously to an "if/then" construct in other
languages.  It returns an instance of :class:`.Case`.

:func:`.case` in its usual form is passed a series of "when"
constructs, that is, a list of conditions and results as tuples::

from sqlalchemy import case

stmt = select(users_table).\
where(
case(
(users_table.c.name == 'wendy', 'W'),
(users_table.c.name == 'jack', 'J'),
else_='E'
)
)

The above statement will produce SQL resembling::

SELECT id, name FROM user
WHERE CASE
WHEN (name = :name_1) THEN :param_1
WHEN (name = :name_2) THEN :param_2
ELSE :param_3
END

When simple equality expressions of several values against a single
parent column are needed, :func:`.case` also has a "shorthand" format
used via the
:paramref:`.case.value` parameter, which is passed a column
expression to be compared.  In this form, the :paramref:`.case.whens`
parameter is passed as a dictionary containing expressions to be
compared against keyed to result expressions.  The statement below is
equivalent to the preceding statement::

stmt = select(users_table).\
where(
case(
{"wendy": "W", "jack": "J"},
value=users_table.c.name,
else_='E'
)
)

The values which are accepted as result values in
:paramref:`.case.whens` as well as with :paramref:`.case.else_` are
coerced from Python literals into :func:`.bindparam` constructs.
SQL expressions, e.g. :class:`_expression.ColumnElement` constructs,
are accepted
as well.  To coerce a literal string expression into a constant
expression rendered inline, use the :func:`_expression.literal_column`
construct,
as in::

from sqlalchemy import case, literal_column

case(
(
orderline.c.qty > 100,
literal_column("'greaterthan100'")
),
(
orderline.c.qty > 10,
literal_column("'greaterthan10'")
),
else_=literal_column("'lessthan10'")
)

The above will render the given constants without using bound
parameters for the result values (but still for the comparison
values), as in::

CASE
WHEN (orderline.qty > :qty_1) THEN 'greaterthan100'
WHEN (orderline.qty > :qty_2) THEN 'greaterthan10'
ELSE 'lessthan10'
END

:param \*whens: The criteria to be compared against,
:paramref:`.case.whens` accepts two different forms, based on
whether or not :paramref:`.case.value` is used.

.. versionchanged:: 1.4 the :func:`_sql.case`
function now accepts the series of WHEN conditions positionally

In the first form, it accepts multiple 2-tuples passed as positional
arguments; each 2-tuple consists of ``(<sql expression>, <value>)``,
where the SQL expression is a boolean expression and "value" is a
resulting value, e.g.::

case(
(users_table.c.name == 'wendy', 'W'),
(users_table.c.name == 'jack', 'J')
)

In the second form, it accepts a Python dictionary of comparison
values mapped to a resulting value; this form requires
:paramref:`.case.value` to be present, and values will be compared
using the ``==`` operator, e.g.::

case(
{"wendy": "W", "jack": "J"},
value=users_table.c.name
)

:param value: An optional SQL expression which will be used as a
fixed "comparison point" for candidate values within a dictionary
passed to :paramref:`.case.whens`.

:param else\_: An optional SQL expression which will be the evaluated
result of the ``CASE`` construct if all expressions within
:paramref:`.case.whens` evaluate to false.  When omitted, most
databases will produce a result of NULL if none of the "when"
expressions evaluate to true.

**Line:** 723

---

### `def cast(expression: _ColumnExpressionOrLiteralArgument[Any], type_: _TypeEngineArgument[_T]) -> Cast[_T]`

**Description:**
Produce a ``CAST`` expression.

:func:`.cast` returns an instance of :class:`.Cast`.

E.g.::

from sqlalchemy import cast, Numeric

stmt = select(cast(product_table.c.unit_price, Numeric(10, 4)))

The above statement will produce SQL resembling::

SELECT CAST(unit_price AS NUMERIC(10, 4)) FROM product

The :func:`.cast` function performs two distinct functions when
used.  The first is that it renders the ``CAST`` expression within
the resulting SQL string.  The second is that it associates the given
type (e.g. :class:`.TypeEngine` class or instance) with the column
expression on the Python side, which means the expression will take
on the expression operator behavior associated with that type,
as well as the bound-value handling and result-row-handling behavior
of the type.

An alternative to :func:`.cast` is the :func:`.type_coerce` function.
This function performs the second task of associating an expression
with a specific type, but does not render the ``CAST`` expression
in SQL.

:param expression: A SQL expression, such as a
:class:`_expression.ColumnElement`
expression or a Python string which will be coerced into a bound
literal value.

:param type\_: A :class:`.TypeEngine` class or instance indicating
the type to which the ``CAST`` should apply.

.. seealso::

:ref:`tutorial_casts`

:func:`.try_cast` - an alternative to CAST that results in
NULLs when the cast fails, instead of raising an error.
Only supported by some dialects.

:func:`.type_coerce` - an alternative to CAST that coerces the type
on the Python side only, which is often sufficient to generate the
correct SQL and data coercion.

**Line:** 853

---

### `def try_cast(expression: _ColumnExpressionOrLiteralArgument[Any], type_: _TypeEngineArgument[_T]) -> TryCast[_T]`

**Description:**
Produce a ``TRY_CAST`` expression for backends which support it;
this is a ``CAST`` which returns NULL for un-castable conversions.

In SQLAlchemy, this construct is supported **only** by the SQL Server
dialect, and will raise a :class:`.CompileError` if used on other
included backends.  However, third party backends may also support
this construct.

.. tip:: As :func:`_sql.try_cast` originates from the SQL Server dialect,
it's importable both from ``sqlalchemy.`` as well as from
``sqlalchemy.dialects.mssql``.

:func:`_sql.try_cast` returns an instance of :class:`.TryCast` and
generally behaves similarly to the :class:`.Cast` construct;
at the SQL level, the difference between ``CAST`` and ``TRY_CAST``
is that ``TRY_CAST`` returns NULL for an un-castable expression,
such as attempting to cast a string ``"hi"`` to an integer value.

E.g.::

from sqlalchemy import select, try_cast, Numeric

stmt = select(
try_cast(product_table.c.unit_price, Numeric(10, 4))
)

The above would render on Microsoft SQL Server as::

SELECT TRY_CAST (product_table.unit_price AS NUMERIC(10, 4))
FROM product_table

.. versionadded:: 2.0.14  :func:`.try_cast` has been
generalized from the SQL Server dialect into a general use
construct that may be supported by additional dialects.

**Line:** 910

---

### `def column(text: str, type_: Optional[_TypeEngineArgument[_T]] = None, is_literal: bool = False, _selectable: Optional[FromClause] = None) -> ColumnClause[_T]`

**Description:**
Produce a :class:`.ColumnClause` object.

The :class:`.ColumnClause` is a lightweight analogue to the
:class:`_schema.Column` class.  The :func:`_expression.column`
function can
be invoked with just a name alone, as in::

from sqlalchemy import column

id, name = column("id"), column("name")
stmt = select(id, name).select_from("user")

The above statement would produce SQL like::

SELECT id, name FROM user

Once constructed, :func:`_expression.column`
may be used like any other SQL
expression element such as within :func:`_expression.select`
constructs::

from sqlalchemy.sql import column

id, name = column("id"), column("name")
stmt = select(id, name).select_from("user")

The text handled by :func:`_expression.column`
is assumed to be handled
like the name of a database column; if the string contains mixed case,
special characters, or matches a known reserved word on the target
backend, the column expression will render using the quoting
behavior determined by the backend.  To produce a textual SQL
expression that is rendered exactly without any quoting,
use :func:`_expression.literal_column` instead,
or pass ``True`` as the
value of :paramref:`_expression.column.is_literal`.   Additionally,
full SQL
statements are best handled using the :func:`_expression.text`
construct.

:func:`_expression.column` can be used in a table-like
fashion by combining it with the :func:`.table` function
(which is the lightweight analogue to :class:`_schema.Table`
) to produce
a working table construct with minimal boilerplate::

from sqlalchemy import table, column, select

user = table("user",
column("id"),
column("name"),
column("description"),
)

stmt = select(user.c.description).where(user.c.name == 'wendy')

A :func:`_expression.column` / :func:`.table`
construct like that illustrated
above can be created in an
ad-hoc fashion and is not associated with any
:class:`_schema.MetaData`, DDL, or events, unlike its
:class:`_schema.Table` counterpart.

:param text: the text of the element.

:param type: :class:`_types.TypeEngine` object which can associate
this :class:`.ColumnClause` with a type.

:param is_literal: if True, the :class:`.ColumnClause` is assumed to
be an exact expression that will be delivered to the output with no
quoting rules applied regardless of case sensitive settings. the
:func:`_expression.literal_column()` function essentially invokes
:func:`_expression.column` while passing ``is_literal=True``.

.. seealso::

:class:`_schema.Column`

:func:`_expression.literal_column`

:func:`.table`

:func:`_expression.text`

:ref:`tutorial_select_arbitrary_text`

**Line:** 953

---

### `def desc(column: _ColumnExpressionOrStrLabelArgument[_T]) -> UnaryExpression[_T]`

**Description:**
Produce a descending ``ORDER BY`` clause element.

e.g.::

from sqlalchemy import desc

stmt = select(users_table).order_by(desc(users_table.c.name))

will produce SQL as::

SELECT id, name FROM user ORDER BY name DESC

The :func:`.desc` function is a standalone version of the
:meth:`_expression.ColumnElement.desc`
method available on all SQL expressions,
e.g.::


stmt = select(users_table).order_by(users_table.c.name.desc())

:param column: A :class:`_expression.ColumnElement` (e.g.
scalar SQL expression)
with which to apply the :func:`.desc` operation.

.. seealso::

:func:`.asc`

:func:`.nulls_first`

:func:`.nulls_last`

:meth:`_expression.Select.order_by`

**Line:** 1049

---

### `def distinct(expr: _ColumnExpressionArgument[_T]) -> UnaryExpression[_T]`

**Description:**
Produce an column-expression-level unary ``DISTINCT`` clause.

This applies the ``DISTINCT`` keyword to an individual column
expression, and is typically contained within an aggregate function,
as in::

from sqlalchemy import distinct, func
stmt = select(func.count(distinct(users_table.c.name)))

The above would produce an expression resembling::

SELECT COUNT(DISTINCT name) FROM user

The :func:`.distinct` function is also available as a column-level
method, e.g. :meth:`_expression.ColumnElement.distinct`, as in::

stmt = select(func.count(users_table.c.name.distinct()))

The :func:`.distinct` operator is different from the
:meth:`_expression.Select.distinct` method of
:class:`_expression.Select`,
which produces a ``SELECT`` statement
with ``DISTINCT`` applied to the result set as a whole,
e.g. a ``SELECT DISTINCT`` expression.  See that method for further
information.

.. seealso::

:meth:`_expression.ColumnElement.distinct`

:meth:`_expression.Select.distinct`

:data:`.func`

**Line:** 1090

---

### `def bitwise_not(expr: _ColumnExpressionArgument[_T]) -> UnaryExpression[_T]`

**Description:**
Produce a unary bitwise NOT clause, typically via the ``~`` operator.

Not to be confused with boolean negation :func:`_sql.not_`.

.. versionadded:: 2.0.2

.. seealso::

:ref:`operators_bitwise`

**Line:** 1129

---

### `def extract(field: str, expr: _ColumnExpressionArgument[Any]) -> Extract`

**Description:**
Return a :class:`.Extract` construct.

This is typically available as :func:`.extract`
as well as ``func.extract`` from the
:data:`.func` namespace.

:param field: The field to extract.

:param expr: A column or Python scalar expression serving as the
right side of the ``EXTRACT`` expression.

E.g.::

from sqlalchemy import extract
from sqlalchemy import table, column

logged_table = table("user",
column("id"),
column("date_created"),
)

stmt = select(logged_table.c.id).where(
extract("YEAR", logged_table.c.date_created) == 2021
)

In the above example, the statement is used to select ids from the
database where the ``YEAR`` component matches a specific value.

Similarly, one can also select an extracted component::

stmt = select(
extract("YEAR", logged_table.c.date_created)
).where(logged_table.c.id == 1)

The implementation of ``EXTRACT`` may vary across database backends.
Users are reminded to consult their database documentation.

**Line:** 1146

---

### `def false() -> False_`

**Description:**
Return a :class:`.False_` construct.

E.g.:

.. sourcecode:: pycon+sql

>>> from sqlalchemy import false
>>> print(select(t.c.x).where(false()))
{printsql}SELECT x FROM t WHERE false

A backend which does not support true/false constants will render as
an expression against 1 or 0:

.. sourcecode:: pycon+sql

>>> print(select(t.c.x).where(false()))
{printsql}SELECT x FROM t WHERE 0 = 1

The :func:`.true` and :func:`.false` constants also feature
"short circuit" operation within an :func:`.and_` or :func:`.or_`
conjunction:

.. sourcecode:: pycon+sql

>>> print(select(t.c.x).where(or_(t.c.x > 5, true())))
{printsql}SELECT x FROM t WHERE true{stop}

>>> print(select(t.c.x).where(and_(t.c.x > 5, false())))
{printsql}SELECT x FROM t WHERE false{stop}

.. seealso::

:func:`.true`

**Line:** 1187

---

### `def funcfilter(func: FunctionElement[_T], *criterion: _ColumnExpressionArgument[bool]) -> FunctionFilter[_T]`

**Description:**
Produce a :class:`.FunctionFilter` object against a function.

Used against aggregate and window functions,
for database backends that support the "FILTER" clause.

E.g.::

from sqlalchemy import funcfilter
funcfilter(func.count(1), MyClass.name == 'some name')

Would produce "COUNT(1) FILTER (WHERE myclass.name = 'some name')".

This function is also available from the :data:`~.expression.func`
construct itself via the :meth:`.FunctionElement.filter` method.

.. seealso::

:ref:`tutorial_functions_within_group` - in the
:ref:`unified_tutorial`

:meth:`.FunctionElement.filter`

**Line:** 1227

---

### `def label(name: str, element: _ColumnExpressionArgument[_T], type_: Optional[_TypeEngineArgument[_T]] = None) -> Label[_T]`

**Description:**
Return a :class:`Label` object for the
given :class:`_expression.ColumnElement`.

A label changes the name of an element in the columns clause of a
``SELECT`` statement, typically via the ``AS`` SQL keyword.

This functionality is more conveniently available via the
:meth:`_expression.ColumnElement.label` method on
:class:`_expression.ColumnElement`.

:param name: label name

:param obj: a :class:`_expression.ColumnElement`.

**Line:** 1256

---

### `def null() -> Null`

**Description:**
Return a constant :class:`.Null` construct.

**Line:** 1279

---

### `def nulls_first(column: _ColumnExpressionArgument[_T]) -> UnaryExpression[_T]`

**Description:**
Produce the ``NULLS FIRST`` modifier for an ``ORDER BY`` expression.

:func:`.nulls_first` is intended to modify the expression produced
by :func:`.asc` or :func:`.desc`, and indicates how NULL values
should be handled when they are encountered during ordering::


from sqlalchemy import desc, nulls_first

stmt = select(users_table).order_by(
nulls_first(desc(users_table.c.name)))

The SQL expression from the above would resemble::

SELECT id, name FROM user ORDER BY name DESC NULLS FIRST

Like :func:`.asc` and :func:`.desc`, :func:`.nulls_first` is typically
invoked from the column expression itself using
:meth:`_expression.ColumnElement.nulls_first`,
rather than as its standalone
function version, as in::

stmt = select(users_table).order_by(
users_table.c.name.desc().nulls_first())

.. versionchanged:: 1.4 :func:`.nulls_first` is renamed from
:func:`.nullsfirst` in previous releases.
The previous name remains available for backwards compatibility.

.. seealso::

:func:`.asc`

:func:`.desc`

:func:`.nulls_last`

:meth:`_expression.Select.order_by`

**Line:** 1285

---

### `def nulls_last(column: _ColumnExpressionArgument[_T]) -> UnaryExpression[_T]`

**Description:**
Produce the ``NULLS LAST`` modifier for an ``ORDER BY`` expression.

:func:`.nulls_last` is intended to modify the expression produced
by :func:`.asc` or :func:`.desc`, and indicates how NULL values
should be handled when they are encountered during ordering::


from sqlalchemy import desc, nulls_last

stmt = select(users_table).order_by(
nulls_last(desc(users_table.c.name)))

The SQL expression from the above would resemble::

SELECT id, name FROM user ORDER BY name DESC NULLS LAST

Like :func:`.asc` and :func:`.desc`, :func:`.nulls_last` is typically
invoked from the column expression itself using
:meth:`_expression.ColumnElement.nulls_last`,
rather than as its standalone
function version, as in::

stmt = select(users_table).order_by(
users_table.c.name.desc().nulls_last())

.. versionchanged:: 1.4 :func:`.nulls_last` is renamed from
:func:`.nullslast` in previous releases.
The previous name remains available for backwards compatibility.

.. seealso::

:func:`.asc`

:func:`.desc`

:func:`.nulls_first`

:meth:`_expression.Select.order_by`

**Line:** 1329

---

### `def or_(initial_clause: Union[(Literal[False], _ColumnExpressionArgument[bool])], *clauses: _ColumnExpressionArgument[bool]) -> ColumnElement[bool]`

**Description:**
Produce a conjunction of expressions joined by ``OR``.

E.g.::

from sqlalchemy import or_

stmt = select(users_table).where(
or_(
users_table.c.name == 'wendy',
users_table.c.name == 'jack'
)
)

The :func:`.or_` conjunction is also available using the
Python ``|`` operator (though note that compound expressions
need to be parenthesized in order to function with Python
operator precedence behavior)::

stmt = select(users_table).where(
(users_table.c.name == 'wendy') |
(users_table.c.name == 'jack')
)

The :func:`.or_` construct must be given at least one positional
argument in order to be valid; a :func:`.or_` construct with no
arguments is ambiguous.   To produce an "empty" or dynamically
generated :func:`.or_`  expression, from a given list of expressions,
a "default" element of :func:`_sql.false` (or just ``False``) should be
specified::

from sqlalchemy import false
or_criteria = or_(false(), *expressions)

The above expression will compile to SQL as the expression ``false``
or ``0 = 1``, depending on backend, if no other expressions are
present.  If expressions are present, then the :func:`_sql.false` value is
ignored as it does not affect the outcome of an OR expression which
has other elements.

.. deprecated:: 1.4  The :func:`.or_` element now requires that at
least one argument is passed; creating the :func:`.or_` construct
with no arguments is deprecated, and will emit a deprecation warning
while continuing to produce a blank SQL string.

.. seealso::

:func:`.and_`

**Line:** 1373

---

### `def or_(*clauses)`

**Description:**
Produce a conjunction of expressions joined by ``OR``.

E.g.::

from sqlalchemy import or_

stmt = select(users_table).where(
or_(
users_table.c.name == 'wendy',
users_table.c.name == 'jack'
)
)

The :func:`.or_` conjunction is also available using the
Python ``|`` operator (though note that compound expressions
need to be parenthesized in order to function with Python
operator precedence behavior)::

stmt = select(users_table).where(
(users_table.c.name == 'wendy') |
(users_table.c.name == 'jack')
)

The :func:`.or_` construct must be given at least one positional
argument in order to be valid; a :func:`.or_` construct with no
arguments is ambiguous.   To produce an "empty" or dynamically
generated :func:`.or_`  expression, from a given list of expressions,
a "default" element of :func:`_sql.false` (or just ``False``) should be
specified::

from sqlalchemy import false
or_criteria = or_(false(), *expressions)

The above expression will compile to SQL as the expression ``false``
or ``0 = 1``, depending on backend, if no other expressions are
present.  If expressions are present, then the :func:`_sql.false` value
is ignored as it does not affect the outcome of an OR expression which
has other elements.

.. deprecated:: 1.4  The :func:`.or_` element now requires that at
least one argument is passed; creating the :func:`.or_` construct
with no arguments is deprecated, and will emit a deprecation warning
while continuing to produce a blank SQL string.

.. seealso::

:func:`.and_`

**Line:** 1431

---

### `def over(element: FunctionElement[_T], partition_by: Optional[Union[(Iterable[_ColumnExpressionArgument[Any]], _ColumnExpressionArgument[Any])]] = None, order_by: Optional[Union[(Iterable[_ColumnExpressionArgument[Any]], _ColumnExpressionArgument[Any])]] = None, range_: Optional[typing_Tuple[(Optional[int], Optional[int])]] = None, rows: Optional[typing_Tuple[(Optional[int], Optional[int])]] = None) -> Over[_T]`

**Description:**
Produce an :class:`.Over` object against a function.

Used against aggregate or so-called "window" functions,
for database backends that support window functions.

:func:`_expression.over` is usually called using
the :meth:`.FunctionElement.over` method, e.g.::

func.row_number().over(order_by=mytable.c.some_column)

Would produce::

ROW_NUMBER() OVER(ORDER BY some_column)

Ranges are also possible using the :paramref:`.expression.over.range_`
and :paramref:`.expression.over.rows` parameters.  These
mutually-exclusive parameters each accept a 2-tuple, which contains
a combination of integers and None::

func.row_number().over(
order_by=my_table.c.some_column, range_=(None, 0))

The above would produce::

ROW_NUMBER() OVER(ORDER BY some_column
RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)

A value of ``None`` indicates "unbounded", a
value of zero indicates "current row", and negative / positive
integers indicate "preceding" and "following":

* RANGE BETWEEN 5 PRECEDING AND 10 FOLLOWING::

func.row_number().over(order_by='x', range_=(-5, 10))

* ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW::

func.row_number().over(order_by='x', rows=(None, 0))

* RANGE BETWEEN 2 PRECEDING AND UNBOUNDED FOLLOWING::

func.row_number().over(order_by='x', range_=(-2, None))

* RANGE BETWEEN 1 FOLLOWING AND 3 FOLLOWING::

func.row_number().over(order_by='x', range_=(1, 3))

:param element: a :class:`.FunctionElement`, :class:`.WithinGroup`,
or other compatible construct.
:param partition_by: a column element or string, or a list
of such, that will be used as the PARTITION BY clause
of the OVER construct.
:param order_by: a column element or string, or a list
of such, that will be used as the ORDER BY clause
of the OVER construct.
:param range\_: optional range clause for the window.  This is a
tuple value which can contain integer values or ``None``,
and will render a RANGE BETWEEN PRECEDING / FOLLOWING clause.

:param rows: optional rows clause for the window.  This is a tuple
value which can contain integer values or None, and will render
a ROWS BETWEEN PRECEDING / FOLLOWING clause.

This function is also available from the :data:`~.expression.func`
construct itself via the :meth:`.FunctionElement.over` method.

.. seealso::

:ref:`tutorial_window_functions` - in the :ref:`unified_tutorial`

:data:`.expression.func`

:func:`_expression.within_group`

**Line:** 1484

---

### `def text(text: str) -> TextClause`

**Decorators:**
- `@_document_text_coercion(...)`

**Description:**
Construct a new :class:`_expression.TextClause` clause,
representing
a textual SQL string directly.

E.g.::

from sqlalchemy import text

t = text("SELECT * FROM users")
result = connection.execute(t)

The advantages :func:`_expression.text`
provides over a plain string are
backend-neutral support for bind parameters, per-statement
execution options, as well as
bind parameter and result-column typing behavior, allowing
SQLAlchemy type constructs to play a role when executing
a statement that is specified literally.  The construct can also
be provided with a ``.c`` collection of column elements, allowing
it to be embedded in other SQL expression constructs as a subquery.

Bind parameters are specified by name, using the format ``:name``.
E.g.::

t = text("SELECT * FROM users WHERE id=:user_id")
result = connection.execute(t, user_id=12)

For SQL statements where a colon is required verbatim, as within
an inline string, use a backslash to escape::

t = text(r"SELECT * FROM users WHERE name='\:username'")

The :class:`_expression.TextClause`
construct includes methods which can
provide information about the bound parameters as well as the column
values which would be returned from the textual statement, assuming
it's an executable SELECT type of statement.  The
:meth:`_expression.TextClause.bindparams`
method is used to provide bound
parameter detail, and :meth:`_expression.TextClause.columns`
method allows
specification of return columns including names and types::

t = text("SELECT * FROM users WHERE id=:user_id").\
bindparams(user_id=7).\
columns(id=Integer, name=String)

for id, name in connection.execute(t):
print(id, name)

The :func:`_expression.text` construct is used in cases when
a literal string SQL fragment is specified as part of a larger query,
such as for the WHERE clause of a SELECT statement::

s = select(users.c.id, users.c.name).where(text("id=:user_id"))
result = connection.execute(s, user_id=12)

:func:`_expression.text` is also used for the construction
of a full, standalone statement using plain text.
As such, SQLAlchemy refers
to it as an :class:`.Executable` object and may be used
like any other statement passed to an ``.execute()`` method.

:param text:
the text of the SQL statement to be created.  Use ``:<param>``
to specify bind parameters; they will be compiled to their
engine-specific format.

.. seealso::

:ref:`tutorial_select_arbitrary_text`

**Line:** 1580

---

### `def true() -> True_`

**Description:**
Return a constant :class:`.True_` construct.

E.g.:

.. sourcecode:: pycon+sql

>>> from sqlalchemy import true
>>> print(select(t.c.x).where(true()))
{printsql}SELECT x FROM t WHERE true

A backend which does not support true/false constants will render as
an expression against 1 or 0:

.. sourcecode:: pycon+sql

>>> print(select(t.c.x).where(true()))
{printsql}SELECT x FROM t WHERE 1 = 1

The :func:`.true` and :func:`.false` constants also feature
"short circuit" operation within an :func:`.and_` or :func:`.or_`
conjunction:

.. sourcecode:: pycon+sql

>>> print(select(t.c.x).where(or_(t.c.x > 5, true())))
{printsql}SELECT x FROM t WHERE true{stop}

>>> print(select(t.c.x).where(and_(t.c.x > 5, false())))
{printsql}SELECT x FROM t WHERE false{stop}

.. seealso::

:func:`.false`

**Line:** 1657

---

### `def tuple_(types: Optional[Sequence[_TypeEngineArgument[Any]]] = None, *clauses: _ColumnExpressionArgument[Any]) -> Tuple`

**Description:**
Return a :class:`.Tuple`.

Main usage is to produce a composite IN construct using
:meth:`.ColumnOperators.in_` ::

from sqlalchemy import tuple_

tuple_(table.c.col1, table.c.col2).in_(
[(1, 2), (5, 12), (10, 19)]
)

.. versionchanged:: 1.3.6 Added support for SQLite IN tuples.

.. warning::

The composite IN construct is not supported by all backends, and is
currently known to work on PostgreSQL, MySQL, and SQLite.
Unsupported backends will raise a subclass of
:class:`~sqlalchemy.exc.DBAPIError` when such an expression is
invoked.

**Line:** 1697

---

### `def type_coerce(expression: _ColumnExpressionOrLiteralArgument[Any], type_: _TypeEngineArgument[_T]) -> TypeCoerce[_T]`

**Description:**
Associate a SQL expression with a particular type, without rendering
``CAST``.

E.g.::

from sqlalchemy import type_coerce

stmt = select(type_coerce(log_table.date_string, StringDateTime()))

The above construct will produce a :class:`.TypeCoerce` object, which
does not modify the rendering in any way on the SQL side, with the
possible exception of a generated label if used in a columns clause
context:

.. sourcecode:: sql

SELECT date_string AS date_string FROM log

When result rows are fetched, the ``StringDateTime`` type processor
will be applied to result rows on behalf of the ``date_string`` column.

.. note:: the :func:`.type_coerce` construct does not render any
SQL syntax of its own, including that it does not imply
parenthesization.   Please use :meth:`.TypeCoerce.self_group`
if explicit parenthesization is required.

In order to provide a named label for the expression, use
:meth:`_expression.ColumnElement.label`::

stmt = select(
type_coerce(log_table.date_string, StringDateTime()).label('date')
)


A type that features bound-value handling will also have that behavior
take effect when literal values or :func:`.bindparam` constructs are
passed to :func:`.type_coerce` as targets.
For example, if a type implements the
:meth:`.TypeEngine.bind_expression`
method or :meth:`.TypeEngine.bind_processor` method or equivalent,
these functions will take effect at statement compilation/execution
time when a literal value is passed, as in::

# bound-value handling of MyStringType will be applied to the
# literal value "some string"
stmt = select(type_coerce("some string", MyStringType))

When using :func:`.type_coerce` with composed expressions, note that
**parenthesis are not applied**.   If :func:`.type_coerce` is being
used in an operator context where the parenthesis normally present from
CAST are necessary, use the :meth:`.TypeCoerce.self_group` method:

.. sourcecode:: pycon+sql

>>> some_integer = column("someint", Integer)
>>> some_string = column("somestr", String)
>>> expr = type_coerce(some_integer + 5, String) + some_string
>>> print(expr)
{printsql}someint + :someint_1 || somestr{stop}
>>> expr = type_coerce(some_integer + 5, String).self_group() + some_string
>>> print(expr)
{printsql}(someint + :someint_1) || somestr{stop}

:param expression: A SQL expression, such as a
:class:`_expression.ColumnElement`
expression or a Python string which will be coerced into a bound
literal value.

:param type\_: A :class:`.TypeEngine` class or instance indicating
the type to which the expression is coerced.

.. seealso::

:ref:`tutorial_casts`

:func:`.cast`

**Line:** 1726

---

### `def within_group(element: FunctionElement[_T], *order_by: _ColumnExpressionArgument[Any]) -> WithinGroup[_T]`

**Description:**
Produce a :class:`.WithinGroup` object against a function.

Used against so-called "ordered set aggregate" and "hypothetical
set aggregate" functions, including :class:`.percentile_cont`,
:class:`.rank`, :class:`.dense_rank`, etc.

:func:`_expression.within_group` is usually called using
the :meth:`.FunctionElement.within_group` method, e.g.::

from sqlalchemy import within_group
stmt = select(
department.c.id,
func.percentile_cont(0.5).within_group(
department.c.salary.desc()
)
)

The above statement would produce SQL similar to
``SELECT department.id, percentile_cont(0.5)
WITHIN GROUP (ORDER BY department.salary DESC)``.

:param element: a :class:`.FunctionElement` construct, typically
generated by :data:`~.expression.func`.
:param \*order_by: one or more column elements that will be used
as the ORDER BY clause of the WITHIN GROUP construct.

.. seealso::

:ref:`tutorial_functions_within_group` - in the
:ref:`unified_tutorial`

:data:`.expression.func`

:func:`_expression.over`

**Line:** 1811

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql._selectable_constructors
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/_selectable_constructors.py`

**Imports:**
- __future__.annotations
- _typing._ColumnsClauseArgument
- _typing._FromClauseArgument
- _typing._OnClauseArgument
- _typing._SelectStatementForCompoundArgument
- _typing._T0
- _typing._T1
- _typing._T2
- _typing._T3
- _typing._T4
- _typing._T5
- _typing._T6
- _typing._T7
- _typing._T8
- _typing._T9
- _typing._TypedColumnClauseArgument
- _typing._no_kw
- elements.ColumnClause
- functions.Function
- selectable.Alias
- selectable.CTE
- selectable.CompoundSelect
- selectable.Exists
- selectable.FromClause
- selectable.HasCTE
- selectable.Join
- selectable.Lateral
- selectable.LateralFromClause
- selectable.NamedFromClause
- selectable.ScalarSelect
- selectable.Select
- selectable.SelectBase
- selectable.TableClause
- selectable.TableSample
- selectable.Values
- typing.Any
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.overload

**Functions:**

### `def alias(selectable: FromClause, name: Optional[str] = None, flat: bool = False) -> NamedFromClause`

**Description:**
Return a named alias of the given :class:`.FromClause`.

For :class:`.Table` and :class:`.Join` objects, the return type is the
:class:`_expression.Alias` object. Other kinds of :class:`.NamedFromClause`
objects may be returned for other kinds of :class:`.FromClause` objects.

The named alias represents any :class:`_expression.FromClause` with an
alternate name assigned within SQL, typically using the ``AS`` clause when
generated, e.g. ``SELECT * FROM table AS aliasname``.

Equivalent functionality is available via the
:meth:`_expression.FromClause.alias`
method available on all :class:`_expression.FromClause` objects.

:param selectable: any :class:`_expression.FromClause` subclass,
such as a table, select statement, etc.

:param name: string name to be assigned as the alias.
If ``None``, a name will be deterministically generated at compile
time. Deterministic means the name is guaranteed to be unique against
other constructs used in the same statement, and will also be the same
name for each successive compilation of the same statement object.

:param flat: Will be passed through to if the given selectable
is an instance of :class:`_expression.Join` - see
:meth:`_expression.Join.alias` for details.

**Line:** 61

---

### `def cte(selectable: HasCTE, name: Optional[str] = None, recursive: bool = False) -> CTE`

**Description:**
Return a new :class:`_expression.CTE`,
or Common Table Expression instance.

Please see :meth:`_expression.HasCTE.cte` for detail on CTE usage.

**Line:** 95

---

### `def except_(*selects: _SelectStatementForCompoundArgument) -> CompoundSelect`

**Description:**
Return an ``EXCEPT`` of multiple selectables.

The returned object is an instance of
:class:`_expression.CompoundSelect`.

:param \*selects:
a list of :class:`_expression.Select` instances.

**Line:** 109

---

### `def except_all(*selects: _SelectStatementForCompoundArgument) -> CompoundSelect`

**Description:**
Return an ``EXCEPT ALL`` of multiple selectables.

The returned object is an instance of
:class:`_expression.CompoundSelect`.

:param \*selects:
a list of :class:`_expression.Select` instances.

**Line:** 124

---

### `def exists(__argument: Optional[Union[(_ColumnsClauseArgument[Any], SelectBase, ScalarSelect[Any])]] = None) -> Exists`

**Description:**
Construct a new :class:`_expression.Exists` construct.

The :func:`_sql.exists` can be invoked by itself to produce an
:class:`_sql.Exists` construct, which will accept simple WHERE
criteria::

exists_criteria = exists().where(table1.c.col1 == table2.c.col2)

However, for greater flexibility in constructing the SELECT, an
existing :class:`_sql.Select` construct may be converted to an
:class:`_sql.Exists`, most conveniently by making use of the
:meth:`_sql.SelectBase.exists` method::

exists_criteria = (
select(table2.c.col2).
where(table1.c.col1 == table2.c.col2).
exists()
)

The EXISTS criteria is then used inside of an enclosing SELECT::

stmt = select(table1.c.col1).where(exists_criteria)

The above statement will then be of the form::

SELECT col1 FROM table1 WHERE EXISTS
(SELECT table2.col2 FROM table2 WHERE table2.col2 = table1.col1)

.. seealso::

:ref:`tutorial_exists` - in the :term:`2.0 style` tutorial.

:meth:`_sql.SelectBase.exists` - method to transform a ``SELECT`` to an
``EXISTS`` clause.

**Line:** 139

---

### `def intersect(*selects: _SelectStatementForCompoundArgument) -> CompoundSelect`

**Description:**
Return an ``INTERSECT`` of multiple selectables.

The returned object is an instance of
:class:`_expression.CompoundSelect`.

:param \*selects:
a list of :class:`_expression.Select` instances.

**Line:** 184

---

### `def intersect_all(*selects: _SelectStatementForCompoundArgument) -> CompoundSelect`

**Description:**
Return an ``INTERSECT ALL`` of multiple selectables.

The returned object is an instance of
:class:`_expression.CompoundSelect`.

:param \*selects:
a list of :class:`_expression.Select` instances.

**Line:** 199

---

### `def join(left: _FromClauseArgument, right: _FromClauseArgument, onclause: Optional[_OnClauseArgument] = None, isouter: bool = False, full: bool = False) -> Join`

**Description:**
Produce a :class:`_expression.Join` object, given two
:class:`_expression.FromClause`
expressions.

E.g.::

j = join(user_table, address_table,
user_table.c.id == address_table.c.user_id)
stmt = select(user_table).select_from(j)

would emit SQL along the lines of::

SELECT user.id, user.name FROM user
JOIN address ON user.id = address.user_id

Similar functionality is available given any
:class:`_expression.FromClause` object (e.g. such as a
:class:`_schema.Table`) using
the :meth:`_expression.FromClause.join` method.

:param left: The left side of the join.

:param right: the right side of the join; this is any
:class:`_expression.FromClause` object such as a
:class:`_schema.Table` object, and
may also be a selectable-compatible object such as an ORM-mapped
class.

:param onclause: a SQL expression representing the ON clause of the
join.  If left at ``None``, :meth:`_expression.FromClause.join`
will attempt to
join the two tables based on a foreign key relationship.

:param isouter: if True, render a LEFT OUTER JOIN, instead of JOIN.

:param full: if True, render a FULL OUTER JOIN, instead of JOIN.

.. seealso::

:meth:`_expression.FromClause.join` - method form,
based on a given left side.

:class:`_expression.Join` - the type of object produced.

**Line:** 215

---

### `def lateral(selectable: Union[(SelectBase, _FromClauseArgument)], name: Optional[str] = None) -> LateralFromClause`

**Description:**
Return a :class:`_expression.Lateral` object.

:class:`_expression.Lateral` is an :class:`_expression.Alias`
subclass that represents
a subquery with the LATERAL keyword applied to it.

The special behavior of a LATERAL subquery is that it appears in the
FROM clause of an enclosing SELECT, but may correlate to other
FROM clauses of that SELECT.   It is a special case of subquery
only supported by a small number of backends, currently more recent
PostgreSQL versions.

.. seealso::

:ref:`tutorial_lateral_correlation` -  overview of usage.

**Line:** 271

---

### `def outerjoin(left: _FromClauseArgument, right: _FromClauseArgument, onclause: Optional[_OnClauseArgument] = None, full: bool = False) -> Join`

**Description:**
Return an ``OUTER JOIN`` clause element.

The returned object is an instance of :class:`_expression.Join`.

Similar functionality is also available via the
:meth:`_expression.FromClause.outerjoin` method on any
:class:`_expression.FromClause`.

:param left: The left side of the join.

:param right: The right side of the join.

:param onclause:  Optional criterion for the ``ON`` clause, is
derived from foreign key relationships established between
left and right otherwise.

To chain joins together, use the :meth:`_expression.FromClause.join`
or
:meth:`_expression.FromClause.outerjoin` methods on the resulting
:class:`_expression.Join` object.

**Line:** 295

---

### `def select(__ent0: _TCCA[_T0]) -> Select[Tuple[_T0]]`

**Decorators:**
- `@overload`

**Line:** 333

---

### `def select(__ent0: _TCCA[_T0], __ent1: _TCCA[_T1]) -> Select[Tuple[(_T0, _T1)]]`

**Decorators:**
- `@overload`

**Line:** 338

---

### `def select(__ent0: _TCCA[_T0], __ent1: _TCCA[_T1], __ent2: _TCCA[_T2]) -> Select[Tuple[(_T0, _T1, _T2)]]`

**Decorators:**
- `@overload`

**Line:** 343

---

### `def select(__ent0: _TCCA[_T0], __ent1: _TCCA[_T1], __ent2: _TCCA[_T2], __ent3: _TCCA[_T3]) -> Select[Tuple[(_T0, _T1, _T2, _T3)]]`

**Decorators:**
- `@overload`

**Line:** 350

---

### `def select(__ent0: _TCCA[_T0], __ent1: _TCCA[_T1], __ent2: _TCCA[_T2], __ent3: _TCCA[_T3], __ent4: _TCCA[_T4]) -> Select[Tuple[(_T0, _T1, _T2, _T3, _T4)]]`

**Decorators:**
- `@overload`

**Line:** 360

---

### `def select(__ent0: _TCCA[_T0], __ent1: _TCCA[_T1], __ent2: _TCCA[_T2], __ent3: _TCCA[_T3], __ent4: _TCCA[_T4], __ent5: _TCCA[_T5]) -> Select[Tuple[(_T0, _T1, _T2, _T3, _T4, _T5)]]`

**Decorators:**
- `@overload`

**Line:** 371

---

### `def select(__ent0: _TCCA[_T0], __ent1: _TCCA[_T1], __ent2: _TCCA[_T2], __ent3: _TCCA[_T3], __ent4: _TCCA[_T4], __ent5: _TCCA[_T5], __ent6: _TCCA[_T6]) -> Select[Tuple[(_T0, _T1, _T2, _T3, _T4, _T5, _T6)]]`

**Decorators:**
- `@overload`

**Line:** 383

---

### `def select(__ent0: _TCCA[_T0], __ent1: _TCCA[_T1], __ent2: _TCCA[_T2], __ent3: _TCCA[_T3], __ent4: _TCCA[_T4], __ent5: _TCCA[_T5], __ent6: _TCCA[_T6], __ent7: _TCCA[_T7]) -> Select[Tuple[(_T0, _T1, _T2, _T3, _T4, _T5, _T6, _T7)]]`

**Decorators:**
- `@overload`

**Line:** 396

---

### `def select(__ent0: _TCCA[_T0], __ent1: _TCCA[_T1], __ent2: _TCCA[_T2], __ent3: _TCCA[_T3], __ent4: _TCCA[_T4], __ent5: _TCCA[_T5], __ent6: _TCCA[_T6], __ent7: _TCCA[_T7], __ent8: _TCCA[_T8]) -> Select[Tuple[(_T0, _T1, _T2, _T3, _T4, _T5, _T6, _T7, _T8)]]`

**Decorators:**
- `@overload`

**Line:** 410

---

### `def select(__ent0: _TCCA[_T0], __ent1: _TCCA[_T1], __ent2: _TCCA[_T2], __ent3: _TCCA[_T3], __ent4: _TCCA[_T4], __ent5: _TCCA[_T5], __ent6: _TCCA[_T6], __ent7: _TCCA[_T7], __ent8: _TCCA[_T8], __ent9: _TCCA[_T9]) -> Select[Tuple[(_T0, _T1, _T2, _T3, _T4, _T5, _T6, _T7, _T8, _T9)]]`

**Decorators:**
- `@overload`

**Line:** 425

---

### `def select(*entities: _ColumnsClauseArgument[Any], **__kw: Any) -> Select[Any]`

**Decorators:**
- `@overload`

**Line:** 444

---

### `def select(*entities: _ColumnsClauseArgument[Any], **__kw: Any) -> Select[Any]`

**Description:**
Construct a new :class:`_expression.Select`.


.. versionadded:: 1.4 - The :func:`_sql.select` function now accepts
column arguments positionally.   The top-level :func:`_sql.select`
function will automatically use the 1.x or 2.x style API based on
the incoming arguments; using :func:`_sql.select` from the
``sqlalchemy.future`` module will enforce that only the 2.x style
constructor is used.

Similar functionality is also available via the
:meth:`_expression.FromClause.select` method on any
:class:`_expression.FromClause`.

.. seealso::

:ref:`tutorial_selecting_data` - in the :ref:`unified_tutorial`

:param \*entities:
Entities to SELECT from.  For Core usage, this is typically a series
of :class:`_expression.ColumnElement` and / or
:class:`_expression.FromClause`
objects which will form the columns clause of the resulting
statement.   For those objects that are instances of
:class:`_expression.FromClause` (typically :class:`_schema.Table`
or :class:`_expression.Alias`
objects), the :attr:`_expression.FromClause.c`
collection is extracted
to form a collection of :class:`_expression.ColumnElement` objects.

This parameter will also accept :class:`_expression.TextClause`
constructs as
given, as well as ORM-mapped classes.

**Line:** 448

---

### `def table(name: str, *columns: ColumnClause[Any], **kw: Any) -> TableClause`

**Description:**
Produce a new :class:`_expression.TableClause`.

The object returned is an instance of
:class:`_expression.TableClause`, which
represents the "syntactical" portion of the schema-level
:class:`_schema.Table` object.
It may be used to construct lightweight table constructs.

:param name: Name of the table.

:param columns: A collection of :func:`_expression.column` constructs.

:param schema: The schema name for this table.

.. versionadded:: 1.3.18 :func:`_expression.table` can now
accept a ``schema`` argument.

**Line:** 492

---

### `def tablesample(selectable: _FromClauseArgument, sampling: Union[(float, Function[Any])], name: Optional[str] = None, seed: Optional[roles.ExpressionElementRole[Any]] = None) -> TableSample`

**Description:**
Return a :class:`_expression.TableSample` object.

:class:`_expression.TableSample` is an :class:`_expression.Alias`
subclass that represents
a table with the TABLESAMPLE clause applied to it.
:func:`_expression.tablesample`
is also available from the :class:`_expression.FromClause`
class via the
:meth:`_expression.FromClause.tablesample` method.

The TABLESAMPLE clause allows selecting a randomly selected approximate
percentage of rows from a table. It supports multiple sampling methods,
most commonly BERNOULLI and SYSTEM.

e.g.::

from sqlalchemy import func

selectable = people.tablesample(
func.bernoulli(1),
name='alias',
seed=func.random())
stmt = select(selectable.c.people_id)

Assuming ``people`` with a column ``people_id``, the above
statement would render as::

SELECT alias.people_id FROM
people AS alias TABLESAMPLE bernoulli(:bernoulli_1)
REPEATABLE (random())

:param sampling: a ``float`` percentage between 0 and 100 or
:class:`_functions.Function`.

:param name: optional alias name

:param seed: any real-valued SQL expression.  When specified, the
REPEATABLE sub-clause is also rendered.

**Line:** 514

---

### `def union(*selects: _SelectStatementForCompoundArgument) -> CompoundSelect`

**Description:**
Return a ``UNION`` of multiple selectables.

The returned object is an instance of
:class:`_expression.CompoundSelect`.

A similar :func:`union()` method is available on all
:class:`_expression.FromClause` subclasses.

:param \*selects:
a list of :class:`_expression.Select` instances.

:param \**kwargs:
available keyword arguments are the same as those of
:func:`select`.

**Line:** 563

---

### `def union_all(*selects: _SelectStatementForCompoundArgument) -> CompoundSelect`

**Description:**
Return a ``UNION ALL`` of multiple selectables.

The returned object is an instance of
:class:`_expression.CompoundSelect`.

A similar :func:`union_all()` method is available on all
:class:`_expression.FromClause` subclasses.

:param \*selects:
a list of :class:`_expression.Select` instances.

**Line:** 585

---

### `def values(name: Optional[str] = None, literal_binds: bool = False, *columns: ColumnClause[Any]) -> Values`

**Description:**
Construct a :class:`_expression.Values` construct.

The column expressions and the actual data for
:class:`_expression.Values` are given in two separate steps.  The
constructor receives the column expressions typically as
:func:`_expression.column` constructs,
and the data is then passed via the
:meth:`_expression.Values.data` method as a list,
which can be called multiple
times to add more data, e.g.::

from sqlalchemy import column
from sqlalchemy import values

value_expr = values(
column('id', Integer),
column('name', String),
name="my_values"
).data(
[(1, 'name1'), (2, 'name2'), (3, 'name3')]
)

:param \*columns: column expressions, typically composed using
:func:`_expression.column` objects.

:param name: the name for this VALUES construct.  If omitted, the
VALUES construct will be unnamed in a SQL expression.   Different
backends may have different requirements here.

:param literal_binds: Defaults to False.  Whether or not to render
the data values inline in the SQL output, rather than using bound
parameters.

**Line:** 603

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql._typing
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/_typing.py`

**Imports:**
- __future__.annotations
- base.Executable
- compiler.Compiled
- compiler.DDLCompiler
- compiler.SQLCompiler
- datetime.date
- datetime.datetime
- datetime.time
- datetime.timedelta
- decimal.Decimal
- dml.UpdateBase
- dml.ValuesBase
- elements.ClauseElement
- elements.ColumnElement
- elements.KeyedColumnElement
- elements.SQLCoreOperations
- elements.TextClause
- elements.quoted_name
- inspection.Inspectable
- lambdas.LambdaElement
- operator
- roles.ColumnsClauseRole
- roles.FromClauseRole
- schema.Column
- selectable.Alias
- selectable.CTE
- selectable.FromClause
- selectable.Join
- selectable.NamedFromClause
- selectable.ReturnsRows
- selectable.Select
- selectable.SelectBase
- selectable.Selectable
- selectable.Subquery
- selectable.TableClause
- sqltypes.TableValueType
- sqltypes.TupleType
- type_api.TypeEngine
- typing.Any
- typing.Callable
- typing.Dict
- typing.Mapping
- typing.NoReturn
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.overload
- util.typing.Literal
- util.typing.Protocol
- util.typing.TypeAlias
- util.typing.TypeGuard
- uuid.UUID

**Functions:**

### `def is_sql_compiler(c: Compiled) -> TypeGuard[SQLCompiler]`

**Line:** 283

---

### `def is_ddl_compiler(c: Compiled) -> TypeGuard[DDLCompiler]`

**Line:** 286

---

### `def is_named_from_clause(t: FromClauseRole) -> TypeGuard[NamedFromClause]`

**Line:** 289

---

### `def is_column_element(c: ClauseElement) -> TypeGuard[ColumnElement[Any]]`

**Line:** 292

---

### `def is_keyed_column_element(c: ClauseElement) -> TypeGuard[KeyedColumnElement[Any]]`

**Line:** 295

---

### `def is_text_clause(c: ClauseElement) -> TypeGuard[TextClause]`

**Line:** 300

---

### `def is_from_clause(c: ClauseElement) -> TypeGuard[FromClause]`

**Line:** 303

---

### `def is_tuple_type(t: TypeEngine[Any]) -> TypeGuard[TupleType]`

**Line:** 306

---

### `def is_table_value_type(t: TypeEngine[Any]) -> TypeGuard[TableValueType]`

**Line:** 309

---

### `def is_selectable(t: Any) -> TypeGuard[Selectable]`

**Line:** 312

---

### `def is_select_base(t: Union[(Executable, ReturnsRows)]) -> TypeGuard[SelectBase]`

**Line:** 315

---

### `def is_select_statement(t: Union[(Executable, ReturnsRows)]) -> TypeGuard[Select[Any]]`

**Line:** 320

---

### `def is_table(t: FromClause) -> TypeGuard[TableClause]`

**Line:** 325

---

### `def is_subquery(t: FromClause) -> TypeGuard[Subquery]`

**Line:** 328

---

### `def is_dml(c: ClauseElement) -> TypeGuard[UpdateBase]`

**Line:** 331

---

### `def has_schema_attr(t: FromClauseRole) -> TypeGuard[TableClause]`

**Line:** 352

---

### `def is_quoted_name(s: str) -> TypeGuard[quoted_name]`

**Line:** 356

---

### `def is_has_clause_element(s: object) -> TypeGuard[_HasClauseElement]`

**Line:** 360

---

### `def is_insert_update(c: ClauseElement) -> TypeGuard[ValuesBase]`

**Line:** 364

---

### `def _no_kw() -> exc.ArgumentError`

**Line:** 368

---

### `def _unexpected_kw(methname: str, kw: Dict[(str, Any)]) -> NoReturn`

**Line:** 375

---

### `def Nullable(val: 'SQLCoreOperations[_T]') -> 'SQLCoreOperations[Optional[_T]]'`

**Decorators:**
- `@overload`

**Line:** 381

---

### `def Nullable(val: roles.ExpressionElementRole[_T]) -> roles.ExpressionElementRole[Optional[_T]]`

**Decorators:**
- `@overload`

**Line:** 388

---

### `def Nullable(val: Type[_T]) -> Type[Optional[_T]]`

**Decorators:**
- `@overload`

**Line:** 395

---

### `def Nullable(val: _TypedColumnClauseArgument[_T]) -> _TypedColumnClauseArgument[Optional[_T]]`

**Description:**
Types a column or ORM class as nullable.

This can be used in select and other contexts to express that the value of
a column can be null, for example due to an outer join::

stmt1 = select(A, Nullable(B)).outerjoin(A.bs)
stmt2 = select(A.data, Nullable(B.data)).outerjoin(A.bs)

At runtime this method returns the input unchanged.

.. versionadded:: 2.0.20

**Line:** 399

---

### `def NotNullable(val: 'SQLCoreOperations[Optional[_T]]') -> 'SQLCoreOperations[_T]'`

**Decorators:**
- `@overload`

**Line:** 418

---

### `def NotNullable(val: roles.ExpressionElementRole[Optional[_T]]) -> roles.ExpressionElementRole[_T]`

**Decorators:**
- `@overload`

**Line:** 425

---

### `def NotNullable(val: Type[Optional[_T]]) -> Type[_T]`

**Decorators:**
- `@overload`

**Line:** 432

---

### `def NotNullable(val: Optional[Type[_T]]) -> Type[_T]`

**Decorators:**
- `@overload`

**Line:** 437

---

### `def NotNullable(val: Union[(_TypedColumnClauseArgument[Optional[_T]], Optional[Type[_T]])]) -> _TypedColumnClauseArgument[_T]`

**Description:**
Types a column or ORM class as not nullable.

This can be used in select and other contexts to express that the value of
a column cannot be null, for example due to a where condition on a
nullable column::

stmt = select(NotNullable(A.value)).where(A.value.is_not(None))

At runtime this method returns the input unchanged.

.. versionadded:: 2.0.20

**Line:** 441

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.annotation
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/annotation.py`

**Imports:**
- __future__.annotations
- base._EntityNamespace
- cache_key.HasCacheKey
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.FrozenSet
- typing.Mapping
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.cast
- typing.overload
- util.typing.Literal
- util.typing.Self
- visitors.ExternallyTraversible
- visitors.InternalTraversal
- visitors._TraverseInternalsType
- visitors.anon_map

**Functions:**

### `def _safe_annotate(to_annotate: _SA, annotations: _AnnotationDict) -> _SA`

**Line:** 405

---

### `def _deep_annotate(element: _SA, annotations: _AnnotationDict, exclude: Optional[Sequence[SupportsAnnotations]] = None, detect_subquery_cols: bool = False, ind_cols_on_fromclause: bool = False, annotate_callable: Optional[Callable[([SupportsAnnotations, _AnnotationDict], SupportsAnnotations)]] = None) -> _SA`

**Description:**
Deep copy the given ClauseElement, annotating each element
with the given annotations dictionary.

Elements within the exclude collection will be cloned but not annotated.

**Line:** 417

---

### `def _deep_deannotate(element: Literal[None], values: Optional[Sequence[str]] = None) -> Literal[None]`

**Decorators:**
- `@overload`

**Line:** 488

---

### `def _deep_deannotate(element: _SA, values: Optional[Sequence[str]] = None) -> _SA`

**Decorators:**
- `@overload`

**Line:** 495

---

### `def _deep_deannotate(element: Optional[_SA], values: Optional[Sequence[str]] = None) -> Optional[_SA]`

**Description:**
Deep copy the given element, removing annotations.

**Line:** 501

---

### `def _shallow_annotate(element: _SA, annotations: _AnnotationDict) -> _SA`

**Description:**
Annotate the given ClauseElement and copy its internals so that
internal objects refer to the new annotated object.

Basically used to apply a "don't traverse" annotation to a
selectable, without digging throughout the whole
structure wasting time.

**Line:** 529

---

### `def _new_annotation_type(cls: Type[SupportsWrappingAnnotations], base_cls: Type[Annotated]) -> Type[Annotated]`

**Description:**
Generates a new class that subclasses Annotated and proxies a given
element type.

**Line:** 542

---

### `def _prepare_annotations(target_hierarchy: Type[SupportsWrappingAnnotations], base_cls: Type[Annotated]) -> None`

**Line:** 589

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.base
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/base.py`

**Imports:**
- __future__.annotations
- _orm_types.DMLStrategyArgument
- _orm_types.SynchronizeSessionArgument
- _typing._CLE
- cache_key.HasCacheKey
- cache_key.MemoizedHasCacheKey
- collections
- elements.BindParameter
- elements.ClauseList
- elements.ColumnClause
- elements.ColumnElement
- elements.KeyedColumnElement
- elements.NamedColumn
- elements.SQLCoreOperations
- elements.TextClause
- engine.Connection
- engine.CursorResult
- engine.interfaces.CacheStats
- engine.interfaces.Compiled
- engine.interfaces.CompiledCacheType
- engine.interfaces.CoreExecuteOptionsParameter
- engine.interfaces.Dialect
- engine.interfaces.IsolationLevel
- engine.interfaces.SchemaTranslateMapType
- engine.interfaces._CoreMultiExecuteParams
- engine.interfaces._ExecuteOptions
- engine.interfaces._ImmutableExecuteOptions
- enum.Enum
- event.dispatcher
- itertools
- itertools.zip_longest
- operator
- re
- schema.Column
- schema.DefaultGenerator
- selectable.FromClause
- selectable._JoinTargetElement
- selectable._SelectIterable
- traversals.HasCopyInternals
- typing.Any
- typing.Callable
- typing.Dict
- typing.FrozenSet
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.MutableMapping
- typing.NamedTuple
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.HasMemoized
- util.hybridmethod
- util.typing
- util.typing.Protocol
- util.typing.Self
- util.typing.TypeGuard
- visitors.ClauseVisitor
- visitors.ExtendedInternalTraversal
- visitors.ExternallyTraversible
- visitors.InternalTraversal

**Functions:**

### `def _is_has_entity_namespace(element: Any) -> TypeGuard[_HasEntityNamespace]`

**Line:** 168

---

### `def _from_objects(*elements: Union[(ColumnElement[Any], FromClause, TextClause, _JoinTargetElement)]) -> Iterator[FromClause]`

**Line:** 238

---

### `def _select_iterables(elements: Iterable[roles.ColumnsClauseRole]) -> _SelectIterable`

**Description:**
expand tables into individual columns in the
given list of column expressions.

**Line:** 248

---

### `def _generative(fn: _Fn) -> _Fn`

**Description:**
non-caching _generative() decorator.

This is basically the legacy decorator that copies the object and
runs a method on the new copy.

**Line:** 268

---

### `def _exclusive_against(*names: str, **kw: Any) -> Callable[([_Fn], _Fn)]`

**Line:** 292

---

### `def _clone(element, **kw)`

**Line:** 321

---

### `def _expand_cloned(elements: Iterable[_CLE]) -> Iterable[_CLE]`

**Description:**
expand the given set of ClauseElements to be the set of all 'cloned'
predecessors.

**Line:** 325

---

### `def _de_clone(elements: Iterable[_CLE]) -> Iterable[_CLE]`

**Line:** 336

---

### `def _cloned_intersection(a: Iterable[_CLE], b: Iterable[_CLE]) -> Set[_CLE]`

**Description:**
return the intersection of sets a and b, counting
any overlap between 'cloned' predecessors.

The returned set is in terms of the entities present within 'a'.

**Line:** 345

---

### `def _cloned_difference(a: Iterable[_CLE], b: Iterable[_CLE]) -> Set[_CLE]`

**Line:** 356

---

### `def _kw_reg_for_dialect(dialect_name)`

**Decorators:**
- `@util.preload_module(...)`

**Line:** 453

---

### `def _entity_namespace(entity: Union[(_HasEntityNamespace, ExternallyTraversible)]) -> _EntityNamespace`

**Description:**
Return the nearest .entity_namespace for the given entity.

If not immediately available, does an iterate to find a sub-element
that has one, if any.

**Line:** 2155

---

### `def _entity_namespace_key(entity: Union[(_HasEntityNamespace, ExternallyTraversible)], key: str, default: Union[(SQLCoreOperations[Any], _NoArg)] = NO_ARG) -> SQLCoreOperations[Any]`

**Description:**
Return an entry from an entity_namespace.


Raises :class:`_exc.InvalidRequestError` rather than attribute error
on not found.

**Line:** 2174

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.cache_key
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/cache_key.py`

**Imports:**
- __future__.annotations
- elements.BindParameter
- elements.ClauseElement
- engine.interfaces._CoreSingleExecuteParams
- enum
- inspection.inspect
- itertools.zip_longest
- typing
- typing.Any
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.MutableMapping
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.Tuple
- typing.Union
- util.HasMemoized
- util.typing.Literal
- util.typing.Protocol
- visitors.HasTraversalDispatch
- visitors.HasTraverseInternals
- visitors.InternalTraversal
- visitors._TraverseInternalsType
- visitors.anon_map
- visitors.prefix_anon_map

**Functions:**

### `def _ad_hoc_cache_key_from_args(tokens: Tuple[(Any, ...)], traverse_args: Iterable[Tuple[(str, InternalTraversal)]], args: Iterable[Any]) -> Tuple[(Any, ...)]`

**Description:**
a quick cache key generator used by reflection.flexi_cache.

**Line:** 560

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.coercions
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/coercions.py`

**Imports:**
- __future__.annotations
- _typing._ColumnExpressionArgument
- _typing._ColumnsClauseArgument
- _typing._DDLColumnArgument
- _typing._DMLTableArgument
- _typing._FromClauseArgument
- _typing.is_from_clause
- base.ExecutableOption
- base.Options
- cache_key.HasCacheKey
- collections.abc
- dml._DMLTableElement
- elements.BindParameter
- elements.ClauseElement
- elements.ColumnClause
- elements.ColumnElement
- elements.DQLDMLClauseElement
- elements.NamedColumn
- elements.SQLCoreOperations
- numbers
- re
- schema.Column
- selectable.FromClause
- selectable.HasCTE
- selectable.SelectBase
- selectable.Subquery
- selectable._ColumnsClauseElement
- selectable._JoinTargetProtocol
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util._deep_deannotate
- util.typing.Literal
- visitors.Visitable
- visitors._TraverseCallableType

**Functions:**

### `def _is_literal(element)`

**Description:**
Return whether or not the element is a "literal" in the context
of a SQL expression construct.

**Line:** 79

---

### `def _deep_is_literal(element)`

**Description:**
Return whether or not the element is a "literal" in the context
of a SQL expression construct.

does a deeper more esoteric check than _is_literal.   is used
for lambda elements that have to distinguish values that would
be bound vs. not without any context.

**Line:** 91

---

### `def _document_text_coercion(paramname: str, meth_rst: str, param_rst: str) -> Callable[([_F], _F)]`

**Line:** 129

---

### `def _expression_collection_was_a_list(attrname: str, fnname: str, args: Union[(Sequence[_T], Sequence[Sequence[_T]])]) -> Sequence[_T]`

**Line:** 145

---

### `def expect(role: Type[roles.TruncatedLabelRole], element: Any, **kw: Any) -> str`

**Decorators:**
- `@overload`

**Line:** 164

---

### `def expect(role: Type[roles.DMLColumnRole], element: Any, as_key: Literal[True] = Ellipsis, **kw: Any) -> str`

**Decorators:**
- `@overload`

**Line:** 173

---

### `def expect(role: Type[roles.LiteralValueRole], element: Any, **kw: Any) -> BindParameter[Any]`

**Decorators:**
- `@overload`

**Line:** 184

---

### `def expect(role: Type[roles.DDLReferredColumnRole], element: Any, **kw: Any) -> Column[Any]`

**Decorators:**
- `@overload`

**Line:** 193

---

### `def expect(role: Type[roles.DDLConstraintColumnRole], element: Any, **kw: Any) -> Union[(Column[Any], str)]`

**Decorators:**
- `@overload`

**Line:** 202

---

### `def expect(role: Type[roles.StatementOptionRole], element: Any, **kw: Any) -> DQLDMLClauseElement`

**Decorators:**
- `@overload`

**Line:** 211

---

### `def expect(role: Type[roles.LabeledColumnExprRole[Any]], element: _ColumnExpressionArgument[_T], **kw: Any) -> NamedColumn[_T]`

**Decorators:**
- `@overload`

**Line:** 220

---

### `def expect(role: Union[(Type[roles.ExpressionElementRole[Any]], Type[roles.LimitOffsetRole], Type[roles.WhereHavingRole])], element: _ColumnExpressionArgument[_T], **kw: Any) -> ColumnElement[_T]`

**Decorators:**
- `@overload`

**Line:** 229

---

### `def expect(role: Union[(Type[roles.ExpressionElementRole[Any]], Type[roles.LimitOffsetRole], Type[roles.WhereHavingRole], Type[roles.OnClauseRole], Type[roles.ColumnArgumentRole])], element: Any, **kw: Any) -> ColumnElement[Any]`

**Decorators:**
- `@overload`

**Line:** 242

---

### `def expect(role: Type[roles.DMLTableRole], element: _DMLTableArgument, **kw: Any) -> _DMLTableElement`

**Decorators:**
- `@overload`

**Line:** 257

---

### `def expect(role: Type[roles.HasCTERole], element: HasCTE, **kw: Any) -> HasCTE`

**Decorators:**
- `@overload`

**Line:** 266

---

### `def expect(role: Type[roles.SelectStatementRole], element: SelectBase, **kw: Any) -> SelectBase`

**Decorators:**
- `@overload`

**Line:** 275

---

### `def expect(role: Type[roles.FromClauseRole], element: _FromClauseArgument, **kw: Any) -> FromClause`

**Decorators:**
- `@overload`

**Line:** 284

---

### `def expect(role: Type[roles.FromClauseRole], element: SelectBase, explicit_subquery: Literal[True] = Ellipsis, **kw: Any) -> Subquery`

**Decorators:**
- `@overload`

**Line:** 293

---

### `def expect(role: Type[roles.ColumnsClauseRole], element: _ColumnsClauseArgument[Any], **kw: Any) -> _ColumnsClauseElement`

**Decorators:**
- `@overload`

**Line:** 304

---

### `def expect(role: Type[roles.JoinTargetRole], element: _JoinTargetProtocol, **kw: Any) -> _JoinTargetProtocol`

**Decorators:**
- `@overload`

**Line:** 313

---

### `def expect(role: Type[_SR], element: Any, **kw: Any) -> Any`

**Decorators:**
- `@overload`

**Line:** 323

---

### `def expect(role: Type[_SR], element: Any, apply_propagate_attrs: Optional[ClauseElement] = None, argname: Optional[str] = None, post_inspect: bool = False, disable_inspection: bool = False, **kw: Any) -> Any`

**Line:** 331

---

### `def expect_as_key(role: Type[roles.DMLColumnRole], element: Any, **kw: Any) -> str`

**Line:** 447

---

### `def expect_col_expression_collection(role: Type[roles.DDLConstraintColumnRole], expressions: Iterable[_DDLColumnArgument]) -> Iterator[Tuple[(Union[str, Column[Any]], Optional[ColumnClause[Any]], Optional[str], Optional[Union[Column[Any], str]])]]`

**Line:** 454

---

### `def _no_text_coercion(element: Any, argname: Optional[str] = None, exc_cls: Type[exc.SQLAlchemyError] = exc.ArgumentError, extra: Optional[str] = None, err: Optional[Exception] = None) -> NoReturn`

**Line:** 594

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.crud
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/crud.py`

**Imports:**
- __future__.annotations
- base._DefaultDescriptionTuple
- compiler.SQLCompiler
- compiler._BindNameForColProtocol
- dml.DMLState
- dml.ValuesBase
- dml._DMLColumnElement
- dml.isinsert
- elements.ColumnClause
- elements.ColumnElement
- elements.KeyedColumnElement
- functools
- operator
- schema.Column
- schema._SQLExprDefault
- schema.default_is_clause_element
- schema.default_is_sequence
- selectable.Select
- selectable.TableClause
- typing.Any
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.List
- typing.MutableMapping
- typing.NamedTuple
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- typing.cast
- typing.overload
- util.typing.Literal

**Functions:**

### `def _as_dml_column(c: ColumnElement[Any]) -> ColumnClause[Any]`

**Line:** 74

---

### `def _get_crud_params(compiler: SQLCompiler, stmt: ValuesBase, compile_state: DMLState, toplevel: bool, **kw: Any) -> _CrudParams`

**Description:**
create a set of tuples representing column/string pairs for use
in an INSERT or UPDATE statement.

Also generates the Compiled object's postfetch, prefetch, and
returning column collections, used for default handling and ultimately
populating the CursorResult's prefetch_cols() and postfetch_cols()
collections.

**Line:** 114

---

### `def _create_bind_param(compiler: SQLCompiler, col: ColumnElement[Any], value: Any, process: Literal[True] = Ellipsis, required: bool = False, name: Optional[str] = None, **kw: Any) -> str`

**Decorators:**
- `@overload`

**Line:** 389

---

### `def _create_bind_param(compiler: SQLCompiler, col: ColumnElement[Any], value: Any, **kw: Any) -> str`

**Decorators:**
- `@overload`

**Line:** 402

---

### `def _create_bind_param(compiler: SQLCompiler, col: ColumnElement[Any], value: Any, process: bool = True, required: bool = False, name: Optional[str] = None, **kw: Any) -> Union[(str, elements.BindParameter[Any])]`

**Line:** 411

---

### `def _handle_values_anonymous_param(compiler, col, value, name, **kw)`

**Line:** 432

---

### `def _key_getters_for_crud_column(compiler: SQLCompiler, stmt: ValuesBase, compile_state: DMLState) -> Tuple[(Callable[[Union[str, ColumnClause[Any]]], Union[str, Tuple[str, str]]], Callable[[ColumnClause[Any]], Union[str, Tuple[str, str]]], _BindNameForColProtocol)]`

**Line:** 470

---

### `def _scan_insert_from_select_cols(compiler, stmt, compile_state, parameters, _getattr_col_key, _column_as_key, _col_bind_name, check_columns, values, toplevel, kw)`

**Line:** 524

---

### `def _scan_cols(compiler, stmt, compile_state, parameters, _getattr_col_key, _column_as_key, _col_bind_name, check_columns, values, toplevel, kw)`

**Line:** 593

---

### `def _setup_delete_return_defaults(compiler, stmt, compile_state, parameters, _getattr_col_key, _column_as_key, _col_bind_name, check_columns, values, toplevel, kw)`

**Line:** 789

---

### `def _append_param_parameter(compiler, stmt, compile_state, c, col_key, parameters, _col_bind_name, implicit_returning, implicit_return_defaults, postfetch_lastrowid, values, autoincrement_col, insert_null_pk_still_autoincrements, kw)`

**Line:** 819

---

### `def _append_param_insert_pk_returning(compiler, stmt, c, values, kw)`

**Description:**
Create a primary key expression in the INSERT statement where
we want to populate result.inserted_primary_key and RETURNING
is available.

**Line:** 930

---

### `def _append_param_insert_pk_no_returning(compiler, stmt, c, values, kw)`

**Description:**
Create a primary key expression in the INSERT statement where
we want to populate result.inserted_primary_key and we cannot use
RETURNING.

Depending on the kind of default here we may create a bound parameter
in the INSERT statement and pre-execute a default generation function,
or we may use cursor.lastrowid if supported by the dialect.

**Line:** 991

---

### `def _append_param_insert_hasdefault(compiler, stmt, c, implicit_return_defaults, values, kw)`

**Line:** 1068

---

### `def _append_param_insert_select_hasdefault(compiler: SQLCompiler, stmt: ValuesBase, c: ColumnClause[Any], values: List[_CrudParamElementSQLExpr], kw: Dict[(str, Any)]) -> None`

**Line:** 1123

---

### `def _append_param_update(compiler, compile_state, stmt, c, implicit_return_defaults, values, kw)`

**Line:** 1164

---

### `def _create_insert_prefetch_bind_param(compiler: SQLCompiler, c: ColumnElement[Any], process: Literal[True] = Ellipsis, **kw: Any) -> str`

**Decorators:**
- `@overload`

**Line:** 1211

---

### `def _create_insert_prefetch_bind_param(compiler: SQLCompiler, c: ColumnElement[Any], process: Literal[False], **kw: Any) -> elements.BindParameter[Any]`

**Decorators:**
- `@overload`

**Line:** 1221

---

### `def _create_insert_prefetch_bind_param(compiler: SQLCompiler, c: ColumnElement[Any], process: bool = True, name: Optional[str] = None, **kw: Any) -> Union[(elements.BindParameter[Any], str)]`

**Line:** 1230

---

### `def _create_update_prefetch_bind_param(compiler: SQLCompiler, c: ColumnElement[Any], process: Literal[True] = Ellipsis, **kw: Any) -> str`

**Decorators:**
- `@overload`

**Line:** 1245

---

### `def _create_update_prefetch_bind_param(compiler: SQLCompiler, c: ColumnElement[Any], process: Literal[False], **kw: Any) -> elements.BindParameter[Any]`

**Decorators:**
- `@overload`

**Line:** 1255

---

### `def _create_update_prefetch_bind_param(compiler: SQLCompiler, c: ColumnElement[Any], process: bool = True, name: Optional[str] = None, **kw: Any) -> Union[(elements.BindParameter[Any], str)]`

**Line:** 1264

---

### `def _process_multiparam_default_bind(compiler: SQLCompiler, stmt: ValuesBase, c: KeyedColumnElement[Any], index: int, kw: Dict[(str, Any)]) -> str`

**Line:** 1314

---

### `def _get_update_multitable_params(compiler, stmt, compile_state, stmt_parameter_tuples, check_columns, _col_bind_name, _getattr_col_key, values, kw)`

**Line:** 1347

---

### `def _extend_values_for_multiparams(compiler: SQLCompiler, stmt: ValuesBase, compile_state: DMLState, initial_values: Sequence[_CrudParamElementStr], _column_as_key: Callable[(..., str)], kw: Dict[(str, Any)]) -> List[Sequence[_CrudParamElementStr]]`

**Line:** 1429

---

### `def _get_stmt_parameter_tuples_params(compiler, compile_state, parameters, stmt_parameter_tuples, _column_as_key, values, kw)`

**Line:** 1473

---

### `def _get_returning_modifiers(compiler, stmt, compile_state, toplevel)`

**Description:**
determines RETURNING strategy, if any, for the statement.

This is where it's determined what we need to fetch from the
INSERT or UPDATE statement after it's invoked.

**Line:** 1515

---

### `def _warn_pk_with_no_anticipated_value(c)`

**Line:** 1652

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.ddl
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py`

**Imports:**
- __future__.annotations
- base.Executable
- base.SchemaVisitor
- base._generative
- compiler.Compiled
- compiler.DDLCompiler
- contextlib
- elements.BindParameter
- elements.ClauseElement
- engine.base.Connection
- engine.interfaces.CacheStats
- engine.interfaces.CompiledCacheType
- engine.interfaces.Dialect
- engine.interfaces.SchemaTranslateMapType
- schema.Constraint
- schema.ForeignKeyConstraint
- schema.SchemaItem
- schema.Sequence
- schema.Table
- selectable.TableClause
- typing
- typing.Any
- typing.Callable
- typing.Iterable
- typing.List
- typing.Optional
- typing.Sequence
- typing.Tuple
- util.topological
- util.typing.Protocol
- util.typing.Self

**Functions:**

### `def sort_tables(tables: Iterable[TableClause], skip_fn: Optional[Callable[([ForeignKeyConstraint], bool)]] = None, extra_dependencies: Optional[typing_Sequence[Tuple[(TableClause, TableClause)]]] = None) -> List[Table]`

**Description:**
Sort a collection of :class:`_schema.Table` objects based on
dependency.

This is a dependency-ordered sort which will emit :class:`_schema.Table`
objects such that they will follow their dependent :class:`_schema.Table`
objects.
Tables are dependent on another based on the presence of
:class:`_schema.ForeignKeyConstraint`
objects as well as explicit dependencies
added by :meth:`_schema.Table.add_is_dependent_on`.

.. warning::

The :func:`._schema.sort_tables` function cannot by itself
accommodate automatic resolution of dependency cycles between
tables, which are usually caused by mutually dependent foreign key
constraints. When these cycles are detected, the foreign keys
of these tables are omitted from consideration in the sort.
A warning is emitted when this condition occurs, which will be an
exception raise in a future release.   Tables which are not part
of the cycle will still be returned in dependency order.

To resolve these cycles, the
:paramref:`_schema.ForeignKeyConstraint.use_alter` parameter may be
applied to those constraints which create a cycle.  Alternatively,
the :func:`_schema.sort_tables_and_constraints` function will
automatically return foreign key constraints in a separate
collection when cycles are detected so that they may be applied
to a schema separately.

.. versionchanged:: 1.3.17 - a warning is emitted when
:func:`_schema.sort_tables` cannot perform a proper sort due to
cyclical dependencies.  This will be an exception in a future
release.  Additionally, the sort will continue to return
other tables not involved in the cycle in dependency order
which was not the case previously.

:param tables: a sequence of :class:`_schema.Table` objects.

:param skip_fn: optional callable which will be passed a
:class:`_schema.ForeignKeyConstraint` object; if it returns True, this
constraint will not be considered as a dependency.  Note this is
**different** from the same parameter in
:func:`.sort_tables_and_constraints`, which is
instead passed the owning :class:`_schema.ForeignKeyConstraint` object.

:param extra_dependencies: a sequence of 2-tuples of tables which will
also be considered as dependent on each other.

.. seealso::

:func:`.sort_tables_and_constraints`

:attr:`_schema.MetaData.sorted_tables` - uses this function to sort

**Line:** 1171

---

### `def sort_tables_and_constraints(tables, filter_fn = None, extra_dependencies = None, _warn_for_cycles = False)`

**Description:**
Sort a collection of :class:`_schema.Table`  /
:class:`_schema.ForeignKeyConstraint`
objects.

This is a dependency-ordered sort which will emit tuples of
``(Table, [ForeignKeyConstraint, ...])`` such that each
:class:`_schema.Table` follows its dependent :class:`_schema.Table`
objects.
Remaining :class:`_schema.ForeignKeyConstraint`
objects that are separate due to
dependency rules not satisfied by the sort are emitted afterwards
as ``(None, [ForeignKeyConstraint ...])``.

Tables are dependent on another based on the presence of
:class:`_schema.ForeignKeyConstraint` objects, explicit dependencies
added by :meth:`_schema.Table.add_is_dependent_on`,
as well as dependencies
stated here using the :paramref:`~.sort_tables_and_constraints.skip_fn`
and/or :paramref:`~.sort_tables_and_constraints.extra_dependencies`
parameters.

:param tables: a sequence of :class:`_schema.Table` objects.

:param filter_fn: optional callable which will be passed a
:class:`_schema.ForeignKeyConstraint` object,
and returns a value based on
whether this constraint should definitely be included or excluded as
an inline constraint, or neither.   If it returns False, the constraint
will definitely be included as a dependency that cannot be subject
to ALTER; if True, it will **only** be included as an ALTER result at
the end.   Returning None means the constraint is included in the
table-based result unless it is detected as part of a dependency cycle.

:param extra_dependencies: a sequence of 2-tuples of tables which will
also be considered as dependent on each other.

.. seealso::

:func:`.sort_tables`

**Line:** 1261

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.default_comparator
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/default_comparator.py`

**Imports:**
- __future__.annotations
- elements.BinaryExpression
- elements.ClauseElement
- elements.CollationClause
- elements.CollectionAggregate
- elements.ColumnElement
- elements.ExpressionClauseList
- elements.False_
- elements.Null
- elements.OperatorExpression
- elements.True_
- elements.UnaryExpression
- elements.and_
- elements.or_
- operators.OperatorType
- operators.custom_op
- type_api.TypeEngine
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.NoReturn
- typing.Optional
- typing.Tuple
- typing.Type
- typing.Union

**Functions:**

### `def _boolean_compare(expr: ColumnElement[Any], op: OperatorType, obj: Any, negate_op: Optional[OperatorType] = None, reverse: bool = False, _python_is_types: Tuple[(Type[Any], ...)] = (), _any_all_expr: bool = False, result_type: Optional[TypeEngine[bool]] = None, **kwargs: Any) -> OperatorExpression[bool]`

**Line:** 51

---

### `def _custom_op_operate(expr: ColumnElement[Any], op: custom_op[Any], obj: Any, reverse: bool = False, result_type: Optional[TypeEngine[Any]] = None, **kw: Any) -> ColumnElement[Any]`

**Line:** 146

---

### `def _binary_operate(expr: ColumnElement[Any], op: OperatorType, obj: roles.BinaryElementRole[Any], reverse: bool = False, result_type: Optional[TypeEngine[_T]] = None, **kw: Any) -> OperatorExpression[_T]`

**Line:** 165

---

### `def _conjunction_operate(expr: ColumnElement[Any], op: OperatorType, other: Any, **kw: Any) -> ColumnElement[Any]`

**Line:** 193

---

### `def _scalar(expr: ColumnElement[Any], op: OperatorType, fn: Callable[([ColumnElement[Any]], ColumnElement[Any])], **kw: Any) -> ColumnElement[Any]`

**Line:** 204

---

### `def _in_impl(expr: ColumnElement[Any], op: OperatorType, seq_or_selectable: ClauseElement, negate_op: OperatorType, **kw: Any) -> ColumnElement[Any]`

**Line:** 213

---

### `def _getitem_impl(expr: ColumnElement[Any], op: OperatorType, other: Any, **kw: Any) -> ColumnElement[Any]`

**Line:** 231

---

### `def _unsupported_impl(expr: ColumnElement[Any], op: OperatorType, *arg: Any, **kw: Any) -> NoReturn`

**Line:** 247

---

### `def _inv_impl(expr: ColumnElement[Any], op: OperatorType, **kw: Any) -> ColumnElement[Any]`

**Description:**
See :meth:`.ColumnOperators.__inv__`.

**Line:** 255

---

### `def _neg_impl(expr: ColumnElement[Any], op: OperatorType, **kw: Any) -> ColumnElement[Any]`

**Description:**
See :meth:`.ColumnOperators.__neg__`.

**Line:** 268

---

### `def _bitwise_not_impl(expr: ColumnElement[Any], op: OperatorType, **kw: Any) -> ColumnElement[Any]`

**Description:**
See :meth:`.ColumnOperators.bitwise_not`.

**Line:** 275

---

### `def _match_impl(expr: ColumnElement[Any], op: OperatorType, other: Any, **kw: Any) -> ColumnElement[Any]`

**Description:**
See :meth:`.ColumnOperators.match`.

**Line:** 285

---

### `def _distinct_impl(expr: ColumnElement[Any], op: OperatorType, **kw: Any) -> ColumnElement[Any]`

**Description:**
See :meth:`.ColumnOperators.distinct`.

**Line:** 307

---

### `def _between_impl(expr: ColumnElement[Any], op: OperatorType, cleft: Any, cright: Any, **kw: Any) -> ColumnElement[Any]`

**Description:**
See :meth:`.ColumnOperators.between`.

**Line:** 316

---

### `def _collate_impl(expr: ColumnElement[str], op: OperatorType, collation: str, **kw: Any) -> ColumnElement[str]`

**Line:** 351

---

### `def _regexp_match_impl(expr: ColumnElement[str], op: OperatorType, pattern: Any, flags: Optional[str], **kw: Any) -> ColumnElement[Any]`

**Line:** 357

---

### `def _regexp_replace_impl(expr: ColumnElement[Any], op: OperatorType, pattern: Any, replacement: Any, flags: Optional[str], **kw: Any) -> ColumnElement[Any]`

**Line:** 378

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.dml
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/dml.py`

**Imports:**
- __future__.annotations
- _typing._ColumnExpressionArgument
- _typing._ColumnsClauseArgument
- _typing._DMLColumnArgument
- _typing._DMLColumnKeyMapping
- _typing._DMLTableArgument
- _typing._T0
- _typing._T1
- _typing._T2
- _typing._T3
- _typing._T4
- _typing._T5
- _typing._T6
- _typing._T7
- _typing._TP
- _typing._TypedColumnClauseArgument
- _typing._unexpected_kw
- _typing.is_column_element
- _typing.is_named_from_clause
- base.ColumnCollection
- base.CompileState
- base.DialectKWArgs
- base.Executable
- base.Generative
- base.HasCompileState
- base.ReadOnlyColumnCollection
- base._entity_namespace_key
- base._exclusive_against
- base._from_objects
- base._generative
- base._select_iterables
- collections.abc
- compiler.SQLCompiler
- elements.BooleanClauseList
- elements.ClauseElement
- elements.ColumnClause
- elements.ColumnElement
- elements.KeyedColumnElement
- elements.Null
- operator
- selectable.Alias
- selectable.ExecutableReturnsRows
- selectable.FromClause
- selectable.HasCTE
- selectable.HasPrefixes
- selectable.Join
- selectable.Select
- selectable.SelectLabelStyle
- selectable.Selectable
- selectable.TableClause
- selectable.TypedReturnsRows
- selectable._ColumnsClauseElement
- selectable._SelectIterable
- sqltypes.NullType
- typing.Any
- typing.Dict
- typing.Iterable
- typing.List
- typing.MutableMapping
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.typing.Self
- util.typing.TypeGuard
- visitors.InternalTraversal

**Functions:**

### `def isupdate(dml: DMLState) -> TypeGuard[UpdateDMLState]`

**Line:** 94

---

### `def isdelete(dml: DMLState) -> TypeGuard[DeleteDMLState]`

**Line:** 97

---

### `def isinsert(dml: DMLState) -> TypeGuard[InsertDMLState]`

**Line:** 100

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.elements
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/elements.py`

**Imports:**
- __future__.annotations
- _typing._ColumnExpressionArgument
- _typing._ColumnExpressionOrStrLabelArgument
- _typing._InfoType
- _typing._PropagateAttrsType
- _typing._TypeEngineArgument
- _typing.has_schema_attr
- _typing.is_named_from_clause
- _typing.is_quoted_name
- _typing.is_tuple_type
- annotation.Annotated
- annotation.SupportsWrappingAnnotations
- base.Executable
- base.Generative
- base.HasMemoized
- base.Immutable
- base.NO_ARG
- base.SingletonConstant
- base._NoArg
- base._clone
- base._expand_cloned
- base._generative
- cache_key.CacheKey
- cache_key.MemoizedHasCacheKey
- cache_key.NO_CACHE
- cache_key._CacheKeyTraversalType
- coercions._document_text_coercion
- compiler.Compiled
- compiler.SQLCompiler
- decimal.Decimal
- engine.Connection
- engine.Dialect
- engine.Engine
- engine.interfaces.CacheStats
- engine.interfaces.CompiledCacheType
- engine.interfaces.CoreExecuteOptionsParameter
- engine.interfaces.SchemaTranslateMapType
- engine.interfaces._CoreMultiExecuteParams
- engine.result.Result
- enum.IntEnum
- functions.FunctionElement
- itertools
- operator
- operators.ColumnOperators
- operators.OperatorType
- re
- schema.Column
- schema.DefaultGenerator
- schema.FetchedValue
- schema.ForeignKey
- selectable.FromClause
- selectable.NamedFromClause
- selectable.TextualSelect
- selectable._SelectIterable
- sqltypes.TupleType
- traversals.HasCopyInternals
- type_api.TypeEngine
- typing
- typing.AbstractSet
- typing.Any
- typing.Callable
- typing.Dict
- typing.FrozenSet
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.HasMemoized_ro_memoized_attribute
- util.TypingOnly
- util.typing.Literal
- util.typing.Self
- visitors.ExternallyTraversible
- visitors.InternalTraversal
- visitors.Visitable
- visitors._CloneCallableType
- visitors._TraverseInternalsType
- visitors.cloned_traverse
- visitors.traverse

**Functions:**

### `def literal(value: Any, type_: _TypeEngineArgument[_T], literal_execute: bool = False) -> BindParameter[_T]`

**Decorators:**
- `@overload`

**Line:** 128

---

### `def literal(value: _T, type_: None = None, literal_execute: bool = False) -> BindParameter[_T]`

**Decorators:**
- `@overload`

**Line:** 137

---

### `def literal(value: Any, type_: Optional[_TypeEngineArgument[Any]] = None, literal_execute: bool = False) -> BindParameter[Any]`

**Decorators:**
- `@overload`

**Line:** 146

---

### `def literal(value: Any, type_: Optional[_TypeEngineArgument[Any]] = None, literal_execute: bool = False) -> BindParameter[Any]`

**Description:**
Return a literal clause, bound to a bind parameter.

Literal clauses are created automatically when non-
:class:`_expression.ClauseElement` objects (such as strings, ints, dates,
etc.) are
used in a comparison operation with a :class:`_expression.ColumnElement`
subclass,
such as a :class:`~sqlalchemy.schema.Column` object.  Use this function
to force the generation of a literal clause, which will be created as a
:class:`BindParameter` with a bound value.

:param value: the value to be bound. Can be any Python object supported by
the underlying DB-API, or is translatable via the given type argument.

:param type\_: an optional :class:`~sqlalchemy.types.TypeEngine` which will
provide bind-parameter translation for this literal.

:param literal_execute: optional bool, when True, the SQL engine will
attempt to render the bound value directly in the SQL statement at
execution time rather than providing as a parameter value.

.. versionadded:: 2.0

**Line:** 154

---

### `def literal_column(text: str, type_: Optional[_TypeEngineArgument[_T]] = None) -> ColumnClause[_T]`

**Description:**
Produce a :class:`.ColumnClause` object that has the
:paramref:`_expression.column.is_literal` flag set to True.

:func:`_expression.literal_column` is similar to
:func:`_expression.column`, except that
it is more often used as a "standalone" column expression that renders
exactly as stated; while :func:`_expression.column`
stores a string name that
will be assumed to be part of a table and may be quoted as such,
:func:`_expression.literal_column` can be that,
or any other arbitrary column-oriented
expression.

:param text: the text of the expression; can be any SQL expression.
Quoting rules will not be applied. To specify a column-name expression
which should be subject to quoting rules, use the :func:`column`
function.

:param type\_: an optional :class:`~sqlalchemy.types.TypeEngine`
object which will
provide result-set translation and additional expression semantics for
this column. If left as ``None`` the type will be :class:`.NullType`.

.. seealso::

:func:`_expression.column`

:func:`_expression.text`

:ref:`tutorial_select_arbitrary_text`

**Line:** 191

---

### `def _find_columns(clause: ClauseElement) -> Set[ColumnClause[Any]]`

**Description:**
locate Column objects within the given expression.

**Line:** 5197

---

### `def _type_from_args(args)`

**Line:** 5205

---

### `def _corresponding_column_or_error(fromclause, column, require_embedded = False)`

**Line:** 5213

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.functions
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/functions.py`

**Imports:**
- __future__.annotations
- _typing._TypeEngineArgument
- _typing.is_table_value_type
- base.ColumnCollection
- base.Executable
- base.Generative
- base.HasMemoized
- base._entity_namespace
- datetime
- decimal
- elements.BinaryExpression
- elements.BindParameter
- elements.Cast
- elements.ClauseList
- elements.ColumnElement
- elements.Extract
- elements.FunctionFilter
- elements.Grouping
- elements.NamedColumn
- elements.Over
- elements.WithinGroup
- elements._type_from_args
- elements.literal_column
- engine.base.Connection
- engine.cursor.CursorResult
- engine.interfaces.CoreExecuteOptionsParameter
- engine.interfaces._CoreMultiExecuteParams
- selectable.FromClause
- selectable.Select
- selectable.TableValuedAlias
- sqltypes.TableValueType
- type_api.TypeEngine
- typing.Any
- typing.Dict
- typing.Mapping
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.cast
- typing.overload
- visitors.InternalTraversal

**Functions:**

### `def register_function(identifier, fn, package = '_default')`

**Description:**
Associate a callable with a particular func. name.

This is normally called by GenericFunction, but is also
available by itself so that a non-Function construct
can be associated with the :data:`.func` accessor (i.e.
CAST, EXTRACT).

**Line:** 78

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.lambdas
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/lambdas.py`

**Imports:**
- __future__.annotations
- base.Executable
- base.Options
- base._clone
- cache_key.CacheConst
- collections.abc
- elements.BindParameter
- elements.ClauseElement
- inspect
- itertools
- operator
- operators.ColumnOperators
- roles.SQLRole
- threading
- types
- types.CodeType
- typing.Any
- typing.Callable
- typing.List
- typing.MutableMapping
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- util.typing.Literal
- visitors._CloneCallableType
- weakref

**Functions:**

### `def lambda_stmt(lmb: _StmtLambdaType, enable_tracking: bool = True, track_closure_variables: bool = True, track_on: Optional[object] = None, global_track_bound_values: bool = True, track_bound_values: bool = True, lambda_cache: Optional[_LambdaCacheType] = None) -> StatementLambdaElement`

**Description:**
Produce a SQL statement that is cached as a lambda.

The Python code object within the lambda is scanned for both Python
literals that will become bound parameters as well as closure variables
that refer to Core or ORM constructs that may vary.   The lambda itself
will be invoked only once per particular set of constructs detected.

E.g.::

from sqlalchemy import lambda_stmt

stmt = lambda_stmt(lambda: table.select())
stmt += lambda s: s.where(table.c.id == 5)

result = connection.execute(stmt)

The object returned is an instance of :class:`_sql.StatementLambdaElement`.

.. versionadded:: 1.4

:param lmb: a Python function, typically a lambda, which takes no arguments
and returns a SQL expression construct
:param enable_tracking: when False, all scanning of the given lambda for
changes in closure variables or bound parameters is disabled.  Use for
a lambda that produces the identical results in all cases with no
parameterization.
:param track_closure_variables: when False, changes in closure variables
within the lambda will not be scanned.   Use for a lambda where the
state of its closure variables will never change the SQL structure
returned by the lambda.
:param track_bound_values: when False, bound parameter tracking will
be disabled for the given lambda.  Use for a lambda that either does
not produce any bound values, or where the initial bound values never
change.
:param global_track_bound_values: when False, bound parameter tracking
will be disabled for the entire statement including additional links
added via the :meth:`_sql.StatementLambdaElement.add_criteria` method.
:param lambda_cache: a dictionary or other mapping-like object where
information about the lambda's Python code as well as the tracked closure
variables in the lambda itself will be stored.   Defaults
to a global LRU cache.  This cache is independent of the "compiled_cache"
used by the :class:`_engine.Connection` object.

.. seealso::

:ref:`engine_lambda_caching`

**Line:** 81

---

### `def insp(lmb)`

**Decorators:**
- `@inspection._inspects(...)`

**Line:** 1449

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.naming
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/naming.py`

**Imports:**
- __future__.annotations
- base._NONE_NAME
- elements.conv
- re
- schema.CheckConstraint
- schema.Column
- schema.Constraint
- schema.ForeignKeyConstraint
- schema.Index
- schema.PrimaryKeyConstraint
- schema.Table
- schema.UniqueConstraint

**Functions:**

### `def _get_convention(dict_, key)`

**Line:** 142

---

### `def _constraint_name_for_table(const, table)`

**Line:** 152

---

### `def _column_added_to_pk_constraint(pk_constraint, col)`

**Decorators:**
- `@event.listens_for(...)`

**Line:** 178

---

### `def _constraint_name(const, table)`

**Decorators:**
- `@event.listens_for(...)`
- `@event.listens_for(...)`

**Line:** 193

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.operators
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/operators.py`

**Imports:**
- __future__.annotations
- _typing.ColumnExpressionArgument
- cache_key.CacheConst
- elements.ColumnElement
- enum.IntEnum
- operator.add
- operator.and_
- operator.contains
- operator.eq
- operator.floordiv
- operator.ge
- operator.getitem
- operator.gt
- operator.inv
- operator.le
- operator.lshift
- operator.lt
- operator.mod
- operator.mul
- operator.ne
- operator.neg
- operator.or_
- operator.rshift
- operator.sub
- operator.truediv
- type_api.TypeEngine
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generic
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.typing.Literal
- util.typing.Protocol

**Functions:**

### `def _operator_fn(fn: Callable[(..., Any)]) -> OperatorType`

**Line:** 1927

---

### `def commutative_op(fn: _FN) -> _FN`

**Line:** 1931

---

### `def comparison_op(fn: _FN) -> _FN`

**Line:** 1936

---

### `def from_() -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 1942

---

### `def function_as_comparison_op() -> Any`

**Decorators:**
- `@_operator_fn`
- `@comparison_op`

**Line:** 1948

---

### `def as_() -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 1953

---

### `def exists() -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 1958

---

### `def is_true(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 1963

---

### `def istrue(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 1971

---

### `def is_false(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 1979

---

### `def isfalse(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 1987

---

### `def is_distinct_from(a: Any, b: Any) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 1996

---

### `def is_not_distinct_from(a: Any, b: Any) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2002

---

### `def isnot_distinct_from(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2010

---

### `def is_(a: Any, b: Any) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2019

---

### `def is_not(a: Any, b: Any) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2025

---

### `def isnot(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2033

---

### `def collate(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2041

---

### `def op(a: Any, opstring: str, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2046

---

### `def like_op(a: Any, b: Any, escape: Optional[str] = None) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2052

---

### `def not_like_op(a: Any, b: Any, escape: Optional[str] = None) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2058

---

### `def notlike_op(a: Any, b: Any, escape: Optional[str] = None) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2066

---

### `def ilike_op(a: Any, b: Any, escape: Optional[str] = None) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2075

---

### `def not_ilike_op(a: Any, b: Any, escape: Optional[str] = None) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2081

---

### `def notilike_op(a: Any, b: Any, escape: Optional[str] = None) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2089

---

### `def between_op(a: Any, b: Any, c: Any, symmetric: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2098

---

### `def not_between_op(a: Any, b: Any, c: Any, symmetric: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2104

---

### `def notbetween_op(a: Any, b: Any, c: Any, symmetric: bool = False) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2112

---

### `def in_op(a: Any, b: Any) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2121

---

### `def not_in_op(a: Any, b: Any) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2127

---

### `def notin_op(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2135

---

### `def distinct_op(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2143

---

### `def any_op(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2148

---

### `def all_op(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2153

---

### `def _escaped_like_impl(fn: Callable[(..., Any)], other: Any, escape: Optional[str], autoescape: bool) -> Any`

**Line:** 2157

---

### `def startswith_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2181

---

### `def not_startswith_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2189

---

### `def notstartswith_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2199

---

### `def istartswith_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2210

---

### `def not_istartswith_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2218

---

### `def endswith_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2226

---

### `def not_endswith_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2234

---

### `def notendswith_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2244

---

### `def iendswith_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2255

---

### `def not_iendswith_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2263

---

### `def contains_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2271

---

### `def not_contains_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2279

---

### `def notcontains_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2289

---

### `def icontains_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2300

---

### `def not_icontains_op(a: Any, b: Any, escape: Optional[str] = None, autoescape: bool = False) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2308

---

### `def match_op(a: Any, b: Any, **kw: Any) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2316

---

### `def regexp_match_op(a: Any, b: Any, flags: Optional[str] = None) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2322

---

### `def not_regexp_match_op(a: Any, b: Any, flags: Optional[str] = None) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2328

---

### `def regexp_replace_op(a: Any, b: Any, replacement: Any, flags: Optional[str] = None) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2333

---

### `def not_match_op(a: Any, b: Any, **kw: Any) -> Any`

**Decorators:**
- `@comparison_op`
- `@_operator_fn`

**Line:** 2341

---

### `def notmatch_op(a: Any, b: Any, **kw: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2349

---

### `def comma_op(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2357

---

### `def filter_op(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2362

---

### `def concat_op(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2367

---

### `def desc_op(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2377

---

### `def asc_op(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2382

---

### `def nulls_first_op(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2387

---

### `def nullsfirst_op(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2395

---

### `def nulls_last_op(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2403

---

### `def nullslast_op(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2411

---

### `def json_getitem_op(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2419

---

### `def json_path_getitem_op(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2424

---

### `def bitwise_xor_op(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2429

---

### `def bitwise_or_op(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2434

---

### `def bitwise_and_op(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2439

---

### `def bitwise_not_op(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2444

---

### `def bitwise_lshift_op(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2449

---

### `def bitwise_rshift_op(a: Any, b: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2454

---

### `def is_comparison(op: OperatorType) -> bool`

**Line:** 2458

---

### `def is_commutative(op: OperatorType) -> bool`

**Line:** 2462

---

### `def is_ordering_modifier(op: OperatorType) -> bool`

**Line:** 2466

---

### `def is_natural_self_precedent(op: OperatorType) -> bool`

**Line:** 2470

---

### `def is_boolean(op: OperatorType) -> bool`

**Line:** 2481

---

### `def mirror(op: OperatorType) -> OperatorType`

**Description:**
rotate a comparison operator 180 degrees.

Note this is not the same as negation.

**Line:** 2488

---

### `def is_associative(op: OperatorType) -> bool`

**Line:** 2500

---

### `def _asbool(a: Any) -> Any`

**Decorators:**
- `@_operator_fn`

**Line:** 2514

---

### `def is_precedent(operator: OperatorType, against: OperatorType) -> bool`

**Line:** 2585

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.schema
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/schema.py`

**Imports:**
- __future__.annotations
- _typing._AutoIncrementType
- _typing._DDLColumnArgument
- _typing._InfoType
- _typing._TextCoercedExpressionArgument
- _typing._TypeEngineArgument
- abc.ABC
- base.DedupeColumnCollection
- base.DialectKWArgs
- base.Executable
- base.ReadOnlyColumnCollection
- base.SchemaEventTarget
- base._DefaultDescriptionTuple
- base._NoneName
- base._SentinelColumnCharacterization
- base._SentinelDefaultCharacterization
- coercions._document_text_coercion
- collections
- compiler.DDLCompiler
- elements.BindParameter
- elements.ClauseElement
- elements.ColumnClause
- elements.ColumnElement
- elements.TextClause
- elements.quoted_name
- engine.Connection
- engine.Engine
- engine.interfaces.CoreExecuteOptionsParameter
- engine.interfaces.ExecutionContext
- engine.interfaces._CoreMultiExecuteParams
- engine.mock.MockConnection
- engine.reflection._ReflectionInfo
- enum.Enum
- functions.Function
- operator
- selectable.TableClause
- sql.selectable.FromClause
- type_api.TypeEngine
- type_api.to_instance
- typing
- typing.Any
- typing.Callable
- typing.Collection
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.HasMemoized
- util.typing.Final
- util.typing.Literal
- util.typing.Protocol
- util.typing.Self
- util.typing.TypeGuard
- util.typing.TypedDict
- visitors.ExternallyTraversible
- visitors.InternalTraversal
- visitors._TraverseInternalsType
- visitors.anon_map

**Functions:**

### `def _get_table_key(name: str, schema: Optional[str]) -> str`

**Line:** 173

---

### `def _copy_expression(expression: ColumnElement[Any], source_table: Optional[Table], target_table: Optional[Table]) -> ColumnElement[Any]`

**Line:** 182

---

### `def insert_sentinel(name: Optional[str] = None, type_: Optional[_TypeEngineArgument[_T]] = None, default: Optional[Any] = None, omit_from_statements: bool = True) -> Column[Any]`

**Description:**
Provides a surrogate :class:`_schema.Column` that will act as a
dedicated insert :term:`sentinel` column, allowing efficient bulk
inserts with deterministic RETURNING sorting for tables that
don't otherwise have qualifying primary key configurations.

Adding this column to a :class:`.Table` object requires that a
corresponding database table actually has this column present, so if adding
it to an existing model, existing database tables would need to be migrated
(e.g. using ALTER TABLE or similar) to include this column.

For background on how this object is used, see the section
:ref:`engine_insertmanyvalues_sentinel_columns` as part of the
section :ref:`engine_insertmanyvalues`.

The :class:`_schema.Column` returned will be a nullable integer column by
default and make use of a sentinel-specific default generator used only in
"insertmanyvalues" operations.

.. seealso::

:func:`_orm.orm_insert_sentinel`

:paramref:`_schema.Column.insert_sentinel`

:ref:`engine_insertmanyvalues`

:ref:`engine_insertmanyvalues_sentinel_columns`


.. versionadded:: 2.0.10

**Line:** 2673

---

### `def default_is_sequence(obj: Optional[DefaultGenerator]) -> TypeGuard[Sequence]`

**Line:** 3284

---

### `def default_is_clause_element(obj: Optional[DefaultGenerator]) -> TypeGuard[ColumnElementColumnDefault]`

**Line:** 3289

---

### `def default_is_scalar(obj: Optional[DefaultGenerator]) -> TypeGuard[ScalarElementColumnDefault]`

**Line:** 3294

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.sqltypes
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/sqltypes.py`

**Imports:**
- __future__.annotations
- _typing._ColumnExpressionArgument
- _typing._TypeEngineArgument
- base.NO_ARG
- base.SchemaEventTarget
- base._NONE_NAME
- cache_key.HasCacheKey
- collections.abc
- datetime
- decimal
- elements.Slice
- elements.TypeCoerce
- elements.quoted_name
- engine.interfaces.Dialect
- engine.processors
- enum
- json
- operators.OperatorType
- pickle
- schema.MetaData
- type_api.Emulated
- type_api.NativeForEmulated
- type_api.TypeDecorator
- type_api.TypeEngine
- type_api.TypeEngineMixin
- type_api.Variant
- type_api._BindProcessorType
- type_api._ComparatorFactory
- type_api._MatchedOnType
- type_api._ResultProcessorType
- type_api.to_instance
- typing.Any
- typing.Callable
- typing.Dict
- typing.List
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.OrderedDict
- util.langhelpers
- util.typing.Literal
- util.typing.is_literal
- util.typing.typing_get_args
- uuid.UUID
- visitors.InternalTraversal

**Functions:**

### `def _resolve_value_to_type(value: Any) -> TypeEngine[Any]`

**Line:** 3814

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.traversals
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/traversals.py`

**Imports:**
- __future__.annotations
- cache_key.HasCacheKey
- collections.abc
- collections.deque
- itertools
- itertools.zip_longest
- operator
- typing
- typing.Any
- typing.Callable
- typing.Deque
- typing.Dict
- typing.Iterable
- typing.Optional
- typing.Set
- typing.Tuple
- typing.Type
- util.langhelpers
- util.typing.Self
- visitors.ExternallyTraversible
- visitors.HasTraversalDispatch
- visitors.HasTraverseInternals
- visitors._TraverseInternalsType
- visitors.anon_map

**Functions:**

### `def compare(obj1: Any, obj2: Any, **kw: Any) -> bool`

**Line:** 44

---

### `def _preconfigure_traversals(target_hierarchy: Type[Any]) -> None`

**Line:** 54

---

### `def _clone(element, **kw)`

**Line:** 209

---

### `def _flatten_clauseelement(element)`

**Line:** 375

---

### `def _resolve_name_for_compare(element, name, anon_map, **kw)`

**Decorators:**
- `@util.preload_module(...)`

**Line:** 459

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.type_api
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py`

**Imports:**
- __future__.annotations
- _typing._TypeEngineArgument
- base.SchemaEventTarget
- cache_key.CacheConst
- cache_key.NO_CACHE
- elements.BindParameter
- elements.ColumnElement
- engine.interfaces.Dialect
- enum.Enum
- operators.ColumnOperators
- operators.OperatorType
- sqltypes.BOOLEANTYPE
- sqltypes.INDEXABLE
- sqltypes.INTEGERTYPE
- sqltypes.MATCHTYPE
- sqltypes.NULLTYPE
- sqltypes.NUMERICTYPE
- sqltypes.STRINGTYPE
- sqltypes.TABLEVALUE
- sqltypes._resolve_value_to_type
- types.ModuleType
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.Generic
- typing.Mapping
- typing.NewType
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.typing.GenericProtocol
- util.typing.Protocol
- util.typing.Self
- util.typing.TypeGuard
- util.typing.TypedDict
- visitors.Visitable

**Functions:**

### `def _is_native_for_emulated(typ: Type[Union[(TypeEngine[Any], TypeEngineMixin)]]) -> TypeGuard[Type[NativeForEmulated]]`

**Line:** 1461

---

### `def to_instance(typeobj: Union[(Type[_TE], _TE)], *arg: Any, **kw: Any) -> _TE`

**Decorators:**
- `@overload`

**Line:** 2283

---

### `def to_instance(typeobj: None, *arg: Any, **kw: Any) -> TypeEngine[None]`

**Decorators:**
- `@overload`

**Line:** 2288

---

### `def to_instance(typeobj: Union[(Type[_TE], _TE, None)], *arg: Any, **kw: Any) -> Union[(_TE, TypeEngine[None])]`

**Line:** 2292

---

### `def adapt_type(typeobj: TypeEngine[Any], colspecs: Mapping[(Type[Any], Type[TypeEngine[Any]])]) -> TypeEngine[Any]`

**Line:** 2304

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.util
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/util.py`

**Imports:**
- __future__.annotations
- _typing._EquivalentColumnMap
- _typing._LimitOffsetType
- _typing._TypeEngineArgument
- _typing.is_text_clause
- annotation._deep_annotate
- annotation._deep_deannotate
- annotation._shallow_annotate
- base._expand_cloned
- base._from_objects
- cache_key.HasCacheKey
- collections.deque
- copy
- ddl.sort_tables
- elements.BinaryExpression
- elements.BindParameter
- elements.ClauseElement
- elements.ColumnClause
- elements.ColumnElement
- elements.Grouping
- elements.KeyedColumnElement
- elements.Label
- elements.NamedColumn
- elements.Null
- elements.TextClause
- elements.UnaryExpression
- elements._find_columns
- elements._label_reference
- elements._textual_label_reference
- engine.interfaces._AnyExecuteParams
- engine.interfaces._AnyMultiExecuteParams
- engine.interfaces._AnySingleExecuteParams
- engine.interfaces._CoreSingleExecuteParams
- engine.row.Row
- itertools.chain
- schema.Column
- selectable.Alias
- selectable.FromClause
- selectable.FromGrouping
- selectable.Join
- selectable.ScalarSelect
- selectable.SelectBase
- selectable.Selectable
- selectable.TableClause
- selectable._JoinTargetElement
- selectable._SelectIterable
- typing
- typing.AbstractSet
- typing.Any
- typing.Callable
- typing.Collection
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Optional
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util.typing.Literal
- util.typing.Protocol
- visitors.ExternalTraversal
- visitors.ExternallyTraversible
- visitors._ET
- visitors._TraverseCallableType

**Functions:**

### `def join_condition(a: FromClause, b: FromClause, a_subset: Optional[FromClause] = None, consider_as_foreign_keys: Optional[AbstractSet[ColumnClause[Any]]] = None) -> ColumnElement[bool]`

**Description:**
Create a join condition between two tables or selectables.

e.g.::

join_condition(tablea, tableb)

would produce an expression along the lines of::

tablea.c.id==tableb.c.tablea_id

The join is determined based on the foreign key relationships
between the two selectables.   If there are multiple ways
to join, or no way to join, an error is raised.

:param a_subset: An optional expression that is a sub-component
of ``a``.  An attempt will be made to join to just this sub-component
first before looking at the full ``a`` construct, and if found
will be successful even if there are other ways to join to ``a``.
This allows the "right side" of a join to be passed thereby
providing a "natural join".

**Line:** 95

---

### `def find_join_source(clauses: List[FromClause], join_to: FromClause) -> List[int]`

**Description:**
Given a list of FROM clauses and a selectable,
return the first index and element from the list of
clauses which can be joined against the selectable.  returns
None, None if no match is found.

e.g.::

clause1 = table1.join(table2)
clause2 = table4.join(table5)

join_to = table2.join(table3)

find_join_source([clause1, clause2], join_to) == clause1

**Line:** 131

---

### `def find_left_clause_that_matches_given(clauses: Sequence[FromClause], join_from: FromClause) -> List[int]`

**Description:**
Given a list of FROM clauses and a selectable,
return the indexes from the list of
clauses which is derived from the selectable.

**Line:** 159

---

### `def find_left_clause_to_join_from(clauses: Sequence[FromClause], join_to: _JoinTargetElement, onclause: Optional[ColumnElement[Any]]) -> List[int]`

**Description:**
Given a list of FROM clauses, a selectable,
and optional ON clause, return a list of integer indexes from the
clauses list indicating the clauses that can be joined from.

The presence of an "onclause" indicates that at least one clause can
definitely be joined from; if the list of clauses is of length one
and the onclause is given, returns that index.   If the list of clauses
is more than length one, and the onclause is given, attempts to locate
which clauses contain the same columns.

**Line:** 203

---

### `def visit_binary_product(fn: Callable[([BinaryExpression[Any], ColumnElement[Any], ColumnElement[Any]], None)], expr: ColumnElement[Any]) -> None`

**Description:**
Produce a traversal of the given expression, delivering
column comparisons to the given function.

The function is of the form::

def my_fn(binary, left, right)

For each binary expression located which has a
comparison operator, the product of "left" and
"right" will be delivered to that function,
in terms of that binary.

Hence an expression like::

and_(
(a + b) == q + func.sum(e + f),
j == r
)

would have the traversal::

a <eq> q
a <eq> e
a <eq> f
b <eq> q
b <eq> e
b <eq> f
j <eq> r

That is, every combination of "left" and
"right" that doesn't further contain
a binary comparison is passed as pairs.

**Line:** 260

---

### `def find_tables(clause: ClauseElement, check_columns: bool = False, include_aliases: bool = False, include_joins: bool = False, include_selects: bool = False, include_crud: bool = False) -> List[TableClause]`

**Description:**
locate Table objects within the given expression.

**Line:** 327

---

### `def unwrap_order_by(clause)`

**Description:**
Break up an 'order by' expression into individual column-expressions,
without DESC/ASC/NULLS FIRST/NULLS LAST

**Line:** 370

---

### `def unwrap_label_reference(element)`

**Line:** 417

---

### `def expand_column_list_from_order_by(collist, order_by)`

**Description:**
Given the columns clause and ORDER BY of a selectable,
return a list of column expressions that can be added to the collist
corresponding to the ORDER BY, without repeating those already
in the collist.

**Line:** 430

---

### `def clause_is_present(clause, search)`

**Description:**
Given a target clause and a second to search within, return True
if the target is plainly present in the search without any
subqueries or aliases involved.

Basically descends through Joins.

**Line:** 447

---

### `def tables_from_leftmost(clause: FromClause) -> Iterator[FromClause]`

**Line:** 463

---

### `def surface_selectables(clause)`

**Line:** 473

---

### `def surface_selectables_only(clause)`

**Line:** 484

---

### `def extract_first_column_annotation(column, annotation_name)`

**Line:** 503

---

### `def selectables_overlap(left: FromClause, right: FromClause) -> bool`

**Description:**
Return True if left/right have some overlapping selectable

**Line:** 518

---

### `def bind_values(clause)`

**Description:**
Return an ordered list of "bound" values in the given clause.

E.g.::

>>> expr = and_(
...    table.c.foo==5, table.c.foo==7
... )
>>> bind_values(expr)
[5, 7]

**Line:** 526

---

### `def _quote_ddl_expr(element)`

**Line:** 547

---

### `def _repr_single_value(value)`

**Line:** 580

---

### `def adapt_criterion_to_null(crit: _CE, nulls: Collection[Any]) -> _CE`

**Description:**
given criterion containing bind params, convert selected elements
to IS NULL.

**Line:** 820

---

### `def splice_joins(left: Optional[FromClause], right: Optional[FromClause], stop_on: Optional[FromClause] = None) -> Optional[FromClause]`

**Line:** 847

---

### `def reduce_columns(columns: Iterable[ColumnElement[Any]], *clauses: Optional[ClauseElement], **kw: bool) -> Sequence[ColumnElement[Any]]`

**Decorators:**
- `@overload`

**Line:** 877

---

### `def reduce_columns(columns: _SelectIterable, *clauses: Optional[ClauseElement], **kw: bool) -> Sequence[Union[(ColumnElement[Any], TextClause)]]`

**Decorators:**
- `@overload`

**Line:** 886

---

### `def reduce_columns(columns: _SelectIterable, *clauses: Optional[ClauseElement], **kw: bool) -> Collection[Union[(ColumnElement[Any], TextClause)]]`

**Description:**
given a list of columns, return a 'reduced' set based on natural
equivalents.

the set is reduced to the smallest list of columns which have no natural
equivalent present in the list.  A "natural equivalent" means that two
columns will ultimately represent the same value because they are related
by a foreign key.

\*clauses is an optional list of join clauses which will be traversed
to further identify columns that are "equivalent".

\**kw may specify 'ignore_nonexistent_tables' to ignore foreign keys
whose tables are not yet configured, or columns that aren't yet present.

This function is primarily used to determine the most minimal "primary
key" from a selectable, by reducing the set of primary key columns present
in the selectable to just those that are not repeated.

**Line:** 894

---

### `def criterion_as_pairs(expression, consider_as_foreign_keys = None, consider_as_referenced_keys = None, any_operator = False)`

**Description:**
traverse an expression and locate binary criterion pairs.

**Line:** 978

---

### `def _offset_or_limit_clause(element: _LimitOffsetType, name: Optional[str] = None, type_: Optional[_TypeEngineArgument[int]] = None) -> ColumnElement[int]`

**Description:**
Convert the given value to an "offset or limit" clause.

This handles incoming integers and converts to an expression; if
an expression is already given, it is passed through.

**Line:** 1417

---

### `def _offset_or_limit_clause_asint_if_possible(clause: _LimitOffsetType) -> _LimitOffsetType`

**Description:**
Return the offset or limit clause as a simple integer if possible,
else return the clause.

**Line:** 1433

---

### `def _make_slice(limit_clause: _LimitOffsetType, offset_clause: _LimitOffsetType, start: int, stop: int) -> Tuple[(Optional[ColumnElement[int]], Optional[ColumnElement[int]])]`

**Description:**
Compute LIMIT/OFFSET in terms of slice start/end

**Line:** 1449

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.sql.visitors
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py`

**Imports:**
- __future__.annotations
- _py_util.cache_anon_map
- _py_util.prefix_anon_map
- annotation._AnnotationDict
- collections.deque
- elements.ColumnElement
- enum.Enum
- itertools
- operator
- sqlalchemy.cyextension.util.cache_anon_map
- sqlalchemy.cyextension.util.prefix_anon_map
- typing
- typing.Any
- typing.Callable
- typing.ClassVar
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- util._has_cy.HAS_CYEXTENSION
- util.langhelpers
- util.typing.Literal
- util.typing.Protocol
- util.typing.Self

**Functions:**

### `def _generate_traversal_dispatch() -> None`

**Line:** 582

---

### `def iterate(obj: Optional[ExternallyTraversible], opts: Mapping[(str, Any)] = util.EMPTY_DICT) -> Iterator[ExternallyTraversible]`

**Description:**
Traverse the given expression structure, returning an iterator.

Traversal is configured to be breadth-first.

The central API feature used by the :func:`.visitors.iterate`
function is the
:meth:`_expression.ClauseElement.get_children` method of
:class:`_expression.ClauseElement` objects.  This method should return all
the :class:`_expression.ClauseElement` objects which are associated with a
particular :class:`_expression.ClauseElement` object. For example, a
:class:`.Case` structure will refer to a series of
:class:`_expression.ColumnElement` objects within its "whens" and "else\_"
member variables.

:param obj: :class:`_expression.ClauseElement` structure to be traversed

:param opts: dictionary of iteration options.   This dictionary is usually
empty in modern usage.

**Line:** 823

---

### `def traverse_using(iterator: Iterable[ExternallyTraversible], obj: Literal[None], visitors: Mapping[(str, _TraverseCallableType[Any])]) -> None`

**Decorators:**
- `@overload`

**Line:** 865

---

### `def traverse_using(iterator: Iterable[ExternallyTraversible], obj: ExternallyTraversible, visitors: Mapping[(str, _TraverseCallableType[Any])]) -> ExternallyTraversible`

**Decorators:**
- `@overload`

**Line:** 874

---

### `def traverse_using(iterator: Iterable[ExternallyTraversible], obj: Optional[ExternallyTraversible], visitors: Mapping[(str, _TraverseCallableType[Any])]) -> Optional[ExternallyTraversible]`

**Description:**
Visit the given expression structure using the given iterator of
objects.

:func:`.visitors.traverse_using` is usually called internally as the result
of the :func:`.visitors.traverse` function.

:param iterator: an iterable or sequence which will yield
:class:`_expression.ClauseElement`
structures; the iterator is assumed to be the
product of the :func:`.visitors.iterate` function.

:param obj: the :class:`_expression.ClauseElement`
that was used as the target of the
:func:`.iterate` function.

:param visitors: dictionary of visit functions.  See :func:`.traverse`
for details on this dictionary.

.. seealso::

:func:`.traverse`

**Line:** 882

---

### `def traverse(obj: Literal[None], opts: Mapping[(str, Any)], visitors: Mapping[(str, _TraverseCallableType[Any])]) -> None`

**Decorators:**
- `@overload`

**Line:** 919

---

### `def traverse(obj: ExternallyTraversible, opts: Mapping[(str, Any)], visitors: Mapping[(str, _TraverseCallableType[Any])]) -> ExternallyTraversible`

**Decorators:**
- `@overload`

**Line:** 928

---

### `def traverse(obj: Optional[ExternallyTraversible], opts: Mapping[(str, Any)], visitors: Mapping[(str, _TraverseCallableType[Any])]) -> Optional[ExternallyTraversible]`

**Description:**
Traverse and visit the given expression structure using the default
iterator.

e.g.::

from sqlalchemy.sql import visitors

stmt = select(some_table).where(some_table.c.foo == 'bar')

def visit_bindparam(bind_param):
print("found bound value: %s" % bind_param.value)

visitors.traverse(stmt, {}, {"bindparam": visit_bindparam})

The iteration of objects uses the :func:`.visitors.iterate` function,
which does a breadth-first traversal using a stack.

:param obj: :class:`_expression.ClauseElement` structure to be traversed

:param opts: dictionary of iteration options.   This dictionary is usually
empty in modern usage.

:param visitors: dictionary of visit functions.   The dictionary should
have strings as keys, each of which would correspond to the
``__visit_name__`` of a particular kind of SQL expression object, and
callable functions  as values, each of which represents a visitor function
for that kind of object.

**Line:** 936

---

### `def cloned_traverse(obj: Literal[None], opts: Mapping[(str, Any)], visitors: Mapping[(str, _TraverseCallableType[Any])]) -> None`

**Decorators:**
- `@overload`

**Line:** 974

---

### `def cloned_traverse(obj: _ET, opts: Mapping[(str, Any)], visitors: Mapping[(str, _TraverseCallableType[Any])]) -> _ET`

**Decorators:**
- `@overload`

**Line:** 987

---

### `def cloned_traverse(obj: Optional[ExternallyTraversible], opts: Mapping[(str, Any)], visitors: Mapping[(str, _TraverseCallableType[Any])]) -> Optional[ExternallyTraversible]`

**Description:**
Clone the given expression structure, allowing modifications by
visitors for mutable objects.

Traversal usage is the same as that of :func:`.visitors.traverse`.
The visitor functions present in the ``visitors`` dictionary may also
modify the internals of the given structure as the traversal proceeds.

The :func:`.cloned_traverse` function does **not** provide objects that are
part of the :class:`.Immutable` interface to the visit methods (this
primarily includes :class:`.ColumnClause`, :class:`.Column`,
:class:`.TableClause` and :class:`.Table` objects). As this traversal is
only intended to allow in-place mutation of objects, :class:`.Immutable`
objects are skipped. The :meth:`.Immutable._clone` method is still called
on each object to allow for objects to replace themselves with a different
object based on a clone of their sub-internals (e.g. a
:class:`.ColumnClause` that clones its subquery to return a new
:class:`.ColumnClause`).

.. versionchanged:: 2.0  The :func:`.cloned_traverse` function omits
objects that are part of the :class:`.Immutable` interface.

The central API feature used by the :func:`.visitors.cloned_traverse`
and :func:`.visitors.replacement_traverse` functions, in addition to the
:meth:`_expression.ClauseElement.get_children`
function that is used to achieve
the iteration, is the :meth:`_expression.ClauseElement._copy_internals`
method.
For a :class:`_expression.ClauseElement`
structure to support cloning and replacement
traversals correctly, it needs to be able to pass a cloning function into
its internal members in order to make copies of them.

.. seealso::

:func:`.visitors.traverse`

:func:`.visitors.replacement_traverse`

**Line:** 995

---

### `def replacement_traverse(obj: Literal[None], opts: Mapping[(str, Any)], replace: _TraverseTransformCallableType[Any]) -> None`

**Decorators:**
- `@overload`

**Line:** 1087

---

### `def replacement_traverse(obj: _CE, opts: Mapping[(str, Any)], replace: _TraverseTransformCallableType[Any]) -> _CE`

**Decorators:**
- `@overload`

**Line:** 1096

---

### `def replacement_traverse(obj: ExternallyTraversible, opts: Mapping[(str, Any)], replace: _TraverseTransformCallableType[Any]) -> ExternallyTraversible`

**Decorators:**
- `@overload`

**Line:** 1105

---

### `def replacement_traverse(obj: Optional[ExternallyTraversible], opts: Mapping[(str, Any)], replace: _TraverseTransformCallableType[Any]) -> Optional[ExternallyTraversible]`

**Description:**
Clone the given expression structure, allowing element
replacement by a given replacement function.

This function is very similar to the :func:`.visitors.cloned_traverse`
function, except instead of being passed a dictionary of visitors, all
elements are unconditionally passed into the given replace function.
The replace function then has the option to return an entirely new object
which will replace the one given.  If it returns ``None``, then the object
is kept in place.

The difference in usage between :func:`.visitors.cloned_traverse` and
:func:`.visitors.replacement_traverse` is that in the former case, an
already-cloned object is passed to the visitor function, and the visitor
function can then manipulate the internal state of the object.
In the case of the latter, the visitor function should only return an
entirely different object, or do nothing.

The use case for :func:`.visitors.replacement_traverse` is that of
replacing a FROM clause inside of a SQL structure with a different one,
as is a common use case within the ORM.

**Line:** 1113

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.__init__
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/__init__.py`

**Imports:**
- assertions.AssertsCompiledSQL
- assertions.AssertsExecutionResults
- assertions.ComparesIndexes
- assertions.ComparesTables
- assertions.assert_raises
- assertions.assert_raises_context_ok
- assertions.assert_raises_message
- assertions.assert_raises_message_context_ok
- assertions.assert_warns
- assertions.assert_warns_message
- assertions.emits_warning
- assertions.emits_warning_on
- assertions.eq_
- assertions.eq_ignore_whitespace
- assertions.eq_regex
- assertions.expect_deprecated
- assertions.expect_deprecated_20
- assertions.expect_raises
- assertions.expect_raises_message
- assertions.expect_warnings
- assertions.in_
- assertions.int_within_variance
- assertions.is_
- assertions.is_false
- assertions.is_instance_of
- assertions.is_none
- assertions.is_not
- assertions.is_not_
- assertions.is_not_none
- assertions.is_true
- assertions.le_
- assertions.ne_
- assertions.not_in
- assertions.not_in_
- assertions.startswith_
- assertions.uses_deprecated
- config.Variation
- config.add_to_marker
- config.async_test
- config.combinations
- config.combinations_list
- config.db
- config.fixture
- config.requirements
- config.skip_test
- config.variation
- config.variation_fixture
- exclusions._is_excluded
- exclusions._server_version
- exclusions.against
- exclusions.db_spec
- exclusions.exclude
- exclusions.fails
- exclusions.fails_if
- exclusions.fails_on
- exclusions.fails_on_everything_except
- exclusions.future
- exclusions.only_if
- exclusions.only_on
- exclusions.skip
- exclusions.skip_if
- schema.eq_clause_element
- schema.eq_type_affinity
- unittest.mock
- util.adict
- util.fail
- util.flag_combinations
- util.force_drop_names
- util.lambda_combinations
- util.metadata_fixture
- util.provide_metadata
- util.resolve_lambda
- util.rowset
- util.run_as_contextmanager
- util.teardown_events
- warnings.assert_warnings
- warnings.warn_test_suite

**Functions:**

### `def against(*queries)`

**Line:** 91

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.assertions
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/assertions.py`

**Imports:**
- __future__.annotations
- collections.defaultdict
- contextlib
- copy.copy
- engine.default
- engine.url
- exclusions.db_spec
- itertools.filterfalse
- re
- sql.selectable.LABEL_STYLE_TABLENAME_PLUS_COL
- sqlalchemy.orm
- sys
- util.decorator
- util.fail
- warnings

**Functions:**

### `def expect_warnings(*messages, **kw)`

**Description:**
Context manager which expects one or more warnings.

With no arguments, squelches all SAWarning emitted via
sqlalchemy.util.warn and sqlalchemy.util.warn_limited.   Otherwise
pass string expressions that will match selected warnings via regex;
all non-matching warnings are sent through.

The expect version **asserts** that the warnings were in fact seen.

Note that the test suite sets SAWarning warnings to raise exceptions.

**Line:** 37

---

### `def expect_warnings_on(db, *messages, **kw)`

**Decorators:**
- `@contextlib.contextmanager`

**Description:**
Context manager which expects one or more warnings on specific
dialects.

The expect version **asserts** that the warnings were in fact seen.

**Line:** 54

---

### `def emits_warning(*messages)`

**Description:**
Decorator form of expect_warnings().

Note that emits_warning does **not** assert that the warnings
were in fact seen.

**Line:** 70

---

### `def expect_deprecated(*messages, **kw)`

**Line:** 86

---

### `def expect_deprecated_20(*messages, **kw)`

**Line:** 92

---

### `def emits_warning_on(db, *messages)`

**Description:**
Mark a test as emitting a warning on a specific dialect.

With no arguments, squelches all SAWarning failures.  Or pass one or more
strings; these will be matched to the root of the warning description by
warnings.filterwarnings().

Note that emits_warning_on does **not** assert that the warnings
were in fact seen.

**Line:** 98

---

### `def uses_deprecated(*messages)`

**Description:**
Mark a test as immune from fatal deprecation warnings.

With no arguments, squelches all SADeprecationWarning failures.
Or pass one or more strings; these will be matched to the root
of the warning description by warnings.filterwarnings().

As a special case, you may pass a function name prefixed with //
and it will be re-written as needed to match the standard warning
verbiage emitted by the sqlalchemy.util.deprecated decorator.

Note that uses_deprecated does **not** assert that the warnings
were in fact seen.

**Line:** 118

---

### `def _expect_warnings_sqla_only(exc_cls, messages, regex = True, search_msg = False, assert_ = True)`

**Description:**
SQLAlchemy internal use only _expect_warnings().

Alembic is using _expect_warnings() directly, and should be updated
to use this new interface.

**Line:** 147

---

### `def _expect_warnings(exc_cls, messages, regex = True, search_msg = False, assert_ = True, raise_on_any_unexpected = False, squelch_other_warnings = False)`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 171

---

### `def global_cleanup_assertions()`

**Description:**
Check things that have to be finalized at the end of a test suite.

Hardcoded at the moment, a modular system can be built here
to support things like PG prepared transactions, tables all
dropped, etc.

**Line:** 251

---

### `def _assert_no_stray_pool_connections()`

**Line:** 262

---

### `def int_within_variance(expected, received, variance)`

**Line:** 266

---

### `def eq_regex(a, b, msg = None)`

**Line:** 277

---

### `def eq_(a, b, msg = None)`

**Description:**
Assert a == b, with repr messaging on failure.

**Line:** 281

---

### `def ne_(a, b, msg = None)`

**Description:**
Assert a != b, with repr messaging on failure.

**Line:** 286

---

### `def le_(a, b, msg = None)`

**Description:**
Assert a <= b, with repr messaging on failure.

**Line:** 291

---

### `def is_instance_of(a, b, msg = None)`

**Line:** 296

---

### `def is_none(a, msg = None)`

**Line:** 300

---

### `def is_not_none(a, msg = None)`

**Line:** 304

---

### `def is_true(a, msg = None)`

**Line:** 308

---

### `def is_false(a, msg = None)`

**Line:** 312

---

### `def is_(a, b, msg = None)`

**Description:**
Assert a is b, with repr messaging on failure.

**Line:** 316

---

### `def is_not(a, b, msg = None)`

**Description:**
Assert a is not b, with repr messaging on failure.

**Line:** 321

---

### `def in_(a, b, msg = None)`

**Description:**
Assert a in b, with repr messaging on failure.

**Line:** 330

---

### `def not_in(a, b, msg = None)`

**Description:**
Assert a in not b, with repr messaging on failure.

**Line:** 335

---

### `def startswith_(a, fragment, msg = None)`

**Description:**
Assert a.startswith(fragment), with repr messaging on failure.

**Line:** 344

---

### `def eq_ignore_whitespace(a, b, msg = None)`

**Line:** 352

---

### `def _assert_proper_exception_context(exception)`

**Description:**
assert that any exception we're catching does not have a __context__
without a __cause__, and that __suppress_context__ is never set.

Python 3 will report nested as exceptions as "during the handling of
error X, error Y occurred". That's not what we want to do.  we want
these exceptions in a cause chain.

**Line:** 363

---

### `def assert_raises(except_cls, callable_, *args, **kw)`

**Line:** 384

---

### `def assert_raises_context_ok(except_cls, callable_, *args, **kw)`

**Line:** 388

---

### `def assert_raises_message(except_cls, msg, callable_, *args, **kwargs)`

**Line:** 392

---

### `def assert_warns(except_cls, callable_, *args, **kwargs)`

**Description:**
legacy adapter function for functions that were previously using
assert_raises with SAWarning or similar.

has some workarounds to accommodate the fact that the callable completes
with this approach rather than stopping at the exception raise.

**Line:** 398

---

### `def assert_warns_message(except_cls, msg, callable_, *args, **kwargs)`

**Description:**
legacy adapter function for functions that were previously using
assert_raises with SAWarning or similar.

has some workarounds to accommodate the fact that the callable completes
with this approach rather than stopping at the exception raise.

Also uses regex.search() to match the given message to the error string
rather than regex.match().

**Line:** 411

---

### `def assert_raises_message_context_ok(except_cls, msg, callable_, *args, **kwargs)`

**Line:** 431

---

### `def _assert_raises(except_cls, callable_, args, kwargs, msg = None, check_context = False)`

**Line:** 437

---

### `def _expect_raises(except_cls, msg = None, check_context = False)`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 450

---

### `def expect_raises(except_cls, check_context = True)`

**Line:** 492

---

### `def expect_raises_message(except_cls, msg, check_context = True)`

**Line:** 496

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.assertsql
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/assertsql.py`

**Imports:**
- __future__.annotations
- collections
- contextlib
- engine.default.DefaultDialect
- engine.url
- itertools
- re
- schema.BaseDDLElement

**Functions:**

### `def assert_engine(engine)`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 476

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.asyncio
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/asyncio.py`

**Imports:**
- __future__.annotations
- functools.wraps
- inspect
- util.concurrency._util_async_run
- util.concurrency._util_async_run_coroutine_function

**Functions:**

### `def _run_coroutine_function(fn, *args, **kwargs)`

**Line:** 35

---

### `def _assume_async(fn, *args, **kwargs)`

**Description:**
Run a function in an asyncio loop unconditionally.

This function is used for provisioning features like
testing a database connection for server info.

Note that for blocking IO database drivers, this means they block the
event loop.

**Line:** 39

---

### `def _maybe_async_provisioning(fn, *args, **kwargs)`

**Description:**
Run a function in an asyncio loop if any current drivers might need it.

This function is used for provisioning features that take
place outside of a specific database driver being selected, so if the
current driver that happens to be used for the provisioning operation
is an async driver, it will run in asyncio and not fail.

Note that for blocking IO database drivers, this means they block the
event loop.

**Line:** 56

---

### `def _maybe_async(fn, *args, **kwargs)`

**Description:**
Run a function in an asyncio loop if the current selected driver is
async.

This function is used for test setup/teardown and tests themselves
where the current DB driver is known.

**Line:** 77

---

### `def _maybe_async_wrapper(fn)`

**Description:**
Apply the _maybe_async function to an existing function and return
as a wrapped callable, supporting generator functions as well.

This is currently used for pytest fixtures that support generator use.

**Line:** 97

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.config
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/config.py`

**Imports:**
- __future__.annotations
- argparse.Namespace
- collections
- inspect
- plugin.plugin_base.FixtureFunctions
- typing
- typing.Any
- typing.Callable
- typing.Iterable
- typing.NoReturn
- typing.Optional
- typing.Tuple
- typing.TypeVar
- typing.Union
- util.fail

**Functions:**

### `def combinations(argnames: Optional[str] = None, id_: Optional[str] = None, *comb: Union[(Any, Tuple[Any, ...])], **kw: str) -> Callable[([_FN], _FN)]`

**Description:**
Deliver multiple versions of a test based on positional combinations.

This is a facade over pytest.mark.parametrize.


:param \*comb: argument combinations.  These are tuples that will be passed
positionally to the decorated function.

:param argnames: optional list of argument names.   These are the names
of the arguments in the test function that correspond to the entries
in each argument tuple.   pytest.mark.parametrize requires this, however
the combinations function will derive it automatically if not present
by using ``inspect.getfullargspec(fn).args[1:]``.  Note this assumes the
first argument is "self" which is discarded.

:param id\_: optional id template.  This is a string template that
describes how the "id" for each parameter set should be defined, if any.
The number of characters in the template should match the number of
entries in each argument tuple.   Each character describes how the
corresponding entry in the argument tuple should be handled, as far as
whether or not it is included in the arguments passed to the function, as
well as if it is included in the tokens used to create the id of the
parameter set.

If omitted, the argument combinations are passed to parametrize as is.  If
passed, each argument combination is turned into a pytest.param() object,
mapping the elements of the argument tuple to produce an id based on a
character value in the same position within the string template using the
following scheme::

i - the given argument is a string that is part of the id only, don't
pass it as an argument

n - the given argument should be passed and it should be added to the
id by calling the .__name__ attribute

r - the given argument should be passed and it should be added to the
id by calling repr()

s - the given argument should be passed and it should be added to the
id by calling str()

a - (argument) the given argument should be passed and it should not
be used to generated the id

e.g.::

@testing.combinations(
(operator.eq, "eq"),
(operator.ne, "ne"),
(operator.gt, "gt"),
(operator.lt, "lt"),
id_="na"
)
def test_operator(self, opfunc, name):
pass

The above combination will call ``.__name__`` on the first member of
each tuple and use that as the "id" to pytest.param().

**Line:** 91

---

### `def combinations_list(arg_iterable: Iterable[Tuple[(Any, ...)]], **kw)`

**Description:**
As combination, but takes a single iterable

**Line:** 164

---

### `def variation(argname_or_fn, cases = None)`

**Description:**
a helper around testing.combinations that provides a single namespace
that can be used as a switch.

e.g.::

@testing.variation("querytyp", ["select", "subquery", "legacy_query"])
@testing.variation("lazy", ["select", "raise", "raise_on_sql"])
def test_thing(
self,
querytyp,
lazy,
decl_base
):
class Thing(decl_base):
__tablename__ = 'thing'

# use name directly
rel = relationship("Rel", lazy=lazy.name)

# use as a switch
if querytyp.select:
stmt = select(Thing)
elif querytyp.subquery:
stmt = select(Thing).subquery()
elif querytyp.legacy_query:
stmt = Session.query(Thing)
else:
querytyp.fail()


The variable provided is a slots object of boolean variables, as well
as the name of the case itself under the attribute ".name"

**Line:** 224

---

### `def variation_fixture(argname, cases, scope = 'function')`

**Line:** 295

---

### `def fixture(*arg: Any, **kw: Any) -> Any`

**Line:** 303

---

### `def get_current_test_name() -> str`

**Line:** 307

---

### `def mark_base_test_class() -> Any`

**Line:** 311

---

### `def skip_test(msg)`

**Line:** 419

---

### `def async_test(fn)`

**Line:** 423

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.engines
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/engines.py`

**Imports:**
- __future__.annotations
- collections
- engine.Engine
- engine.url.URL
- ext.asyncio.AsyncEngine
- re
- sqlalchemy.create_engine
- sqlalchemy.create_mock_engine
- sqlalchemy.dialects
- sqlalchemy.engine.url.make_url
- sqlalchemy.ext.asyncio.create_async_engine
- sqlalchemy.pool.StaticPool
- typing
- typing.Any
- typing.Dict
- typing.Optional
- util.await_only
- util.decorator
- util.gc_collect
- util.typing.Literal
- warnings
- weakref

**Functions:**

### `def assert_conns_closed(fn, *args, **kw)`

**Decorators:**
- `@decorator`

**Line:** 174

---

### `def rollback_open_connections(fn, *args, **kw)`

**Decorators:**
- `@decorator`

**Description:**
Decorator that rolls back all open connections after fn execution.

**Line:** 182

---

### `def close_first(fn, *args, **kw)`

**Decorators:**
- `@decorator`

**Description:**
Decorator that closes all connections before fn execution.

**Line:** 192

---

### `def close_open_connections(fn, *args, **kw)`

**Decorators:**
- `@decorator`

**Description:**
Decorator that closes all connections after fn execution.

**Line:** 200

---

### `def all_dialects(exclude = None)`

**Line:** 208

---

### `def reconnecting_engine(url = None, options = None)`

**Line:** 266

---

### `def testing_engine(url: Optional[URL] = None, options: Optional[Dict[(str, Any)]] = None, asyncio: Literal[False] = False, transfer_staticpool: bool = False) -> Engine`

**Decorators:**
- `@typing.overload`

**Line:** 287

---

### `def testing_engine(url: Optional[URL] = None, options: Optional[Dict[(str, Any)]] = None, asyncio: Literal[True] = True, transfer_staticpool: bool = False) -> AsyncEngine`

**Decorators:**
- `@typing.overload`

**Line:** 297

---

### `def testing_engine(url = None, options = None, asyncio = False, transfer_staticpool = False, share_pool = False, _sqlite_savepoint = False)`

**Line:** 306

---

### `def mock_engine(dialect_name = None)`

**Description:**
Provides a mocking engine based on the current testing.db.

This is normally used to test DDL generation flow as emitted
by an Engine.

It should not be used in other cases, as assert_compile() and
assert_sql_execution() are much better choices with fewer
moving parts.

**Line:** 382

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.exclusions
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/exclusions.py`

**Imports:**
- contextlib
- operator
- re
- sys
- util.compat.inspect_getfullargspec
- util.decorator

**Functions:**

### `def skip_if(predicate, reason = None)`

**Line:** 20

---

### `def fails_if(predicate, reason = None)`

**Line:** 27

---

### `def only_if(predicate, reason = None)`

**Line:** 156

---

### `def succeeds_if(predicate, reason = None)`

**Line:** 161

---

### `def _is_excluded(db, op, spec)`

**Line:** 371

---

### `def _server_version(engine)`

**Description:**
Return a server_version_info tuple.

**Line:** 375

---

### `def db_spec(*dbs)`

**Line:** 387

---

### `def open()`

**Line:** 391

---

### `def closed()`

**Line:** 395

---

### `def fails(reason = None)`

**Line:** 399

---

### `def future()`

**Line:** 403

---

### `def fails_on(db, reason = None)`

**Line:** 407

---

### `def fails_on_everything_except(*dbs)`

**Line:** 411

---

### `def skip(db, reason = None)`

**Line:** 415

---

### `def only_on(dbs, reason = None)`

**Line:** 419

---

### `def exclude(db, op, spec, reason = None)`

**Line:** 427

---

### `def against(config, *queries)`

**Line:** 431

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.fixtures.orm
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/fixtures/orm.py`

**Imports:**
- __future__.annotations
- base.TestBase
- entities.BasicEntity
- entities.ComparableEntity
- orm.DeclarativeBase
- orm.events
- orm.registry
- sql.TablesTest
- sqlalchemy
- typing.Any
- util.adict

**Functions:**

### `def fixture_session(**kw)`

**Line:** 203

---

### `def close_all_sessions()`

**Line:** 214

---

### `def stop_test_class_inside_fixtures(cls)`

**Line:** 220

---

### `def after_test()`

**Line:** 225

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.fixtures.sql
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/fixtures/sql.py`

**Imports:**
- __future__.annotations
- assertions.eq_
- assertions.ne_
- base.TestBase
- itertools
- random
- re
- schema.Column
- schema.Computed
- schema.Table
- schema.sort_tables_and_constraints
- sql.elements.ClauseElement
- sql.visitors
- sqlalchemy
- sys
- util.adict
- util.drop_all_tables_from_metadata

**Functions:**

### `def insertmanyvalues_fixture(connection, randomize_rows = False, warn_on_downgraded = False)`

**Line:** 445

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.plugin.bootstrap
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/plugin/bootstrap.py`

**Imports:**
- importlib.util
- os
- sys

**Functions:**

### `def load_file_as_module(name)`

**Line:** 29

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.plugin.plugin_base
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/plugin/plugin_base.py`

**Imports:**
- __future__.annotations
- abc
- argparse.Namespace
- configparser
- logging
- os
- pathlib.Path
- re
- sqlalchemy.dialects.registry
- sqlalchemy.engine.url
- sqlalchemy.testing
- sqlalchemy.testing.assertions
- sqlalchemy.testing.asyncio
- sqlalchemy.testing.config
- sqlalchemy.testing.engines
- sqlalchemy.testing.exclusions
- sqlalchemy.testing.fixtures
- sqlalchemy.testing.profiling
- sqlalchemy.testing.provision
- sqlalchemy.testing.warnings
- sqlalchemy.util
- sqlalchemy.util.has_compiled_ext
- sys
- typing.Any

**Functions:**

### `def setup_options(make_option)`

**Line:** 59

---

### `def configure_follower(follower_ident)`

**Description:**
Configure required state for a follower.

This invokes in the parent process and typically includes
database creation.

**Line:** 240

---

### `def memoize_important_follower_config(dict_)`

**Description:**
Store important configuration we will need to send to a follower.

This invokes in the parent process after normal config is set up.

Hook is currently not used.

**Line:** 252

---

### `def restore_important_follower_config(dict_)`

**Description:**
Restore important configuration needed by a follower.

This invokes in the follower process.

Hook is currently not used.

**Line:** 262

---

### `def read_config(root_path)`

**Line:** 272

---

### `def pre_begin(opt)`

**Description:**
things to set up early, before coverage might be setup.

**Line:** 280

---

### `def set_coverage_flag(value)`

**Line:** 288

---

### `def post_begin()`

**Description:**
things to set up later, once we know coverage is running.

**Line:** 292

---

### `def _log(opt_str, value, parser)`

**Line:** 310

---

### `def _list_dbs(*args)`

**Line:** 323

---

### `def _requirements_opt(opt_str, value, parser)`

**Line:** 334

---

### `def _set_tag_include(tag)`

**Line:** 338

---

### `def _set_tag_exclude(tag)`

**Line:** 345

---

### `def _exclude_tag(opt_str, value, parser)`

**Line:** 352

---

### `def _include_tag(opt_str, value, parser)`

**Line:** 356

---

### `def pre(fn)`

**Line:** 364

---

### `def post(fn)`

**Line:** 369

---

### `def _setup_options(opt, file_config)`

**Decorators:**
- `@pre`

**Line:** 375

---

### `def _register_sqlite_numeric_dialect(opt, file_config)`

**Decorators:**
- `@pre`

**Line:** 381

---

### `def __ensure_cext(opt, file_config)`

**Decorators:**
- `@post`

**Line:** 397

---

### `def _init_symbols(options, file_config)`

**Decorators:**
- `@post`

**Line:** 411

---

### `def _set_disable_asyncio(opt, file_config)`

**Decorators:**
- `@pre`

**Line:** 418

---

### `def _engine_uri(options, file_config)`

**Decorators:**
- `@post`

**Line:** 424

---

### `def _requirements(options, file_config)`

**Decorators:**
- `@post`

**Line:** 474

---

### `def _setup_requirements(argument)`

**Line:** 479

---

### `def _prep_testing_database(options, file_config)`

**Decorators:**
- `@post`

**Line:** 498

---

### `def _post_setup_options(opt, file_config)`

**Decorators:**
- `@post`

**Line:** 509

---

### `def _setup_profiling(options, file_config)`

**Decorators:**
- `@post`

**Line:** 517

---

### `def want_class(name, cls)`

**Line:** 527

---

### `def want_method(cls, fn)`

**Line:** 536

---

### `def generate_sub_tests(cls, module, markers)`

**Line:** 545

---

### `def start_test_class_outside_fixtures(cls)`

**Line:** 569

---

### `def stop_test_class(cls)`

**Line:** 574

---

### `def stop_test_class_outside_fixtures(cls)`

**Line:** 583

---

### `def _restore_engine()`

**Line:** 593

---

### `def final_process_cleanup()`

**Line:** 598

---

### `def _setup_engine(cls)`

**Line:** 604

---

### `def before_test(test, test_module_name, test_class, test_name)`

**Line:** 612

---

### `def after_test(test)`

**Line:** 623

---

### `def after_test_fixtures(test)`

**Line:** 628

---

### `def _possible_configs_for_cls(cls, reasons = None, sparse = False)`

**Line:** 632

---

### `def _do_skips(cls)`

**Line:** 698

---

### `def _setup_config(config_obj, ctx)`

**Line:** 741

---

### `def set_fixture_functions(fixture_fn_class)`

**Line:** 777

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.plugintestplugin
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/plugin/pytestplugin.py`

**Imports:**
- __future__.annotations
- argparse
- collections
- functools.update_wrapper
- inspect
- itertools
- operator
- os
- pyannotate_runtime.collect_types
- pytest
- re
- sqla_plugin_base
- sqlalchemy
- sqlalchemy.__version__
- sqlalchemy.cyextension.util
- sqlalchemy.testing.asyncio
- sqlalchemy.testing.config
- sqlalchemy.testing.exclusions
- sqlalchemy.testing.provision
- sqlalchemy.util._has_cy._CYEXTENSION_MSG
- sqlalchemy.util.compat.inspect_getfullargspec
- sqlalchemy.util.has_compiled_ext
- sqlalchemy.util.langhelpers.format_argspec_plus
- sys
- typing.TYPE_CHECKING
- uuid

**Functions:**

### `def pytest_addoption(parser)`

**Line:** 28

---

### `def pytest_configure(config: pytest.Config)`

**Line:** 77

---

### `def collect_types_fixture()`

**Decorators:**
- `@pytest.fixture(...)`

**Line:** 119

---

### `def _log_sqlalchemy_info(session)`

**Line:** 129

---

### `def pytest_sessionstart(session)`

**Line:** 161

---

### `def pytest_sessionfinish(session)`

**Line:** 168

---

### `def pytest_collection_finish(session)`

**Line:** 179

---

### `def pytest_collection_modifyitems(session, config, items)`

**Line:** 224

---

### `def pytest_pycollect_makeitem(collector, name, obj)`

**Line:** 321

---

### `def _is_wrapped_coroutine_function(fn)`

**Line:** 347

---

### `def _apply_maybe_async(obj, recurse = True)`

**Line:** 354

---

### `def _parametrize_cls(module, cls)`

**Description:**
implement a class-based version of pytest parametrize.

**Line:** 386

---

### `def pytest_runtest_setup(item)`

**Line:** 422

---

### `def pytest_runtest_teardown(item, nextitem)`

**Decorators:**
- `@pytest.hookimpl(...)`

**Line:** 442

---

### `def pytest_runtest_call(item)`

**Line:** 495

---

### `def pytest_runtest_logreport(report)`

**Line:** 513

---

### `def setup_class_methods(request)`

**Decorators:**
- `@pytest.fixture(...)`

**Line:** 520

---

### `def setup_test_methods(request)`

**Decorators:**
- `@pytest.fixture(...)`

**Line:** 537

---

### `def _pytest_fn_decorator(target)`

**Description:**
Port of langhelpers.decorator with pytest-specific tricks.

**Line:** 599

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.profiling
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/profiling.py`

**Imports:**
- __future__.annotations
- cProfile
- collections
- contextlib
- os
- platform
- pstats
- re
- sqlalchemy.util.decorator
- sys
- util.gc_collect
- util.has_compiled_ext

**Functions:**

### `def _start_current_test(id_)`

**Line:** 54

---

### `def function_call_count(variance = 0.05, times = 1, warmup = 0)`

**Description:**
Assert a target for a test case's function call count.

The main purpose of this assertion is to detect changes in
callcounts for various functions - the actual number is not as important.
Callcounts are stored in a file keyed to Python version and OS platform
information.  This file is generated automatically for new tests,
and versioned so that unexpected changes in callcounts will be detected.

**Line:** 227

---

### `def count_functions(variance = 0.05)`

**Decorators:**
- `@contextlib.contextmanager`

**Line:** 259

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.provision
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/provision.py`

**Imports:**
- __future__.annotations
- collections
- engine.url
- logging
- sql.ddl
- sql.schema

**Functions:**

### `def create_follower_db(follower_ident)`

**Line:** 60

---

### `def setup_config(db_url, options, file_config, follower_ident)`

**Line:** 66

---

### `def drop_follower_db(follower_ident)`

**Line:** 94

---

### `def generate_db_urls(db_urls, extra_drivers)`

**Description:**
Generate a set of URLs to test given configured URLs plus additional
driver names.

Given::

--dburi postgresql://db1          --dburi postgresql://db2          --dburi postgresql://db2          --dbdriver=psycopg2 --dbdriver=asyncpg?async_fallback=true

Noting that the default postgresql driver is psycopg2,  the output
would be::

postgresql+psycopg2://db1
postgresql+asyncpg://db1
postgresql+psycopg2://db2
postgresql+psycopg2://db3

That is, for the driver in a --dburi, we want to keep that and use that
driver for each URL it's part of .   For a driver that is only
in --dbdrivers, we want to use it just once for one of the URLs.
for a driver that is both coming from --dburi as well as --dbdrivers,
we want to keep it in that dburi.

Driver specific query options can be specified by added them to the
driver name. For example, to enable the async fallback option for
asyncpg::

--dburi postgresql://db1          --dbdriver=asyncpg?async_fallback=true

**Line:** 100

---

### `def _generate_driver_urls(url, extra_drivers)`

**Line:** 165

---

### `def generate_driver_url(url, driver, query_str)`

**Decorators:**
- `@register.init`

**Line:** 188

---

### `def _configs_for_db_operation()`

**Line:** 205

---

### `def drop_all_schema_objects_pre_tables(cfg, eng)`

**Decorators:**
- `@register.init`

**Line:** 225

---

### `def drop_all_schema_objects_post_tables(cfg, eng)`

**Decorators:**
- `@register.init`

**Line:** 230

---

### `def drop_all_schema_objects(cfg, eng)`

**Line:** 234

---

### `def drop_views(cfg, eng)`

**Line:** 267

---

### `def drop_materialized_views(cfg, eng)`

**Line:** 300

---

### `def create_db(cfg, eng, ident)`

**Decorators:**
- `@register.init`

**Description:**
Dynamically create a database for testing.

Used when a test run will employ multiple processes, e.g., when run
via `tox` or `pytest -n4`.

**Line:** 321

---

### `def drop_db(cfg, eng, ident)`

**Decorators:**
- `@register.init`

**Description:**
Drop a database that we dynamically created for testing.

**Line:** 333

---

### `def _adapt_update_db_opts(fn)`

**Line:** 338

---

### `def update_db_opts(db_url, db_opts, options)`

**Decorators:**
- `@register.init_decorator(...)`

**Description:**
Set database options (db_opts) for a test database that we created.

**Line:** 347

---

### `def post_configure_engine(url, engine, follower_ident)`

**Decorators:**
- `@register.init`

**Description:**
Perform extra steps after configuring an engine for testing.

(For the internal dialects, currently only used by sqlite, oracle)

**Line:** 352

---

### `def follower_url_from_main(url, ident)`

**Decorators:**
- `@register.init`

**Description:**
Create a connection URL for a dynamically-created test database.

:param url: the connection URL specified when the test run was invoked
:param ident: the pytest-xdist "worker identifier" to be used as the
database name

**Line:** 360

---

### `def configure_follower(cfg, ident)`

**Decorators:**
- `@register.init`

**Description:**
Create dialect-specific config settings for a follower database.

**Line:** 372

---

### `def run_reap_dbs(url, ident)`

**Decorators:**
- `@register.init`

**Description:**
Remove databases that were created during the test process, after the
process has ended.

This is an optional step that is invoked for certain backends that do not
reliably release locks on the database as long as a process is still in
use. For the internal dialects, this is currently only necessary for
mssql and oracle.

**Line:** 378

---

### `def reap_dbs(idents_file)`

**Line:** 389

---

### `def temp_table_keyword_args(cfg, eng)`

**Decorators:**
- `@register.init`

**Description:**
Specify keyword arguments for creating a temporary Table.

Dialect-specific implementations of this method will return the
kwargs that are passed to the Table method when creating a temporary
table for testing, e.g., in the define_temp_tables method of the
ComponentReflectionTest class in suite/test_reflection.py

**Line:** 415

---

### `def prepare_for_drop_tables(config, connection)`

**Decorators:**
- `@register.init`

**Line:** 429

---

### `def stop_test_class_outside_fixtures(config, db, testcls)`

**Decorators:**
- `@register.init`

**Line:** 434

---

### `def get_temp_table_name(cfg, eng, base_name)`

**Decorators:**
- `@register.init`

**Description:**
Specify table name for creating a temporary Table.

Dialect-specific implementations of this method will return the
name to use when creating a temporary table for testing,
e.g., in the define_temp_tables method of the
ComponentReflectionTest class in suite/test_reflection.py

Default to just the base name since that's what most dialects will
use. The mssql dialect's implementation will need a "#" prepended.

**Line:** 439

---

### `def set_default_schema_on_connection(cfg, dbapi_connection, schema_name)`

**Decorators:**
- `@register.init`

**Line:** 454

---

### `def upsert(cfg, table, returning, set_lambda = None, sort_by_parameter_order = False)`

**Decorators:**
- `@register.init`

**Description:**
return the backends insert..on conflict / on dupe etc. construct.

while we should add a backend-neutral upsert construct as well, such as
insert().upsert(), it's important that we continue to test the
backend-specific insert() constructs since if we do implement
insert().upsert(), that would be using a different codepath for the things
we need to test like insertmanyvalues, etc.

**Line:** 462

---

### `def normalize_sequence(cfg, sequence)`

**Decorators:**
- `@register.init`

**Description:**
Normalize sequence parameters for dialect that don't start with 1
by default.

The default implementation does nothing

**Line:** 480

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.schema
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/schema.py`

**Imports:**
- __future__.annotations
- orm.mapped_column
- sys
- util.OrderedDict

**Functions:**

### `def Table(*args, **kw) -> schema.Table`

**Description:**
A schema.Table wrapper/hook for dialect-specific tweaks.

**Line:** 26

---

### `def mapped_column(*args, **kw)`

**Description:**
An orm.mapped_column wrapper/hook for dialect-specific tweaks.

**Line:** 63

---

### `def Column(*args, **kw)`

**Description:**
A schema.Column wrapper/hook for dialect-specific tweaks.

**Line:** 69

---

### `def _schema_column(factory, args, kw)`

**Line:** 75

---

### `def _truncate_name(dialect, name)`

**Line:** 178

---

### `def pep435_enum(name)`

**Line:** 189

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.suite.test_reflection
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/suite/test_reflection.py`

**Imports:**
- engine.Inspector
- engine.ObjectKind
- engine.ObjectScope
- exc.NoSuchTableError
- exc.UnreflectableTableError
- operator
- provision.get_temp_table_name
- provision.temp_table_keyword_args
- re
- schema.Column
- schema.DDL
- schema.Index
- schema.Table
- sql.elements.quoted_name
- sql.schema.BLANK_SCHEMA
- sqlalchemy
- sqlalchemy.pool
- testing.ComparesIndexes
- testing.ComparesTables
- testing.is_false
- testing.is_true
- testing.mock

**Functions:**

### `def _multi_combination(fn)`

**Line:** 498

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.util
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/util.py`

**Imports:**
- __future__.annotations
- collections.deque
- decimal
- engine.Connection
- gc
- itertools.chain
- pickle
- random
- schema.Column
- schema.DropConstraint
- schema.DropTable
- schema.ForeignKeyConstraint
- schema.MetaData
- schema.Table
- sql.schema
- sql.sqltypes.Integer
- sys
- sys.getsizeof
- types
- util.decorator
- util.defaultdict
- util.has_refcount_gc
- util.inspect_getfullargspec

**Functions:**

### `def non_refcount_gc_collect(*args)`

**Line:** 41

---

### `def lazy_gc()`

**Line:** 50

---

### `def picklers()`

**Line:** 54

---

### `def random_choices(population, k = 1)`

**Line:** 66

---

### `def round_decimal(value, prec)`

**Line:** 70

---

### `def conforms_partial_ordering(tuples, sorted_elements)`

**Description:**
True if the given sorting conforms to the given partial ordering.

**Line:** 105

---

### `def all_partial_orderings(tuples, elements)`

**Line:** 119

---

### `def function_named(fn, name)`

**Description:**
Return a function with a given __name__.

Will assign to __name__ and return the original function if possible on
the Python implementation, otherwise a new function will be constructed.

This function should be phased out as much as possible
in favor of @decorator.   Tests that "generate" many named tests
should be modernized.

**Line:** 137

---

### `def run_as_contextmanager(ctx, fn, *arg, **kw)`

**Description:**
Run the given function under the given contextmanager,
simulating the behavior of 'with' to support older
Python versions.

This is not necessary anymore as we have placed 2.6
as minimum Python version, however some tests are still using
this structure.

**Line:** 157

---

### `def rowset(results)`

**Description:**
Converts the results of sql execution into a plain set of column tuples.

Useful for asserting the results of an unordered query.

**Line:** 182

---

### `def fail(msg)`

**Line:** 191

---

### `def provide_metadata(fn, *args, **kw)`

**Decorators:**
- `@decorator`

**Description:**
Provide bound MetaData for a single test, dropping afterwards.

Legacy; use the "metadata" pytest fixture.

**Line:** 196

---

### `def flag_combinations(*combinations)`

**Description:**
A facade around @testing.combinations() oriented towards boolean
keyword-based arguments.

Basically generates a nice looking identifier based on the keywords
and also sets up the argument names.

E.g.::

@testing.flag_combinations(
dict(lazy=False, passive=False),
dict(lazy=True, passive=False),
dict(lazy=False, passive=True),
dict(lazy=False, passive=True, raiseload=True),
)


would result in::

@testing.combinations(
('', False, False, False),
('lazy', True, False, False),
('lazy_passive', True, True, False),
('lazy_passive', True, True, True),
id_='iaaa',
argnames='lazy,passive,raiseload'
)

**Line:** 239

---

### `def lambda_combinations(lambda_arg_sets, **kw)`

**Line:** 287

---

### `def resolve_lambda(__fn, **kw)`

**Description:**
Given a no-arg lambda and a namespace, return a new lambda that
has all the values filled in.

This is used so that we can have module-level fixtures that
refer to instance-level variables using lambdas.

**Line:** 304

---

### `def metadata_fixture(ddl = 'function')`

**Description:**
Provide MetaData for a pytest fixture.

**Line:** 321

---

### `def force_drop_names(*names)`

**Description:**
Force the given table names to be dropped after test complete,
isolating for foreign key cycles

**Line:** 341

---

### `def drop_all_tables_from_metadata(metadata, engine_or_connection)`

**Line:** 372

---

### `def drop_all_tables(engine, inspector, schema = None, consider_schemas = (), include_names = None)`

**Line:** 395

---

### `def teardown_events(event_cls)`

**Line:** 451

---

### `def total_size(o)`

**Description:**
Returns the approximate memory footprint an object and all of its
contents.

source: https://code.activestate.com/recipes/577504/

**Line:** 462

---

### `def count_cache_key_tuples(tup)`

**Description:**
given a cache key tuple, counts how many instances of actual
tuples are found.

used to alert large jumps in cache key complexity.

**Line:** 500

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.testing.warnings
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/testing/warnings.py`

**Imports:**
- __future__.annotations
- exc.SATestSuiteWarning
- util.langhelpers._warnings_warn
- warnings

**Functions:**

### `def warn_test_suite(message)`

**Line:** 20

---

### `def setup_filters()`

**Description:**
hook for setting up warnings filters.

SQLAlchemy-specific classes must only be here and not in pytest config,
as we need to delay importing SQLAlchemy until conftest.py has been
processed.

NOTE: filters on subclasses of DeprecationWarning or
PendingDeprecationWarning have no effect if added here, since pytest
will add at each test the following filters
``always::PendingDeprecationWarning`` and ``always::DeprecationWarning``
that will take precedence over any added here.

**Line:** 24

---

### `def assert_warnings(fn, warning_msgs, regex = False)`

**Description:**
Assert that each of the given warnings are emitted by fn.

Deprecated.  Please use assertions.expect_warnings().

**Line:** 42

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.util._collections
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/util/_collections.py`

**Imports:**
- __future__.annotations
- _has_cy.HAS_CYEXTENSION
- _py_collections.IdentitySet
- _py_collections.ImmutableDictBase
- _py_collections.OrderedSet
- _py_collections.ReadOnlyContainer
- _py_collections.immutabledict
- _py_collections.unique_list
- collections.abc
- operator
- sqlalchemy.cyextension.collections.IdentitySet
- sqlalchemy.cyextension.collections.OrderedSet
- sqlalchemy.cyextension.collections.unique_list
- sqlalchemy.cyextension.immutabledict.ImmutableDictBase
- sqlalchemy.cyextension.immutabledict.ReadOnlyContainer
- sqlalchemy.cyextension.immutabledict.immutabledict
- threading
- types
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.FrozenSet
- typing.Generic
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Literal
- typing.Mapping
- typing.NoReturn
- typing.Optional
- typing.Protocol
- typing.Sequence
- typing.Set
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.ValuesView
- typing.cast
- typing.overload
- weakref

**Functions:**

### `def merge_lists_w_ordering(a: List[Any], b: List[Any]) -> List[Any]`

**Description:**
merge two lists, maintaining ordering as much as possible.

this is to reconcile vars(cls) with cls.__annotations__.

Example::

>>> a = ['__tablename__', 'id', 'x', 'created_at']
>>> b = ['id', 'name', 'data', 'y', 'created_at']
>>> merge_lists_w_ordering(a, b)
['__tablename__', 'id', 'name', 'data', 'y', 'x', 'created_at']

This is not necessarily the ordering that things had on the class,
in this case the class is::

class User(Base):
__tablename__ = "users"

id: Mapped[int] = mapped_column(primary_key=True)
name: Mapped[str]
data: Mapped[Optional[str]]
x = Column(Integer)
y: Mapped[int]
created_at: Mapped[datetime.datetime] = mapped_column()

But things are *mostly* ordered.

The algorithm could also be done by creating a partial ordering for
all items in both lists and then using topological_sort(), but that
is too much overhead.

Background on how I came up with this is at:
https://gist.github.com/zzzeek/89de958cf0803d148e74861bd682ebae

**Line:** 75

---

### `def coerce_to_immutabledict(d: Mapping[(_KT, _VT)]) -> immutabledict[(_KT, _VT)]`

**Line:** 131

---

### `def _ordered_dictionary_sort(d, key = None)`

**Description:**
Sort an OrderedDict in-place.

**Line:** 277

---

### `def coerce_generator_arg(arg: Any) -> List[Any]`

**Line:** 412

---

### `def to_list(x: Any, default: Optional[List[Any]] = None) -> List[Any]`

**Line:** 419

---

### `def has_intersection(set_, iterable)`

**Description:**
return True if any items of set\_ are present in iterable.

Goes through special effort to ensure __hash__ is not called
on items in iterable that don't support it.

**Line:** 432

---

### `def to_set(x)`

**Line:** 443

---

### `def to_column_set(x: Any) -> Set[Any]`

**Line:** 452

---

### `def update_copy(d, _new = None, **kw)`

**Description:**
Copy the given dict and update with the given values.

**Line:** 461

---

### `def flatten_iterator(x: Iterable[_T]) -> Iterator[_T]`

**Description:**
Given an iterator of which further sub-elements may also be
iterators, flatten the sub-elements into a single iterator.

**Line:** 471

---

### `def has_dupes(sequence, target)`

**Description:**
Given a sequence and search object, return True if there's more
than one, False if zero or one of them.

**Line:** 695

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.util._concurrency_py3k
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py`

**Imports:**
- __future__.annotations
- asyncio
- contextvars.Context
- greenlet.getcurrent
- greenlet.greenlet
- langhelpers.memoized_property
- sys
- typing
- typing.Any
- typing.Awaitable
- typing.Callable
- typing.Coroutine
- typing.Optional
- typing.TYPE_CHECKING
- typing.TypeVar
- util.typing.Protocol
- util.typing.TypeGuard

**Functions:**

### `def getcurrent() -> greenlet`

**Line:** 45

---

### `def is_exit_exception(e: BaseException) -> bool`

**Line:** 59

---

### `def iscoroutine(awaitable: Awaitable[_T_co]) -> TypeGuard[Coroutine[(Any, Any, _T_co)]]`

**Line:** 86

---

### `def _safe_cancel_awaitable(awaitable: Awaitable[Any]) -> None`

**Line:** 95

---

### `def await_only(awaitable: Awaitable[_T]) -> _T`

**Description:**
Awaits an async function in a sync method.

The sync method must be inside a :func:`greenlet_spawn` context.
:func:`await_only` calls cannot be nested.

:param awaitable: The coroutine to call.

**Line:** 102

---

### `def await_fallback(awaitable: Awaitable[_T]) -> _T`

**Description:**
Awaits an async function in a sync method.

The sync method must be inside a :func:`greenlet_spawn` context.
:func:`await_fallback` calls cannot be nested.

:param awaitable: The coroutine to call.

**Line:** 128

---

### `async def greenlet_spawn(fn: Callable[(..., _T)], _require_await: bool = False, *args: Any, **kwargs: Any) -> _T`

**Description:**
Runs a sync function ``fn`` in a new greenlet.

The sync function can then use :func:`await_only` to wait for async
functions.

:param fn: The sync callable to call.
:param \*args: Positional arguments to pass to the ``fn`` callable.
:param \*\*kwargs: Keyword arguments to pass to the ``fn`` callable.

**Line:** 155

---

### `def _util_async_run_coroutine_function(fn: Callable[(..., Coroutine[Any, Any, Any])], *args: Any, **kwargs: Any) -> Any`

**Description:**
for test suite/ util only

**Line:** 221

---

### `def _util_async_run(fn: Callable[(..., Coroutine[Any, Any, Any])], *args: Any, **kwargs: Any) -> Any`

**Description:**
for test suite/ util only

**Line:** 235

---

### `def get_event_loop() -> asyncio.AbstractEventLoop`

**Description:**
vendor asyncio.get_event_loop() for python 3.7 and above.

Python 3.10 deprecates get_event_loop() as a standalone.

**Line:** 249

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.util._has_cy
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/util/_has_cy.py`

**Imports:**
- cyextension.collections
- cyextension.immutabledict
- cyextension.processors
- cyextension.resultproxy
- cyextension.util
- os
- typing

**Functions:**

### `def _import_cy_extensions()`

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.util._py_collections
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/util/_py_collections.py`

**Imports:**
- __future__.annotations
- itertools.filterfalse
- typing.AbstractSet
- typing.Any
- typing.Callable
- typing.Collection
- typing.Dict
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.NoReturn
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.cast
- util.typing.Self

**Functions:**

### `def unique_list(seq: Iterable[_T], hashfunc: Optional[Callable[([_T], int)]] = None) -> List[_T]`

**Line:** 527

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.util.compat
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/util/compat.py`

**Imports:**
- __future__.annotations
- base64
- collections.abc.AsyncIterator
- dataclasses
- hashlib
- importlib.metadata
- importlib_metadata
- inspect
- operator
- platform
- sys
- typing
- typing.Any
- typing.AsyncGenerator
- typing.Awaitable
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.List
- typing.Mapping
- typing.Optional
- typing.Sequence
- typing.Set
- typing.Tuple
- typing.Type
- typing.TypeVar

**Functions:**

### `def inspect_getfullargspec(func: Callable[(..., Any)]) -> FullArgSpec`

**Description:**
Fully vendored version of getfullargspec from Python 3.3.

**Line:** 67

---

### `def athrow(gen: AsyncGenerator[(_T_co, Any)], typ: Any, value: Any, traceback: Any) -> Awaitable[_T_co]`

**Line:** 110

---

### `def athrow(gen: AsyncGenerator[(_T_co, Any)], typ: Any, value: Any, traceback: Any) -> Awaitable[_T_co]`

**Line:** 117

---

### `def md5_not_for_security() -> Any`

**Line:** 126

---

### `def md5_not_for_security() -> Any`

**Line:** 131

---

### `def dict_union(a: dict, b: dict) -> dict`

**Line:** 146

---

### `async def anext_(async_iterator, default = _NOT_PROVIDED)`

**Description:**
vendored from https://github.com/python/cpython/pull/8895

**Line:** 158

---

### `def importlib_metadata_get(group)`

**Line:** 174

---

### `def b(s)`

**Line:** 182

---

### `def b64decode(x: str) -> bytes`

**Line:** 186

---

### `def b64encode(x: bytes) -> str`

**Line:** 190

---

### `def decode_backslashreplace(text: bytes, encoding: str) -> str`

**Line:** 194

---

### `def cmp(a, b)`

**Line:** 198

---

### `def _formatannotation(annotation, base_module = None)`

**Description:**
vendored from python 3.7

**Line:** 202

---

### `def inspect_formatargspec(args: List[str], varargs: Optional[str] = None, varkw: Optional[str] = None, defaults: Optional[Sequence[Any]] = None, kwonlyargs: Optional[Sequence[str]] = (), kwonlydefaults: Optional[Mapping[(str, Any)]] = {}, annotations: Mapping[(str, Any)] = {}, formatarg: Callable[([str], str)] = str, formatvarargs: Callable[([str], str)] = lambda name: '*' + name, formatvarkw: Callable[([str], str)] = lambda name: '**' + name, formatvalue: Callable[([Any], str)] = lambda value: '=' + repr(value), formatreturns: Callable[([Any], str)] = lambda text: ' -> ' + str(text), formatannotation: Callable[([Any], str)] = _formatannotation) -> str`

**Description:**
Copy formatargspec from python 3.7 standard library.

Python 3 has deprecated formatargspec and requested that Signature
be used instead, however this requires a full reimplementation
of formatargspec() in terms of creating Parameter objects and such.
Instead of introducing all the object-creation overhead and having
to reinvent from scratch, just copy their compatibility routine.

Ultimately we would need to rewrite our "decorator" routine completely
which is not really worth it right now, until all Python 2.x support
is dropped.

**Line:** 219

---

### `def dataclass_fields(cls: Type[Any]) -> Iterable[dataclasses.Field[Any]]`

**Description:**
Return a sequence of all dataclasses.Field objects associated
with a class as an already processed dataclass.

The class must **already be a dataclass** for Field objects to be returned.

**Line:** 291

---

### `def local_dataclass_fields(cls: Type[Any]) -> Iterable[dataclasses.Field[Any]]`

**Description:**
Return a sequence of all dataclasses.Field objects associated with
an already processed dataclass, excluding those that originate from a
superclass.

The class must **already be a dataclass** for Field objects to be returned.

**Line:** 305

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.util.concurrency
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/util/concurrency.py`

**Imports:**
- __future__.annotations
- _concurrency_py3k.AsyncAdaptedLock
- _concurrency_py3k._util_async_run
- _concurrency_py3k._util_async_run_coroutine_function
- _concurrency_py3k.await_fallback
- _concurrency_py3k.await_only
- _concurrency_py3k.greenlet_spawn
- _concurrency_py3k.is_exit_exception
- asyncio
- greenlet
- typing

**Functions:**

### `def _not_implemented()`

**Line:** 37

---

### `def is_exit_exception(e)`

**Line:** 50

---

### `def await_only(thing)`

**Line:** 53

---

### `def await_fallback(thing)`

**Line:** 56

---

### `def greenlet_spawn(fn, *args, **kw)`

**Line:** 59

---

### `def AsyncAdaptedLock(*args, **kw)`

**Line:** 62

---

### `def _util_async_run(fn, *arg, **kw)`

**Line:** 65

---

### `def _util_async_run_coroutine_function(fn, *arg, **kw)`

**Line:** 68

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.util.deprecations
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/util/deprecations.py`

**Imports:**
- __future__.annotations
- langhelpers._hash_limit_string
- langhelpers._warnings_warn
- langhelpers.decorator
- langhelpers.inject_docstring_text
- langhelpers.inject_param_text
- re
- typing.Any
- typing.Callable
- typing.Dict
- typing.Match
- typing.Optional
- typing.Sequence
- typing.Set
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union

**Functions:**

### `def _warn_with_version(msg: str, version: str, type_: Type[exc.SADeprecationWarning], stacklevel: int, code: Optional[str] = None) -> None`

**Line:** 42

---

### `def warn_deprecated(msg: str, version: str, stacklevel: int = 3, code: Optional[str] = None) -> None`

**Line:** 55

---

### `def warn_deprecated_limited(msg: str, args: Sequence[Any], version: str, stacklevel: int = 3, code: Optional[str] = None) -> None`

**Description:**
Issue a deprecation warning with a parameterized string,
limiting the number of registrations.

**Line:** 63

---

### `def deprecated_cls(version: str, message: str, constructor: Optional[str] = '__init__') -> Callable[([Type[_T]], Type[_T])]`

**Line:** 81

---

### `def deprecated(version: str, message: Optional[str] = None, add_deprecation_to_docstring: bool = True, warning: Optional[Type[exc.SADeprecationWarning]] = None, enable_warnings: bool = True) -> Callable[([_F], _F)]`

**Description:**
Decorates a function and issues a deprecation warning on use.

:param version:
Issue version in the warning.

:param message:
If provided, issue message in the warning.  A sensible default
is used if not provided.

:param add_deprecation_to_docstring:
Default True.  If False, the wrapped function's __doc__ is left
as-is.  If True, the 'message' is prepended to the docs if
provided, or sensible default if message is omitted.

**Line:** 99

---

### `def moved_20(message: str, **kw: Any) -> Callable[([Callable[..., _T]], Callable[..., _T])]`

**Line:** 153

---

### `def became_legacy_20(api_name: str, alternative: Optional[str] = None, **kw: Any) -> Callable[([_F], _F)]`

**Line:** 161

---

### `def deprecated_params(**specs: Tuple[(str, str)]) -> Callable[([_F], _F)]`

**Description:**
Decorates a function to warn on use of certain parameters.

e.g. ::

@deprecated_params(
weak_identity_map=(
"0.7",
"the :paramref:`.Session.weak_identity_map parameter "
"is deprecated."
)

)

**Line:** 199

---

### `def _sanitize_restructured_text(text: str) -> str`

**Line:** 300

---

### `def _decorate_cls_with_warning(cls: Type[_T], constructor: Optional[str], wtype: Type[exc.SADeprecationWarning], message: str, version: str, docstring_header: Optional[str] = None) -> Type[_T]`

**Line:** 311

---

### `def _decorate_with_warning(func: _F, wtype: Type[exc.SADeprecationWarning], message: str, version: str, docstring_header: Optional[str] = None, enable_warnings: bool = True) -> _F`

**Description:**
Wrap a function with a warnings.warn and augmented docstring.

**Line:** 359

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.util.langhelpers
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py`

**Imports:**
- __future__.annotations
- _has_cy.HAS_CYEXTENSION
- collections
- enum
- enum.IntFlag
- functools.update_wrapper
- inspect
- itertools
- operator
- re
- sys
- textwrap
- threading
- types
- types.CodeType
- typing.Any
- typing.Callable
- typing.Dict
- typing.FrozenSet
- typing.Generic
- typing.Iterator
- typing.List
- typing.Literal
- typing.Mapping
- typing.NoReturn
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- warnings

**Functions:**

### `def get_annotations(obj: Any) -> Mapping[(str, Any)]`

**Line:** 65

---

### `def get_annotations(obj: Any) -> Mapping[(str, Any)]`

**Line:** 70

---

### `def md5_hex(x: Any) -> str`

**Line:** 87

---

### `def walk_subclasses(cls: Type[_T]) -> Iterator[Type[_T]]`

**Line:** 153

---

### `def string_or_unprintable(element: Any) -> str`

**Line:** 167

---

### `def clsname_as_plain_name(cls: Type[Any]) -> str`

**Line:** 177

---

### `def method_is_overridden(instance_or_cls: Union[(Type[Any], object)], against_method: Callable[(..., Any)]) -> bool`

**Description:**
Return True if the two class methods don't match.

**Line:** 183

---

### `def decode_slice(slc: slice) -> Tuple[(Any, ...)]`

**Description:**
decode a slice object as sent to __getitem__.

takes into account the 2.5 __index__() method, basically.

**Line:** 201

---

### `def _unique_symbols(used: Sequence[str], *bases: str) -> Iterator[str]`

**Line:** 215

---

### `def map_bits(fn: Callable[([int], Any)], n: int) -> Iterator[Any]`

**Description:**
Call the given function given each nonzero bit from n.

**Line:** 231

---

### `def decorator(target: Callable[(..., Any)]) -> Callable[([_Fn], _Fn)]`

**Description:**
A signature-matching decorator factory.

**Line:** 245

---

### `def _update_argspec_defaults_into_env(spec, env)`

**Description:**
given a FullArgSpec, convert defaults to be symbol names in an env.

**Line:** 316

---

### `def _exec_code_in_env(code: Union[(str, types.CodeType)], env: Dict[(str, Any)], fn_name: str) -> Callable[(..., Any)]`

**Line:** 337

---

### `def _inspect_func_args(fn)`

**Line:** 388

---

### `def get_cls_kwargs(cls: type, _set: Optional[Set[str]] = None, raiseerr: Literal[True] = Ellipsis) -> Set[str]`

**Decorators:**
- `@overload`

**Line:** 409

---

### `def get_cls_kwargs(cls: type, _set: Optional[Set[str]] = None, raiseerr: bool = False) -> Optional[Set[str]]`

**Decorators:**
- `@overload`

**Line:** 419

---

### `def get_cls_kwargs(cls: type, _set: Optional[Set[str]] = None, raiseerr: bool = False) -> Optional[Set[str]]`

**Description:**
Return the full set of inherited kwargs for the given `cls`.

Probes a class's __init__ method, collecting all named arguments.  If the
__init__ defines a \**kwargs catch-all, then the constructor is presumed
to pass along unrecognized keywords to its base classes, and the
collection process is repeated recursively on each of the bases.

Uses a subset of inspect.getfullargspec() to cut down on method overhead,
as this is used within the Core typing system to create copies of type
objects which is a performance-sensitive operation.

No anonymous tuple arguments please !

**Line:** 425

---

### `def get_func_kwargs(func: Callable[(..., Any)]) -> List[str]`

**Description:**
Return the set of legal kwargs for the given `func`.

Uses getargspec so is safe to call for methods, functions,
etc.

**Line:** 478

---

### `def get_callable_argspec(fn: Callable[(..., Any)], no_self: bool = False, _is_init: bool = False) -> compat.FullArgSpec`

**Description:**
Return the argument signature for any callable.

All pure-Python callables are accepted, including
functions, methods, classes, objects with __call__;
builtins and other edge cases like functools.partial() objects
raise a TypeError.

**Line:** 489

---

### `def format_argspec_plus(fn: Union[(Callable[..., Any], compat.FullArgSpec)], grouped: bool = True) -> Dict[(str, Optional[str])]`

**Description:**
Returns a dictionary of formatted, introspected function arguments.

A enhanced variant of inspect.formatargspec to support code generation.

fn
An inspectable callable or tuple of inspect getargspec() results.
grouped
Defaults to True; include (parens, around, argument) lists

Returns:

args
Full inspect.formatargspec for fn
self_arg
The name of the first positional argument, varargs[0], or None
if the function defines no positional arguments.
apply_pos
args, re-written in calling rather than receiving syntax.  Arguments are
passed positionally.
apply_kw
Like apply_pos, except keyword-ish args are passed as keywords.
apply_pos_proxied
Like apply_pos but omits the self/cls argument

Example::

>>> format_argspec_plus(lambda self, a, b, c=3, **d: 123)
{'grouped_args': '(self, a, b, c=3, **d)',
'self_arg': 'self',
'apply_kw': '(self, a, b, c=c, **d)',
'apply_pos': '(self, a, b, c, **d)'}

**Line:** 545

---

### `def format_argspec_init(method, grouped = True)`

**Description:**
format_argspec_plus with considerations for typical __init__ methods

Wraps format_argspec_plus with error handling strategies for typical
__init__ cases::

object.__init__ -> (self)
other unreflectable (usually C) -> (self, *args, **kwargs)

**Line:** 662

---

### `def create_proxy_methods(target_cls: Type[Any], target_cls_sphinx_name: str, proxy_cls_sphinx_name: str, classmethods: Sequence[str] = (), methods: Sequence[str] = (), attributes: Sequence[str] = (), use_intermediate_variable: Sequence[str] = ()) -> Callable[([_T], _T)]`

**Description:**
A class decorator indicating attributes should refer to a proxy
class.

This decorator is now a "marker" that does nothing at runtime.  Instead,
it is consumed by the tools/generate_proxy_methods.py script to
statically generate proxy methods and attributes that are fully
recognized by typing tools such as mypy.

**Line:** 693

---

### `def getargspec_init(method)`

**Description:**
inspect.getargspec with considerations for typical __init__ methods

Wraps inspect.getargspec with error handling for typical __init__ cases::

object.__init__ -> (self)
other unreflectable (usually C) -> (self, *args, **kwargs)

**Line:** 718

---

### `def unbound_method_to_callable(func_or_cls)`

**Description:**
Adjust the incoming callable such that a 'self' argument is not
required.

**Line:** 736

---

### `def generic_repr(obj: Any, additional_kw: Sequence[Tuple[(str, Any)]] = (), to_inspect: Optional[Union[(object, List[object])]] = None, omit_kwarg: Sequence[str] = ()) -> str`

**Description:**
Produce a __repr__() based on direct association of the __init__()
specification vs. same-named attributes present.

**Line:** 748

---

### `def class_hierarchy(cls)`

**Description:**
Return an unordered sequence of all classes related to cls.

Traverses diamond hierarchies.

Fibs slightly: subclasses of builtin types are not returned.  Thus
class_hierarchy(class A(object)) returns (A, object), not A plus every
class systemwide that derives from object.

**Line:** 856

---

### `def iterate_attributes(cls)`

**Description:**
iterate all the keys and attributes associated
with a class, without using getattr().

Does not use getattr() so that class-sensitive
descriptors (i.e. property.__get__()) are not called.

**Line:** 894

---

### `def monkeypatch_proxied_specials(into_cls, from_cls, skip = None, only = None, name = 'self.proxy', from_instance = None)`

**Description:**
Automates delegation of __specials__ for a proxying type.

**Line:** 910

---

### `def methods_equivalent(meth1, meth2)`

**Description:**
Return True if the two methods are the same implementation.

**Line:** 977

---

### `def as_interface(obj, cls = None, methods = None, required = None)`

**Description:**
Ensure basic interface compliance for an instance or dict of callables.

Checks that ``obj`` implements public methods of ``cls`` or has members
listed in ``methods``. If ``required`` is not supplied, implementing at
least one interface method is sufficient. Methods present on ``obj`` that
are not in the interface are ignored.

If ``obj`` is a dict and ``dict`` does not meet the interface
requirements, the keys of the dictionary are inspected. Keys present in
``obj`` that are not in the interface will raise TypeErrors.

Raises TypeError if ``obj`` does not meet the interface criteria.

In all passing cases, an object with callable members is returned.  In the
simple case, ``obj`` is returned as-is; if dict processing kicks in then
an anonymous class is returned.

obj
A type, instance, or dictionary of callables.
cls
Optional, a type.  All public methods of cls are considered the
interface.  An ``obj`` instance of cls will always pass, ignoring
``required``..
methods
Optional, a sequence of method names to consider as the interface.
required
Optional, a sequence of mandatory implementations. If omitted, an
``obj`` that provides at least one interface method is considered
sufficient.  As a convenience, required may be a type, in which case
all public methods of the type are required.

**Line:** 985

---

### `def memoized_instancemethod(fn: _F) -> _F`

**Description:**
Decorate a method memoize its return value.

Best applied to no-arg methods: memoization is not sensitive to
argument values, and will always return the same value even when
called with different arguments.

**Line:** 1185

---

### `def asbool(obj: Any) -> bool`

**Line:** 1339

---

### `def bool_or_str(*text: str) -> Callable[([str], Union[str, bool])]`

**Description:**
Return a callable that will evaluate a string as
boolean, or one of a set of "alternate" string values.

**Line:** 1351

---

### `def asint(value: Any) -> Optional[int]`

**Description:**
Coerce to integer.

**Line:** 1366

---

### `def coerce_kw_type(kw: Dict[(str, Any)], key: str, type_: Type[Any], flexi_bool: bool = True, dest: Optional[Dict[(str, Any)]] = None) -> None`

**Description:**
If 'key' is present in dict 'kw', coerce its value to type 'type\_' if
necessary.  If 'flexi_bool' is True, the string '0' is considered false
when coercing to boolean.

**Line:** 1374

---

### `def constructor_key(obj: Any, cls: Type[Any]) -> Tuple[(Any, ...)]`

**Description:**
Produce a tuple structure that is cacheable using the __dict__ of
obj to retrieve values

**Line:** 1400

---

### `def constructor_copy(obj: _T, cls: Type[_T], *args: Any, **kw: Any) -> _T`

**Description:**
Instantiate cls using the __dict__ of obj as constructor arguments.

Uses inspect to match the named arguments of ``cls``.

**Line:** 1411

---

### `def counter() -> Callable[([], int)]`

**Description:**
Return a threadsafe counter function.

**Line:** 1425

---

### `def duck_type_collection(specimen: Any, default: Optional[Type[Any]] = None) -> Optional[Type[Any]]`

**Description:**
Given an instance or class, guess if it is or is acting as one of
the basic collection types: list, set and dict.  If the __emulates__
property is present, return that preferentially.

**Line:** 1439

---

### `def assert_arg_type(arg: Any, argtype: Union[(Tuple[Type[Any], ...], Type[Any])], name: str) -> Any`

**Line:** 1474

---

### `def dictlike_iteritems(dictlike)`

**Description:**
Return a (key, value) iterator for almost any dict-like object.

**Line:** 1492

---

### `def parse_user_argument_for_enum(arg: Any, choices: Dict[(_E, List[Any])], name: str, resolve_symbol_names: bool = False) -> Optional[_E]`

**Description:**
Given a user parameter, parse the parameter into a chosen value
from a list of choice objects, typically Enum values.

The user argument can be a string name that matches the name of a
symbol, or the symbol object itself, or any number of alternate choices
such as True/False/ None etc.

:param arg: the user argument.
:param choices: dictionary of enum values to lists of possible
entries for each.
:param name: name of the argument.   Used in an :class:`.ArgumentError`
that is raised if the parameter doesn't match any available argument.

**Line:** 1711

---

### `def set_creation_order(instance: Any) -> None`

**Description:**
Assign a '_creation_order' sequence to the given instance.

This allows multiple instances to be sorted in order of creation
(typically within a single thread; the counter is not particularly
threadsafe).

**Line:** 1748

---

### `def warn_exception(func: Callable[(..., Any)], *args: Any, **kwargs: Any) -> Any`

**Description:**
executes the given function, catches all exceptions and converts to
a warning.

**Line:** 1761

---

### `def ellipses_string(value, len_ = 25)`

**Line:** 1772

---

### `def warn(msg: str, code: Optional[str] = None) -> None`

**Description:**
Issue a warning.

If msg is a string, :class:`.exc.SAWarning` is used as
the category.

**Line:** 1812

---

### `def warn_limited(msg: str, args: Sequence[Any]) -> None`

**Description:**
Issue a warning with a parameterized string, limiting the number
of registrations.

**Line:** 1825

---

### `def tag_method_for_warnings(message: str, category: Type[Warning]) -> Callable[([_F], _F)]`

**Line:** 1838

---

### `def _warnings_warn(message: Union[(str, Warning)], category: Optional[Type[Warning]] = None, stacklevel: int = 2) -> None`

**Line:** 1851

---

### `def only_once(fn: Callable[(..., _T)], retry_on_exception: bool) -> Callable[(..., Optional[_T])]`

**Description:**
Decorate the given function to be a no-op after it is called exactly
once.

**Line:** 1902

---

### `def chop_traceback(tb: List[str], exclude_prefix: re.Pattern[str] = _UNITTEST_RE, exclude_suffix: re.Pattern[str] = _SQLA_RE) -> List[str]`

**Description:**
Chop extraneous lines off beginning and end of a traceback.

:param tb:
a list of traceback lines as returned by ``traceback.format_stack()``

:param exclude_prefix:
a regular expression object matching lines to skip at beginning of
``tb``

:param exclude_suffix:
a regular expression object matching lines to skip at end of ``tb``

**Line:** 1932

---

### `def attrsetter(attrname)`

**Line:** 1961

---

### `def wrap_callable(wrapper, fn)`

**Description:**
Augment functools.update_wrapper() to work with objects with
a ``__call__()`` method.

:param fn:
object with __call__ method

**Line:** 2036

---

### `def quoted_token_parser(value)`

**Description:**
Parse a dotted identifier with accommodation for quoted names.

Includes support for SQL-style double quotes as a literal character.

E.g.::

>>> quoted_token_parser("name")
["name"]
>>> quoted_token_parser("schema.name")
["schema", "name"]
>>> quoted_token_parser('"Schema"."Name"')
['Schema', 'Name']
>>> quoted_token_parser('"Schema"."Name""Foo"')
['Schema', 'Name""Foo']

**Line:** 2060

---

### `def add_parameter_text(params: Any, text: str) -> Callable[([_F], _F)]`

**Line:** 2104

---

### `def _dedent_docstring(text: str) -> str`

**Line:** 2117

---

### `def inject_docstring_text(given_doctext: Optional[str], injecttext: str, pos: int) -> str`

**Line:** 2129

---

### `def inject_param_text(doctext: str, inject_params: Dict[(str, str)]) -> str`

**Line:** 2152

---

### `def repr_tuple_names(names: List[str]) -> Optional[str]`

**Description:**
Trims a list of strings from the middle and return a string of up to
four elements. Strings greater than 11 characters will be truncated

**Line:** 2195

---

### `def has_compiled_ext(raise_ = False)`

**Line:** 2209

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.util.topological
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/util/topological.py`

**Imports:**
- __future__.annotations
- exc.CircularDependencyError
- typing.Any
- typing.Collection
- typing.DefaultDict
- typing.Iterable
- typing.Iterator
- typing.Sequence
- typing.Set
- typing.Tuple
- typing.TypeVar

**Functions:**

### `def sort_as_subsets(tuples: Collection[Tuple[(_T, _T)]], allitems: Collection[_T]) -> Iterator[Sequence[_T]]`

**Line:** 30

---

### `def sort(tuples: Collection[Tuple[(_T, _T)]], allitems: Collection[_T], deterministic_order: bool = True) -> Iterator[_T]`

**Description:**
sort the given list of items by dependency.

'tuples' is a list of tuples representing a partial ordering.

deterministic_order is no longer used, the order is now always
deterministic given the order of "allitems".    the flag is there
for backwards compatibility with Alembic.

**Line:** 58

---

### `def find_cycles(tuples: Iterable[Tuple[(_T, _T)]], allitems: Iterable[_T]) -> Set[_T]`

**Line:** 77

---

### `def _gen_edges(edges: DefaultDict[(_T, Set[_T])]) -> Set[Tuple[(_T, _T)]]`

**Line:** 119

---


## Module: venv2.libthon3.12.site-packages.sqlalchemy.util.typing
**File:** `venv2/lib/python3.12/site-packages/sqlalchemy/util/typing.py`

**Imports:**
- __future__.annotations
- builtins
- re
- sys
- types.NoneType
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.ForwardRef
- typing.Generic
- typing.Iterable
- typing.Mapping
- typing.NewType
- typing.NoReturn
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- typing_extensions.Annotated
- typing_extensions.Concatenate
- typing_extensions.Final
- typing_extensions.Literal
- typing_extensions.NotRequired
- typing_extensions.ParamSpec
- typing_extensions.Protocol
- typing_extensions.Self
- typing_extensions.SupportsIndex
- typing_extensions.TypeAlias
- typing_extensions.TypeGuard
- typing_extensions.TypedDict
- typing_extensions.dataclass_transform
- typing_extensions.final
- typing_extensions.get_args
- typing_extensions.get_origin

**Functions:**

### `def de_stringify_annotation(cls: Type[Any], annotation: _AnnotationScanType, originating_module: str, locals_: Mapping[(str, Any)], str_cleanup_fn: Optional[Callable[([str, str], str)]] = None, include_generic: bool = False, _already_seen: Optional[Set[Any]] = None) -> Type[Any]`

**Description:**
Resolve annotations that may be string based into real objects.

This is particularly important if a module defines "from __future__ import
annotations", as everything inside of __annotations__ is a string. We want
to at least have generic containers like ``Mapped``, ``Union``, ``List``,
etc.

**Line:** 125

---

### `def _copy_generic_annotation_with(annotation: GenericProtocol[_T], elements: Tuple[(_AnnotationScanType, ...)]) -> Type[_T]`

**Line:** 195

---

### `def eval_expression(expression: str, module_name: str, locals_: Optional[Mapping[(str, Any)]] = None) -> Any`

**Line:** 206

---

### `def eval_name_only(name: str, module_name: str, locals_: Optional[Mapping[(str, Any)]] = None) -> Any`

**Line:** 230

---

### `def resolve_name_to_real_class_name(name: str, module_name: str) -> str`

**Line:** 264

---

### `def de_stringify_union_elements(cls: Type[Any], annotation: ArgsTypeProcotol, originating_module: str, locals_: Mapping[(str, Any)], str_cleanup_fn: Optional[Callable[([str, str], str)]] = None) -> Type[Any]`

**Line:** 273

---

### `def is_pep593(type_: Optional[_AnnotationScanType]) -> bool`

**Line:** 295

---

### `def is_literal(type_: _AnnotationScanType) -> bool`

**Line:** 299

---

### `def is_newtype(type_: Optional[_AnnotationScanType]) -> TypeGuard[NewType]`

**Line:** 303

---

### `def is_generic(type_: _AnnotationScanType) -> TypeGuard[GenericProtocol[Any]]`

**Line:** 311

---

### `def flatten_newtype(type_: NewType) -> Type[Any]`

**Line:** 315

---

### `def is_fwd_ref(type_: _AnnotationScanType, check_generic: bool = False) -> TypeGuard[ForwardRef]`

**Line:** 322

---

### `def de_optionalize_union_types(type_: str) -> str`

**Decorators:**
- `@overload`

**Line:** 334

---

### `def de_optionalize_union_types(type_: Type[Any]) -> Type[Any]`

**Decorators:**
- `@overload`

**Line:** 339

---

### `def de_optionalize_union_types(type_: _AnnotationScanType) -> _AnnotationScanType`

**Decorators:**
- `@overload`

**Line:** 344

---

### `def de_optionalize_union_types(type_: _AnnotationScanType) -> _AnnotationScanType`

**Description:**
Given a type, filter out ``Union`` types that include ``NoneType``
to not include the ``NoneType``.

**Line:** 350

---

### `def de_optionalize_fwd_ref_union_types(type_: ForwardRef) -> _AnnotationScanType`

**Description:**
return the non-optional type for Optional[], Union[None, ...], x|None,
etc. without de-stringifying forward refs.

unfortunately this seems to require lots of hardcoded heuristics

**Line:** 373

---

### `def make_union_type(*types: _AnnotationScanType) -> Type[Any]`

**Description:**
Make a Union type.

This is needed by :func:`.de_optionalize_union_types` which removes
``NoneType`` from a ``Union``.

**Line:** 404

---

### `def expand_unions(type_: Type[Any], include_union: bool = False, discard_none: bool = False) -> Tuple[(Type[Any], ...)]`

**Description:**
Return a type as a tuple of individual types, expanding for
``Union`` types.

**Line:** 414

---

### `def is_optional(type_: Any) -> TypeGuard[ArgsTypeProcotol]`

**Line:** 434

---

### `def is_optional_union(type_: Any) -> bool`

**Line:** 443

---

### `def is_union(type_: Any) -> TypeGuard[ArgsTypeProcotol]`

**Line:** 447

---

### `def is_origin_of_cls(type_: Any, class_obj: Union[(Tuple[Type[Any], ...], Type[Any])]) -> bool`

**Description:**
return True if the given type has an __origin__ that shares a base
with the given class

**Line:** 451

---

### `def is_origin_of(type_: Any, module: Optional[str] = None, *names: str) -> bool`

**Description:**
return True if the given type has an __origin__ with the given name
and optional module.

**Line:** 464

---

### `def _get_type_name(type_: Type[Any]) -> str`

**Line:** 479

---


## Module: venv2.libthon3.12.site-packages.typing_extensions
**File:** `venv2/lib/python3.12/site-packages/typing_extensions.py`

**Imports:**
- _socket
- abc
- annotationlib
- annotationlib.Format
- annotationlib.get_annotations
- asyncio.coroutines
- builtins
- collections
- collections.abc
- contextlib
- enum
- functools
- inspect
- io
- keyword
- operator
- sys
- types
- types.MethodType
- typing
- typing.Any
- typing.AsyncContextManager
- typing.AsyncGenerator
- typing.ContextManager
- typing.Generator
- typing.ParamSpec
- typing.TypeVar
- typing.TypeVarTuple
- warnings

**Functions:**

### `def _should_collect_from_parameters(t)`

**Line:** 172

---

### `def _should_collect_from_parameters(t)`

**Line:** 177

---

### `def final(f)`

**Description:**
This decorator can be used to indicate to type checkers that
the decorated method cannot be overridden, and decorated class
cannot be subclassed. For example:

class Base:
@final
def done(self) -> None:
...
class Sub(Base):
def done(self) -> None:  # Error reported by type checker
...
@final
class Leaf:
...
class Other(Leaf):  # Error reported by type checker
...

There is no runtime checking of these properties. The decorator
sets the ``__final__`` attribute to ``True`` on the decorated object
to allow runtime introspection.

**Line:** 238

---

### `def IntVar(name)`

**Line:** 270

---

### `def _flatten_literal_params(parameters)`

**Description:**
An internal helper for Literal creation: flatten Literals among parameters

**Line:** 278

---

### `def _value_and_type_iter(params)`

**Line:** 288

---

### `def overload(func)`

**Description:**
Decorator for overloaded functions/methods.

In a stub file, place two or more stub definitions for the same
function in a row, each decorated with @overload.  For example:

@overload
def utf8(value: None) -> None: ...
@overload
def utf8(value: bytes) -> bytes: ...
@overload
def utf8(value: str) -> bytes: ...

In a non-stub file (i.e. a regular .py file), do the same but
follow it with an implementation.  The implementation should *not*
be decorated with @overload.  For example:

@overload
def utf8(value: None) -> None: ...
@overload
def utf8(value: bytes) -> bytes: ...
@overload
def utf8(value: str) -> bytes: ...
def utf8(value):
# implementation goes here

The overloads for a function can be retrieved at runtime using the
get_overloads() function.

**Line:** 361

---

### `def get_overloads(func)`

**Description:**
Return all defined overloads for *func* as a sequence.

**Line:** 401

---

### `def clear_overloads()`

**Description:**
Clear all overloads in the registry.

**Line:** 412

---

### `def _is_dunder(attr)`

**Line:** 438

---

### `def _get_protocol_attrs(cls)`

**Line:** 519

---

### `def _caller(depth = 1, default = '__main__')`

**Line:** 531

---

### `def _allow_reckless_class_checks(depth = 2)`

**Description:**
Allow instance and class checks for special stdlib modules.
The abc and functools modules indiscriminately call isinstance() and
issubclass() on the whole MRO of a user class, which may contain protocols.

**Line:** 548

---

### `def _no_init(self, *args, **kwargs)`

**Line:** 555

---

### `def _type_check_issubclass_arg_1(arg)`

**Description:**
Raise TypeError if `arg` is not an instance of `type`
in `issubclass(arg, <protocol>)`.

In most cases, this is verified by type.__subclasscheck__.
Checking it again unnecessarily would slow down issubclass() checks,
so, we don't perform this check unless we absolutely have to.

For various error paths, however,
we want to ensure that *this* error message is shown to the user
where relevant, rather than a typing.py-specific error message.

**Line:** 559

---

### `def _proto_hook(cls, other)`

**Decorators:**
- `@classmethod`

**Line:** 679

---

### `def runtime_checkable(cls)`

**Description:**
Mark a protocol class as a runtime protocol.

Such protocol can be used with isinstance() and issubclass().
Raise TypeError if applied to a non-protocol class.
This allows a simple-minded structural check very similar to
one trick ponies in collections.abc such as Iterable.

For example::

@runtime_checkable
class Closable(Protocol):
def close(self): ...

assert isinstance(open('/some/file'), Closable)

Warning: this will check only the presence of the required methods,
not their type signatures!

**Line:** 728

---

### `def _get_typeddict_qualifiers(annotation_type)`

**Line:** 975

---

### `def _create_typeddict(typename, fields, typing_is_inline, total, closed, extra_items, **kwargs)`

**Line:** 1165

---

### `def TypedDict(self, args)`

**Decorators:**
- `@_TypedDictSpecialForm`

**Description:**
A simple typed namespace. At runtime it is equivalent to a plain dict.

TypedDict creates a dictionary type such that a type checker will expect all
instances to have a certain set of keys, where each key is
associated with a value of a consistent type. This expectation
is not checked at runtime.

Usage::

class Point2D(TypedDict):
x: int
y: int
label: str

a: Point2D = {'x': 1, 'y': 2, 'label': 'good'}  # OK
b: Point2D = {'z': 3, 'label': 'bad'}           # Fails type check

assert Point2D(x=1, y=2, label='first') == dict(x=1, y=2, label='first')

The type info can be accessed via the Point2D.__annotations__ dict, and
the Point2D.__required_keys__ and Point2D.__optional_keys__ frozensets.
TypedDict supports an additional equivalent form::

Point2D = TypedDict('Point2D', {'x': int, 'y': int, 'label': str})

By default, all keys must be present in a TypedDict. It is possible
to override this by specifying totality::

class Point2D(TypedDict, total=False):
x: int
y: int

This means that a Point2D TypedDict can have any of the keys omitted. A type
checker is only expected to support a literal False or True as the value of
the total argument. True is the default, and makes all items defined in the
class body be required.

The Required and NotRequired special forms can also be used to mark
individual keys as being required or not required::

class Point2D(TypedDict):
x: int  # the "x" key must always be present (Required is the default)
y: NotRequired[int]  # the "y" key can be omitted

See PEP 655 for more details on Required and NotRequired.

**Line:** 1252

---

### `def is_typeddict(tp)`

**Description:**
Check if an annotation is a TypedDict class

For example::
class Film(TypedDict):
title: str
year: int

is_typeddict(Film)  # => True
is_typeddict(Union[list, str])  # => False

**Line:** 1316

---

### `def assert_type(val, typ)`

**Description:**
Assert (to the type checker) that the value is of the given type.

When the type checker encounters a call to assert_type(), it
emits an error if the value is not of the specified type::

def greet(name: str) -> None:
assert_type(name, str)  # ok
assert_type(name, int)  # type checker error

At runtime this returns the first argument unchanged and otherwise
does nothing.

**Line:** 1334

---

### `def _strip_extras(t)`

**Description:**
Strips Annotated, Required and NotRequired from a given type.

**Line:** 1354

---

### `def get_type_hints(obj, globalns = None, localns = None, include_extras = False)`

**Description:**
Return type hints for an object.

This is often the same as obj.__annotations__, but it handles
forward references encoded as string literals, adds Optional[t] if a
default value equal to None is set and recursively replaces all
'Annotated[T, ...]', 'Required[T]' or 'NotRequired[T]' with 'T'
(unless 'include_extras=True').

The argument may be a module, class, method, or function. The annotations
are returned as a dictionary. For classes, annotations include also
inherited members.

TypeError is raised if the argument is not of a type that can contain
annotations, and an empty dictionary is returned if no annotations are
present.

BEWARE -- the behavior of globalns and localns is counterintuitive
(unless you are familiar with how eval() and exec() work).  The
search order is locals first, then globals.

- If no dict arguments are passed, an attempt is made to use the
globals from obj (or the respective module's globals for classes),
and these are also used as the locals.  If the object does not appear
to have globals, an empty dictionary is used.

- If one dict argument is passed, it is used for both globals and
locals.

- If two dict arguments are passed, they specify globals and
locals, respectively.

**Line:** 1378

---

### `def _could_be_inserted_optional(t)`

**Description:**
detects Union[..., None] pattern

**Line:** 1421

---

### `def _clean_optional(obj, hints, globalns = None, localns = None)`

**Line:** 1431

---

### `def get_origin(tp)`

**Description:**
Get the unsubscripted version of a type.

This supports generic types, Callable, Tuple, Union, Literal, Final, ClassVar
and Annotated. Return None for unsupported types. Examples::

get_origin(Literal[42]) is Literal
get_origin(int) is None
get_origin(ClassVar[int]) is ClassVar
get_origin(Generic) is Generic
get_origin(Generic[T]) is Generic
get_origin(Union[T, int]) is Union
get_origin(List[Tuple[T, T]][int]) == list
get_origin(P.args) is P

**Line:** 1490

---

### `def get_args(tp)`

**Description:**
Get type arguments with all substitutions performed.

For unions, basic simplifications used by Union constructor are performed.
Examples::
get_args(Dict[str, int]) == (str, int)
get_args(int) == ()
get_args(Union[int, Union[T, int], str][int]) == (int, str)
get_args(Union[int, Tuple[T, int]][str]) == (int, Tuple[str, int])
get_args(Callable[[], T][int]) == ([], int)

**Line:** 1514

---

### `def TypeAlias(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
Special marker indicating that an assignment should
be recognized as a proper type alias definition by type
checkers.

For example::

Predicate: TypeAlias = Callable[..., bool]

It's invalid when used anywhere except as in the example above.

**Line:** 1541

---

### `def _set_default(type_param, default)`

**Line:** 1555

---

### `def _set_module(typevarlike)`

**Line:** 1560

---

### `def _type_convert(arg, module = None, allow_special_forms = False)`

**Description:**
For converting None to type(None), and strings to ForwardRef.

**Line:** 1848

---

### `def _create_concatenate_alias(origin, parameters)`

**Line:** 2011

---

### `def _concatenate_getitem(self, parameters)`

**Decorators:**
- `@typing._tp_cache`

**Line:** 2036

---

### `def Concatenate(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
Used in conjunction with ``ParamSpec`` and ``Callable`` to represent a
higher order function which adds, removes or transforms parameters of a
callable.

For example::

Callable[Concatenate[int, P], int]

See PEP 612 for detailed information.

**Line:** 2056

---

### `def TypeGuard(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
Special typing form used to annotate the return type of a user-defined
type guard function.  ``TypeGuard`` only accepts a single type argument.
At runtime, functions marked this way should return a boolean.

``TypeGuard`` aims to benefit *type narrowing* -- a technique used by static
type checkers to determine a more precise type of an expression within a
program's code flow.  Usually type narrowing is done by analyzing
conditional code flow and applying the narrowing to a block of code.  The
conditional expression here is sometimes referred to as a "type guard".

Sometimes it would be convenient to use a user-defined boolean function
as a type guard.  Such a function should use ``TypeGuard[...]`` as its
return type to alert static type checkers to this intention.

Using  ``-> TypeGuard`` tells the static type checker that for a given
function:

1. The return value is a boolean.
2. If the return value is ``True``, the type of its argument
is the type inside ``TypeGuard``.

For example::

def is_str(val: Union[str, float]):
# "isinstance" type guard
if isinstance(val, str):
# Type of ``val`` is narrowed to ``str``
...
else:
# Else, type of ``val`` is narrowed to ``float``.
...

Strict type narrowing is not enforced -- ``TypeB`` need not be a narrower
form of ``TypeA`` (it can even be a wider form) and this may lead to
type-unsafe results.  The main reason is to allow for things like
narrowing ``List[object]`` to ``List[str]`` even though the latter is not
a subtype of the former, since ``List`` is invariant.  The responsibility of
writing type-safe type guards is left to the user.

``TypeGuard`` also works with type variables.  For more information, see
PEP 647 (User-Defined Type Guards).

**Line:** 2076

---

### `def TypeIs(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
Special typing form used to annotate the return type of a user-defined
type narrower function.  ``TypeIs`` only accepts a single type argument.
At runtime, functions marked this way should return a boolean.

``TypeIs`` aims to benefit *type narrowing* -- a technique used by static
type checkers to determine a more precise type of an expression within a
program's code flow.  Usually type narrowing is done by analyzing
conditional code flow and applying the narrowing to a block of code.  The
conditional expression here is sometimes referred to as a "type guard".

Sometimes it would be convenient to use a user-defined boolean function
as a type guard.  Such a function should use ``TypeIs[...]`` as its
return type to alert static type checkers to this intention.

Using  ``-> TypeIs`` tells the static type checker that for a given
function:

1. The return value is a boolean.
2. If the return value is ``True``, the type of its argument
is the intersection of the type inside ``TypeIs`` and the argument's
previously known type.

For example::

def is_awaitable(val: object) -> TypeIs[Awaitable[Any]]:
return hasattr(val, '__await__')

def f(val: Union[int, Awaitable[int]]) -> int:
if is_awaitable(val):
assert_type(val, Awaitable[int])
else:
assert_type(val, int)

``TypeIs`` also works with type variables.  For more information, see
PEP 742 (Narrowing types with TypeIs).

**Line:** 2129

---

### `def TypeForm(self, parameters)`

**Decorators:**
- `@_TypeFormForm`

**Description:**
A special form representing the value that results from the evaluation
of a type expression. This value encodes the information supplied in the
type expression, and it represents the type described by that type expression.

When used in a type expression, TypeForm describes a set of type form objects.
It accepts a single type argument, which must be a valid type expression.
``TypeForm[T]`` describes the set of all type form objects that represent
the type T or types that are assignable to T.

Usage:

def cast[T](typ: TypeForm[T], value: Any) -> T: ...

reveal_type(cast(int, "x"))  # int

See PEP 747 for more information.

**Line:** 2182

---

### `def LiteralString(self, params)`

**Decorators:**
- `@_SpecialForm`

**Description:**
Represents an arbitrary literal string.

Example::

from typing_extensions import LiteralString

def query(sql: LiteralString) -> ...:
...

query("SELECT * FROM table")  # ok
query(f"SELECT * FROM {input()}")  # not ok

See PEP 675 for details.

**Line:** 2252

---

### `def Self(self, params)`

**Decorators:**
- `@_SpecialForm`

**Description:**
Used to spell the type of "self" in classes.

Example::

from typing import Self

class ReturnsSelf:
def parse(self, data: bytes) -> Self:
...
return self

**Line:** 2275

---

### `def Never(self, params)`

**Decorators:**
- `@_SpecialForm`

**Description:**
The bottom type, a type that has no members.

This can be used to define a function that should never be
called, or a function that never returns::

from typing_extensions import Never

def never_call_me(arg: Never) -> None:
pass

def int_or_str(arg: int | str) -> None:
never_call_me(arg)  # type checker error
match arg:
case int():
print("It's an int")
case str():
print("It's a str")
case _:
never_call_me(arg)  # ok, arg is of type Never

**Line:** 2296

---

### `def Required(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
A special typing construct to mark a key of a total=False TypedDict
as required. For example:

class Movie(TypedDict, total=False):
title: Required[str]
year: int

m = Movie(
title='The Matrix',  # typechecker error if key is omitted
year=1999,
)

There is no runtime checking that a required key is actually provided
when instantiating a related TypedDict.

**Line:** 2327

---

### `def NotRequired(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
A special typing construct to mark a key of a TypedDict as
potentially missing. For example:

class Movie(TypedDict):
title: str
year: NotRequired[int]

m = Movie(
title='The Matrix',  # typechecker error if key is omitted
year=1999,
)

**Line:** 2347

---

### `def ReadOnly(self, parameters)`

**Decorators:**
- `@_ExtensionsSpecialForm`

**Description:**
A special typing construct to mark an item of a TypedDict as read-only.

For example:

class Movie(TypedDict):
title: ReadOnly[str]
year: int

def mutate_movie(m: Movie) -> None:
m["year"] = 1992  # allowed
m["title"] = "The Matrix"  # typechecker error

There is no runtime checking for this property.

**Line:** 2368

---

### `def _is_unpack(obj)`

**Line:** 2432

---

### `def Unpack(self, parameters)`

**Decorators:**
- `@_UnpackSpecialForm`

**Line:** 2469

---

### `def _is_unpack(obj)`

**Line:** 2473

---

### `def _unpack_args(*args)`

**Line:** 2477

---

### `def reveal_type(obj: T) -> T`

**Description:**
Reveal the inferred type of a variable.

When a static type checker encounters a call to ``reveal_type()``,
it will emit the inferred type of the argument::

x: int = 1
reveal_type(x)

Running a static type checker (e.g., ``mypy``) on this example
will produce output similar to 'Revealed type is "builtins.int"'.

At runtime, the function prints the runtime type of the
argument and returns it unchanged.

**Line:** 2637

---

### `def assert_never(arg: Never) -> Never`

**Description:**
Assert to the type checker that a line of code is unreachable.

Example::

def int_or_str(arg: int | str) -> None:
match arg:
case int():
print("It's an int")
case str():
print("It's a str")
case _:
assert_never(arg)

If a type checker finds that a call to assert_never() is
reachable, it will emit an error.

At runtime, this throws an exception when called.

**Line:** 2666

---

### `def dataclass_transform(eq_default: bool = True, order_default: bool = False, kw_only_default: bool = False, frozen_default: bool = False, field_specifiers: typing.Tuple[(typing.Union[typing.Type[typing.Any], typing.Callable[..., typing.Any]], ...)] = (), **kwargs: typing.Any) -> typing.Callable[([T], T)]`

**Description:**
Decorator that marks a function, class, or metaclass as providing
dataclass-like behavior.

Example:

from typing_extensions import dataclass_transform

_T = TypeVar("_T")

# Used on a decorator function
@dataclass_transform()
def create_model(cls: type[_T]) -> type[_T]:
...
return cls

@create_model
class CustomerModel:
id: int
name: str

# Used on a base class
@dataclass_transform()
class ModelBase: ...

class CustomerModel(ModelBase):
id: int
name: str

# Used on a metaclass
@dataclass_transform()
class ModelMeta(type): ...

class ModelBase(metaclass=ModelMeta): ...

class CustomerModel(ModelBase):
id: int
name: str

Each of the ``CustomerModel`` classes defined in this example will now
behave similarly to a dataclass created with the ``@dataclasses.dataclass``
decorator. For example, the type checker will synthesize an ``__init__``
method.

The arguments to this decorator can be used to customize this behavior:
- ``eq_default`` indicates whether the ``eq`` parameter is assumed to be
True or False if it is omitted by the caller.
- ``order_default`` indicates whether the ``order`` parameter is
assumed to be True or False if it is omitted by the caller.
- ``kw_only_default`` indicates whether the ``kw_only`` parameter is
assumed to be True or False if it is omitted by the caller.
- ``frozen_default`` indicates whether the ``frozen`` parameter is
assumed to be True or False if it is omitted by the caller.
- ``field_specifiers`` specifies a static list of supported classes
or functions that describe fields, similar to ``dataclasses.field()``.

At runtime, this decorator records its arguments in the
``__dataclass_transform__`` attribute on the decorated object.

See PEP 681 for details.

**Line:** 2696

---

### `def override(arg: _F) -> _F`

**Description:**
Indicate that a method is intended to override a method in a base class.

Usage:

class Base:
def method(self) -> None:
pass

class Child(Base):
@override
def method(self) -> None:
super().method()

When this decorator is applied to a method, the type checker will
validate that it overrides a method with the same name on a base class.
This helps prevent bugs that may occur when a base class is changed
without an equivalent change to a child class.

There is no runtime checking of these properties. The decorator
sets the ``__override__`` attribute to ``True`` on the decorated object
to allow runtime introspection.

See PEP 698 for details.

**Line:** 2787

---

### `def _is_param_expr(arg)`

**Line:** 2967

---

### `def _is_param_expr(arg)`

**Line:** 2972

---

### `def _check_generic(cls, parameters, elen = _marker)`

**Description:**
Check correct count for parameters of a generic cls (internal helper).

This gives a nice error message in case of count mismatch.

**Line:** 2993

---

### `def _check_generic(cls, parameters, elen)`

**Description:**
Check correct count for parameters of a generic cls (internal helper).

This gives a nice error message in case of count mismatch.

**Line:** 3048

---

### `def _has_generic_or_protocol_as_origin() -> bool`

**Line:** 3086

---

### `def _is_unpacked_typevartuple(x) -> bool`

**Line:** 3108

---

### `def _collect_type_vars(types, typevar_types = None)`

**Description:**
Collect all type variable contained in types in order of
first appearance (lexicographic order). For example::

_collect_type_vars((T, List[S, T])) == (T, S)

**Line:** 3121

---

### `def _collect_parameters(args)`

**Description:**
Collect all type variables and parameter specifications in args
in order of first appearance (lexicographic order).

For example::

assert _collect_parameters((T, Callable[P, T])) == (T, P)

**Line:** 3171

---

### `def _make_nmtuple(name, types, module, defaults = ())`

**Line:** 3238

---

### `def _namedtuple_mro_entries(bases)`

**Line:** 3322

---

### `def NamedTuple(typename, fields, **kwargs)`

**Description:**
Typed version of namedtuple.

Usage::

class Employee(NamedTuple):
name: str
id: int

This is equivalent to::

Employee = collections.namedtuple('Employee', ['name', 'id'])

The resulting class has an extra __annotations__ attribute, giving a
dict that maps field names to types.  (The field names are also in
the _fields attribute, which is part of the namedtuple API.)
An alternative equivalent functional syntax is also accepted::

Employee = NamedTuple('Employee', [('name', str), ('id', int)])

**Line:** 3326

---

### `def get_original_bases(cls)`

**Description:**
Return the class's "original" bases prior to modification by `__mro_entries__`.

Examples::

from typing import TypeVar, Generic
from typing_extensions import NamedTuple, TypedDict

T = TypeVar("T")
class Foo(Generic[T]): ...
class Bar(Foo[int], float): ...
class Baz(list[str]): ...
Eggs = NamedTuple("Eggs", [("a", int), ("b", str)])
Spam = TypedDict("Spam", {"a": int, "b": str})

assert get_original_bases(Bar) == (Foo[int], float)
assert get_original_bases(Baz) == (list[str],)
assert get_original_bases(Eggs) == (NamedTuple,)
assert get_original_bases(Spam) == (TypedDict,)
assert get_original_bases(int) == (object,)

**Line:** 3427

---

### `def _is_unionable(obj)`

**Description:**
Corresponds to is_unionable() in unionobject.c in CPython.

**Line:** 3527

---

### `def _is_unionable(obj)`

**Description:**
Corresponds to is_unionable() in unionobject.c in CPython.

**Line:** 3538

---

### `def is_protocol(tp: type) -> bool`

**Description:**
Return True if the given type is a Protocol.

Example::

>>> from typing_extensions import Protocol, is_protocol
>>> class P(Protocol):
...     def a(self) -> str: ...
...     b: int
>>> is_protocol(P)
True
>>> is_protocol(int)
False

**Line:** 3738

---

### `def get_protocol_members(tp: type) -> typing.FrozenSet[str]`

**Description:**
Return the set of members defined in a Protocol.

Example::

>>> from typing_extensions import Protocol, get_protocol_members
>>> class P(Protocol):
...     def a(self) -> str: ...
...     b: int
>>> get_protocol_members(P)
frozenset({'a', 'b'})

Raise a TypeError for arguments that are not Protocols.

**Line:** 3759

---

### `def get_annotations(obj, globals = None, locals = None, eval_str = False, format = Format.VALUE)`

**Description:**
Compute the annotations dict for an object.

obj may be a callable, class, or module.
Passing in an object of any other type raises TypeError.

Returns a dict.  get_annotations() returns a new dict every time
it's called; calling it twice on the same object will return two
different but equivalent dicts.

This is a backport of `inspect.get_annotations`, which has been
in the standard library since Python 3.10. See the standard library
documentation for more:

https://docs.python.org/3/library/inspect.html#inspect.get_annotations

This backport adds the *format* argument introduced by PEP 649. The
three formats supported are:
* VALUE: the annotations are returned as-is. This is the default and
it is compatible with the behavior on previous Python versions.
* FORWARDREF: return annotations as-is if possible, but replace any
undefined names with ForwardRef objects. The implementation proposed by
PEP 649 relies on language changes that cannot be backported; the
typing-extensions implementation simply returns the same result as VALUE.
* STRING: return annotations as strings, in a format close to the original
source. Again, this behavior cannot be replicated directly in a backport.
As an approximation, typing-extensions retrieves the annotations under
VALUE semantics and then stringifies them.

The purpose of this backport is to allow users who would like to use
FORWARDREF or STRING semantics once PEP 649 is implemented, but who also
want to support earlier Python versions, to simply write:

typing_extensions.get_annotations(obj, format=Format.FORWARDREF)

**Line:** 3841

---

### `def _eval_with_owner(forward_ref, owner = None, globals = None, locals = None, type_params = None)`

**Line:** 3975

---

### `def evaluate_forward_ref(forward_ref, owner = None, globals = None, locals = None, type_params = None, format = None, _recursive_guard = frozenset())`

**Description:**
Evaluate a forward reference as a type hint.

This is similar to calling the ForwardRef.evaluate() method,
but unlike that method, evaluate_forward_ref() also:

* Recursively evaluates forward references nested within the type hint.
* Rejects certain objects that are not valid type hints.
* Replaces type hints that evaluate to None with types.NoneType.
* Supports the *FORWARDREF* and *STRING* formats.

*forward_ref* must be an instance of ForwardRef. *owner*, if given,
should be the object that holds the annotations that the forward reference
derived from, such as a module, class object, or function. It is used to
infer the namespaces to use for looking up names. *globals* and *locals*
can also be explicitly given to provide the global and local namespaces.
*type_params* is a tuple of type parameters that are in scope when
evaluating the forward reference. This parameter must be provided (though
it may be an empty tuple) if *owner* is not given and the forward reference
does not already have an owner set. *format* specifies the format of the
annotation and is a member of the annotationlib.Format enum.

**Line:** 4063

---


## Module: venv2.libthon3.12.site-packages.werkzeug._internal
**File:** `venv2/lib/python3.12/site-packages/werkzeug/_internal.py`

**Imports:**
- __future__.annotations
- _typeshed.wsgi.WSGIEnvironment
- colorama
- datetime.datetime
- datetime.timezone
- logging
- re
- sys
- typing
- wrappers.request.Request

**Functions:**

### `def _wsgi_decoding_dance(s: str) -> str`

**Line:** 29

---

### `def _wsgi_encoding_dance(s: str) -> str`

**Line:** 33

---

### `def _get_environ(obj: WSGIEnvironment | Request) -> WSGIEnvironment`

**Line:** 37

---

### `def _has_level_handler(logger: logging.Logger) -> bool`

**Description:**
Check if there is a handler in the logging chain that will handle
the given logger's effective level.

**Line:** 45

---

### `def _log(type: str, message: str, *args: t.Any, **kwargs: t.Any) -> None`

**Description:**
Log a message to the 'werkzeug' logger.

The logger is created the first time it is needed. If there is no
level set, it is set to :data:`logging.INFO`. If there is no handler
for the logger's effective level, a :class:`logging.StreamHandler`
is added.

**Line:** 78

---

### `def _dt_as_utc(dt: None) -> None`

**Decorators:**
- `@t.overload`

**Line:** 101

---

### `def _dt_as_utc(dt: datetime) -> datetime`

**Decorators:**
- `@t.overload`

**Line:** 105

---

### `def _dt_as_utc(dt: datetime | None) -> datetime | None`

**Line:** 108

---

### `def _plain_int(value: str) -> int`

**Description:**
Parse an int only if it is only ASCII digits and ``-``.

This disallows ``+``, ``_``, and non-ASCII digits, which are accepted by ``int`` but
are not allowed in HTTP header values.

Any leading or trailing whitespace is stripped

**Line:** 199

---


## Module: venv2.libthon3.12.site-packages.werkzeug._reloader
**File:** `venv2/lib/python3.12/site-packages/werkzeug/_reloader.py`

**Imports:**
- __future__.annotations
- _internal._log
- fnmatch
- itertools.chain
- os
- pathlib.PurePath
- signal
- subprocess
- sys
- termios
- threading
- time
- typing
- watchdog.events.EVENT_TYPE_CLOSED
- watchdog.events.EVENT_TYPE_CREATED
- watchdog.events.EVENT_TYPE_DELETED
- watchdog.events.EVENT_TYPE_MODIFIED
- watchdog.events.EVENT_TYPE_MOVED
- watchdog.events.FileModifiedEvent
- watchdog.events.PatternMatchingEventHandler
- watchdog.observers.Observer

**Functions:**

### `def _iter_module_paths() -> t.Iterator[str]`

**Description:**
Find the filesystem paths associated with imported modules.

**Line:** 40

---

### `def _remove_by_pattern(paths: set[str], exclude_patterns: set[str]) -> None`

**Line:** 60

---

### `def _find_stat_paths(extra_files: set[str], exclude_patterns: set[str]) -> t.Iterable[str]`

**Description:**
Find paths for the stat reloader to watch. Returns imported
module files, Python files under non-system paths. Extra files and
Python files under extra directories can also be scanned.

System paths have to be excluded for efficiency. Non-system paths,
such as a project root or ``sys.path.insert``, should be the paths
of interest to the user anyway.

**Line:** 65

---

### `def _find_watchdog_paths(extra_files: set[str], exclude_patterns: set[str]) -> t.Iterable[str]`

**Description:**
Find paths for the stat reloader to watch. Looks at the same
sources as the stat reloader, but watches everything under
directories instead of individual files.

**Line:** 119

---

### `def _find_common_roots(paths: t.Iterable[str]) -> t.Iterable[str]`

**Line:** 143

---

### `def _get_args_for_reloading() -> list[str]`

**Description:**
Determine how the script was executed, and return the args needed
to execute it again in a new process.

**Line:** 169

---

### `def ensure_echo_on() -> None`

**Description:**
Ensure that echo mode is enabled. Some tools such as PDB disable
it which causes usability issues after a reload.

**Line:** 423

---

### `def run_with_reloader(main_func: t.Callable[([], None)], extra_files: t.Iterable[str] | None = None, exclude_patterns: t.Iterable[str] | None = None, interval: int | float = 1, reloader_type: str = 'auto') -> None`

**Description:**
Run the given function in an independent Python interpreter.

**Line:** 442

---


## Module: venv2.libthon3.12.site-packages.werkzeug.datastructures.__init__
**File:** `venv2/lib/python3.12/site-packages/werkzeug/datastructures/__init__.py`

**Imports:**
- __future__.annotations
- accept.Accept
- accept.CharsetAccept
- accept.LanguageAccept
- accept.MIMEAccept
- auth.Authorization
- auth.WWWAuthenticate
- cache_control.RequestCacheControl
- cache_control.ResponseCacheControl
- csp.ContentSecurityPolicy
- etag.ETags
- file_storage.FileMultiDict
- file_storage.FileStorage
- headers.EnvironHeaders
- headers.Headers
- mixins.ImmutableDictMixin
- mixins.ImmutableHeadersMixin
- mixins.ImmutableListMixin
- mixins.ImmutableMultiDictMixin
- mixins.UpdateDictMixin
- range.ContentRange
- range.IfRange
- range.Range
- structures.CallbackDict
- structures.CombinedMultiDict
- structures.HeaderSet
- structures.ImmutableDict
- structures.ImmutableList
- structures.ImmutableMultiDict
- structures.ImmutableTypeConversionDict
- structures.MultiDict
- structures.TypeConversionDict
- structures._ImmutableOrderedMultiDict
- structures._OrderedMultiDict
- structures.iter_multi_items
- typing
- warnings

**Functions:**

### `def __getattr__(name: str) -> t.Any`

**Line:** 39

---


## Module: venv2.libthon3.12.site-packages.werkzeug.datastructures.accept
**File:** `venv2/lib/python3.12/site-packages/werkzeug/datastructures/accept.py`

**Imports:**
- __future__.annotations
- codecs
- collections.abc
- re
- structures.ImmutableList
- typing

**Functions:**

### `def _normalize_mime(value: str) -> list[str]`

**Line:** 204

---

### `def _normalize_lang(value: str) -> list[str]`

**Description:**
Process a language tag for matching.

**Line:** 275

---


## Module: venv2.libthon3.12.site-packages.werkzeug.datastructures.cache_control
**File:** `venv2/lib/python3.12/site-packages/werkzeug/datastructures/cache_control.py`

**Imports:**
- __future__.annotations
- collections.abc
- inspect.cleandoc
- mixins.ImmutableDictMixin
- structures.CallbackDict
- typing

**Functions:**

### `def cache_control_property(key: str, empty: t.Any, type: type[t.Any] | None, doc: str | None = None) -> t.Any`

**Description:**
Return a new property object for a cache header. Useful if you
want to add support for a cache extension in a subclass.

:param key: The attribute name present in the parsed cache-control header dict.
:param empty: The value to use if the key is present without a value.
:param type: The type to convert the string value to instead of a string. If
conversion raises a ``ValueError``, the returned value is ``None``.
:param doc: The docstring for the property. If not given, it is generated
based on the other params.

.. versionchanged:: 3.1
Added the ``doc`` param.

.. versionchanged:: 2.0
Renamed from ``cache_property``.

**Line:** 11

---


## Module: venv2.libthon3.12.site-packages.werkzeug.datastructures.csp
**File:** `venv2/lib/python3.12/site-packages/werkzeug/datastructures/csp.py`

**Imports:**
- __future__.annotations
- collections.abc
- http.dump_csp_header
- structures.CallbackDict
- typing

**Functions:**

### `def csp_property(key: str) -> t.Any`

**Description:**
Return a new property object for a content security policy header.
Useful if you want to add support for a csp extension in a
subclass.

**Line:** 9

---


## Module: venv2.libthon3.12.site-packages.werkzeug.datastructures.headers
**File:** `venv2/lib/python3.12/site-packages/werkzeug/datastructures/headers.py`

**Imports:**
- __future__.annotations
- _internal._missing
- _typeshed.wsgi.WSGIEnvironment
- collections.abc
- exceptions.BadRequestKeyError
- mixins.ImmutableHeadersMixin
- re
- structures.MultiDict
- structures.iter_multi_items
- typing
- typing_extensions

**Functions:**

### `def _options_header_vkw(value: str, kw: dict[(str, t.Any)]) -> str`

**Line:** 586

---

### `def _str_header_value(value: t.Any) -> str`

**Line:** 595

---


## Module: venv2.libthon3.12.site-packages.werkzeug.datastructures.mixins
**File:** `venv2/lib/python3.12/site-packages/werkzeug/datastructures/mixins.py`

**Imports:**
- __future__.annotations
- _internal._missing
- collections.abc
- functools.update_wrapper
- itertools.repeat
- typing
- typing_extensions

**Functions:**

### `def _immutable_error(self: t.Any) -> t.NoReturn`

**Line:** 19

---

### `def _always_update(f: F) -> F`

**Line:** 231

---


## Module: venv2.libthon3.12.site-packages.werkzeug.datastructures.structures
**File:** `venv2/lib/python3.12/site-packages/werkzeug/datastructures/structures.py`

**Imports:**
- __future__.annotations
- _internal._missing
- collections.abc
- copy.deepcopy
- mixins.ImmutableDictMixin
- mixins.ImmutableListMixin
- mixins.ImmutableMultiDictMixin
- mixins.UpdateDictMixin
- typing
- typing_extensions
- warnings

**Functions:**

### `def iter_multi_items(mapping: MultiDict[K, V] | cabc.Mapping[K, V | list[V] | tuple[V, ...] | set[V]] | cabc.Iterable[tuple[K, V]]) -> cabc.Iterator[tuple[(K, V)]]`

**Description:**
Iterates over the items of a mapping yielding keys and values
without dropping any from more complex structures.

**Line:** 22

---

### `def __getattr__(name: str) -> t.Any`

**Line:** 1218

---


## Module: venv2.libthon3.12.site-packages.werkzeug.debug.__init__
**File:** `venv2/lib/python3.12/site-packages/werkzeug/debug/__init__.py`

**Imports:**
- __future__.annotations
- _internal._log
- _typeshed.wsgi.StartResponse
- _typeshed.wsgi.WSGIApplication
- _typeshed.wsgi.WSGIEnvironment
- console.Console
- contextlib.ExitStack
- exceptions.NotFound
- exceptions.SecurityError
- getpass
- hashlib
- http.parse_cookie
- io.BytesIO
- itertools.chain
- json
- multiprocessing.Value
- os
- os.path.basename
- os.path.join
- pkgutil
- re
- sansio.utils.host_is_trusted
- security.gen_salt
- subprocess.PIPE
- subprocess.Popen
- sys
- tbtools.DebugFrameSummary
- tbtools.DebugTraceback
- tbtools.render_console_html
- time
- typing
- utils.send_file
- uuid
- winreg
- wrappers.request.Request
- wrappers.response.Response
- zlib.adler32

**Functions:**

### `def hash_pin(pin: str) -> str`

**Line:** 44

---

### `def get_machine_id() -> str | bytes | None`

**Line:** 51

---

### `def get_pin_and_cookie_name(app: WSGIApplication) -> tuple[str, str] | tuple[None, None]`

**Description:**
Given an application object this returns a semi-stable 9 digit pin
code and a random key.  The hope is that this is stable between
restarts to not make debugging particularly frustrating.  If the pin
was forcefully disabled this returns `None`.

Second item in the resulting tuple is the cookie name for remembering.

**Line:** 142

---


## Module: venv2.libthon3.12.site-packages.werkzeug.debug.repr
**File:** `venv2/lib/python3.12/site-packages/werkzeug/debug/repr.py`

**Imports:**
- __future__.annotations
- codecs
- collections.deque
- markupsafe.escape
- pydoc
- re
- sys
- traceback.format_exception_only
- typing

**Functions:**

### `def debug_repr(obj: object) -> str`

**Description:**
Creates a debug repr of an object as HTML string.

**Line:** 38

---

### `def dump(obj: object = missing) -> None`

**Description:**
Print the object details to stdout._write (for the interactive
console of the web debugger.

**Line:** 43

---

### `def _add_subclass_info(inner: str, obj: object, base: type | tuple[type, ...]) -> str`

**Line:** 84

---

### `def _sequence_repr_maker(left: str, right: str, base: type, limit: int = 8) -> t.Callable[([DebugReprGenerator, t.Iterable[t.Any], bool], str)]`

**Line:** 97

---


## Module: venv2.libthon3.12.site-packages.werkzeug.debug.tbtools
**File:** `venv2/lib/python3.12/site-packages/werkzeug/debug/tbtools.py`

**Imports:**
- __future__.annotations
- console.Console
- itertools
- linecache
- markupsafe.escape
- os
- re
- sys
- sysconfig
- traceback
- typing
- utils.cached_property

**Functions:**

### `def _process_traceback(exc: BaseException, te: traceback.TracebackException | None = None, skip: int = 0, hide: bool = True) -> traceback.TracebackException`

**Line:** 126

---

### `def render_console_html(secret: str, evalex_trusted: bool) -> str`

**Line:** 443

---


## Module: venv2.libthon3.12.site-packages.werkzeug.exceptions
**File:** `venv2/lib/python3.12/site-packages/werkzeug/exceptions.py`

**Imports:**
- __future__.annotations
- _internal._get_environ
- _typeshed.wsgi.StartResponse
- _typeshed.wsgi.WSGIEnvironment
- datastructures.WWWAuthenticate
- datetime.datetime
- http.HTTP_STATUS_CODES
- http.http_date
- markupsafe.Markup
- markupsafe.escape
- sansio.response.Response
- typing
- wrappers.request.Request
- wrappers.response.Response

**Functions:**

### `def _find_exceptions() -> None`

**Line:** 827

---

### `def abort(status: int | Response, *args: t.Any, **kwargs: t.Any) -> t.NoReturn`

**Description:**
Raises an :py:exc:`HTTPException` for the given status code or WSGI
application.

If a status code is given, it will be looked up in the list of
exceptions and will raise that exception.  If passed a WSGI application,
it will wrap it in a proxy WSGI exception and raise that::

abort(404)  # 404 Not Found
abort(Response('Hello World'))

**Line:** 879

---


## Module: venv2.libthon3.12.site-packages.werkzeug.formparser
**File:** `venv2/lib/python3.12/site-packages/werkzeug/formparser.py`

**Imports:**
- __future__.annotations
- _internal._plain_int
- _typeshed.wsgi.WSGIEnvironment
- datastructures.FileStorage
- datastructures.Headers
- datastructures.MultiDict
- exceptions.RequestEntityTooLarge
- http.parse_options_header
- io.BytesIO
- sansio.multipart.Data
- sansio.multipart.Epilogue
- sansio.multipart.Field
- sansio.multipart.File
- sansio.multipart.MultipartDecoder
- sansio.multipart.NeedData
- tempfile.SpooledTemporaryFile
- tempfile.TemporaryFile
- typing
- urllib.parse.parse_qsl
- wsgi.get_content_length
- wsgi.get_input_stream

**Functions:**

### `def default_stream_factory(total_content_length: int | None, content_type: str | None, filename: str | None, content_length: int | None = None) -> t.IO[bytes]`

**Line:** 53

---

### `def parse_form_data(environ: WSGIEnvironment, stream_factory: TStreamFactory | None = None, max_form_memory_size: int | None = None, max_content_length: int | None = None, cls: type[MultiDict[str, t.Any]] | None = None, silent: bool = True, max_form_parts: int | None = None) -> t_parse_result`

**Description:**
Parse the form data in the environ and return it as tuple in the form
``(stream, form, files)``.  You should only call this method if the
transport method is `POST`, `PUT`, or `PATCH`.

If the mimetype of the data transmitted is `multipart/form-data` the
files multidict will be filled with `FileStorage` objects.  If the
mimetype is unknown the input stream is wrapped and returned as first
argument, else the stream is empty.

This is a shortcut for the common usage of :class:`FormDataParser`.

:param environ: the WSGI environment to be used for parsing.
:param stream_factory: An optional callable that returns a new read and
writeable file descriptor.  This callable works
the same as :meth:`Response._get_file_stream`.
:param max_form_memory_size: the maximum number of bytes to be accepted for
in-memory stored form data.  If the data
exceeds the value specified an
:exc:`~exceptions.RequestEntityTooLarge`
exception is raised.
:param max_content_length: If this is provided and the transmitted data
is longer than this value an
:exc:`~exceptions.RequestEntityTooLarge`
exception is raised.
:param cls: an optional dict class to use.  If this is not specified
or `None` the default :class:`MultiDict` is used.
:param silent: If set to False parsing errors will not be caught.
:param max_form_parts: The maximum number of multipart parts to be parsed. If this
is exceeded, a :exc:`~exceptions.RequestEntityTooLarge` exception is raised.
:return: A tuple in the form ``(stream, form, files)``.

.. versionchanged:: 3.0
The ``charset`` and ``errors`` parameters were removed.

.. versionchanged:: 2.3
Added the ``max_form_parts`` parameter.

.. versionadded:: 0.5.1
Added the ``silent`` parameter.

.. versionadded:: 0.5
Added the ``max_form_memory_size``, ``max_content_length``, and ``cls``
parameters.

**Line:** 69

---

### `def _chunk_iter(read: t.Callable[([int], bytes)], size: int) -> t.Iterator[bytes | None]`

**Description:**
Read data in chunks for multipart/form-data parsing. Stop if no data is read.
Yield ``None`` at the end to signal end of parsing.

**Line:** 418

---


## Module: venv2.libthon3.12.site-packages.werkzeug.http
**File:** `venv2/lib/python3.12/site-packages/werkzeug/http.py`

**Imports:**
- __future__.annotations
- _internal._dt_as_utc
- _internal._plain_int
- _typeshed.wsgi.WSGIEnvironment
- datetime.date
- datetime.datetime
- datetime.time
- datetime.timedelta
- datetime.timezone
- email.utils
- enum.Enum
- hashlib.sha1
- re
- sansio.http
- time.mktime
- time.struct_time
- typing
- urllib.parse.quote
- urllib.parse.unquote
- urllib.request.parse_http_list
- warnings

**Functions:**

### `def quote_header_value(value: t.Any, allow_token: bool = True) -> str`

**Description:**
Add double quotes around a header value. If the header contains only ASCII token
characters, it will be returned unchanged. If the header contains ``"`` or ``\``
characters, they will be escaped with an additional ``\`` character.

This is the reverse of :func:`unquote_header_value`.

:param value: The value to quote. Will be converted to a string.
:param allow_token: Disable to quote the value even if it only has token characters.

.. versionchanged:: 3.0
Passing bytes is not supported.

.. versionchanged:: 3.0
The ``extra_chars`` parameter is removed.

.. versionchanged:: 2.3
The value is quoted if it is the empty string.

.. versionadded:: 0.5

**Line:** 139

---

### `def unquote_header_value(value: str) -> str`

**Description:**
Remove double quotes and decode slash-escaped ``"`` and ``\`` characters in a
header value.

This is the reverse of :func:`quote_header_value`.

:param value: The header value to unquote.

.. versionchanged:: 3.0
The ``is_filename`` parameter is removed.

**Line:** 175

---

### `def dump_options_header(header: str | None, options: t.Mapping[(str, t.Any)]) -> str`

**Description:**
Produce a header value and ``key=value`` parameters separated by semicolons
``;``. For example, the ``Content-Type`` header.

.. code-block:: python

dump_options_header("text/html", {"charset": "UTF-8"})
'text/html; charset=UTF-8'

This is the reverse of :func:`parse_options_header`.

If a value contains non-token characters, it will be quoted.

If a value is ``None``, the parameter is skipped.

In some keys for some headers, a UTF-8 value can be encoded using a special
``key*=UTF-8''value`` form, where ``value`` is percent encoded. This function will
not produce that format automatically, but if a given key ends with an asterisk
``*``, the value is assumed to have that form and will not be quoted further.

:param header: The primary header value.
:param options: Parameters to encode as ``key=value`` pairs.

.. versionchanged:: 2.3
Keys with ``None`` values are skipped rather than treated as a bare key.

.. versionchanged:: 2.2.3
If a key ends with ``*``, its value will not be quoted.

**Line:** 193

---

### `def dump_header(iterable: dict[str, t.Any] | t.Iterable[t.Any]) -> str`

**Description:**
Produce a header value from a list of items or ``key=value`` pairs, separated by
commas ``,``.

This is the reverse of :func:`parse_list_header`, :func:`parse_dict_header`, and
:func:`parse_set_header`.

If a value contains non-token characters, it will be quoted.

If a value is ``None``, the key is output alone.

In some keys for some headers, a UTF-8 value can be encoded using a special
``key*=UTF-8''value`` form, where ``value`` is percent encoded. This function will
not produce that format automatically, but if a given key ends with an asterisk
``*``, the value is assumed to have that form and will not be quoted further.

.. code-block:: python

dump_header(["foo", "bar baz"])
'foo, "bar baz"'

dump_header({"foo": "bar baz"})
'foo="bar baz"'

:param iterable: The items to create a header from.

.. versionchanged:: 3.0
The ``allow_token`` parameter is removed.

.. versionchanged:: 2.2.3
If a key ends with ``*``, its value will not be quoted.

**Line:** 239

---

### `def dump_csp_header(header: ds.ContentSecurityPolicy) -> str`

**Description:**
Dump a Content Security Policy header.

These are structured into policies such as "default-src 'self';
script-src 'self'".

.. versionadded:: 1.0.0
Support for Content Security Policy headers was added.

**Line:** 287

---

### `def parse_list_header(value: str) -> list[str]`

**Description:**
Parse a header value that consists of a list of comma separated items according
to `RFC 9110 <https://httpwg.org/specs/rfc9110.html#abnf.extension>`__.

This extends :func:`urllib.request.parse_http_list` to remove surrounding quotes
from values.

.. code-block:: python

parse_list_header('token, "quoted value"')
['token', 'quoted value']

This is the reverse of :func:`dump_header`.

:param value: The header value to parse.

**Line:** 300

---

### `def parse_dict_header(value: str) -> dict[(str, str | None)]`

**Description:**
Parse a list header using :func:`parse_list_header`, then parse each item as a
``key=value`` pair.

.. code-block:: python

parse_dict_header('a=b, c="d, e", f')
{"a": "b", "c": "d, e", "f": None}

This is the reverse of :func:`dump_header`.

If a key does not have a value, it is ``None``.

This handles charsets for values as described in
`RFC 2231 <https://www.rfc-editor.org/rfc/rfc2231#section-3>`__. Only ASCII, UTF-8,
and ISO-8859-1 charsets are accepted, otherwise the value remains quoted.

:param value: The header value to parse.

.. versionchanged:: 3.0
Passing bytes is not supported.

.. versionchanged:: 3.0
The ``cls`` argument is removed.

.. versionchanged:: 2.3
Added support for ``key*=charset''value`` encoded items.

.. versionchanged:: 0.9
The ``cls`` argument was added.

**Line:** 327

---

### `def parse_options_header(value: str | None) -> tuple[(str, dict[str, str])]`

**Description:**
Parse a header that consists of a value with ``key=value`` parameters separated
by semicolons ``;``. For example, the ``Content-Type`` header.

.. code-block:: python

parse_options_header("text/html; charset=UTF-8")
('text/html', {'charset': 'UTF-8'})

parse_options_header("")
("", {})

This is the reverse of :func:`dump_options_header`.

This parses valid parameter parts as described in
`RFC 9110 <https://httpwg.org/specs/rfc9110.html#parameter>`__. Invalid parts are
skipped.

This handles continuations and charsets as described in
`RFC 2231 <https://www.rfc-editor.org/rfc/rfc2231#section-3>`__, although not as
strictly as the RFC. Only ASCII, UTF-8, and ISO-8859-1 charsets are accepted,
otherwise the value remains quoted.

Clients may not be consistent in how they handle a quote character within a quoted
value. The `HTML Standard <https://html.spec.whatwg.org/#multipart-form-data>`__
replaces it with ``%22`` in multipart form data.
`RFC 9110 <https://httpwg.org/specs/rfc9110.html#quoted.strings>`__ uses backslash
escapes in HTTP headers. Both are decoded to the ``"`` character.

Clients may not be consistent in how they handle non-ASCII characters. HTML
documents must declare ``<meta charset=UTF-8>``, otherwise browsers may replace with
HTML character references, which can be decoded using :func:`html.unescape`.

:param value: The header value to parse.
:return: ``(value, options)``, where ``options`` is a dict

.. versionchanged:: 2.3
Invalid parts, such as keys with no value, quoted keys, and incorrectly quoted
values, are discarded instead of treating as ``None``.

.. versionchanged:: 2.3
Only ASCII, UTF-8, and ISO-8859-1 are accepted for charset values.

.. versionchanged:: 2.3
Escaped quotes in quoted values, like ``%22`` and ``\"``, are handled.

.. versionchanged:: 2.2
Option names are always converted to lowercase.

.. versionchanged:: 2.2
The ``multiple`` parameter was removed.

.. versionchanged:: 0.15
:rfc:`2231` parameter continuations are handled.

.. versionadded:: 0.5

**Line:** 417

---

### `def parse_accept_header(value: str | None) -> ds.Accept`

**Decorators:**
- `@t.overload`

**Line:** 577

---

### `def parse_accept_header(value: str | None, cls: type[_TAnyAccept]) -> _TAnyAccept`

**Decorators:**
- `@t.overload`

**Line:** 581

---

### `def parse_accept_header(value: str | None, cls: type[_TAnyAccept] | None = None) -> _TAnyAccept`

**Description:**
Parse an ``Accept`` header according to
`RFC 9110 <https://httpwg.org/specs/rfc9110.html#field.accept>`__.

Returns an :class:`.Accept` instance, which can sort and inspect items based on
their quality parameter. When parsing ``Accept-Charset``, ``Accept-Encoding``, or
``Accept-Language``, pass the appropriate :class:`.Accept` subclass.

:param value: The header value to parse.
:param cls: The :class:`.Accept` class to wrap the result in.
:return: An instance of ``cls``.

.. versionchanged:: 2.3
Parse according to RFC 9110. Items with invalid ``q`` values are skipped.

**Line:** 584

---

### `def parse_cache_control_header(value: str | None, on_update: t.Callable[[ds.cache_control._CacheControl], None] | None = None) -> ds.RequestCacheControl`

**Decorators:**
- `@t.overload`

**Line:** 641

---

### `def parse_cache_control_header(value: str | None, on_update: t.Callable[[ds.cache_control._CacheControl], None] | None = None, cls: type[_TAnyCC] = Ellipsis) -> _TAnyCC`

**Decorators:**
- `@t.overload`

**Line:** 648

---

### `def parse_cache_control_header(value: str | None, on_update: t.Callable[[ds.cache_control._CacheControl], None] | None = None, cls: type[_TAnyCC] | None = None) -> _TAnyCC`

**Description:**
Parse a cache control header.  The RFC differs between response and
request cache control, this method does not.  It's your responsibility
to not use the wrong control statements.

.. versionadded:: 0.5
The `cls` was added.  If not specified an immutable
:class:`~werkzeug.datastructures.RequestCacheControl` is returned.

:param value: a cache control header to be parsed.
:param on_update: an optional callable that is called every time a value
on the :class:`~werkzeug.datastructures.CacheControl`
object is changed.
:param cls: the class for the returned object.  By default
:class:`~werkzeug.datastructures.RequestCacheControl` is used.
:return: a `cls` object.

**Line:** 655

---

### `def parse_csp_header(value: str | None, on_update: t.Callable[[ds.ContentSecurityPolicy], None] | None = None) -> ds.ContentSecurityPolicy`

**Decorators:**
- `@t.overload`

**Line:** 689

---

### `def parse_csp_header(value: str | None, on_update: t.Callable[[ds.ContentSecurityPolicy], None] | None = None, cls: type[_TAnyCSP] = Ellipsis) -> _TAnyCSP`

**Decorators:**
- `@t.overload`

**Line:** 696

---

### `def parse_csp_header(value: str | None, on_update: t.Callable[[ds.ContentSecurityPolicy], None] | None = None, cls: type[_TAnyCSP] | None = None) -> _TAnyCSP`

**Description:**
Parse a Content Security Policy header.

.. versionadded:: 1.0.0
Support for Content Security Policy headers was added.

:param value: a csp header to be parsed.
:param on_update: an optional callable that is called every time a value
on the object is changed.
:param cls: the class for the returned object.  By default
:class:`~werkzeug.datastructures.ContentSecurityPolicy` is used.
:return: a `cls` object.

**Line:** 703

---

### `def parse_set_header(value: str | None, on_update: t.Callable[[ds.HeaderSet], None] | None = None) -> ds.HeaderSet`

**Description:**
Parse a set-like header and return a
:class:`~werkzeug.datastructures.HeaderSet` object:

>>> hs = parse_set_header('token, "quoted value"')

The return value is an object that treats the items case-insensitively
and keeps the order of the items:

>>> 'TOKEN' in hs
True
>>> hs.index('quoted value')
1
>>> hs
HeaderSet(['token', 'quoted value'])

To create a header from the :class:`HeaderSet` again, use the
:func:`dump_header` function.

:param value: a set header to be parsed.
:param on_update: an optional callable that is called every time a
value on the :class:`~werkzeug.datastructures.HeaderSet`
object is changed.
:return: a :class:`~werkzeug.datastructures.HeaderSet`

**Line:** 739

---

### `def parse_if_range_header(value: str | None) -> ds.IfRange`

**Description:**
Parses an if-range header which can be an etag or a date.  Returns
a :class:`~werkzeug.datastructures.IfRange` object.

.. versionchanged:: 2.0
If the value represents a datetime, it is timezone-aware.

.. versionadded:: 0.7

**Line:** 772

---

### `def parse_range_header(value: str | None, make_inclusive: bool = True) -> ds.Range | None`

**Description:**
Parses a range header into a :class:`~werkzeug.datastructures.Range`
object.  If the header is missing or malformed `None` is returned.
`ranges` is a list of ``(start, stop)`` tuples where the ranges are
non-inclusive.

.. versionadded:: 0.7

**Line:** 790

---

### `def parse_content_range_header(value: str | None, on_update: t.Callable[[ds.ContentRange], None] | None = None) -> ds.ContentRange | None`

**Description:**
Parses a range header into a
:class:`~werkzeug.datastructures.ContentRange` object or `None` if
parsing is not possible.

.. versionadded:: 0.7

:param value: a content range header to be parsed.
:param on_update: an optional callable that is called every time a value
on the :class:`~werkzeug.datastructures.ContentRange`
object is changed.

**Line:** 849

---

### `def quote_etag(etag: str, weak: bool = False) -> str`

**Description:**
Quote an etag.

:param etag: the etag to quote.
:param weak: set to `True` to tag it "weak".

**Line:** 903

---

### `def unquote_etag(etag: str) -> tuple[(str, bool)]`

**Decorators:**
- `@t.overload`

**Line:** 918

---

### `def unquote_etag(etag: None) -> tuple[(None, None)]`

**Decorators:**
- `@t.overload`

**Line:** 920

---

### `def unquote_etag(etag: str | None) -> tuple[str, bool] | tuple[None, None]`

**Description:**
Unquote a single etag:

>>> unquote_etag('W/"bar"')
('bar', True)
>>> unquote_etag('"bar"')
('bar', False)

:param etag: the etag identifier to unquote.
:return: a ``(etag, weak)`` tuple.

**Line:** 921

---

### `def parse_etags(value: str | None) -> ds.ETags`

**Description:**
Parse an etag header.

:param value: the tag header to parse
:return: an :class:`~werkzeug.datastructures.ETags` object.

**Line:** 946

---

### `def generate_etag(data: bytes) -> str`

**Description:**
Generate an etag for some data.

.. versionchanged:: 2.0
Use SHA-1. MD5 may not be available in some environments.

**Line:** 975

---

### `def parse_date(value: str | None) -> datetime | None`

**Description:**
Parse an :rfc:`2822` date into a timezone-aware
:class:`datetime.datetime` object, or ``None`` if parsing fails.

This is a wrapper for :func:`email.utils.parsedate_to_datetime`. It
returns ``None`` if parsing fails instead of raising an exception,
and always returns a timezone-aware datetime object. If the string
doesn't have timezone information, it is assumed to be UTC.

:param value: A string with a supported date format.

.. versionchanged:: 2.0
Return a timezone-aware datetime object. Use
``email.utils.parsedate_to_datetime``.

**Line:** 984

---

### `def http_date(timestamp: datetime | date | int | float | struct_time | None = None) -> str`

**Description:**
Format a datetime object or timestamp into an :rfc:`2822` date
string.

This is a wrapper for :func:`email.utils.format_datetime`. It
assumes naive datetime objects are in UTC instead of raising an
exception.

:param timestamp: The datetime or timestamp to format. Defaults to
the current time.

.. versionchanged:: 2.0
Use ``email.utils.format_datetime``. Accept ``date`` objects.

**Line:** 1013

---

### `def parse_age(value: str | None = None) -> timedelta | None`

**Description:**
Parses a base-10 integer count of seconds into a timedelta.

If parsing fails, the return value is `None`.

:param value: a string consisting of an integer represented in base-10
:return: a :class:`datetime.timedelta` object or `None`.

**Line:** 1045

---

### `def dump_age(age: timedelta | int | None = None) -> str | None`

**Description:**
Formats the duration as a base-10 integer.

:param age: should be an integer number of seconds,
a :class:`datetime.timedelta` object, or,
if the age is unknown, `None` (default).

**Line:** 1067

---

### `def is_resource_modified(environ: WSGIEnvironment, etag: str | None = None, data: bytes | None = None, last_modified: datetime | str | None = None, ignore_if_range: bool = True) -> bool`

**Description:**
Convenience method for conditional requests.

:param environ: the WSGI environment of the request to be checked.
:param etag: the etag for the response for comparison.
:param data: or alternatively the data of the response to automatically
generate an etag using :func:`generate_etag`.
:param last_modified: an optional date of the last modification.
:param ignore_if_range: If `False`, `If-Range` header will be taken into
account.
:return: `True` if the resource was modified, otherwise `False`.

.. versionchanged:: 2.0
SHA-1 is used to generate an etag value for the data. MD5 may
not be available in some environments.

.. versionchanged:: 1.0.0
The check is run for methods other than ``GET`` and ``HEAD``.

**Line:** 1087

---

### `def remove_entity_headers(headers: ds.Headers | list[tuple[str, str]], allowed: t.Iterable[str] = ()) -> None`

**Description:**
Remove all entity headers from a list or :class:`Headers` object.  This
operation works in-place.  `Expires` and `Content-Location` headers are
by default not removed.  The reason for this is :rfc:`2616` section
10.3.5 which specifies some entity headers that should be sent.

.. versionchanged:: 0.5
added `allowed` parameter.

:param headers: a list or :class:`Headers` object.
:param allowed: a list of headers that should still be allowed even though
they are entity headers.

**Line:** 1125

---

### `def remove_hop_by_hop_headers(headers: ds.Headers | list[tuple[str, str]]) -> None`

**Description:**
Remove all HTTP/1.1 "Hop-by-Hop" headers from a list or
:class:`Headers` object.  This operation works in-place.

.. versionadded:: 0.5

:param headers: a list or :class:`Headers` object.

**Line:** 1149

---

### `def is_entity_header(header: str) -> bool`

**Description:**
Check if a header is an entity header.

.. versionadded:: 0.5

:param header: the header to test.
:return: `True` if it's an entity header, `False` otherwise.

**Line:** 1162

---

### `def is_hop_by_hop_header(header: str) -> bool`

**Description:**
Check if a header is an HTTP/1.1 "Hop-by-Hop" header.

.. versionadded:: 0.5

:param header: the header to test.
:return: `True` if it's an HTTP/1.1 "Hop-by-Hop" header, `False` otherwise.

**Line:** 1173

---

### `def parse_cookie(header: WSGIEnvironment | str | None, cls: type[ds.MultiDict[str, str]] | None = None) -> ds.MultiDict[(str, str)]`

**Description:**
Parse a cookie from a string or WSGI environ.

The same key can be provided multiple times, the values are stored
in-order. The default :class:`MultiDict` will have the first value
first, and all values can be retrieved with
:meth:`MultiDict.getlist`.

:param header: The cookie header as a string, or a WSGI environ dict
with a ``HTTP_COOKIE`` key.
:param cls: A dict-like class to store the parsed cookies in.
Defaults to :class:`MultiDict`.

.. versionchanged:: 3.0
Passing bytes, and the ``charset`` and ``errors`` parameters, were removed.

.. versionchanged:: 1.0
Returns a :class:`MultiDict` instead of a ``TypeConversionDict``.

.. versionchanged:: 0.5
Returns a :class:`TypeConversionDict` instead of a regular dict. The ``cls``
parameter was added.

**Line:** 1184

---

### `def dump_cookie(key: str, value: str = '', max_age: timedelta | int | None = None, expires: str | datetime | int | float | None = None, path: str | None = '/', domain: str | None = None, secure: bool = False, httponly: bool = False, sync_expires: bool = True, max_size: int = 4093, samesite: str | None = None, partitioned: bool = False) -> str`

**Description:**
Create a Set-Cookie header without the ``Set-Cookie`` prefix.

The return value is usually restricted to ascii as the vast majority
of values are properly escaped, but that is no guarantee. It's
tunneled through latin1 as required by :pep:`3333`.

The return value is not ASCII safe if the key contains unicode
characters.  This is technically against the specification but
happens in the wild.  It's strongly recommended to not use
non-ASCII values for the keys.

:param max_age: should be a number of seconds, or `None` (default) if
the cookie should last only as long as the client's
browser session.  Additionally `timedelta` objects
are accepted, too.
:param expires: should be a `datetime` object or unix timestamp.
:param path: limits the cookie to a given path, per default it will
span the whole domain.
:param domain: Use this if you want to set a cross-domain cookie. For
example, ``domain="example.com"`` will set a cookie
that is readable by the domain ``www.example.com``,
``foo.example.com`` etc. Otherwise, a cookie will only
be readable by the domain that set it.
:param secure: The cookie will only be available via HTTPS
:param httponly: disallow JavaScript to access the cookie.  This is an
extension to the cookie standard and probably not
supported by all browsers.
:param charset: the encoding for string values.
:param sync_expires: automatically set expires if max_age is defined
but expires not.
:param max_size: Warn if the final header value exceeds this size. The
default, 4093, should be safely `supported by most browsers
<cookie_>`_. Set to 0 to disable this check.
:param samesite: Limits the scope of the cookie such that it will
only be attached to requests if those requests are same-site.
:param partitioned: Opts the cookie into partitioned storage. This
will also set secure to True

.. _`cookie`: http://browsercookielimits.squawky.net/

.. versionchanged:: 3.1
The ``partitioned`` parameter was added.

.. versionchanged:: 3.0
Passing bytes, and the ``charset`` parameter, were removed.

.. versionchanged:: 2.3.3
The ``path`` parameter is ``/`` by default.

.. versionchanged:: 2.3.1
The value allows more characters without quoting.

.. versionchanged:: 2.3
``localhost`` and other names without a dot are allowed for the domain. A
leading dot is ignored.

.. versionchanged:: 2.3
The ``path`` parameter is ``None`` by default.

.. versionchanged:: 1.0.0
The string ``'None'`` is accepted for ``samesite``.

**Line:** 1230

---

### `def is_byte_range_valid(start: int | None, stop: int | None, length: int | None) -> bool`

**Description:**
Checks if a given byte content range is valid for the given length.

.. versionadded:: 0.7

**Line:** 1385

---


## Module: venv2.libthon3.12.site-packages.werkzeug.local
**File:** `venv2/lib/python3.12/site-packages/werkzeug/local.py`

**Imports:**
- __future__.annotations
- _typeshed.wsgi.StartResponse
- _typeshed.wsgi.WSGIApplication
- _typeshed.wsgi.WSGIEnvironment
- contextvars.ContextVar
- copy
- functools.partial
- functools.update_wrapper
- math
- operator
- operator.attrgetter
- typing
- wsgi.ClosingIterator

**Functions:**

### `def release_local(local: Local | LocalStack[t.Any]) -> None`

**Description:**
Release the data for the current context in a :class:`Local` or
:class:`LocalStack` without using a :class:`LocalManager`.

This should not be needed for modern use cases, and may be removed
in the future.

.. versionadded:: 0.6.1

**Line:** 23

---

### `def _l_to_r_op(op: F) -> F`

**Description:**
Swap the argument order to turn an l-op into an r-op.

**Line:** 375

---

### `def _identity(o: T) -> T`

**Line:** 384

---


## Module: venv2.libthon3.12.site-packages.werkzeug.middleware.lint
**File:** `venv2/lib/python3.12/site-packages/werkzeug/middleware/lint.py`

**Imports:**
- __future__.annotations
- _typeshed.wsgi.StartResponse
- _typeshed.wsgi.WSGIApplication
- _typeshed.wsgi.WSGIEnvironment
- datastructures.Headers
- http.is_entity_header
- types.TracebackType
- typing
- urllib.parse.urlparse
- warnings.warn
- wsgi.FileWrapper

**Functions:**

### `def check_type(context: str, obj: object, need: type = str) -> None`

**Line:** 41

---


## Module: venv2.libthon3.12.site-packages.werkzeug.routing.rules
**File:** `venv2/lib/python3.12/site-packages/werkzeug/routing/rules.py`

**Imports:**
- __future__.annotations
- ast
- converters.BaseConverter
- converters.ValidationError
- dataclasses.dataclass
- datastructures.iter_multi_items
- map.Map
- re
- string.Template
- types.CodeType
- typing
- urllib.parse.quote
- urls._urlencode

**Functions:**

### `def _find(value: str, target: str, pos: int) -> int`

**Description:**
Find the *target* in *value* after *pos*.

Returns the *value* length if *target* isn't found.

**Line:** 88

---

### `def _pythonize(value: str) -> None | bool | int | float | str`

**Line:** 99

---

### `def parse_converter_args(argstr: str) -> tuple[(tuple[t.Any, ...], dict[str, t.Any])]`

**Line:** 112

---

### `def _prefix_names(src: str, expected_type: type[_ASTT]) -> _ASTT`

**Description:**
ast parse and prefix names with `.` to avoid collision with user vars

**Line:** 300

---


## Module: venv2.libthon3.12.site-packages.werkzeug.sansio.http
**File:** `venv2/lib/python3.12/site-packages/werkzeug/sansio/http.py`

**Imports:**
- __future__.annotations
- _internal._dt_as_utc
- datetime.datetime
- http.generate_etag
- http.parse_date
- http.parse_etags
- http.parse_if_range_header
- http.unquote_etag
- re
- typing

**Functions:**

### `def is_resource_modified(http_range: str | None = None, http_if_range: str | None = None, http_if_modified_since: str | None = None, http_if_none_match: str | None = None, http_if_match: str | None = None, etag: str | None = None, data: bytes | None = None, last_modified: datetime | str | None = None, ignore_if_range: bool = True) -> bool`

**Description:**
Convenience method for conditional requests.
:param http_range: Range HTTP header
:param http_if_range: If-Range HTTP header
:param http_if_modified_since: If-Modified-Since HTTP header
:param http_if_none_match: If-None-Match HTTP header
:param http_if_match: If-Match HTTP header
:param etag: the etag for the response for comparison.
:param data: or alternatively the data of the response to automatically
generate an etag using :func:`generate_etag`.
:param last_modified: an optional date of the last modification.
:param ignore_if_range: If `False`, `If-Range` header will be taken into
account.
:return: `True` if the resource was modified, otherwise `False`.

.. versionadded:: 2.2

**Line:** 17

---

### `def _cookie_unslash_replace(m: t.Match[bytes]) -> bytes`

**Line:** 113

---

### `def parse_cookie(cookie: str | None = None, cls: type[ds.MultiDict[str, str]] | None = None) -> ds.MultiDict[(str, str)]`

**Description:**
Parse a cookie from a string.

The same key can be provided multiple times, the values are stored
in-order. The default :class:`MultiDict` will have the first value
first, and all values can be retrieved with
:meth:`MultiDict.getlist`.

:param cookie: The cookie header as a string.
:param cls: A dict-like class to store the parsed cookies in.
Defaults to :class:`MultiDict`.

.. versionchanged:: 3.0
Passing bytes, and the ``charset`` and ``errors`` parameters, were removed.

.. versionadded:: 2.2

**Line:** 122

---


## Module: venv2.libthon3.12.site-packages.werkzeug.sansio.response
**File:** `venv2/lib/python3.12/site-packages/werkzeug/sansio/response.py`

**Imports:**
- __future__.annotations
- datastructures.CallbackDict
- datastructures.ContentRange
- datastructures.ContentSecurityPolicy
- datastructures.HeaderSet
- datastructures.Headers
- datastructures.ResponseCacheControl
- datastructures.WWWAuthenticate
- datastructures.cache_control._CacheControl
- datetime.datetime
- datetime.timedelta
- datetime.timezone
- http.COEP
- http.COOP
- http.HTTPStatus
- http.HTTP_STATUS_CODES
- http.dump_age
- http.dump_cookie
- http.dump_header
- http.dump_options_header
- http.http_date
- http.parse_age
- http.parse_cache_control_header
- http.parse_content_range_header
- http.parse_csp_header
- http.parse_date
- http.parse_options_header
- http.parse_set_header
- http.quote_etag
- http.unquote_etag
- typing
- utils.get_content_type
- utils.header_property

**Functions:**

### `def _set_property(name: str, doc: str | None = None) -> property`

**Line:** 40

---


## Module: venv2.libthon3.12.site-packages.werkzeug.sansio.utils
**File:** `venv2/lib/python3.12/site-packages/werkzeug/sansio/utils.py`

**Imports:**
- __future__.annotations
- _internal._plain_int
- exceptions.SecurityError
- typing
- urllib.parse.quote
- urls.uri_to_iri

**Functions:**

### `def host_is_trusted(hostname: str | None, trusted_list: t.Iterable[str]) -> bool`

**Description:**
Check if a host matches a list of trusted names.

:param hostname: The name to check.
:param trusted_list: A list of valid names to match. If a name
starts with a dot it will match all subdomains.

.. versionadded:: 0.9

**Line:** 11

---

### `def get_host(scheme: str, host_header: str | None, server: tuple[str, int | None] | None = None, trusted_hosts: t.Iterable[str] | None = None) -> str`

**Description:**
Return the host for the given parameters.

This first checks the ``host_header``. If it's not present, then
``server`` is used. The host will only contain the port if it is
different than the standard port for the protocol.

Optionally, verify that the host is trusted using
:func:`host_is_trusted` and raise a
:exc:`~werkzeug.exceptions.SecurityError` if it is not.

:param scheme: The protocol the request used, like ``"https"``.
:param host_header: The ``Host`` header value.
:param server: Address of the server. ``(host, port)``, or
``(path, None)`` for unix sockets.
:param trusted_hosts: A list of trusted host names.

:return: Host, with port if necessary.
:raise ~werkzeug.exceptions.SecurityError: If the host is not
trusted.

.. versionchanged:: 3.1.3
If ``SERVER_NAME`` is IPv6, it is wrapped in ``[]``.

**Line:** 49

---

### `def get_current_url(scheme: str, host: str, root_path: str | None = None, path: str | None = None, query_string: bytes | None = None) -> str`

**Description:**
Recreate the URL for a request. If an optional part isn't
provided, it and subsequent parts are not included in the URL.

The URL is an IRI, not a URI, so it may contain Unicode characters.
Use :func:`~werkzeug.urls.iri_to_uri` to convert it to ASCII.

:param scheme: The protocol the request used, like ``"https"``.
:param host: The host the request was made to. See :func:`get_host`.
:param root_path: Prefix that the application is mounted under. This
is prepended to ``path``.
:param path: The path part of the URL after ``root_path``.
:param query_string: The portion of the URL after the "?".

**Line:** 105

---

### `def get_content_length(http_content_length: str | None = None, http_transfer_encoding: str | None = None) -> int | None`

**Description:**
Return the ``Content-Length`` header value as an int. If the header is not given
or the ``Transfer-Encoding`` header is ``chunked``, ``None`` is returned to indicate
a streaming request. If the value is not an integer, or negative, 0 is returned.

:param http_content_length: The Content-Length HTTP header.
:param http_transfer_encoding: The Transfer-Encoding HTTP header.

.. versionadded:: 2.2

**Line:** 148

---


## Module: venv2.libthon3.12.site-packages.werkzeug.security
**File:** `venv2/lib/python3.12/site-packages/werkzeug/security.py`

**Imports:**
- __future__.annotations
- hashlib
- hmac
- os
- posixpath
- secrets

**Functions:**

### `def gen_salt(length: int) -> str`

**Description:**
Generate a random string of SALT_CHARS with specified ``length``.

**Line:** 17

---

### `def _hash_internal(method: str, salt: str, password: str) -> tuple[(str, str)]`

**Line:** 25

---

### `def generate_password_hash(password: str, method: str = 'scrypt', salt_length: int = 16) -> str`

**Description:**
Securely hash a password for storage. A password can be compared to a stored hash
using :func:`check_password_hash`.

The following methods are supported:

-   ``scrypt``, the default. The parameters are ``n``, ``r``, and ``p``, the default
is ``scrypt:32768:8:1``. See :func:`hashlib.scrypt`.
-   ``pbkdf2``, less secure. The parameters are ``hash_method`` and ``iterations``,
the default is ``pbkdf2:sha256:600000``. See :func:`hashlib.pbkdf2_hmac`.

Default parameters may be updated to reflect current guidelines, and methods may be
deprecated and removed if they are no longer considered secure. To migrate old
hashes, you may generate a new hash when checking an old hash, or you may contact
users with a link to reset their password.

:param password: The plaintext password.
:param method: The key derivation function and parameters.
:param salt_length: The number of characters to generate for the salt.

.. versionchanged:: 3.1
The default iterations for pbkdf2 was increased to 1,000,000.

.. versionchanged:: 2.3
Scrypt support was added.

.. versionchanged:: 2.3
The default iterations for pbkdf2 was increased to 600,000.

.. versionchanged:: 2.3
All plain hashes are deprecated and will not be supported in Werkzeug 3.0.

**Line:** 73

---

### `def check_password_hash(pwhash: str, password: str) -> bool`

**Description:**
Securely check that the given stored password hash, previously generated using
:func:`generate_password_hash`, matches the given password.

Methods may be deprecated and removed if they are no longer considered secure. To
migrate old hashes, you may generate a new hash when checking an old hash, or you
may contact users with a link to reset their password.

:param pwhash: The hashed password.
:param password: The plaintext password.

.. versionchanged:: 2.3
All plain hashes are deprecated and will not be supported in Werkzeug 3.0.

**Line:** 112

---

### `def safe_join(directory: str, *pathnames: str) -> str | None`

**Description:**
Safely join zero or more untrusted path components to a base
directory to avoid escaping the base directory.

:param directory: The trusted base directory.
:param pathnames: The untrusted path components relative to the
base directory.
:return: A safe path, otherwise ``None``.

**Line:** 134

---


## Module: venv2.libthon3.12.site-packages.werkzeug.serving
**File:** `venv2/lib/python3.12/site-packages/werkzeug/serving.py`

**Imports:**
- __future__.annotations
- _internal._log
- _internal._wsgi_encoding_dance
- _reloader.run_with_reloader
- _typeshed.wsgi.WSGIApplication
- _typeshed.wsgi.WSGIEnvironment
- atexit
- cryptography.hazmat.backends.default_backend
- cryptography.hazmat.primitives.asymmetric.rsa
- cryptography.hazmat.primitives.asymmetric.rsa.RSAPrivateKeyWithSerialization
- cryptography.hazmat.primitives.hashes
- cryptography.hazmat.primitives.serialization
- cryptography.x509
- cryptography.x509.Certificate
- cryptography.x509.oid.NameOID
- datetime.datetime
- datetime.timedelta
- datetime.timezone
- debug.DebuggedApplication
- debug.tbtools.DebugTraceback
- errno
- exceptions.InternalServerError
- http.server.BaseHTTPRequestHandler
- http.server.HTTPServer
- importlib.metadata
- io
- middleware.shared_data.SharedDataMiddleware
- os
- selectors
- socket
- socketserver
- ssl
- sys
- tempfile
- typing
- urllib.parse.unquote
- urllib.parse.urlsplit
- urls.uri_to_iri

**Functions:**

### `def _ansi_style(value: str, *styles: str) -> str`

**Line:** 485

---

### `def generate_adhoc_ssl_pair(cn: str | None = None) -> tuple[(Certificate, RSAPrivateKeyWithSerialization)]`

**Line:** 504

---

### `def make_ssl_devcert(base_path: str, host: str | None = None, cn: str | None = None) -> tuple[(str, str)]`

**Description:**
Creates an SSL key for development.  This should be used instead of
the ``'adhoc'`` key which generates a new cert on each server start.
It accepts a path for where it should store the key and cert and
either a host or CN.  If a host is given it will use the CN
``*.host/CN=host``.

For more information see :func:`run_simple`.

.. versionadded:: 0.9

:param base_path: the path to the certificate and key.  The extension
``.crt`` is added for the certificate, ``.key`` is
added for the key.
:param host: the name of the host.  This can be used as an alternative
for the `cn`.
:param cn: the `CN` to use.

**Line:** 553

---

### `def generate_adhoc_ssl_context() -> ssl.SSLContext`

**Description:**
Generates an adhoc SSL context for the development server.

**Line:** 597

---

### `def load_ssl_context(cert_file: str, pkey_file: str | None = None, protocol: int | None = None) -> ssl.SSLContext`

**Description:**
Loads SSL context from cert/private key files and optional protocol.
Many parameters are directly taken from the API of
:py:class:`ssl.SSLContext`.

:param cert_file: Path of the certificate to use.
:param pkey_file: Path of the private key to use. If not given, the key
will be obtained from the certificate file.
:param protocol: A ``PROTOCOL`` constant from the :mod:`ssl` module.
Defaults to :data:`ssl.PROTOCOL_TLS_SERVER`.

**Line:** 627

---

### `def is_ssl_error(error: Exception | None = None) -> bool`

**Description:**
Checks if the given error (or the current one) is an SSL error.

**Line:** 648

---

### `def select_address_family(host: str, port: int) -> socket.AddressFamily`

**Description:**
Return ``AF_INET4``, ``AF_INET6``, or ``AF_UNIX`` depending on
the host and port.

**Line:** 655

---

### `def get_sockaddr(host: str, port: int, family: socket.AddressFamily) -> tuple[str, int] | str`

**Description:**
Return a fully qualified socket address that can be passed to
:func:`socket.bind`.

**Line:** 665

---

### `def get_interface_ip(family: socket.AddressFamily) -> str`

**Description:**
Get the IP address of an external interface. Used when binding to
0.0.0.0 or ::1 to show a more useful URL.

:meta private:

**Line:** 682

---

### `def make_server(host: str, port: int, app: WSGIApplication, threaded: bool = False, processes: int = 1, request_handler: type[WSGIRequestHandler] | None = None, passthrough_errors: bool = False, ssl_context: _TSSLContextArg | None = None, fd: int | None = None) -> BaseWSGIServer`

**Description:**
Create an appropriate WSGI server instance based on the value of
``threaded`` and ``processes``.

This is called from :func:`run_simple`, but can be used separately
to have access to the server object, such as to run it in a separate
thread.

See :func:`run_simple` for parameter docs.

**Line:** 906

---

### `def is_running_from_reloader() -> bool`

**Description:**
Check if the server is running as a subprocess within the
Werkzeug reloader.

.. versionadded:: 0.10

**Line:** 951

---

### `def run_simple(hostname: str, port: int, application: WSGIApplication, use_reloader: bool = False, use_debugger: bool = False, use_evalex: bool = True, extra_files: t.Iterable[str] | None = None, exclude_patterns: t.Iterable[str] | None = None, reloader_interval: int = 1, reloader_type: str = 'auto', threaded: bool = False, processes: int = 1, request_handler: type[WSGIRequestHandler] | None = None, static_files: dict[str, str | tuple[str, str]] | None = None, passthrough_errors: bool = False, ssl_context: _TSSLContextArg | None = None) -> None`

**Description:**
Start a development server for a WSGI application. Various
optional features can be enabled.

.. warning::

Do not use the development server when deploying to production.
It is intended for use only during local development. It is not
designed to be particularly efficient, stable, or secure.

:param hostname: The host to bind to, for example ``'localhost'``.
Can be a domain, IPv4 or IPv6 address, or file path starting
with ``unix://`` for a Unix socket.
:param port: The port to bind to, for example ``8080``. Using ``0``
tells the OS to pick a random free port.
:param application: The WSGI application to run.
:param use_reloader: Use a reloader process to restart the server
process when files are changed.
:param use_debugger: Use Werkzeug's debugger, which will show
formatted tracebacks on unhandled exceptions.
:param use_evalex: Make the debugger interactive. A Python terminal
can be opened for any frame in the traceback. Some protection is
provided by requiring a PIN, but this should never be enabled
on a publicly visible server.
:param extra_files: The reloader will watch these files for changes
in addition to Python modules. For example, watch a
configuration file.
:param exclude_patterns: The reloader will ignore changes to any
files matching these :mod:`fnmatch` patterns. For example,
ignore cache files.
:param reloader_interval: How often the reloader tries to check for
changes.
:param reloader_type: The reloader to use. The ``'stat'`` reloader
is built in, but may require significant CPU to watch files. The
``'watchdog'`` reloader is much more efficient but requires
installing the ``watchdog`` package first.
:param threaded: Handle concurrent requests using threads. Cannot be
used with ``processes``.
:param processes: Handle concurrent requests using up to this number
of processes. Cannot be used with ``threaded``.
:param request_handler: Use a different
:class:`~BaseHTTPServer.BaseHTTPRequestHandler` subclass to
handle requests.
:param static_files: A dict mapping URL prefixes to directories to
serve static files from using
:class:`~werkzeug.middleware.SharedDataMiddleware`.
:param passthrough_errors: Don't catch unhandled exceptions at the
server level, let the server crash instead. If ``use_debugger``
is enabled, the debugger will still catch such errors.
:param ssl_context: Configure TLS to serve over HTTPS. Can be an
:class:`ssl.SSLContext` object, a ``(cert_file, key_file)``
tuple to create a typical context, or the string ``'adhoc'`` to
generate a temporary self-signed certificate.

.. versionchanged:: 2.1
Instructions are shown for dealing with an "address already in
use" error.

.. versionchanged:: 2.1
Running on ``0.0.0.0`` or ``::`` shows the loopback IP in
addition to a real IP.

.. versionchanged:: 2.1
The command-line interface was removed.

.. versionchanged:: 2.0
Running on ``0.0.0.0`` or ``::`` shows a real IP address that
was bound as well as a warning not to run the development server
in production.

.. versionchanged:: 2.0
The ``exclude_patterns`` parameter was added.

.. versionchanged:: 0.15
Bind to a Unix socket by passing a ``hostname`` that starts with
``unix://``.

.. versionchanged:: 0.10
Improved the reloader and added support for changing the backend
through the ``reloader_type`` parameter.

.. versionchanged:: 0.9
A command-line interface was added.

.. versionchanged:: 0.8
``ssl_context`` can be a tuple of paths to the certificate and
private key files.

.. versionchanged:: 0.6
The ``ssl_context`` parameter was added.

.. versionchanged:: 0.5
The ``static_files`` and ``passthrough_errors`` parameters were
added.

**Line:** 960

---


## Module: venv2.libthon3.12.site-packages.werkzeug.test
**File:** `venv2/lib/python3.12/site-packages/werkzeug/test.py`

**Imports:**
- __future__.annotations
- _internal._get_environ
- _internal._wsgi_decoding_dance
- _internal._wsgi_encoding_dance
- _typeshed.wsgi.WSGIApplication
- _typeshed.wsgi.WSGIEnvironment
- collections.defaultdict
- dataclasses
- datastructures.Authorization
- datastructures.CallbackDict
- datastructures.CombinedMultiDict
- datastructures.EnvironHeaders
- datastructures.FileMultiDict
- datastructures.Headers
- datastructures.MultiDict
- datetime.datetime
- http.dump_cookie
- http.dump_options_header
- http.parse_cookie
- http.parse_date
- http.parse_options_header
- io.BytesIO
- itertools.chain
- json
- mimetypes
- random.random
- sansio.multipart.Data
- sansio.multipart.Epilogue
- sansio.multipart.Field
- sansio.multipart.File
- sansio.multipart.MultipartEncoder
- sansio.multipart.Preamble
- sys
- tempfile.TemporaryFile
- time.time
- typing
- typing_extensions
- urllib.parse.unquote
- urllib.parse.urlsplit
- urllib.parse.urlunsplit
- urls._urlencode
- urls.iri_to_uri
- utils.cached_property
- utils.get_content_type
- wrappers.request.Request
- wrappers.response.Response
- wsgi.ClosingIterator
- wsgi.get_current_url

**Functions:**

### `def stream_encode_multipart(data: t.Mapping[(str, t.Any)], use_tempfile: bool = True, threshold: int = 1024 * 500, boundary: str | None = None) -> tuple[(t.IO[bytes], int, str)]`

**Description:**
Encode a dict of values (either strings or file descriptors or
:class:`FileStorage` objects.) into a multipart encoded string stored
in a file descriptor.

.. versionchanged:: 3.0
The ``charset`` parameter was removed.

**Line:** 54

---

### `def encode_multipart(values: t.Mapping[(str, t.Any)], boundary: str | None = None) -> tuple[(str, bytes)]`

**Description:**
Like `stream_encode_multipart` but returns a tuple in the form
(``boundary``, ``data``) where data is bytes.

.. versionchanged:: 3.0
The ``charset`` parameter was removed.

**Line:** 144

---

### `def _iter_data(data: t.Mapping[(str, t.Any)]) -> t.Iterator[tuple[(str, t.Any)]]`

**Description:**
Iterate over a mapping that might have a list of values, yielding
all key, value pairs. Almost like iter_multi_items but only allows
lists, not tuples, of values so tuples can be used for files.

**Line:** 159

---

### `def create_environ(*args: t.Any, **kwargs: t.Any) -> WSGIEnvironment`

**Description:**
Create a new WSGI environ dict based on the values passed.  The first
parameter should be the path of the request which defaults to '/'.  The
second one can either be an absolute path (in that case the host is
localhost:80) or a full path to the request with scheme, netloc port and
the path to the script.

This accepts the same arguments as the :class:`EnvironBuilder`
constructor.

.. versionchanged:: 0.5
This function is now a thin wrapper over :class:`EnvironBuilder` which
was added in 0.5.  The `headers`, `environ_base`, `environ_overrides`
and `charset` parameters were added.

**Line:** 1203

---

### `def run_wsgi_app(app: WSGIApplication, environ: WSGIEnvironment, buffered: bool = False) -> tuple[(t.Iterable[bytes], str, Headers)]`

**Description:**
Return a tuple in the form (app_iter, status, headers) of the
application output.  This works best if you pass it an application that
returns an iterator all the time.

Sometimes applications may use the `write()` callable returned
by the `start_response` function.  This tries to resolve such edge
cases automatically.  But if you don't get the expected output you
should set `buffered` to `True` which enforces buffering.

If passed an invalid WSGI application the behavior of this function is
undefined.  Never pass non-conforming WSGI applications to this function.

:param app: the application to execute.
:param buffered: set to `True` to enforce buffering.
:return: tuple in the form ``(app_iter, status, headers)``

**Line:** 1226

---


## Module: venv2.libthon3.12.site-packages.werkzeug.testapp
**File:** `venv2/lib/python3.12/site-packages/werkzeug/testapp.py`

**Imports:**
- __future__.annotations
- importlib.metadata
- markupsafe.escape
- os
- pkg_resources
- serving.run_simple
- sys
- textwrap.wrap
- typing
- wrappers.request.Request
- wrappers.response.Response

**Functions:**

### `def iter_sys_path() -> t.Iterator[tuple[(str, bool, bool)]]`

**Line:** 95

---

### `def test_app(req: Request) -> Response`

**Decorators:**
- `@Request.application`

**Description:**
Simple test application that dumps the environment.  You can use
it to check if Werkzeug is working properly:

.. sourcecode:: pycon

>>> from werkzeug.serving import run_simple
>>> from werkzeug.testapp import test_app
>>> run_simple('localhost', 3000, test_app)
* Running on http://localhost:3000/

The application displays important information from the WSGI environment,
the Python interpreter and the installed libraries.

**Line:** 116

---

### `def _get_werkzeug_version() -> str`

**Line:** 182

---


## Module: venv2.libthon3.12.site-packages.werkzeug.urls
**File:** `venv2/lib/python3.12/site-packages/werkzeug/urls.py`

**Imports:**
- __future__.annotations
- codecs
- datastructures.iter_multi_items
- re
- typing
- urllib.parse
- urllib.parse.quote
- urllib.parse.unquote
- urllib.parse.urlencode
- urllib.parse.urlsplit
- urllib.parse.urlunsplit

**Functions:**

### `def _codec_error_url_quote(e: UnicodeError) -> tuple[(str, int)]`

**Description:**
Used in :func:`uri_to_iri` after unquoting to re-quote any
invalid bytes.

**Line:** 16

---

### `def _make_unquote_part(name: str, chars: str) -> t.Callable[([str], str)]`

**Description:**
Create a function that unquotes all percent encoded characters except those
given. This allows working with unquoted characters if possible while not changing
the meaning of a given part of a URL.

**Line:** 29

---

### `def uri_to_iri(uri: str) -> str`

**Description:**
Convert a URI to an IRI. All valid UTF-8 characters are unquoted,
leaving all reserved and invalid characters quoted. If the URL has
a domain, it is decoded from Punycode.

>>> uri_to_iri("http://xn--n3h.net/p%C3%A5th?q=%C3%A8ry%DF")
'http://\u2603.net/p\xe5th?q=\xe8ry%DF'

:param uri: The URI to convert.

.. versionchanged:: 3.0
Passing a tuple or bytes, and the ``charset`` and ``errors`` parameters,
are removed.

.. versionchanged:: 2.3
Which characters remain quoted is specific to each part of the URL.

.. versionchanged:: 0.15
All reserved and invalid characters remain quoted. Previously,
only some reserved characters were preserved, and invalid bytes
were replaced instead of left quoted.

.. versionadded:: 0.6

**Line:** 61

---

### `def iri_to_uri(iri: str) -> str`

**Description:**
Convert an IRI to a URI. All non-ASCII and unsafe characters are
quoted. If the URL has a domain, it is encoded to Punycode.

>>> iri_to_uri('http://\u2603.net/p\xe5th?q=\xe8ry%DF')
'http://xn--n3h.net/p%C3%A5th?q=%C3%A8ry%DF'

:param iri: The IRI to convert.

.. versionchanged:: 3.0
Passing a tuple or bytes, the ``charset`` and ``errors`` parameters,
and the ``safe_conversion`` parameter, are removed.

.. versionchanged:: 2.3
Which characters remain unquoted is specific to each part of the URL.

.. versionchanged:: 0.15
All reserved characters remain unquoted. Previously, only some reserved
characters were left unquoted.

.. versionchanged:: 0.9.6
The ``safe_conversion`` parameter was added.

.. versionadded:: 0.6

**Line:** 113

---

### `def _decode_idna(domain: str) -> str`

**Line:** 175

---

### `def _urlencode(query: t.Mapping[str, str] | t.Iterable[tuple[str, str]]) -> str`

**Line:** 200

---


## Module: venv2.libthon3.12.site-packages.werkzeug.utils
**File:** `venv2/lib/python3.12/site-packages/werkzeug/utils.py`

**Imports:**
- __future__.annotations
- _internal._DictAccessorProperty
- _internal._TAccessorValue
- _internal._missing
- _typeshed.wsgi.WSGIEnvironment
- datastructures.Headers
- datetime.datetime
- exceptions.NotFound
- exceptions.RequestedRangeNotSatisfiable
- io
- markupsafe.escape
- mimetypes
- os
- pkgutil
- re
- security.safe_join
- sys
- time.time
- typing
- unicodedata
- urllib.parse.quote
- wrappers.Response
- wrappers.request.Request
- wrappers.response.Response
- wsgi.wrap_file
- zlib.adler32

**Functions:**

### `def get_content_type(mimetype: str, charset: str) -> str`

**Description:**
Returns the full content type string with charset for a mimetype.

If the mimetype represents text, the charset parameter will be
appended, otherwise the mimetype is returned unchanged.

:param mimetype: The mimetype to be used as content type.
:param charset: The charset to be appended for text mimetypes.
:return: The content type.

.. versionchanged:: 0.15
Any type that ends with ``+xml`` gets a charset, not just those
that start with ``application/``. Known text types such as
``application/javascript`` are also given charsets.

**Line:** 170

---

### `def secure_filename(filename: str) -> str`

**Description:**
Pass it a filename and it will return a secure version of it.  This
filename can then safely be stored on a regular file system and passed
to :func:`os.path.join`.  The filename returned is an ASCII only string
for maximum portability.

On windows systems the function also makes sure that the file is not
named after one of the special device files.

>>> secure_filename("My cool movie.mov")
'My_cool_movie.mov'
>>> secure_filename("../../../etc/passwd")
'etc_passwd'
>>> secure_filename('i contain cool \xfcml\xe4uts.txt')
'i_contain_cool_umlauts.txt'

The function might return an empty filename.  It's your responsibility
to ensure that the filename is unique and that you abort or
generate a random filename if the function returned an empty one.

.. versionadded:: 0.5

:param filename: the filename to secure

**Line:** 195

---

### `def redirect(location: str, code: int = 302, Response: type[Response] | None = None) -> Response`

**Description:**
Returns a response object (a WSGI application) that, if called,
redirects the client to the target location. Supported codes are
301, 302, 303, 305, 307, and 308. 300 is not supported because
it's not a real redirect and 304 because it's the answer for a
request with a request with defined If-Modified-Since headers.

.. versionadded:: 0.6
The location can now be a unicode string that is encoded using
the :func:`iri_to_uri` function.

.. versionadded:: 0.10
The class used for the Response object can now be passed in.

:param location: the location the response should redirect to.
:param code: the redirect status code. defaults to 302.
:param class Response: a Response class to use when instantiating a
response. The default is :class:`werkzeug.wrappers.Response` if
unspecified.

**Line:** 242

---

### `def append_slash_redirect(environ: WSGIEnvironment, code: int = 308) -> Response`

**Description:**
Redirect to the current URL with a slash appended.

If the current URL is ``/user/42``, the redirect URL will be
``42/``. When joined to the current URL during response
processing or by the browser, this will produce ``/user/42/``.

The behavior is undefined if the path ends with a slash already. If
called unconditionally on a URL, it may produce a redirect loop.

:param environ: Use the path and query from this WSGI environment
to produce the redirect URL.
:param code: the status code for the redirect.

.. versionchanged:: 2.1
Produce a relative URL that only modifies the last segment.
Relevant when the current path has multiple segments.

.. versionchanged:: 2.1
The default status code is 308 instead of 301. This preserves
the request method and body.

**Line:** 282

---

### `def send_file(path_or_file: os.PathLike[str] | str | t.IO[bytes], environ: WSGIEnvironment, mimetype: str | None = None, as_attachment: bool = False, download_name: str | None = None, conditional: bool = True, etag: bool | str = True, last_modified: datetime | int | float | None = None, max_age: None | (int | t.Callable[[str | None], int | None]) = None, use_x_sendfile: bool = False, response_class: type[Response] | None = None, _root_path: os.PathLike[str] | str | None = None) -> Response`

**Description:**
Send the contents of a file to the client.

The first argument can be a file path or a file-like object. Paths
are preferred in most cases because Werkzeug can manage the file and
get extra information from the path. Passing a file-like object
requires that the file is opened in binary mode, and is mostly
useful when building a file in memory with :class:`io.BytesIO`.

Never pass file paths provided by a user. The path is assumed to be
trusted, so a user could craft a path to access a file you didn't
intend. Use :func:`send_from_directory` to safely serve user-provided paths.

If the WSGI server sets a ``file_wrapper`` in ``environ``, it is
used, otherwise Werkzeug's built-in wrapper is used. Alternatively,
if the HTTP server supports ``X-Sendfile``, ``use_x_sendfile=True``
will tell the server to send the given path, which is much more
efficient than reading it in Python.

:param path_or_file: The path to the file to send, relative to the
current working directory if a relative path is given.
Alternatively, a file-like object opened in binary mode. Make
sure the file pointer is seeked to the start of the data.
:param environ: The WSGI environ for the current request.
:param mimetype: The MIME type to send for the file. If not
provided, it will try to detect it from the file name.
:param as_attachment: Indicate to a browser that it should offer to
save the file instead of displaying it.
:param download_name: The default name browsers will use when saving
the file. Defaults to the passed file name.
:param conditional: Enable conditional and range responses based on
request headers. Requires passing a file path and ``environ``.
:param etag: Calculate an ETag for the file, which requires passing
a file path. Can also be a string to use instead.
:param last_modified: The last modified time to send for the file,
in seconds. If not provided, it will try to detect it from the
file path.
:param max_age: How long the client should cache the file, in
seconds. If set, ``Cache-Control`` will be ``public``, otherwise
it will be ``no-cache`` to prefer conditional caching.
:param use_x_sendfile: Set the ``X-Sendfile`` header to let the
server to efficiently send the file. Requires support from the
HTTP server. Requires passing a file path.
:param response_class: Build the response using this class. Defaults
to :class:`~werkzeug.wrappers.Response`.
:param _root_path: Do not use. For internal use only. Use
:func:`send_from_directory` to safely send files under a path.

.. versionchanged:: 2.0.2
``send_file`` only sets a detected ``Content-Encoding`` if
``as_attachment`` is disabled.

.. versionadded:: 2.0
Adapted from Flask's implementation.

.. versionchanged:: 2.0
``download_name`` replaces Flask's ``attachment_filename``
parameter. If ``as_attachment=False``, it is passed with
``Content-Disposition: inline`` instead.

.. versionchanged:: 2.0
``max_age`` replaces Flask's ``cache_timeout`` parameter.
``conditional`` is enabled and ``max_age`` is not set by
default.

.. versionchanged:: 2.0
``etag`` replaces Flask's ``add_etags`` parameter. It can be a
string to use instead of generating one.

.. versionchanged:: 2.0
If an encoding is returned when guessing ``mimetype`` from
``download_name``, set the ``Content-Encoding`` header.

**Line:** 319

---

### `def send_from_directory(directory: os.PathLike[str] | str, path: os.PathLike[str] | str, environ: WSGIEnvironment, **kwargs: t.Any) -> Response`

**Description:**
Send a file from within a directory using :func:`send_file`.

This is a secure way to serve files from a folder, such as static
files or uploads. Uses :func:`~werkzeug.security.safe_join` to
ensure the path coming from the client is not maliciously crafted to
point outside the specified directory.

If the final path does not point to an existing regular file,
returns a 404 :exc:`~werkzeug.exceptions.NotFound` error.

:param directory: The directory that ``path`` must be located under. This *must not*
be a value provided by the client, otherwise it becomes insecure.
:param path: The path to the file to send, relative to ``directory``. This is the
part of the path provided by the client, which is checked for security.
:param environ: The WSGI environ for the current request.
:param kwargs: Arguments to pass to :func:`send_file`.

.. versionadded:: 2.0
Adapted from Flask's implementation.

**Line:** 538

---

### `def import_string(import_name: str, silent: bool = False) -> t.Any`

**Description:**
Imports an object based on a string.  This is useful if you want to
use import paths as endpoints or something similar.  An import path can
be specified either in dotted notation (``xml.sax.saxutils.escape``)
or with a colon as object delimiter (``xml.sax.saxutils:escape``).

If `silent` is True the return value will be `None` if the import fails.

:param import_name: the dotted name for the object to import.
:param silent: if set to `True` import errors are ignored and
`None` is returned instead.
:return: imported object

**Line:** 580

---

### `def find_modules(import_path: str, include_packages: bool = False, recursive: bool = False) -> t.Iterator[str]`

**Description:**
Finds all the modules below a package.  This can be useful to
automatically import all views / controllers so that their metaclasses /
function decorators have a chance to register themselves on the
application.

Packages are not returned unless `include_packages` is `True`.  This can
also recursively list modules but in that case it will import all the
packages to get the correct load path of that module.

:param import_path: the dotted name for the package to find child modules.
:param include_packages: set to `True` if packages should be returned, too.
:param recursive: set to `True` if recursion should happen.
:return: generator

**Line:** 619

---


## Module: venv2.libthon3.12.site-packages.werkzeug.wrappers.response
**File:** `venv2/lib/python3.12/site-packages/werkzeug/wrappers/response.py`

**Imports:**
- __future__.annotations
- _internal._get_environ
- _typeshed.wsgi.StartResponse
- _typeshed.wsgi.WSGIApplication
- _typeshed.wsgi.WSGIEnvironment
- datastructures.Headers
- exceptions.RequestedRangeNotSatisfiable
- http.HTTPStatus
- http.generate_etag
- http.http_date
- http.is_resource_modified
- http.parse_etags
- http.parse_range_header
- http.remove_entity_headers
- json
- request.Request
- sansio.response.Response
- test.run_wsgi_app
- typing
- urllib.parse.urljoin
- urls.iri_to_uri
- utils.cached_property
- wsgi.ClosingIterator
- wsgi._RangeWrapper
- wsgi.get_current_url

**Functions:**

### `def _iter_encoded(iterable: t.Iterable[str | bytes]) -> t.Iterator[bytes]`

**Line:** 31

---


## Module: venv2.libthon3.12.site-packages.werkzeug.wsgi
**File:** `venv2/lib/python3.12/site-packages/werkzeug/wsgi.py`

**Imports:**
- __future__.annotations
- _typeshed.wsgi.WSGIApplication
- _typeshed.wsgi.WSGIEnvironment
- exceptions.ClientDisconnected
- exceptions.RequestEntityTooLarge
- functools.partial
- functools.update_wrapper
- io
- sansio.utils
- sansio.utils.host_is_trusted
- typing

**Functions:**

### `def responder(f: t.Callable[(..., WSGIApplication)]) -> WSGIApplication`

**Description:**
Marks a function as responder.  Decorate a function with it and it
will automatically call the return value as WSGI application.

Example::

@responder
def application(environ, start_response):
return Response('Hello World!')

**Line:** 18

---

### `def get_current_url(environ: WSGIEnvironment, root_only: bool = False, strip_querystring: bool = False, host_only: bool = False, trusted_hosts: t.Iterable[str] | None = None) -> str`

**Description:**
Recreate the URL for a request from the parts in a WSGI
environment.

The URL is an IRI, not a URI, so it may contain Unicode characters.
Use :func:`~werkzeug.urls.iri_to_uri` to convert it to ASCII.

:param environ: The WSGI environment to get the URL parts from.
:param root_only: Only build the root path, don't include the
remaining path or query string.
:param strip_querystring: Don't include the query string.
:param host_only: Only build the scheme and host.
:param trusted_hosts: A list of trusted host names to validate the
host against.

**Line:** 31

---

### `def _get_server(environ: WSGIEnvironment) -> tuple[str, int | None] | None`

**Line:** 69

---

### `def get_host(environ: WSGIEnvironment, trusted_hosts: t.Iterable[str] | None = None) -> str`

**Description:**
Return the host for the given WSGI environment.

The ``Host`` header is preferred, then ``SERVER_NAME`` if it's not
set. The returned host will only contain the port if it is different
than the standard port for the protocol.

Optionally, verify that the host is trusted using
:func:`host_is_trusted` and raise a
:exc:`~werkzeug.exceptions.SecurityError` if it is not.

:param environ: A WSGI environment dict.
:param trusted_hosts: A list of trusted host names.

:return: Host, with port if necessary.
:raise ~werkzeug.exceptions.SecurityError: If the host is not
trusted.

**Line:** 86

---

### `def get_content_length(environ: WSGIEnvironment) -> int | None`

**Description:**
Return the ``Content-Length`` header value as an int. If the header is not given
or the ``Transfer-Encoding`` header is ``chunked``, ``None`` is returned to indicate
a streaming request. If the value is not an integer, or negative, 0 is returned.

:param environ: The WSGI environ to get the content length from.

.. versionadded:: 0.9

**Line:** 114

---

### `def get_input_stream(environ: WSGIEnvironment, safe_fallback: bool = True, max_content_length: int | None = None) -> t.IO[bytes]`

**Description:**
Return the WSGI input stream, wrapped so that it may be read safely without going
past the ``Content-Length`` header value or ``max_content_length``.

If ``Content-Length`` exceeds ``max_content_length``, a
:exc:`RequestEntityTooLarge`` ``413 Content Too Large`` error is raised.

If the WSGI server sets ``environ["wsgi.input_terminated"]``, it indicates that the
server handles terminating the stream, so it is safe to read directly. For example,
a server that knows how to handle chunked requests safely would set this.

If ``max_content_length`` is set, it can be enforced on streams if
``wsgi.input_terminated`` is set. Otherwise, an empty stream is returned unless the
user explicitly disables this safe fallback.

If the limit is reached before the underlying stream is exhausted (such as a file
that is too large, or an infinite stream), the remaining contents of the stream
cannot be read safely. Depending on how the server handles this, clients may show a
"connection reset" failure instead of seeing the 413 response.

:param environ: The WSGI environ containing the stream.
:param safe_fallback: Return an empty stream when ``Content-Length`` is not set.
Disabling this allows infinite streams, which can be a denial-of-service risk.
:param max_content_length: The maximum length that content-length or streaming
requests may not exceed.

.. versionchanged:: 2.3.2
``max_content_length`` is only applied to streaming requests if the server sets
``wsgi.input_terminated``.

.. versionchanged:: 2.3
Check ``max_content_length`` and raise an error if it is exceeded.

.. versionadded:: 0.9

**Line:** 129

---

### `def get_path_info(environ: WSGIEnvironment) -> str`

**Description:**
Return ``PATH_INFO`` from  the WSGI environment.

:param environ: WSGI environment to get the path from.

.. versionchanged:: 3.0
The ``charset`` and ``errors`` parameters were removed.

.. versionadded:: 0.9

**Line:** 197

---

### `def wrap_file(environ: WSGIEnvironment, file: t.IO[bytes], buffer_size: int = 8192) -> t.Iterable[bytes]`

**Description:**
Wraps a file.  This uses the WSGI server's file wrapper if available
or otherwise the generic :class:`FileWrapper`.

.. versionadded:: 0.5

If the file wrapper from the WSGI server is used it's important to not
iterate over it from inside the application but to pass it through
unchanged.  If you want to pass out a file wrapper inside a response
object you have to set :attr:`Response.direct_passthrough` to `True`.

More information about file wrappers are available in :pep:`333`.

:param file: a :class:`file`-like object with a :meth:`~file.read` method.
:param buffer_size: number of bytes for one iteration.

**Line:** 263

---


## Module: venv2.libthon3.12.site-packages.wrapt.arguments
**File:** `venv2/lib/python3.12/site-packages/wrapt/arguments.py`

**Imports:**
- inspect.Parameter
- inspect.Signature
- inspect.formatargspec

**Functions:**

### `def formatargspec(args, varargs = None, varkw = None, defaults = None, kwonlyargs = (), kwonlydefaults = {}, annotations = {})`

**Line:** 12

---


## Module: venv2.libthon3.12.site-packages.wrapt.decorators
**File:** `venv2/lib/python3.12/site-packages/wrapt/decorators.py`

**Imports:**
- __wrapt__.BoundFunctionWrapper
- __wrapt__.CallableObjectProxy
- __wrapt__.FunctionWrapper
- __wrapt__.ObjectProxy
- arguments.formatargspec
- builtins
- functools.partial
- inspect.isclass
- inspect.signature
- sys
- threading.Lock
- threading.RLock

**Functions:**

### `def exec_(_code_, _globs_ = None, _locs_ = None)`

**Description:**
Execute code in a namespace.

**Line:** 13

---

### `def decorator(wrapper = None, enabled = None, adapter = None, proxy = FunctionWrapper)`

**Line:** 177

---

### `def synchronized(wrapped)`

**Line:** 448

---


## Module: venv2.libthon3.12.site-packages.wrapt.importer
**File:** `venv2/lib/python3.12/site-packages/wrapt/importer.py`

**Imports:**
- __wrapt__.ObjectProxy
- importlib.util.find_spec
- pkg_resources
- sys
- threading

**Functions:**

### `def _create_import_hook_from_string(name)`

**Line:** 37

---

### `def register_post_import_hook(hook, name)`

**Line:** 48

---

### `def _create_import_hook_from_entrypoint(entrypoint)`

**Line:** 83

---

### `def discover_post_import_hooks(group)`

**Line:** 92

---

### `def notify_module_loaded(module)`

**Line:** 107

---

### `def when_imported(name)`

**Line:** 291

---


## Module: venv2.libthon3.12.site-packages.wrapt.patches
**File:** `venv2/lib/python3.12/site-packages/wrapt/patches.py`

**Imports:**
- __wrapt__.FunctionWrapper
- inspect
- sys

**Functions:**

### `def resolve_path(module, name)`

**Line:** 15

---

### `def apply_patch(parent, attribute, replacement)`

**Line:** 56

---

### `def wrap_object(module, name, factory, args = (), kwargs = {})`

**Line:** 59

---

### `def wrap_object_attribute(module, name, factory, args = (), kwargs = {})`

**Line:** 89

---

### `def function_wrapper(wrapper)`

**Line:** 101

---

### `def wrap_function_wrapper(module, name, wrapper)`

**Line:** 113

---

### `def patch_function_wrapper(module, name, enabled = None)`

**Line:** 116

---

### `def transient_function_wrapper(module, name)`

**Line:** 121

---


## Module: venv2.libthon3.12.site-packages.wrapt.weakrefs
**File:** `venv2/lib/python3.12/site-packages/wrapt/weakrefs.py`

**Imports:**
- __wrapt__.ObjectProxy
- __wrapt__._FunctionWrapperBase
- functools
- weakref

**Functions:**

### `def _weak_function_proxy_callback(ref, proxy, callback)`

**Line:** 15

---


## Module: venv2.libthon3.12.site-packages.wrapt.wrappers
**File:** `venv2/lib/python3.12/site-packages/wrapt/wrappers.py`

**Imports:**
- inspect
- operator
- sys

**Functions:**

### `def with_metaclass(meta, *bases)`

**Description:**
Create a base class with a metaclass.

**Line:** 12

---


## Module: venv2.libthon3.12.site-packagesdantic.__init__
**File:** `venv2/lib/python3.12/site-packages/pydantic/__init__.py`

**Imports:**
- _internal._generate_schema.GenerateSchema
- _migration.getattr_migration
- annotated_handlers.GetCoreSchemaHandler
- annotated_handlers.GetJsonSchemaHandler
- config.ConfigDict
- deprecated.class_validators.root_validator
- deprecated.class_validators.validator
- deprecated.config.BaseConfig
- deprecated.config.Extra
- deprecated.tools.*
- errors.*
- fields.AliasChoices
- fields.AliasPath
- fields.Field
- fields.PrivateAttr
- fields.computed_field
- functional_serializers.PlainSerializer
- functional_serializers.SerializeAsAny
- functional_serializers.WrapSerializer
- functional_serializers.field_serializer
- functional_serializers.model_serializer
- functional_validators.AfterValidator
- functional_validators.BeforeValidator
- functional_validators.InstanceOf
- functional_validators.PlainValidator
- functional_validators.SkipValidation
- functional_validators.WrapValidator
- functional_validators.field_validator
- functional_validators.model_validator
- importlib.import_module
- json_schema.WithJsonSchema
- main.*
- networks.*
- pydantic_core
- pydantic_core.core_schema.FieldSerializationInfo
- pydantic_core.core_schema.SerializationInfo
- pydantic_core.core_schema.SerializerFunctionWrapHandler
- pydantic_core.core_schema.ValidationInfo
- pydantic_core.core_schema.ValidatorFunctionWrapHandler
- root_model.RootModel
- type_adapter.TypeAdapter
- types.*
- typing
- validate_call_decorator.validate_call
- version.VERSION
- warnings.PydanticDeprecatedSince20
- warnings.PydanticDeprecationWarning

**Functions:**

### `def __getattr__(attr_name: str) -> object`

**Line:** 360

---

### `def __dir__() -> 'list[str]'`

**Line:** 376

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._config
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_config.py`

**Imports:**
- __future__.annotations
- _internal._schema_generation_shared.GenerateSchema
- config.ConfigDict
- config.ExtraValues
- config.JsonDict
- config.JsonEncoder
- config.JsonSchemaExtraCallable
- contextlib.contextmanager
- errors.PydanticUserError
- pydantic_core.core_schema
- typing.Any
- typing.Callable
- typing.TYPE_CHECKING
- typing.cast
- typing_extensions.Literal
- typing_extensions.Self
- warnings
- warnings.PydanticDeprecatedSince20

**Functions:**

### `def prepare_config(config: ConfigDict | dict[str, Any] | type[Any] | None) -> ConfigDict`

**Description:**
Create a `ConfigDict` instance from an existing dict, a class (e.g. old class-based config) or None.

Args:
config: The input config.

Returns:
A ConfigDict object created from config.

**Line:** 255

---

### `def check_deprecated(config_dict: ConfigDict) -> None`

**Description:**
Check for deprecated config keys and warn the user.

Args:
config_dict: The input config.

**Line:** 305

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._core_metadata
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_core_metadata.py`

**Imports:**
- __future__.annotations
- _schema_generation_shared.CoreSchemaOrField
- _schema_generation_shared.GetJsonSchemaFunction
- typing
- typing.Any
- typing_extensions

**Functions:**

### `def build_metadata_dict(js_functions: list[GetJsonSchemaFunction] | None = None, js_annotation_functions: list[GetJsonSchemaFunction] | None = None, js_prefer_positional_arguments: bool | None = None, typed_dict_cls: type[Any] | None = None, initial_metadata: Any | None = None) -> Any`

**Description:**
Builds a dict to use as the metadata field of a CoreSchema object in a manner that is consistent
with the CoreMetadataHandler class.

**Line:** 67

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._core_utils
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_core_utils.py`

**Imports:**
- __future__.annotations
- _typing_extra.is_generic_alias
- collections.defaultdict
- os
- pydantic_core.CoreSchema
- pydantic_core.core_schema
- pydantic_core.validate_core_schema
- rich.print
- typing.Any
- typing.Callable
- typing.Hashable
- typing.TypeVar
- typing.Union
- typing.cast
- typing_extensions.TypeAliasType
- typing_extensions.TypeGuard
- typing_extensions.get_args
- typing_extensions.get_origin

**Functions:**

### `def is_core_schema(schema: CoreSchemaOrField) -> TypeGuard[CoreSchema]`

**Line:** 61

---

### `def is_core_schema_field(schema: CoreSchemaOrField) -> TypeGuard[CoreSchemaField]`

**Line:** 67

---

### `def is_function_with_inner_schema(schema: CoreSchemaOrField) -> TypeGuard[FunctionSchemaWithInnerSchema]`

**Line:** 73

---

### `def is_list_like_schema_with_items_schema(schema: CoreSchema) -> TypeGuard[core_schema.ListSchema | core_schema.TupleVariableSchema | core_schema.SetSchema | core_schema.FrozenSetSchema]`

**Line:** 79

---

### `def get_type_ref(type_: type[Any], args_override: tuple[type[Any], ...] | None = None) -> str`

**Description:**
Produces the ref to be used for this type by pydantic_core's core schemas.

This `args_override` argument was added for the purpose of creating valid recursive references
when creating generic models without needing to create a concrete class.

**Line:** 87

---

### `def get_ref(s: core_schema.CoreSchema) -> None | str`

**Description:**
Get the ref from the schema if it has one.
This exists just for type checking to work correctly.

**Line:** 125

---

### `def collect_definitions(schema: core_schema.CoreSchema) -> dict[(str, core_schema.CoreSchema)]`

**Line:** 132

---

### `def define_expected_missing_refs(schema: core_schema.CoreSchema, allowed_missing_refs: set[str]) -> core_schema.CoreSchema | None`

**Line:** 146

---

### `def collect_invalid_schemas(schema: core_schema.CoreSchema) -> bool`

**Line:** 168

---

### `def walk_core_schema(schema: core_schema.CoreSchema, f: Walk) -> core_schema.CoreSchema`

**Description:**
Recursively traverse a CoreSchema.

Args:
schema (core_schema.CoreSchema): The CoreSchema to process, it will not be modified.
f (Walk): A function to apply. This function takes two arguments:
1. The current CoreSchema that is being processed
(not the same one you passed into this function, one level down).
2. The "next" `f` to call. This lets you for example use `f=functools.partial(some_method, some_context)`
to pass data down the recursive calls without using globals or other mutable state.

Returns:
core_schema.CoreSchema: A processed CoreSchema.

**Line:** 417

---

### `def simplify_schema_references(schema: core_schema.CoreSchema) -> core_schema.CoreSchema`

**Line:** 434

---

### `def _strip_metadata(schema: CoreSchema) -> CoreSchema`

**Line:** 532

---

### `def pretty_print_core_schema(schema: CoreSchema, include_metadata: bool = False) -> None`

**Description:**
Pretty print a CoreSchema using rich.
This is intended for debugging purposes.

Args:
schema: The CoreSchema to print.
include_metadata: Whether to include metadata in the output. Defaults to `False`.

**Line:** 563

---

### `def validate_core_schema(schema: CoreSchema) -> CoreSchema`

**Line:** 582

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._dataclasses
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_dataclasses.py`

**Imports:**
- __future__.annotations
- _config.ConfigWrapper
- _fields.collect_dataclass_fields
- _generate_schema.GenerateSchema
- _generate_schema.generate_pydantic_signature
- _generics.get_standard_typevars_map
- _mock_val_ser.set_dataclass_mocks
- _schema_generation_shared.CallbackGetCoreSchemaHandler
- _utils.is_valid_identifier
- config.ConfigDict
- dataclasses
- errors.PydanticUndefinedAnnotation
- fields.FieldInfo
- functools.partial
- functools.wraps
- inspect
- inspect.Parameter
- inspect.Signature
- plugin._schema_validator.create_schema_validator
- pydantic_core.ArgsKwargs
- pydantic_core.PydanticUndefined
- pydantic_core.SchemaSerializer
- pydantic_core.SchemaValidator
- pydantic_core.core_schema
- typing
- typing.Any
- typing.Callable
- typing.ClassVar
- typing_extensions.TypeGuard
- warnings
- warnings.PydanticDeprecatedSince20

**Functions:**

### `def set_dataclass_fields(cls: type[StandardDataclass], types_namespace: dict[str, Any] | None = None) -> None`

**Description:**
Collect and set `cls.__pydantic_fields__`.

Args:
cls: The class.
types_namespace: The types namespace, defaults to `None`.

**Line:** 72

---

### `def complete_dataclass(cls: type[Any], config_wrapper: _config.ConfigWrapper, raise_errors: bool = True, types_namespace: dict[str, Any] | None) -> bool`

**Description:**
Finish building a pydantic dataclass.

This logic is called on a class which has already been wrapped in `dataclasses.dataclass()`.

This is somewhat analogous to `pydantic._internal._model_construction.complete_model_class`.

Args:
cls: The class.
config_wrapper: The config wrapper instance.
raise_errors: Whether to raise errors, defaults to `True`.
types_namespace: The types namespace.

Returns:
`True` if building a pydantic dataclass is successfully completed, `False` otherwise.

Raises:
PydanticUndefinedAnnotation: If `raise_error` is `True` and there is an undefined annotations.

**Line:** 85

---

### `def process_param_defaults(param: Parameter) -> Parameter`

**Description:**
Custom processing where the parameter default is of type FieldInfo

Args:
param (Parameter): The parameter

Returns:
Parameter: The custom processed parameter

**Line:** 190

---

### `def generate_dataclass_signature(cls: type[StandardDataclass], fields: dict[(str, FieldInfo)], config_wrapper: ConfigWrapper) -> Signature`

**Description:**
Generate signature for a pydantic dataclass.

Args:
cls: The dataclass.
fields: The model fields.
config_wrapper: The config wrapper instance.

Returns:
The dataclass signature.

**Line:** 229

---

### `def is_builtin_dataclass(_cls: type[Any]) -> TypeGuard[type[StandardDataclass]]`

**Description:**
Returns True if a class is a stdlib dataclass and *not* a pydantic dataclass.

We check that
- `_cls` is a dataclass
- `_cls` does not inherit from a processed pydantic dataclass (and thus have a `__pydantic_validator__`)
- `_cls` does not have any annotations that are not dataclass fields
e.g.
```py
import dataclasses

import pydantic.dataclasses

@dataclasses.dataclass
class A:
x: int

@pydantic.dataclasses.dataclass
class B(A):
y: int
```
In this case, when we first check `B`, we make an extra check and look at the annotations ('y'),
which won't be a superset of all the dataclass fields (only the stdlib fields i.e. 'x')

Args:
cls: The class.

Returns:
`True` if the class is a stdlib dataclass, `False` otherwise.

**Line:** 247

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._decorators
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_decorators.py`

**Imports:**
- __future__.annotations
- _core_utils.get_type_ref
- _internal_dataclass.slots_true
- _typing_extra.get_function_type_hints
- collections.deque
- dataclasses.dataclass
- dataclasses.field
- errors.PydanticUserError
- fields.ComputedFieldInfo
- functional_validators.FieldValidatorModes
- functools.cached_property
- functools.partial
- functools.partialmethod
- inspect.Parameter
- inspect.Signature
- inspect.isdatadescriptor
- inspect.ismethoddescriptor
- inspect.signature
- itertools.islice
- pydantic_core.PydanticUndefined
- pydantic_core.core_schema
- typing.Any
- typing.Callable
- typing.ClassVar
- typing.Generic
- typing.Iterable
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.Union
- typing_extensions.Literal
- typing_extensions.TypeAlias
- typing_extensions.is_typeddict

**Functions:**

### `def get_bases(tp: type[Any]) -> tuple[(type[Any], ...)]`

**Description:**
Get the base classes of a class or typeddict.

Args:
tp: The type or class to get the bases.

Returns:
The base classes.

**Line:** 281

---

### `def mro(tp: type[Any]) -> tuple[(type[Any], ...)]`

**Description:**
Calculate the Method Resolution Order of bases using the C3 algorithm.

See https://www.python.org/download/releases/2.3/mro/

**Line:** 298

---

### `def mro_for_bases(bases: tuple[(type[Any], ...)]) -> tuple[(type[Any], ...)]`

**Line:** 316

---

### `def get_attribute_from_bases(tp: type[Any] | tuple[type[Any], ...], name: str) -> Any`

**Description:**
Get the attribute from the next class in the MRO that has it,
aiming to simulate calling the method on the actual class.

The reason for iterating over the mro instead of just getting
the attribute (which would do that for us) is to support TypedDict,
which lacks a real __mro__, but can have a virtual one constructed
from its bases (as done here).

Args:
tp: The type or class to search for the attribute. If a tuple, this is treated as a set of base classes.
name: The name of the attribute to retrieve.

Returns:
Any: The attribute value, if found.

Raises:
AttributeError: If the attribute is not found in any class in the MRO.

**Line:** 347

---

### `def get_attribute_from_base_dicts(tp: type[Any], name: str) -> Any`

**Description:**
Get an attribute out of the `__dict__` following the MRO.
This prevents the call to `__get__` on the descriptor, and allows
us to get the original function for classmethod properties.

Args:
tp: The type or class to search for the attribute.
name: The name of the attribute to retrieve.

Returns:
Any: The attribute value, if found.

Raises:
KeyError: If the attribute is not found in any class's `__dict__` in the MRO.

**Line:** 382

---

### `def inspect_validator(validator: Callable[(..., Any)], mode: FieldValidatorModes) -> bool`

**Description:**
Look at a field or model validator function and determine whether it takes an info argument.

An error is raised if the function has an invalid signature.

Args:
validator: The validator function to inspect.
mode: The proposed validator mode.

Returns:
Whether the validator takes an info argument.

**Line:** 509

---

### `def inspect_field_serializer(serializer: Callable[(..., Any)], mode: Literal[('plain', 'wrap')], computed_field: bool = False) -> tuple[(bool, bool)]`

**Description:**
Look at a field serializer function and determine if it is a field serializer,
and whether it takes an info argument.

An error is raised if the function has an invalid signature.

Args:
serializer: The serializer function to inspect.
mode: The serializer mode, either 'plain' or 'wrap'.
computed_field: When serializer is applied on computed_field. It doesn't require
info signature.

Returns:
Tuple of (is_field_serializer, info_arg).

**Line:** 547

---

### `def inspect_annotated_serializer(serializer: Callable[(..., Any)], mode: Literal[('plain', 'wrap')]) -> bool`

**Description:**
Look at a serializer function used via `Annotated` and determine whether it takes an info argument.

An error is raised if the function has an invalid signature.

Args:
serializer: The serializer function to check.
mode: The serializer mode, either 'plain' or 'wrap'.

Returns:
info_arg

**Line:** 590

---

### `def inspect_model_serializer(serializer: Callable[(..., Any)], mode: Literal[('plain', 'wrap')]) -> bool`

**Description:**
Look at a model serializer function and determine whether it takes an info argument.

An error is raised if the function has an invalid signature.

Args:
serializer: The serializer function to check.
mode: The serializer mode, either 'plain' or 'wrap'.

Returns:
`info_arg` - whether the function expects an info argument.

**Line:** 613

---

### `def _serializer_info_arg(mode: Literal[('plain', 'wrap')], n_positional: int) -> bool | None`

**Line:** 641

---

### `def is_instance_method_from_sig(function: AnyDecoratorCallable) -> bool`

**Description:**
Whether the function is an instance method.

It will consider a function as instance method if the first parameter of
function is `self`.

Args:
function: The function to check.

Returns:
`True` if the function is an instance method, `False` otherwise.

**Line:** 666

---

### `def ensure_classmethod_based_on_signature(function: AnyDecoratorCallable) -> Any`

**Description:**
Apply the `@classmethod` decorator on the function.

Args:
function: The function to apply the decorator on.

Return:
The `@classmethod` decorator applied function.

**Line:** 685

---

### `def _is_classmethod_from_sig(function: AnyDecoratorCallable) -> bool`

**Line:** 701

---

### `def unwrap_wrapped_function(func: Any, unwrap_partial: bool = True, unwrap_class_static_method: bool = True) -> Any`

**Description:**
Recursively unwraps a wrapped function until the underlying function is reached.
This handles property, functools.partial, functools.partialmethod, staticmethod and classmethod.

Args:
func: The function to unwrap.
unwrap_partial: If True (default), unwrap partial and partialmethod decorators, otherwise don't.
decorators.
unwrap_class_static_method: If True (default), also unwrap classmethod and staticmethod
decorators. If False, only unwrap partial and partialmethod decorators.

Returns:
The underlying function of the wrapped function.

**Line:** 709

---

### `def get_function_return_type(func: Any, explicit_return_type: Any, types_namespace: dict[str, Any] | None = None) -> Any`

**Description:**
Get the function return type.

It gets the return type from the type annotation if `explicit_return_type` is `None`.
Otherwise, it returns `explicit_return_type`.

Args:
func: The function to get its return type.
explicit_return_type: The explicit return type.
types_namespace: The types namespace, defaults to `None`.

Returns:
The function return type.

**Line:** 758

---

### `def count_positional_params(sig: Signature) -> int`

**Line:** 784

---

### `def can_be_positional(param: Parameter) -> bool`

**Line:** 788

---

### `def ensure_property(f: Any) -> Any`

**Description:**
Ensure that a function is a `property` or `cached_property`, or is a valid descriptor.

Args:
f: The function to check.

Returns:
The function, or a `property` or `cached_property` instance wrapping the function.

**Line:** 792

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._decorators_v1
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_decorators_v1.py`

**Imports:**
- __future__.annotations
- _decorators.can_be_positional
- errors.PydanticUserError
- inspect.Parameter
- inspect.signature
- pydantic_core.core_schema
- typing.Any
- typing.Dict
- typing.Tuple
- typing.Union
- typing.cast
- typing_extensions.Protocol

**Functions:**

### `def can_be_keyword(param: Parameter) -> bool`

**Line:** 54

---

### `def make_generic_v1_field_validator(validator: V1Validator) -> core_schema.WithInfoValidatorFunction`

**Description:**
Wrap a V1 style field validator for V2 compatibility.

Args:
validator: The V1 style field validator.

Returns:
A wrapped V2 style field validator.

Raises:
PydanticUserError: If the signature is not supported or the parameters are
not available in Pydantic V2.

**Line:** 58

---

### `def make_v1_generic_root_validator(validator: V1RootValidatorFunction, pre: bool) -> V2CoreBeforeRootValidator | V2CoreAfterRootValidator`

**Description:**
Wrap a V1 style root validator for V2 compatibility.

Args:
validator: The V1 style field validator.
pre: Whether the validator is a pre validator.

Returns:
A wrapped V2 style validator.

**Line:** 140

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._discriminated_union
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_discriminated_union.py`

**Imports:**
- __future__.annotations
- _core_utils.CoreSchemaField
- _core_utils.NEEDS_APPLY_DISCRIMINATED_UNION_METADATA_KEY
- _core_utils.collect_definitions
- _core_utils.simplify_schema_references
- errors.PydanticUserError
- pydantic_core.CoreSchema
- pydantic_core.core_schema
- types.Discriminator
- typing.Any
- typing.Hashable
- typing.Sequence
- typing.TYPE_CHECKING

**Functions:**

### `def set_discriminator(schema: CoreSchema, discriminator: Any) -> None`

**Line:** 32

---

### `def apply_discriminators(schema: core_schema.CoreSchema) -> core_schema.CoreSchema`

**Line:** 39

---

### `def apply_discriminator(schema: core_schema.CoreSchema, discriminator: str | Discriminator, definitions: dict[str, core_schema.CoreSchema] | None = None) -> core_schema.CoreSchema`

**Description:**
Applies the discriminator and returns a new core schema.

Args:
schema: The input schema.
discriminator: The name of the field which will serve as the discriminator.
definitions: A mapping of schema ref to schema.

Returns:
The new core schema.

Raises:
TypeError:
- If `discriminator` is used with invalid union variant.
- If `discriminator` is used with `Union` type with one variant.
- If `discriminator` value mapped to multiple choices.
MissingDefinitionForUnionRef:
If the definition for ref is missing.
PydanticUserError:
- If a model in union doesn't have a discriminator field.
- If discriminator field has a non-string alias.
- If discriminator fields have different aliases.
- If discriminator field not of type `Literal`.

**Line:** 63

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._fields
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_fields.py`

**Imports:**
- __future__.annotations
- _config.ConfigWrapper
- _dataclasses.StandardDataclass
- _decorators.DecoratorInfos
- _repr.Representation
- _typing_extra.get_cls_type_hints_lenient
- _typing_extra.get_type_hints
- _typing_extra.is_classvar
- _typing_extra.is_finalvar
- annotated_types.BaseMetadata
- copy.copy
- dataclasses
- fields.FieldInfo
- functools.lru_cache
- main.BaseModel
- pydantic_core.PydanticUndefined
- sys
- typing.Any
- typing.TYPE_CHECKING
- warnings

**Functions:**

### `def get_type_hints_infer_globalns(obj: Any, localns: dict[str, Any] | None = None, include_extras: bool = False) -> dict[(str, Any)]`

**Description:**
Gets type hints for an object by inferring the global namespace.

It uses the `typing.get_type_hints`, The only thing that we do here is fetching
global namespace from `obj.__module__` if it is not `None`.

Args:
obj: The object to get its type hints.
localns: The local namespaces.
include_extras: Whether to recursively include annotation metadata.

Returns:
The object type hints.

**Line:** 27

---

### `def pydantic_general_metadata(**metadata: Any) -> BaseMetadata`

**Description:**
Create a new `_PydanticGeneralMetadata` class with the given metadata.

Args:
**metadata: The metadata to add.

Returns:
The new `_PydanticGeneralMetadata` class.

**Line:** 62

---

### `def _general_metadata_cls() -> type[BaseMetadata]`

**Decorators:**
- `@lru_cache(...)`

**Description:**
Do it this way to avoid importing `annotated_types` at import time.

**Line:** 75

---

### `def collect_model_fields(cls: type[BaseModel], bases: tuple[(type[Any], ...)], config_wrapper: ConfigWrapper, types_namespace: dict[str, Any] | None, typevars_map: dict[Any, Any] | None = None) -> tuple[(dict[str, FieldInfo], set[str])]`

**Description:**
Collect the fields of a nascent pydantic model.

Also collect the names of any ClassVars present in the type hints.

The returned value is a tuple of two items: the fields dict, and the set of ClassVar names.

Args:
cls: BaseModel or dataclass.
bases: Parents of the class, generally `cls.__bases__`.
config_wrapper: The config wrapper instance.
types_namespace: Optional extra namespace to look for types in.
typevars_map: A dictionary mapping type variables to their concrete types.

Returns:
A tuple contains fields and class variables.

Raises:
NameError:
- If there is a conflict between a field name and protected namespaces.
- If there is a field other than `root` in `RootModel`.
- If a field shadows an attribute in the parent model.

**Line:** 88

---

### `def _is_finalvar_with_default_val(type_: type[Any], val: Any) -> bool`

**Line:** 235

---

### `def collect_dataclass_fields(cls: type[StandardDataclass], types_namespace: dict[str, Any] | None, typevars_map: dict[Any, Any] | None = None) -> dict[(str, FieldInfo)]`

**Description:**
Collect the fields of a dataclass.

Args:
cls: dataclass.
types_namespace: Optional extra namespace to look for types in.
typevars_map: A dictionary mapping type variables to their concrete types.

Returns:
The dataclass fields.

**Line:** 248

---

### `def is_valid_field_name(name: str) -> bool`

**Line:** 301

---

### `def is_valid_privateattr_name(name: str) -> bool`

**Line:** 305

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._generate_schema
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py`

**Imports:**
- __future__.annotations
- _config.ConfigWrapper
- _config.ConfigWrapperStack
- _core_metadata.CoreMetadataHandler
- _core_metadata.build_metadata_dict
- _core_utils.CoreSchemaOrField
- _core_utils.NEEDS_APPLY_DISCRIMINATED_UNION_METADATA_KEY
- _core_utils.collect_invalid_schemas
- _core_utils.define_expected_missing_refs
- _core_utils.get_ref
- _core_utils.get_type_ref
- _core_utils.is_list_like_schema_with_items_schema
- _core_utils.simplify_schema_references
- _core_utils.validate_core_schema
- _dataclasses.StandardDataclass
- _decorators.Decorator
- _decorators.DecoratorInfos
- _decorators.FieldSerializerDecoratorInfo
- _decorators.FieldValidatorDecoratorInfo
- _decorators.ModelSerializerDecoratorInfo
- _decorators.ModelValidatorDecoratorInfo
- _decorators.RootValidatorDecoratorInfo
- _decorators.ValidatorDecoratorInfo
- _decorators.get_attribute_from_bases
- _decorators.inspect_field_serializer
- _decorators.inspect_model_serializer
- _decorators.inspect_validator
- _fields.collect_dataclass_fields
- _fields.get_type_hints_infer_globalns
- _forward_ref.PydanticRecursiveRef
- _generics.get_standard_typevars_map
- _generics.has_instance_in_type
- _generics.recursively_defined_type_refs
- _generics.replace_types
- _schema_generation_shared.CallbackGetCoreSchemaHandler
- _schema_generation_shared.GetJsonSchemaFunction
- _std_types_schema.PREPARE_METHODS
- _std_types_schema.get_enum_core_schema
- _typing_extra.is_finalvar
- _utils.is_valid_identifier
- _utils.lenient_issubclass
- _validators.sequence_validator
- annotated_handlers.GetCoreSchemaHandler
- annotated_handlers.GetJsonSchemaHandler
- collections.abc
- config.ConfigDict
- config.JsonDict
- config.JsonEncoder
- contextlib.contextmanager
- copy.copy
- copy.deepcopy
- dataclasses
- dataclasses.is_pydantic_dataclass
- enum.Enum
- errors.PydanticSchemaGenerationError
- errors.PydanticUndefinedAnnotation
- errors.PydanticUserError
- fields.AliasChoices
- fields.AliasPath
- fields.ComputedFieldInfo
- fields.FieldInfo
- functools.partial
- inspect
- inspect.Parameter
- inspect._ParameterKind
- inspect.signature
- itertools.chain
- itertools.islice
- json_schema.JsonSchemaValue
- main.BaseModel
- operator.attrgetter
- pydantic.BaseModel
- pydantic_core.CoreSchema
- pydantic_core.PydanticUndefined
- pydantic_core.core_schema
- pydantic_core.to_jsonable_python
- re
- sys
- types.Discriminator
- types.FunctionType
- types.LambdaType
- types.MethodType
- typing
- typing.Any
- typing.Callable
- typing.Dict
- typing.ForwardRef
- typing.Iterable
- typing.Iterator
- typing.Mapping
- typing.TYPE_CHECKING
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- typing_extensions.Annotated
- typing_extensions.Final
- typing_extensions.Literal
- typing_extensions.TypeAliasType
- typing_extensions.TypedDict
- typing_extensions.get_args
- typing_extensions.get_origin
- typing_extensions.is_typeddict
- validators.FieldValidatorModes
- version.version_short
- warnings
- warnings.PydanticDeprecatedSince20
- warnings.warn

**Functions:**

### `def check_validator_fields_against_field_name(info: FieldDecoratorInfo, field: str) -> bool`

**Description:**
Check if field name is in validator fields.

Args:
info: The field info.
field: The field name to check.

Returns:
`True` if field name is in validator fields, `False` otherwise.

**Line:** 112

---

### `def check_decorator_fields_exist(decorators: Iterable[AnyFieldDecorator], fields: Iterable[str]) -> None`

**Description:**
Check if the defined fields in decorators exist in `fields` param.

It ignores the check for a decorator if the decorator has `*` as field or `check_fields=False`.

Args:
decorators: An iterable of decorators.
fields: An iterable of fields name.

Raises:
PydanticUserError: If one of the field names does not exist in `fields` param.

**Line:** 134

---

### `def filter_field_decorator_info_by_field(validator_functions: Iterable[Decorator[FieldDecoratorInfoType]], field: str) -> list[Decorator[FieldDecoratorInfoType]]`

**Line:** 161

---

### `def apply_each_item_validators(schema: core_schema.CoreSchema, each_item_validators: list[Decorator[ValidatorDecoratorInfo]], field_name: str | None) -> core_schema.CoreSchema`

**Line:** 167

---

### `def modify_model_json_schema(schema_or_field: CoreSchemaOrField, handler: GetJsonSchemaHandler, cls: Any) -> JsonSchemaValue`

**Description:**
Add title and description for model-like classes' JSON schema.

Args:
schema_or_field: The schema data to generate a JSON schema from.
handler: The `GetCoreSchemaHandler` instance.
cls: The model-like class.

Returns:
JsonSchemaValue: The updated JSON schema.

**Line:** 199

---

### `def _add_custom_serialization_from_json_encoders(json_encoders: JsonEncoders | None, tp: Any, schema: CoreSchema) -> CoreSchema`

**Description:**
Iterate over the json_encoders and add the first matching encoder to the schema.

Args:
json_encoders: A dictionary of types and their encoder functions.
tp: The type to check for a matching encoder.
schema: The schema to add the encoder to.

**Line:** 230

---

### `def apply_validators(schema: core_schema.CoreSchema, validators: Iterable[Decorator[RootValidatorDecoratorInfo]] | Iterable[Decorator[ValidatorDecoratorInfo]] | Iterable[Decorator[FieldValidatorDecoratorInfo]], field_name: str | None) -> core_schema.CoreSchema`

**Description:**
Apply validators to a schema.

Args:
schema: The schema to apply validators on.
validators: An iterable of validators.
field_name: The name of the field if validators are being applied to a model field.

Returns:
The updated schema.

**Line:** 1866

---

### `def _validators_require_validate_default(validators: Iterable[Decorator[ValidatorDecoratorInfo]]) -> bool`

**Description:**
In v1, if any of the validators for a field had `always=True`, the default value would be validated.

This serves as an auxiliary function for re-implementing that logic, by looping over a provided
collection of (v1-style) ValidatorDecoratorInfo's and checking if any of them have `always=True`.

We should be able to drop this function and the associated logic calling it once we drop support
for v1-style validator decorators. (Or we can extend it and keep it if we add something equivalent
to the v1-validator `always` kwarg to `field_validator`.)

**Line:** 1891

---

### `def apply_model_validators(schema: core_schema.CoreSchema, validators: Iterable[Decorator[ModelValidatorDecoratorInfo]], mode: Literal[('inner', 'outer', 'all')]) -> core_schema.CoreSchema`

**Description:**
Apply model validators to a schema.

If mode == 'inner', only "before" validators are applied
If mode == 'outer', validators other than "before" are applied
If mode == 'all', all validators are applied

Args:
schema: The schema to apply validators on.
validators: An iterable of validators.
mode: The validator mode.

Returns:
The updated schema.

**Line:** 1907

---

### `def wrap_default(field_info: FieldInfo, schema: core_schema.CoreSchema) -> core_schema.CoreSchema`

**Description:**
Wrap schema with default schema if default value or `default_factory` are available.

Args:
field_info: The field info object.
schema: The schema to apply default on.

Returns:
Updated schema by default value or `default_factory`.

**Line:** 1954

---

### `def _extract_get_pydantic_json_schema(tp: Any, schema: CoreSchema) -> GetJsonSchemaFunction | None`

**Description:**
Extract `__get_pydantic_json_schema__` from a type, handling the deprecated `__modify_schema__`.

**Line:** 1976

---

### `def get_json_schema_update_func(json_schema_update: JsonSchemaValue, json_schema_extra: JsonDict | typing.Callable[[JsonDict], None] | None) -> GetJsonSchemaFunction`

**Line:** 2006

---

### `def add_json_schema_extra(json_schema: JsonSchemaValue, json_schema_extra: JsonDict | typing.Callable[[JsonDict], None] | None)`

**Line:** 2019

---

### `def _common_field(schema: core_schema.CoreSchema, validation_alias: str | list[str | int] | list[list[str | int]] | None = None, serialization_alias: str | None = None, serialization_exclude: bool | None = None, frozen: bool | None = None, metadata: Any = None) -> _CommonField`

**Line:** 2037

---

### `def resolve_original_schema(schema: CoreSchema, definitions: dict[(str, CoreSchema)]) -> CoreSchema | None`

**Line:** 2095

---

### `def generate_pydantic_signature(init: Callable[(..., None)], fields: dict[(str, FieldInfo)], config_wrapper: ConfigWrapper, post_process_parameter: Callable[([Parameter], Parameter)] = lambda x: x) -> inspect.Signature`

**Description:**
Generate signature for a pydantic class generated by inheriting from BaseModel or
using the dataclass annotation

Args:
init: The class init.
fields: The model fields.
config_wrapper: The config wrapper instance.
post_process_parameter: Optional additional processing for parameter

Returns:
The dataclass/BaseModel subclass signature.

**Line:** 2123

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._generics
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_generics.py`

**Imports:**
- __future__.annotations
- _core_utils.get_type_ref
- _forward_ref.PydanticRecursiveRef
- _typing_extra.TypeVarType
- _typing_extra.typing_base
- _utils.all_identical
- _utils.is_model_class
- collections.ChainMap
- contextlib.contextmanager
- contextvars.ContextVar
- main.BaseModel
- sys
- types
- types.prepare_class
- typing
- typing.Any
- typing.Iterator
- typing.List
- typing.Mapping
- typing.MutableMapping
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing._UnionGenericAlias
- typing_extensions
- weakref.WeakValueDictionary

**Functions:**

### `def create_generic_submodel(model_name: str, origin: type[BaseModel], args: tuple[(Any, ...)], params: tuple[(Any, ...)]) -> type[BaseModel]`

**Description:**
Dynamically create a submodel of a provided (generic) BaseModel.

This is used when producing concrete parametrizations of generic models. This function
only *creates* the new subclass; the schema/validators/serialization must be updated to
reflect a concrete parametrization elsewhere.

Args:
model_name: The name of the newly created model.
origin: The base class for the new model to inherit from.
args: A tuple of generic metadata arguments.
params: A tuple of generic metadata parameters.

Returns:
The created submodel.

**Line:** 120

---

### `def _get_caller_frame_info(depth: int = 2) -> tuple[(str | None, bool)]`

**Description:**
Used inside a function to check whether it was called globally.

Args:
depth: The depth to get the frame.

Returns:
A tuple contains `module_nam` and `called_globally`.

Raises:
RuntimeError: If the function is not called inside a function.

**Line:** 167

---

### `def iter_contained_typevars(v: Any) -> Iterator[TypeVarType]`

**Description:**
Recursively iterate through all subtypes and type args of `v` and yield any typevars that are found.

This is inspired as an alternative to directly accessing the `__parameters__` attribute of a GenericAlias,
since __parameters__ of (nested) generic BaseModel subclasses won't show up in that list.

**Line:** 192

---

### `def get_args(v: Any) -> Any`

**Line:** 211

---

### `def get_origin(v: Any) -> Any`

**Line:** 218

---

### `def get_standard_typevars_map(cls: type[Any]) -> dict[TypeVarType, Any] | None`

**Description:**
Package a generic type's typevars and parametrization (if present) into a dictionary compatible with the
`replace_types` function. Specifically, this works with standard typing generics and typing._GenericAlias.

**Line:** 225

---

### `def get_model_typevars_map(cls: type[BaseModel]) -> dict[TypeVarType, Any] | None`

**Description:**
Package a generic BaseModel's typevars and concrete parametrization (if present) into a dictionary compatible
with the `replace_types` function.

Since BaseModel.__class_getitem__ does not produce a typing._GenericAlias, and the BaseModel generic info is
stored in the __pydantic_generic_metadata__ attribute, we need special handling here.

**Line:** 242

---

### `def replace_types(type_: Any, type_map: Mapping[Any, Any] | None) -> Any`

**Description:**
Return type with all occurrences of `type_map` keys recursively replaced with their values.

Args:
type_: The class or generic alias.
type_map: Mapping from `TypeVar` instance to concrete types.

Returns:
A new type representing the basic structure of `type_` with all
`typevar_map` keys recursively replaced.

Example:
```py
from typing import List, Tuple, Union

from pydantic._internal._generics import replace_types

replace_types(Tuple[str, Union[List[str], float]], {str: int})
#> Tuple[int, Union[List[int], float]]
```

**Line:** 257

---

### `def has_instance_in_type(type_: Any, isinstance_target: Any) -> bool`

**Description:**
Checks if the type, or any of its arbitrary nested args, satisfy
`isinstance(<type>, isinstance_target)`.

**Line:** 342

---

### `def check_parameters_count(cls: type[BaseModel], parameters: tuple[(Any, ...)]) -> None`

**Description:**
Check the generic model parameters count is equal.

Args:
cls: The generic model.
parameters: A tuple of passed parameters to the generic model.

Raises:
TypeError: If the passed parameters count is not equal to generic model parameters count.

**Line:** 370

---

### `def generic_recursion_self_type(origin: type[BaseModel], args: tuple[(Any, ...)]) -> Iterator[PydanticRecursiveRef | None]`

**Decorators:**
- `@contextmanager`

**Description:**
This contextmanager should be placed around the recursive calls used to build a generic type,
and accept as arguments the generic origin type and the type arguments being passed to it.

If the same origin and arguments are observed twice, it implies that a self-reference placeholder
can be used while building the core schema, and will produce a schema_ref that will be valid in the
final parent schema.

**Line:** 391

---

### `def recursively_defined_type_refs() -> set[str]`

**Line:** 421

---

### `def get_cached_generic_type_early(parent: type[BaseModel], typevar_values: Any) -> type[BaseModel] | None`

**Description:**
The use of a two-stage cache lookup approach was necessary to have the highest performance possible for
repeated calls to `__class_getitem__` on generic types (which may happen in tighter loops during runtime),
while still ensuring that certain alternative parametrizations ultimately resolve to the same type.

As a concrete example, this approach was necessary to make Model[List[T]][int] equal to Model[List[int]].
The approach could be modified to not use two different cache keys at different points, but the
_early_cache_key is optimized to be as quick to compute as possible (for repeated-access speed), and the
_late_cache_key is optimized to be as "correct" as possible, so that two types that will ultimately be the
same after resolving the type arguments will always produce cache hits.

If we wanted to move to only using a single cache key per type, we would either need to always use the
slower/more computationally intensive logic associated with _late_cache_key, or would need to accept
that Model[List[T]][int] is a different type than Model[List[T]][int]. Because we rely on subclass relationships
during validation, I think it is worthwhile to ensure that types that are functionally equivalent are actually
equal.

**Line:** 429

---

### `def get_cached_generic_type_late(parent: type[BaseModel], typevar_values: Any, origin: type[BaseModel], args: tuple[(Any, ...)]) -> type[BaseModel] | None`

**Description:**
See the docstring of `get_cached_generic_type_early` for more information about the two-stage cache lookup.

**Line:** 449

---

### `def set_cached_generic_type(parent: type[BaseModel], typevar_values: tuple[(Any, ...)], type_: type[BaseModel], origin: type[BaseModel] | None = None, args: tuple[Any, ...] | None = None) -> None`

**Description:**
See the docstring of `get_cached_generic_type_early` for more information about why items are cached with
two different keys.

**Line:** 459

---

### `def _union_orderings_key(typevar_values: Any) -> Any`

**Description:**
This is intended to help differentiate between Union types with the same arguments in different order.

Thanks to caching internal to the `typing` module, it is not possible to distinguish between
List[Union[int, float]] and List[Union[float, int]] (and similarly for other "parent" origins besides List)
because `typing` considers Union[int, float] to be equal to Union[float, int].

However, you _can_ distinguish between (top-level) Union[int, float] vs. Union[float, int].
Because we parse items as the first Union type that is successful, we get slightly more consistent behavior
if we make an effort to distinguish the ordering of items in a union. It would be best if we could _always_
get the exact-correct order of items in the union, but that would require a change to the `typing` module itself.
(See https://github.com/python/cpython/issues/86483 for reference.)

**Line:** 476

---

### `def _early_cache_key(cls: type[BaseModel], typevar_values: Any) -> GenericTypesCacheKey`

**Description:**
This is intended for minimal computational overhead during lookups of cached types.

Note that this is overly simplistic, and it's possible that two different cls/typevar_values
inputs would ultimately result in the same type being created in BaseModel.__class_getitem__.
To handle this, we have a fallback _late_cache_key that is checked later if the _early_cache_key
lookup fails, and should result in a cache hit _precisely_ when the inputs to __class_getitem__
would result in the same type.

**Line:** 500

---

### `def _late_cache_key(origin: type[BaseModel], args: tuple[(Any, ...)], typevar_values: Any) -> GenericTypesCacheKey`

**Description:**
This is intended for use later in the process of creating a new type, when we have more information
about the exact args that will be passed. If it turns out that a different set of inputs to
__class_getitem__ resulted in the same inputs to the generic type creation process, we can still
return the cached type, and update the cache with the _early_cache_key as well.

**Line:** 512

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._known_annotated_metadata
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_known_annotated_metadata.py`

**Imports:**
- __future__.annotations
- _fields.PydanticMetadata
- annotated_handlers.GetJsonSchemaHandler
- annotated_types
- collections.defaultdict
- copy.copy
- functools.partial
- pydantic.fields.FieldInfo
- pydantic_core.CoreSchema
- pydantic_core.PydanticCustomError
- pydantic_core.core_schema
- pydantic_core.to_jsonable_python
- typing.Any
- typing.Callable
- typing.Iterable
- typing.TYPE_CHECKING

**Functions:**

### `def add_js_update_schema(s: cs.CoreSchema, f: Callable[([], dict[str, Any])]) -> None`

**Line:** 94

---

### `def as_jsonable_value(v: Any) -> Any`

**Line:** 110

---

### `def expand_grouped_metadata(annotations: Iterable[Any]) -> Iterable[Any]`

**Description:**
Expand the annotations.

Args:
annotations: An iterable of annotations.

Returns:
An iterable of expanded annotations.

Example:
```py
from annotated_types import Ge, Len

from pydantic._internal._known_annotated_metadata import expand_grouped_metadata

print(list(expand_grouped_metadata([Ge(4), Len(5)])))
#> [Ge(ge=4), MinLen(min_length=5)]
```

**Line:** 116

---

### `def apply_known_metadata(annotation: Any, schema: CoreSchema) -> CoreSchema | None`

**Description:**
Apply `annotation` to `schema` if it is an annotation we know about (Gt, Le, etc.).
Otherwise return `None`.

This does not handle all known annotations. If / when it does, it can always
return a CoreSchema and return the unmodified schema if the annotation should be ignored.

Assumes that GroupedMetadata has already been expanded via `expand_grouped_metadata`.

Args:
annotation: The annotation.
schema: The schema.

Returns:
An updated schema with annotation if it is an annotation we know about, `None` otherwise.

Raises:
PydanticCustomError: If `Predicate` fails.

**Line:** 156

---

### `def collect_known_metadata(annotations: Iterable[Any]) -> tuple[(dict[str, Any], list[Any])]`

**Description:**
Split `annotations` into known metadata and unknown annotations.

Args:
annotations: An iterable of annotations.

Returns:
A tuple contains a dict of known metadata and a list of unknown annotations.

Example:
```py
from annotated_types import Gt, Len

from pydantic._internal._known_annotated_metadata import collect_known_metadata

print(collect_known_metadata([Gt(1), Len(42), ...]))
#> ({'gt': 1, 'min_length': 42}, [Ellipsis])
```

**Line:** 337

---

### `def check_metadata(metadata: dict[(str, Any)], allowed: Iterable[str], source_type: Any) -> None`

**Description:**
A small utility function to validate that the given metadata can be applied to the target.
More than saving lines of code, this gives us a consistent error message for all of our internal implementations.

Args:
metadata: A dict of metadata.
allowed: An iterable of allowed metadata.
source_type: The source type.

Raises:
TypeError: If there is metadatas that can't be applied on source type.

**Line:** 394

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._mock_val_ser
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_mock_val_ser.py`

**Imports:**
- __future__.annotations
- dataclasses.PydanticDataclass
- dataclasses.rebuild_dataclass
- errors.PydanticErrorCodes
- errors.PydanticUserError
- main.BaseModel
- pydantic_core.SchemaSerializer
- pydantic_core.SchemaValidator
- typing.Callable
- typing.Generic
- typing.TYPE_CHECKING
- typing.TypeVar
- typing_extensions.Literal

**Functions:**

### `def set_model_mocks(cls: type[BaseModel], cls_name: str, undefined_name: str = 'all referenced types') -> None`

**Description:**
Set `__pydantic_validator__` and `__pydantic_serializer__` to `MockValSer`s on a model.

Args:
cls: The model class to set the mocks on
cls_name: Name of the model class, used in error messages
undefined_name: Name of the undefined thing, used in error messages

**Line:** 59

---

### `def set_dataclass_mocks(cls: type[PydanticDataclass], cls_name: str, undefined_name: str = 'all referenced types') -> None`

**Description:**
Set `__pydantic_validator__` and `__pydantic_serializer__` to `MockValSer`s on a dataclass.

Args:
cls: The model class to set the mocks on
cls_name: Name of the model class, used in error messages
undefined_name: Name of the undefined thing, used in error messages

**Line:** 99

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._model_construction
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py`

**Imports:**
- __future__.annotations
- _config.ConfigWrapper
- _decorators.DecoratorInfos
- _decorators.PydanticDescriptorProxy
- _decorators.get_attribute_from_bases
- _fields.collect_model_fields
- _fields.is_valid_field_name
- _fields.is_valid_privateattr_name
- _generate_schema.GenerateSchema
- _generate_schema.generate_pydantic_signature
- _generics.PydanticGenericMetadata
- _generics.get_model_typevars_map
- _mock_val_ser.MockValSer
- _mock_val_ser.set_model_mocks
- _schema_generation_shared.CallbackGetCoreSchemaHandler
- _typing_extra.get_cls_types_namespace
- _typing_extra.is_annotated
- _typing_extra.is_classvar
- _typing_extra.parent_frame_namespace
- _utils.ClassAttribute
- _validate_call.ValidateCallWrapper
- abc.ABCMeta
- errors.PydanticUndefinedAnnotation
- errors.PydanticUserError
- fields.ComputedFieldInfo
- fields.Field
- fields.FieldInfo
- fields.ModelPrivateAttr
- fields.PrivateAttr
- functools.partial
- inspect.Signature
- main.BaseModel
- plugin._schema_validator.create_schema_validator
- pydantic_core.PydanticUndefined
- pydantic_core.SchemaSerializer
- types.FunctionType
- typing
- typing.Any
- typing.Callable
- typing.Generic
- typing.Mapping
- typing_extensions
- typing_extensions.dataclass_transform
- typing_extensions.deprecated
- warnings
- warnings.GenericBeforeBaseModelWarning
- warnings.PydanticDeprecatedSince20
- weakref

**Functions:**

### `def init_private_attributes(self: BaseModel, __context: Any) -> None`

**Description:**
This function is meant to behave like a BaseModel method to initialise private attributes.

It takes context as an argument since that's what pydantic-core passes when calling it.

Args:
self: The BaseModel instance.
__context: The context.

**Line:** 252

---

### `def get_model_post_init(namespace: dict[(str, Any)], bases: tuple[(type[Any], ...)]) -> Callable[..., Any] | None`

**Description:**
Get the `model_post_init` method from the namespace or the class bases, or `None` if not defined.

**Line:** 270

---

### `def inspect_namespace(namespace: dict[(str, Any)], ignored_types: tuple[(type[Any], ...)], base_class_vars: set[str], base_class_fields: set[str]) -> dict[(str, ModelPrivateAttr)]`

**Description:**
Iterate over the namespace and:
* gather private attributes
* check for items which look like fields but are not (e.g. have no annotation) and warn.

Args:
namespace: The attribute dictionary of the class to be created.
ignored_types: A tuple of ignore types.
base_class_vars: A set of base class class variables.
base_class_fields: A set of base class fields.

Returns:
A dict contains private attributes info.

Raises:
TypeError: If there is a `__root__` field in model.
NameError: If private attribute name is invalid.
PydanticUserError:
- If a field does not have a type annotation.
- If a field on base class was overridden by a non-annotated attribute.

**Line:** 282

---

### `def set_default_hash_func(namespace: dict[(str, Any)], bases: tuple[(type[Any], ...)]) -> None`

**Line:** 399

---

### `def set_model_fields(cls: type[BaseModel], bases: tuple[(type[Any], ...)], config_wrapper: ConfigWrapper, types_namespace: dict[(str, Any)]) -> None`

**Description:**
Collect and set `cls.model_fields` and `cls.__class_vars__`.

Args:
cls: BaseModel or dataclass.
bases: Parents of the class, generally `cls.__bases__`.
config_wrapper: The config wrapper instance.
types_namespace: Optional extra namespace to look for types in.

**Line:** 414

---

### `def complete_model_class(cls: type[BaseModel], cls_name: str, config_wrapper: ConfigWrapper, raise_errors: bool = True, types_namespace: dict[str, Any] | None, create_model_module: str | None = None) -> bool`

**Description:**
Finish building a model class.

This logic must be called after class has been created since validation functions must be bound
and `get_type_hints` requires a class object.

Args:
cls: BaseModel or dataclass.
cls_name: The model or dataclass name.
config_wrapper: The config wrapper instance.
raise_errors: Whether to raise errors.
types_namespace: Optional extra namespace to look for types in.
create_model_module: The module of the class to be created, if created by `create_model`.

Returns:
`True` if the model is successfully completed, else `False`.

Raises:
PydanticUndefinedAnnotation: If `PydanticUndefinedAnnotation` occurs in`__get_pydantic_core_schema__`
and `raise_errors=True`.

**Line:** 444

---

### `def generate_model_signature(init: Callable[(..., None)], fields: dict[(str, FieldInfo)], config_wrapper: ConfigWrapper) -> Signature`

**Description:**
Generate signature for model based on its fields.

Args:
init: The class init.
fields: The model fields.
config_wrapper: The config wrapper instance.

Returns:
The model signature.

**Line:** 528

---

### `def build_lenient_weakvaluedict(d: dict[str, Any] | None) -> dict[str, Any] | None`

**Description:**
Takes an input dictionary, and produces a new value that (invertibly) replaces the values with weakrefs.

We can't just use a WeakValueDictionary because many types (including int, str, etc.) can't be stored as values
in a WeakValueDictionary.

The `unpack_lenient_weakvaluedict` function can be used to reverse this operation.

**Line:** 579

---

### `def unpack_lenient_weakvaluedict(d: dict[str, Any] | None) -> dict[str, Any] | None`

**Description:**
Inverts the transform performed by `build_lenient_weakvaluedict`.

**Line:** 599

---

### `def default_ignored_types() -> tuple[(type[Any], ...)]`

**Line:** 615

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._repr
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_repr.py`

**Imports:**
- __future__.annotations
- types
- typing
- typing.Any
- typing_extensions

**Functions:**

### `def display_as_type(obj: Any) -> str`

**Description:**
Pretty representation of a type, should be as close as possible to the original type definition string.

Takes some logic from `typing._type_repr`.

**Line:** 85

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._std_types_schema
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_std_types_schema.py`

**Imports:**
- __future__.annotations
- _core_utils.get_type_ref
- _generate_schema.GenerateSchema
- _internal_dataclass.slots_true
- _schema_generation_shared.GetCoreSchemaHandler
- _schema_generation_shared.GetJsonSchemaHandler
- collections
- collections.abc
- config.ConfigDict
- dataclasses
- datetime
- decimal
- enum.Enum
- functools.partial
- inspect
- ipaddress.IPv4Address
- ipaddress.IPv4Interface
- ipaddress.IPv4Network
- ipaddress.IPv6Address
- ipaddress.IPv6Interface
- ipaddress.IPv6Network
- json_schema.JsonSchemaValue
- json_schema.update_json_schema
- os
- pathlib
- pydantic.errors.PydanticSchemaGenerationError
- pydantic.fields.FieldInfo
- pydantic.types.Strict
- pydantic_core.CoreSchema
- pydantic_core.MultiHostUrl
- pydantic_core.PydanticCustomError
- pydantic_core.PydanticOmit
- pydantic_core.Url
- pydantic_core.core_schema
- typing
- typing.Any
- typing.Callable
- typing.Iterable
- typing.TypeVar
- typing_extensions
- typing_extensions.get_args
- typing_extensions.get_origin
- uuid.UUID

**Functions:**

### `def get_enum_core_schema(enum_type: type[Enum], config: ConfigDict) -> CoreSchema`

**Line:** 59

---

### `def decimal_prepare_pydantic_annotations(source: Any, annotations: Iterable[Any], config: ConfigDict) -> tuple[Any, list[Any]] | None`

**Line:** 161

---

### `def datetime_prepare_pydantic_annotations(source_type: Any, annotations: Iterable[Any], _config: ConfigDict) -> tuple[Any, list[Any]] | None`

**Line:** 179

---

### `def uuid_prepare_pydantic_annotations(source_type: Any, annotations: Iterable[Any], _config: ConfigDict) -> tuple[Any, list[Any]] | None`

**Line:** 200

---

### `def path_schema_prepare_pydantic_annotations(source_type: Any, annotations: Iterable[Any], _config: ConfigDict) -> tuple[Any, list[Any]] | None`

**Line:** 213

---

### `def dequeue_validator(input_value: Any, handler: core_schema.ValidatorFunctionWrapHandler, maxlen: None | int) -> collections.deque[Any]`

**Line:** 275

---

### `def identity(s: CoreSchema) -> CoreSchema`

**Line:** 388

---

### `def sequence_like_prepare_pydantic_annotations(source_type: Any, annotations: Iterable[Any], _config: ConfigDict) -> tuple[Any, list[Any]] | None`

**Line:** 392

---

### `def defaultdict_validator(input_value: Any, handler: core_schema.ValidatorFunctionWrapHandler, default_default_factory: Callable[([], Any)]) -> collections.defaultdict[(Any, Any)]`

**Line:** 434

---

### `def get_defaultdict_default_default_factory(values_source_type: Any) -> Callable[([], Any)]`

**Line:** 444

---

### `def mapping_like_prepare_pydantic_annotations(source_type: Any, annotations: Iterable[Any], _config: ConfigDict) -> tuple[Any, list[Any]] | None`

**Line:** 563

---

### `def ip_prepare_pydantic_annotations(source_type: Any, annotations: Iterable[Any], _config: ConfigDict) -> tuple[Any, list[Any]] | None`

**Line:** 598

---

### `def url_prepare_pydantic_annotations(source_type: Any, annotations: Iterable[Any], _config: ConfigDict) -> tuple[Any, list[Any]] | None`

**Line:** 684

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._typing_extra
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py`

**Imports:**
- __future__.annotations
- _dataclasses.StandardDataclass
- _utils.lenient_issubclass
- collections.abc.Callable
- dataclasses
- functools.partial
- sys
- types
- types.GetSetDescriptorType
- types.NoneType
- typing
- typing.Any
- typing.ForwardRef
- typing.GenericAlias
- typing.NotRequired
- typing.Required
- typing.TYPE_CHECKING
- typing._Final
- typing._TypingBase
- typing_extensions.Annotated
- typing_extensions.Final
- typing_extensions.Literal
- typing_extensions.NotRequired
- typing_extensions.Required
- typing_extensions.TypeAliasType
- typing_extensions.TypeGuard
- typing_extensions.get_args
- typing_extensions.get_origin

**Functions:**

### `def origin_is_union(tp: type[Any] | None) -> bool`

**Line:** 41

---

### `def origin_is_union(tp: type[Any] | None) -> bool`

**Line:** 48

---

### `def is_none_type(type_: Any) -> bool`

**Line:** 71

---

### `def is_callable_type(type_: type[Any]) -> bool`

**Line:** 75

---

### `def is_literal_type(type_: type[Any]) -> bool`

**Line:** 79

---

### `def literal_values(type_: type[Any]) -> tuple[(Any, ...)]`

**Line:** 83

---

### `def all_literal_values(type_: type[Any]) -> list[Any]`

**Description:**
This method is used to retrieve all Literal values as
Literal can be used recursively (see https://www.python.org/dev/peps/pep-0586)
e.g. `Literal[Literal[Literal[1, 2, 3], "foo"], 5, None]`.

**Line:** 87

---

### `def is_annotated(ann_type: Any) -> bool`

**Line:** 99

---

### `def is_namedtuple(type_: type[Any]) -> bool`

**Description:**
Check if a given class is a named tuple.
It can be either a `typing.NamedTuple` or `collections.namedtuple`.

**Line:** 106

---

### `def is_new_type(type_: type[Any]) -> bool`

**Description:**
Check whether type_ was created using typing.NewType.

Can't use isinstance because it fails <3.10.

**Line:** 118

---

### `def _check_classvar(v: type[Any] | None) -> bool`

**Line:** 126

---

### `def is_classvar(ann_type: type[Any]) -> bool`

**Line:** 133

---

### `def _check_finalvar(v: type[Any] | None) -> bool`

**Description:**
Check if a given type is a `typing.Final` type.

**Line:** 145

---

### `def is_finalvar(ann_type: Any) -> bool`

**Line:** 153

---

### `def parent_frame_namespace(parent_depth: int = 2) -> dict[str, Any] | None`

**Description:**
We allow use of items in parent namespace to get around the issue with `get_type_hints` only looking in the
global module namespace. See https://github.com/pydantic/pydantic/issues/2678#issuecomment-1008139014 -> Scope
and suggestion at the end of the next comment by @gvanrossum.

WARNING 1: it matters exactly where this is called. By default, this function will build a namespace from the
parent of where it is called.

WARNING 2: this only looks in the parent namespace, not other parents since (AFAIK) there's no way to collect a
dict of exactly what's in scope. Using `f_back` would work sometimes but would be very wrong and confusing in many
other cases. See https://discuss.python.org/t/is-there-a-way-to-access-parent-nested-namespaces/20659.

**Line:** 157

---

### `def add_module_globals(obj: Any, globalns: dict[str, Any] | None = None) -> dict[(str, Any)]`

**Line:** 177

---

### `def get_cls_types_namespace(cls: type[Any], parent_namespace: dict[str, Any] | None = None) -> dict[(str, Any)]`

**Line:** 195

---

### `def get_cls_type_hints_lenient(obj: Any, globalns: dict[str, Any] | None = None) -> dict[(str, Any)]`

**Description:**
Collect annotations from a class, including those from parent classes.

Unlike `typing.get_type_hints`, this function will not error if a forward reference is not resolvable.

**Line:** 201

---

### `def eval_type_lenient(value: Any, globalns: dict[str, Any] | None, localns: dict[str, Any] | None) -> Any`

**Description:**
Behaves like typing._eval_type, except it won't raise an error if a forward reference can't be resolved.

**Line:** 216

---

### `def get_function_type_hints(function: Callable[(..., Any)], include_keys: set[str] | None = None, types_namespace: dict[str, Any] | None = None) -> dict[(str, Any)]`

**Description:**
Like `typing.get_type_hints`, but doesn't convert `X` to `Optional[X]` if the default value is `None`, also
copes with `partial`.

**Line:** 230

---

### `def _make_forward_ref(arg: Any, is_argument: bool = True, is_class: bool = False) -> typing.ForwardRef`

**Description:**
Wrapper for ForwardRef that accounts for the `is_class` argument missing in older versions.
The `module` argument is omitted as it breaks <3.9.8, =3.10.0 and isn't used in the calls below.

See https://github.com/python/cpython/pull/28560 for some background.
The backport happened on 3.9.8, see:
https://github.com/pydantic/pydantic/discussions/6244#discussioncomment-6275458,
and on 3.10.1 for the 3.10 branch, see:
https://github.com/pydantic/pydantic/issues/6912

Implemented as EAFP with memory.

**Line:** 258

---

### `def get_type_hints(obj: Any, globalns: dict[str, Any] | None = None, localns: dict[str, Any] | None = None, include_extras: bool = False) -> dict[(str, Any)]`

**Decorators:**
- `@typing.no_type_check`

**Description:**
Taken verbatim from python 3.10.8 unchanged, except:
* type annotations of the function definition above.
* prefixing `typing.` where appropriate
* Use `_make_forward_ref` instead of `typing.ForwardRef` to handle the `is_class` argument.

https://github.com/python/cpython/blob/aaaf5174241496afca7ce4d4584570190ff972fe/Lib/typing.py#L1773-L1875

DO NOT CHANGE THIS METHOD UNLESS ABSOLUTELY NECESSARY.
======================================================

Return type hints for an object.

This is often the same as obj.__annotations__, but it handles
forward references encoded as string literals, adds Optional[t] if a
default value equal to None is set and recursively replaces all
'Annotated[T, ...]' with 'T' (unless 'include_extras=True').

The argument may be a module, class, method, or function. The annotations
are returned as a dictionary. For classes, annotations include also
inherited members.

TypeError is raised if the argument is not of a type that can contain
annotations, and an empty dictionary is returned if no annotations are
present.

BEWARE -- the behavior of globalns and localns is counterintuitive
(unless you are familiar with how eval() and exec() work).  The
search order is locals first, then globals.

- If no dict arguments are passed, an attempt is made to use the
globals from obj (or the respective module's globals for classes),
and these are also used as the locals.  If the object does not appear
to have globals, an empty dictionary is used.  For classes, the search
order is globals first then locals.

- If one dict argument is passed, it is used for both globals and
locals.

- If two dict arguments are passed, they specify globals and
locals, respectively.

**Line:** 291

---

### `def evaluate_fwd_ref(ref: ForwardRef, globalns: dict[str, Any] | None = None, localns: dict[str, Any] | None = None) -> Any`

**Line:** 415

---

### `def evaluate_fwd_ref(ref: ForwardRef, globalns: dict[str, Any] | None = None, localns: dict[str, Any] | None = None) -> Any`

**Line:** 422

---

### `def is_dataclass(_cls: type[Any]) -> TypeGuard[type[StandardDataclass]]`

**Line:** 428

---

### `def origin_is_type_alias_type(origin: Any) -> TypeGuard[TypeAliasType]`

**Line:** 434

---

### `def is_generic_alias(type_: type[Any]) -> bool`

**Line:** 440

---

### `def is_generic_alias(type_: type[Any]) -> bool`

**Line:** 445

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._utils
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_utils.py`

**Imports:**
- __future__.annotations
- collections.OrderedDict
- collections.defaultdict
- collections.deque
- copy.deepcopy
- itertools.zip_longest
- keyword
- main.BaseModel
- types.BuiltinFunctionType
- types.CodeType
- types.FunctionType
- types.GeneratorType
- types.LambdaType
- types.ModuleType
- typing
- typing.Any
- typing.TypeVar
- typing_extensions.TypeAlias
- typing_extensions.TypeGuard
- weakref

**Functions:**

### `def sequence_like(v: Any) -> bool`

**Line:** 62

---

### `def lenient_isinstance(o: Any, class_or_tuple: type[Any] | tuple[type[Any], ...] | None) -> bool`

**Line:** 66

---

### `def lenient_issubclass(cls: Any, class_or_tuple: Any) -> bool`

**Line:** 73

---

### `def is_model_class(cls: Any) -> TypeGuard[type[BaseModel]]`

**Description:**
Returns true if cls is a _proper_ subclass of BaseModel, and provides proper type-checking,
unlike raw calls to lenient_issubclass.

**Line:** 82

---

### `def is_valid_identifier(identifier: str) -> bool`

**Description:**
Checks that a string is a valid identifier and not a Python keyword.
:param identifier: The identifier to test.
:return: True if the identifier is valid.

**Line:** 91

---

### `def deep_update(mapping: dict[(KeyType, Any)], *updating_mappings: dict[(KeyType, Any)]) -> dict[(KeyType, Any)]`

**Line:** 102

---

### `def update_not_none(mapping: dict[(Any, Any)], **update: Any) -> None`

**Line:** 113

---

### `def unique_list(input_list: list[T] | tuple[T, ...], name_factory: typing.Callable[([T], str)] = str) -> list[T]`

**Description:**
Make a list unique while maintaining order.
We update the list if another one with the same name is set
(e.g. model validator overridden in subclass).

**Line:** 120

---

### `def ClassAttribute(name: str, value: T) -> T`

**Line:** 278

---

### `def smart_deepcopy(obj: Obj) -> Obj`

**Description:**
Return type as is for immutable built-in types
Use obj.copy() for built-in empty collections
Use copy.deepcopy() for non-empty collections and unknown objects.

**Line:** 301

---

### `def all_identical(left: typing.Iterable[Any], right: typing.Iterable[Any]) -> bool`

**Description:**
Check that the items of `left` are the same objects as those in `right`.

>>> a, b = object(), object()
>>> all_identical([a, b, a], [a, b, a])
True
>>> all_identical([a, b, [a]], [a, b, [a]])  # new list object, while "equal" is not "identical"
False

**Line:** 323

---


## Module: venv2.libthon3.12.site-packagesdantic._internal._validators
**File:** `venv2/lib/python3.12/site-packages/pydantic/_internal/_validators.py`

**Imports:**
- __future__.annotations
- importlib.import_module
- ipaddress.IPv4Address
- ipaddress.IPv4Interface
- ipaddress.IPv4Network
- ipaddress.IPv6Address
- ipaddress.IPv6Interface
- ipaddress.IPv6Network
- math
- pydantic_core.PydanticCustomError
- pydantic_core._pydantic_core.PydanticKnownError
- pydantic_core.core_schema
- re
- typing
- typing.Any

**Functions:**

### `def sequence_validator(__input_value: typing.Sequence[Any], validator: core_schema.ValidatorFunctionWrapHandler) -> typing.Sequence[Any]`

**Description:**
Validator for `Sequence` types, isinstance(v, Sequence) has already been called.

**Line:** 18

---

### `def import_string(value: Any) -> Any`

**Line:** 47

---

### `def _import_string_logic(dotted_path: str) -> Any`

**Description:**
Inspired by uvicorn  dotted paths should include a colon before the final item if that item is not a module.
(This is necessary to distinguish between a submodule and an attribute when there is a conflict.).

If the dotted path does not include a colon and the final item is not a valid module, importing as an attribute
rather than a submodule will be attempted automatically.

So, for example, the following values of `dotted_path` result in the following returned values:
* 'collections': <module 'collections'>
* 'collections.abc': <module 'collections.abc'>
* 'collections.abc:Mapping': <class 'collections.abc.Mapping'>
* `collections.abc.Mapping`: <class 'collections.abc.Mapping'> (though this is a bit slower than the previous line)

An error will be raised under any of the following scenarios:
* `dotted_path` contains more than one colon (e.g., 'collections:abc:Mapping')
* the substring of `dotted_path` before the colon is not a valid module in the environment (e.g., '123:Mapping')
* the substring of `dotted_path` after the colon is not an attribute of the module (e.g., 'collections:abc123')

**Line:** 58

---

### `def pattern_either_validator(__input_value: Any) -> typing.Pattern[Any]`

**Line:** 109

---

### `def pattern_str_validator(__input_value: Any) -> typing.Pattern[str]`

**Line:** 119

---

### `def pattern_bytes_validator(__input_value: Any) -> typing.Pattern[bytes]`

**Line:** 133

---

### `def compile_pattern(pattern: PatternType) -> typing.Pattern[PatternType]`

**Line:** 150

---

### `def ip_v4_address_validator(__input_value: Any) -> IPv4Address`

**Line:** 157

---

### `def ip_v6_address_validator(__input_value: Any) -> IPv6Address`

**Line:** 167

---

### `def ip_v4_network_validator(__input_value: Any) -> IPv4Network`

**Description:**
Assume IPv4Network initialised with a default `strict` argument.

See more:
https://docs.python.org/library/ipaddress.html#ipaddress.IPv4Network

**Line:** 177

---

### `def ip_v6_network_validator(__input_value: Any) -> IPv6Network`

**Description:**
Assume IPv6Network initialised with a default `strict` argument.

See more:
https://docs.python.org/library/ipaddress.html#ipaddress.IPv6Network

**Line:** 192

---

### `def ip_v4_interface_validator(__input_value: Any) -> IPv4Interface`

**Line:** 207

---

### `def ip_v6_interface_validator(__input_value: Any) -> IPv6Interface`

**Line:** 217

---

### `def greater_than_validator(x: Any, gt: Any) -> Any`

**Line:** 227

---

### `def greater_than_or_equal_validator(x: Any, ge: Any) -> Any`

**Line:** 233

---

### `def less_than_validator(x: Any, lt: Any) -> Any`

**Line:** 239

---

### `def less_than_or_equal_validator(x: Any, le: Any) -> Any`

**Line:** 245

---

### `def multiple_of_validator(x: Any, multiple_of: Any) -> Any`

**Line:** 251

---

### `def min_length_validator(x: Any, min_length: Any) -> Any`

**Line:** 257

---

### `def max_length_validator(x: Any, max_length: Any) -> Any`

**Line:** 266

---

### `def forbid_inf_nan_check(x: Any) -> Any`

**Line:** 275

---


## Module: venv2.libthon3.12.site-packagesdantic._migration
**File:** `venv2/lib/python3.12/site-packages/pydantic/_migration.py`

**Imports:**
- _internal._validators.import_string
- errors.PydanticImportError
- sys
- typing.Any
- typing.Callable
- typing.Dict
- version.version_short
- warnings

**Functions:**

### `def getattr_migration(module: str) -> Callable[([str], Any)]`

**Description:**
Implement PEP 562 for objects that were either moved or removed on the migration
to V2.

Args:
module: The module name.

Returns:
A callable that will raise an error if the object is not found.

**Line:** 249

---


## Module: venv2.libthon3.12.site-packagesdantic.alias_generators
**File:** `venv2/lib/python3.12/site-packages/pydantic/alias_generators.py`

**Imports:**
- re

**Functions:**

### `def to_pascal(snake: str) -> str`

**Description:**
Convert a snake_case string to PascalCase.

Args:
snake: The string to convert.

Returns:
The PascalCase string.

**Line:** 7

---

### `def to_camel(snake: str) -> str`

**Description:**
Convert a snake_case string to camelCase.

Args:
snake: The string to convert.

Returns:
The converted camelCase string.

**Line:** 20

---

### `def to_snake(camel: str) -> str`

**Description:**
Convert a PascalCase or camelCase string to snake_case.

Args:
camel: The string to convert.

Returns:
The converted string in snake_case.

**Line:** 33

---


## Module: venv2.libthon3.12.site-packagesdantic.color
**File:** `venv2/lib/python3.12/site-packages/pydantic/color.py`

**Imports:**
- _internal._repr
- _internal._schema_generation_shared.GetJsonSchemaHandler
- colorsys.hls_to_rgb
- colorsys.rgb_to_hls
- json_schema.JsonSchemaValue
- math
- pydantic_core.CoreSchema
- pydantic_core.PydanticCustomError
- pydantic_core.core_schema
- re
- typing.Any
- typing.Callable
- typing.Optional
- typing.Tuple
- typing.Type
- typing.Union
- typing.cast
- typing_extensions.deprecated
- warnings.PydanticDeprecatedSince20

**Functions:**

### `def parse_tuple(value: Tuple[(Any, ...)]) -> RGBA`

**Description:**
Parse a tuple or list to get RGBA values.

Args:
value: A tuple or list.

Returns:
An `RGBA` tuple parsed from the input tuple.

Raises:
PydanticCustomError: If tuple is not valid.

**Line:** 257

---

### `def parse_str(value: str) -> RGBA`

**Description:**
Parse a string representing a color to an RGBA tuple.

Possible formats for the input string include:

* named color, see `COLORS_BY_NAME`
* hex short eg. `<prefix>fff` (prefix can be `#`, `0x` or nothing)
* hex long eg. `<prefix>ffffff` (prefix can be `#`, `0x` or nothing)
* `rgb(<r>, <g>, <b>)`
* `rgba(<r>, <g>, <b>, <a>)`

Args:
value: A string representing a color.

Returns:
An `RGBA` tuple parsed from the input string.

Raises:
ValueError: If the input string cannot be parsed to an RGBA tuple.

**Line:** 279

---

### `def ints_to_rgba(r: Union[(int, str)], g: Union[(int, str)], b: Union[(int, str)], alpha: Optional[float] = None) -> RGBA`

**Description:**
Converts integer or string values for RGB color and an optional alpha value to an `RGBA` object.

Args:
r: An integer or string representing the red color value.
g: An integer or string representing the green color value.
b: An integer or string representing the blue color value.
alpha: A float representing the alpha value. Defaults to None.

Returns:
An instance of the `RGBA` class with the corresponding color and alpha values.

**Line:** 338

---

### `def parse_color_value(value: Union[(int, str)], max_val: int = 255) -> float`

**Description:**
Parse the color value provided and return a number between 0 and 1.

Args:
value: An integer or string color value.
max_val: Maximum range value. Defaults to 255.

Raises:
PydanticCustomError: If the value is not a valid color.

Returns:
A number between 0 and 1.

**Line:** 353

---

### `def parse_float_alpha(value: Union[(None, str, float, int)]) -> Optional[float]`

**Description:**
Parse an alpha value checking it's a valid float in the range 0 to 1.

Args:
value: The input value to parse.

Returns:
The parsed value as a float, or `None` if the value was None or equal 1.

Raises:
PydanticCustomError: If the input value cannot be successfully parsed as a float in the expected range.

**Line:** 380

---

### `def parse_hsl(h: str, h_units: str, sat: str, light: str, alpha: Optional[float] = None) -> RGBA`

**Description:**
Parse raw hue, saturation, lightness, and alpha values and convert to RGBA.

Args:
h: The hue value.
h_units: The unit for hue value.
sat: The saturation value.
light: The lightness value.
alpha: Alpha value.

Returns:
An instance of `RGBA`.

**Line:** 410

---

### `def float_to_255(c: float) -> int`

**Description:**
Converts a float value between 0 and 1 (inclusive) to an integer between 0 and 255 (inclusive).

Args:
c: The float value to be converted. Must be between 0 and 1 (inclusive).

Returns:
The integer equivalent of the given float value rounded to the nearest whole number.

Raises:
ValueError: If the given float value is outside the acceptable range of 0 to 1 (inclusive).

**Line:** 438

---


## Module: venv2.libthon3.12.site-packagesdantic.dataclasses
**File:** `venv2/lib/python3.12/site-packages/pydantic/dataclasses.py`

**Imports:**
- __future__.annotations
- _internal._config
- _internal._dataclasses
- _internal._dataclasses.PydanticDataclass
- _internal._decorators
- _internal._typing_extra
- _migration.getattr_migration
- config.ConfigDict
- dataclasses
- fields.Field
- fields.FieldInfo
- sys
- types
- typing.Any
- typing.Callable
- typing.Generic
- typing.NoReturn
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.overload
- typing_extensions.Literal
- typing_extensions.TypeGuard
- typing_extensions.dataclass_transform

**Functions:**

### `def dataclass(init: Literal[False] = False, repr: bool = True, eq: bool = True, order: bool = False, unsafe_hash: bool = False, frozen: bool = False, config: ConfigDict | type[object] | None = None, validate_on_init: bool | None = None, kw_only: bool = Ellipsis, slots: bool = Ellipsis) -> Callable[([type[_T]], type[PydanticDataclass])]`

**Decorators:**
- `@dataclass_transform(...)`
- `@overload`

**Line:** 28

---

### `def dataclass(_cls: type[_T], init: Literal[False] = False, repr: bool = True, eq: bool = True, order: bool = False, unsafe_hash: bool = False, frozen: bool = False, config: ConfigDict | type[object] | None = None, validate_on_init: bool | None = None, kw_only: bool = Ellipsis, slots: bool = Ellipsis) -> type[PydanticDataclass]`

**Decorators:**
- `@dataclass_transform(...)`
- `@overload`

**Line:** 45

---

### `def dataclass(init: Literal[False] = False, repr: bool = True, eq: bool = True, order: bool = False, unsafe_hash: bool = False, frozen: bool = False, config: ConfigDict | type[object] | None = None, validate_on_init: bool | None = None) -> Callable[([type[_T]], type[PydanticDataclass])]`

**Decorators:**
- `@dataclass_transform(...)`
- `@overload`

**Line:** 65

---

### `def dataclass(_cls: type[_T], init: Literal[False] = False, repr: bool = True, eq: bool = True, order: bool = False, unsafe_hash: bool = False, frozen: bool = False, config: ConfigDict | type[object] | None = None, validate_on_init: bool | None = None) -> type[PydanticDataclass]`

**Decorators:**
- `@dataclass_transform(...)`
- `@overload`

**Line:** 80

---

### `def dataclass(_cls: type[_T] | None = None, init: Literal[False] = False, repr: bool = True, eq: bool = True, order: bool = False, unsafe_hash: bool = False, frozen: bool = False, config: ConfigDict | type[object] | None = None, validate_on_init: bool | None = None, kw_only: bool = False, slots: bool = False) -> Callable[[type[_T]], type[PydanticDataclass]] | type[PydanticDataclass]`

**Decorators:**
- `@dataclass_transform(...)`

**Description:**
Usage docs: https://docs.pydantic.dev/2.5/concepts/dataclasses/

A decorator used to create a Pydantic-enhanced dataclass, similar to the standard Python `dataclass`,
but with added validation.

This function should be used similarly to `dataclasses.dataclass`.

Args:
_cls: The target `dataclass`.
init: Included for signature compatibility with `dataclasses.dataclass`, and is passed through to
`dataclasses.dataclass` when appropriate. If specified, must be set to `False`, as pydantic inserts its
own  `__init__` function.
repr: A boolean indicating whether or not to include the field in the `__repr__` output.
eq: Determines if a `__eq__` should be generated for the class.
order: Determines if comparison magic methods should be generated, such as `__lt__`, but not `__eq__`.
unsafe_hash: Determines if an unsafe hashing function should be included in the class.
frozen: Determines if the generated class should be a 'frozen' `dataclass`, which does not allow its
attributes to be modified from its constructor.
config: A configuration for the `dataclass` generation.
validate_on_init: A deprecated parameter included for backwards compatibility; in V2, all Pydantic dataclasses
are validated on init.
kw_only: Determines if `__init__` method parameters must be specified by keyword only. Defaults to `False`.
slots: Determines if the generated class should be a 'slots' `dataclass`, which does not allow the addition of
new attributes after instantiation.

Returns:
A decorator that accepts a class as its argument and returns a Pydantic `dataclass`.

Raises:
AssertionError: Raised if `init` is not `False` or `validate_on_init` is `False`.

**Line:** 96

---

### `def _call_initvar(*args: Any, **kwargs: Any) -> NoReturn`

**Description:**
This function does nothing but raise an error that is as similar as possible to what you'd get
if you were to try calling `InitVar[int]()` without this monkeypatch. The whole purpose is just
to ensure typing._type_check does not error if the type hint evaluates to `InitVar[<parameter>]`.

**Line:** 244

---

### `def rebuild_dataclass(cls: type[PydanticDataclass], force: bool = False, raise_errors: bool = True, _parent_namespace_depth: int = 2, _types_namespace: dict[str, Any] | None = None) -> bool | None`

**Description:**
Try to rebuild the pydantic-core schema for the dataclass.

This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
the initial attempt to build the schema, and automatic rebuilding fails.

This is analogous to `BaseModel.model_rebuild`.

Args:
cls: The class to build the dataclass core schema for.
force: Whether to force the rebuilding of the model schema, defaults to `False`.
raise_errors: Whether to raise errors, defaults to `True`.
_parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
_types_namespace: The types namespace, defaults to `None`.

Returns:
Returns `None` if the schema is already "complete" and rebuilding was not required.
If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.

**Line:** 254

---

### `def is_pydantic_dataclass(__cls: type[Any]) -> TypeGuard[type[PydanticDataclass]]`

**Description:**
Whether a class is a pydantic dataclass.

Args:
__cls: The class.

Returns:
`True` if the class is a pydantic dataclass, `False` otherwise.

**Line:** 303

---


## Module: venv2.libthon3.12.site-packagesdantic.deprecated.class_validators
**File:** `venv2/lib/python3.12/site-packages/pydantic/deprecated/class_validators.py`

**Imports:**
- __future__.annotations
- _internal._decorators
- _internal._decorators_v1
- errors.PydanticUserError
- functools.partial
- functools.partialmethod
- types.FunctionType
- typing.Any
- typing.Callable
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.Union
- typing.overload
- typing_extensions.Literal
- typing_extensions.Protocol
- typing_extensions.TypeAlias
- warnings.PydanticDeprecatedSince20
- warnings.warn

**Functions:**

### `def validator(__field: str, pre: bool = False, each_item: bool = False, always: bool = False, check_fields: bool | None = None, allow_reuse: bool = False, *fields: str) -> Callable[([_V1ValidatorType], _V1ValidatorType)]`

**Description:**
Decorate methods on the class indicating that they should be used to validate fields.

Args:
__field (str): The first field the validator should be called on; this is separate
from `fields` to ensure an error is raised if you don't pass at least one.
*fields (str): Additional field(s) the validator should be called on.
pre (bool, optional): Whether or not this validator should be called before the standard
validators (else after). Defaults to False.
each_item (bool, optional): For complex objects (sets, lists etc.) whether to validate
individual elements rather than the whole object. Defaults to False.
always (bool, optional): Whether this method and other validators should be called even if
the value is missing. Defaults to False.
check_fields (bool | None, optional): Whether to check that the fields actually exist on the model.
Defaults to None.
allow_reuse (bool, optional): Whether to track and raise an error if another validator refers to
the decorated function. Defaults to False.

Returns:
Callable: A decorator that can be used to decorate a
function to be used as a validator.

**Line:** 82

---

### `def root_validator(skip_on_failure: Literal[True], allow_reuse: bool = Ellipsis) -> Callable[([_V1RootValidatorFunctionType], _V1RootValidatorFunctionType)]`

**Decorators:**
- `@overload`

**Line:** 159

---

### `def root_validator(pre: Literal[True], allow_reuse: bool = Ellipsis) -> Callable[([_V1RootValidatorFunctionType], _V1RootValidatorFunctionType)]`

**Decorators:**
- `@overload`

**Line:** 173

---

### `def root_validator(pre: Literal[False], skip_on_failure: Literal[True], allow_reuse: bool = Ellipsis) -> Callable[([_V1RootValidatorFunctionType], _V1RootValidatorFunctionType)]`

**Decorators:**
- `@overload`

**Line:** 187

---

### `def root_validator(pre: bool = False, skip_on_failure: bool = False, allow_reuse: bool = False, *__args) -> Any`

**Description:**
Decorate methods on a model indicating that they should be used to validate (and perhaps
modify) data either before or after standard model parsing/validation is performed.

Args:
pre (bool, optional): Whether this validator should be called before the standard
validators (else after). Defaults to False.
skip_on_failure (bool, optional): Whether to stop validation and return as soon as a
failure is encountered. Defaults to False.
allow_reuse (bool, optional): Whether to track and raise an error if another validator
refers to the decorated function. Defaults to False.

Returns:
Any: A decorator that can be used to decorate a function to be used as a root_validator.

**Line:** 201

---


## Module: venv2.libthon3.12.site-packagesdantic.deprecated.copy_internals
**File:** `venv2/lib/python3.12/site-packages/pydantic/deprecated/copy_internals.py`

**Imports:**
- __future__.annotations
- _internal._model_construction
- _internal._typing_extra
- _internal._utils
- _internal._utils.AbstractSetIntStr
- _internal._utils.MappingIntStrAny
- copy.deepcopy
- enum.Enum
- typing
- typing.Any
- typing.Tuple
- typing_extensions

**Functions:**

### `def _iter(self: BaseModel, to_dict: bool = False, by_alias: bool = False, include: AbstractSetIntStr | MappingIntStrAny | None = None, exclude: AbstractSetIntStr | MappingIntStrAny | None = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> TupleGenerator`

**Line:** 29

---

### `def _copy_and_set_values(self: Model, values: dict[(str, Any)], fields_set: set[str], extra: dict[str, Any] | None = None, private: dict[str, Any] | None = None, deep: bool) -> Model`

**Line:** 98

---

### `def _get_value(cls: type[BaseModel], v: Any, to_dict: bool, by_alias: bool, include: AbstractSetIntStr | MappingIntStrAny | None, exclude: AbstractSetIntStr | MappingIntStrAny | None, exclude_unset: bool, exclude_defaults: bool, exclude_none: bool) -> Any`

**Decorators:**
- `@typing.no_type_check`

**Line:** 124

---

### `def _calculate_keys(self: BaseModel, include: MappingIntStrAny | None, exclude: MappingIntStrAny | None, exclude_unset: bool, update: typing.Dict[str, Any] | None = None) -> typing.AbstractSet[str] | None`

**Line:** 198

---


## Module: venv2.libthon3.12.site-packagesdantic.deprecated.decorator
**File:** `venv2/lib/python3.12/site-packages/pydantic/deprecated/decorator.py`

**Imports:**
- _internal._config
- _internal._typing_extra
- alias_generators.to_pascal
- errors.PydanticUserError
- functional_validators.field_validator
- functools.wraps
- inspect.Parameter
- inspect.signature
- main.BaseModel
- main.create_model
- typing.Any
- typing.Callable
- typing.Dict
- typing.List
- typing.Mapping
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.overload
- typing_extensions.deprecated
- warnings
- warnings.PydanticDeprecatedSince20

**Functions:**

### `def validate_arguments(func: None = None, config: 'ConfigType' = None) -> Callable[(['AnyCallableT'], 'AnyCallableT')]`

**Decorators:**
- `@overload`
- `@deprecated(...)`

**Line:** 32

---

### `def validate_arguments(func: 'AnyCallableT') -> 'AnyCallableT'`

**Decorators:**
- `@overload`
- `@deprecated(...)`

**Line:** 40

---

### `def validate_arguments(func: Optional['AnyCallableT'] = None, config: 'ConfigType' = None) -> Any`

**Description:**
Decorator to validate the arguments passed to a function.

**Line:** 44

---


## Module: venv2.libthon3.12.site-packagesdantic.deprecated.json
**File:** `venv2/lib/python3.12/site-packages/pydantic/deprecated/json.py`

**Imports:**
- collections.deque
- color.Color
- dataclasses.asdict
- dataclasses.is_dataclass
- datetime
- decimal.Decimal
- enum.Enum
- ipaddress.IPv4Address
- ipaddress.IPv4Interface
- ipaddress.IPv4Network
- ipaddress.IPv6Address
- ipaddress.IPv6Interface
- ipaddress.IPv6Network
- main.BaseModel
- networks.NameEmail
- pathlib.Path
- re.Pattern
- types.GeneratorType
- types.SecretBytes
- types.SecretStr
- typing.Any
- typing.Callable
- typing.Dict
- typing.TYPE_CHECKING
- typing.Type
- typing.Union
- typing_extensions.deprecated
- uuid.UUID
- warnings
- warnings.PydanticDeprecatedSince20

**Functions:**

### `def isoformat(o: Union[(datetime.date, datetime.time)]) -> str`

**Line:** 28

---

### `def decimal_encoder(dec_value: Decimal) -> Union[(int, float)]`

**Description:**
Encodes a Decimal as int of there's no exponent, otherwise float.

This is useful when we use ConstrainedDecimal to represent Numeric(x,0)
where a integer (but not int typed) is used. Encoding this as a float
results in failed round-tripping between encode and parse.
Our Id type is a prime example of this.

>>> decimal_encoder(Decimal("1.0"))
1.0

>>> decimal_encoder(Decimal("1"))
1

**Line:** 32

---

### `def pydantic_encoder(obj: Any) -> Any`

**Decorators:**
- `@deprecated(...)`

**Line:** 84

---

### `def custom_pydantic_encoder(type_encoders: Dict[(Any, Callable[[Type[Any]], Any])], obj: Any) -> Any`

**Decorators:**
- `@deprecated(...)`

**Line:** 108

---

### `def timedelta_isoformat(td: datetime.timedelta) -> str`

**Decorators:**
- `@deprecated(...)`

**Description:**
ISO 8601 encoding for Python timedelta object.

**Line:** 125

---


## Module: venv2.libthon3.12.site-packagesdantic.deprecated.parse
**File:** `venv2/lib/python3.12/site-packages/pydantic/deprecated/parse.py`

**Imports:**
- __future__.annotations
- enum.Enum
- json
- pathlib.Path
- pickle
- typing.Any
- typing.Callable
- typing.TYPE_CHECKING
- typing_extensions.deprecated
- warnings
- warnings.PydanticDeprecatedSince20

**Functions:**

### `def load_str_bytes(b: str | bytes, content_type: str | None = None, encoding: str = 'utf8', proto: Protocol | None = None, allow_pickle: bool = False, json_loads: Callable[([str], Any)] = json.loads) -> Any`

**Decorators:**
- `@deprecated(...)`

**Line:** 26

---

### `def load_file(path: str | Path, content_type: str | None = None, encoding: str = 'utf8', proto: Protocol | None = None, allow_pickle: bool = False, json_loads: Callable[([str], Any)] = json.loads) -> Any`

**Decorators:**
- `@deprecated(...)`

**Line:** 60

---


## Module: venv2.libthon3.12.site-packagesdantic.deprecated.tools
**File:** `venv2/lib/python3.12/site-packages/pydantic/deprecated/tools.py`

**Imports:**
- __future__.annotations
- json
- json_schema.DEFAULT_REF_TEMPLATE
- json_schema.GenerateJsonSchema
- type_adapter.TypeAdapter
- typing.Any
- typing.Callable
- typing.TYPE_CHECKING
- typing.Type
- typing.TypeVar
- typing.Union
- typing_extensions.deprecated
- warnings
- warnings.PydanticDeprecatedSince20

**Functions:**

### `def parse_obj_as(type_: type[T], obj: Any, type_name: NameFactory | None = None) -> T`

**Decorators:**
- `@deprecated(...)`

**Line:** 29

---

### `def schema_of(type_: Any, title: NameFactory | None = None, by_alias: bool = True, ref_template: str = DEFAULT_REF_TEMPLATE, schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema) -> dict[(str, Any)]`

**Decorators:**
- `@deprecated(...)`

**Description:**
Generate a JSON schema (as dict) for the passed model or dynamically generated one.

**Line:** 47

---

### `def schema_json_of(type_: Any, title: NameFactory | None = None, by_alias: bool = True, ref_template: str = DEFAULT_REF_TEMPLATE, schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema, **dumps_kwargs: Any) -> str`

**Decorators:**
- `@deprecated(...)`

**Description:**
Generate a JSON schema (as JSON) for the passed model or dynamically generated one.

**Line:** 80

---


## Module: venv2.libthon3.12.site-packagesdantic.fields
**File:** `venv2/lib/python3.12/site-packages/pydantic/fields.py`

**Imports:**
- __future__.annotations
- _internal._decorators
- _internal._fields
- _internal._generics
- _internal._internal_dataclass
- _internal._repr
- _internal._repr.ReprArgs
- _internal._typing_extra
- _internal._utils
- annotated_types
- config.JsonDict
- copy.copy
- dataclasses
- dataclasses.Field
- errors.PydanticUserError
- functools.cached_property
- inspect
- pydantic_core.PydanticUndefined
- sys
- typing
- typing.Any
- typing.ClassVar
- typing_extensions
- typing_extensions.Literal
- typing_extensions.Unpack
- warnings.PydanticDeprecatedSince20
- warnings.warn

**Functions:**

### `def Field(default: Any = PydanticUndefined, default_factory: typing.Callable[[], Any] | None = _Unset, alias: str | None = _Unset, alias_priority: int | None = _Unset, validation_alias: str | AliasPath | AliasChoices | None = _Unset, serialization_alias: str | None = _Unset, title: str | None = _Unset, description: str | None = _Unset, examples: list[Any] | None = _Unset, exclude: bool | None = _Unset, discriminator: str | types.Discriminator | None = _Unset, json_schema_extra: JsonDict | typing.Callable[[JsonDict], None] | None = _Unset, frozen: bool | None = _Unset, validate_default: bool | None = _Unset, repr: bool = _Unset, init_var: bool | None = _Unset, kw_only: bool | None = _Unset, pattern: str | None = _Unset, strict: bool | None = _Unset, gt: float | None = _Unset, ge: float | None = _Unset, lt: float | None = _Unset, le: float | None = _Unset, multiple_of: float | None = _Unset, allow_inf_nan: bool | None = _Unset, max_digits: int | None = _Unset, decimal_places: int | None = _Unset, min_length: int | None = _Unset, max_length: int | None = _Unset, union_mode: Literal[('smart', 'left_to_right')] = _Unset, **extra: Unpack[_EmptyKwargs]) -> Any`

**Description:**
Usage docs: https://docs.pydantic.dev/2.5/concepts/fields

Create a field for objects that can be configured.

Used to provide extra information about a field, either for the model schema or complex validation. Some arguments
apply only to number fields (`int`, `float`, `Decimal`) and some apply only to `str`.

Note:
- Any `_Unset` objects will be replaced by the corresponding value defined in the `_DefaultValues` dictionary. If a key for the `_Unset` object is not found in the `_DefaultValues` dictionary, it will default to `None`

Args:
default: Default value if the field is not set.
default_factory: A callable to generate the default value, such as :func:`~datetime.utcnow`.
alias: An alternative name for the attribute.
alias_priority: Priority of the alias. This affects whether an alias generator is used.
validation_alias: 'Whitelist' validation step. The field will be the single one allowed by the alias or set of
aliases defined.
serialization_alias: 'Blacklist' validation step. The vanilla field will be the single one of the alias' or set
of aliases' fields and all the other fields will be ignored at serialization time.
title: Human-readable title.
description: Human-readable description.
examples: Example values for this field.
exclude: Whether to exclude the field from the model serialization.
discriminator: Field name or Discriminator for discriminating the type in a tagged union.
json_schema_extra: Any additional JSON schema data for the schema property.
frozen: Whether the field is frozen.
validate_default: Run validation that isn't only checking existence of defaults. This can be set to `True` or `False`. If not set, it defaults to `None`.
repr: A boolean indicating whether to include the field in the `__repr__` output.
init_var: Whether the field should be included in the constructor of the dataclass.
kw_only: Whether the field should be a keyword-only argument in the constructor of the dataclass.
strict: If `True`, strict validation is applied to the field.
See [Strict Mode](../concepts/strict_mode.md) for details.
gt: Greater than. If set, value must be greater than this. Only applicable to numbers.
ge: Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers.
lt: Less than. If set, value must be less than this. Only applicable to numbers.
le: Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers.
multiple_of: Value must be a multiple of this. Only applicable to numbers.
min_length: Minimum length for strings.
max_length: Maximum length for strings.
pattern: Pattern for strings.
allow_inf_nan: Allow `inf`, `-inf`, `nan`. Only applicable to numbers.
max_digits: Maximum number of allow digits for strings.
decimal_places: Maximum number of decimal places allowed for numbers.
union_mode: The strategy to apply when validating a union. Can be `smart` (the default), or `left_to_right`.
See [Union Mode](standard_library_types.md#union-mode) for details.
extra: Include extra fields used by the JSON schema.

!!! warning Deprecated
The `extra` kwargs is deprecated. Use `json_schema_extra` instead.

Returns:
A new [`FieldInfo`][pydantic.fields.FieldInfo], the return annotation is `Any` so `Field` can be used on
type annotated fields without causing a typing error.

**Line:** 673

---

### `def PrivateAttr(default: Any = PydanticUndefined, default_factory: typing.Callable[[], Any] | None = None) -> Any`

**Description:**
Indicates that attribute is only used internally and never mixed with regular fields.

Private attributes are not checked by Pydantic, so it's up to you to maintain their accuracy.

Private attributes are stored in `__private_attributes__` on the model.

Args:
default: The attribute's default value. Defaults to Undefined.
default_factory: Callable that will be
called when a default value is needed for this attribute.
If both `default` and `default_factory` are set, an error will be raised.

Returns:
An instance of [`ModelPrivateAttr`][pydantic.fields.ModelPrivateAttr] class.

Raises:
ValueError: If both `default` and `default_factory` are set.

**Line:** 921

---

### `def computed_field(alias: str | None = None, alias_priority: int | None = None, title: str | None = None, description: str | None = None, examples: list[Any] | None = None, json_schema_extra: JsonDict | typing.Callable[[JsonDict], None] | None = None, repr: bool = True, return_type: Any = PydanticUndefined) -> typing.Callable[([PropertyT], PropertyT)]`

**Decorators:**
- `@typing.overload`

**Line:** 988

---

### `def computed_field(__func: PropertyT) -> PropertyT`

**Decorators:**
- `@typing.overload`

**Line:** 1003

---

### `def _wrapped_property_is_private(property_: cached_property | property) -> bool`

**Description:**
Returns true if provided property is private, False otherwise.

**Line:** 1007

---

### `def computed_field(__f: PropertyT | None = None, alias: str | None = None, alias_priority: int | None = None, title: str | None = None, description: str | None = None, examples: list[Any] | None = None, json_schema_extra: JsonDict | typing.Callable[[JsonDict], None] | None = None, repr: bool | None = None, return_type: Any = PydanticUndefined) -> PropertyT | typing.Callable[[PropertyT], PropertyT]`

**Description:**
Decorator to include `property` and `cached_property` when serializing models or dataclasses.

This is useful for fields that are computed from other fields, or for fields that are expensive to compute and should be cached.

```py
from pydantic import BaseModel, computed_field

class Rectangle(BaseModel):
width: int
length: int

@computed_field
@property
def area(self) -> int:
return self.width * self.length

print(Rectangle(width=3, length=2).model_dump())
#> {'width': 3, 'length': 2, 'area': 6}
```

If applied to functions not yet decorated with `@property` or `@cached_property`, the function is
automatically wrapped with `property`. Although this is more concise, you will lose IntelliSense in your IDE,
and confuse static type checkers, thus explicit use of `@property` is recommended.

!!! warning "Mypy Warning"
Even with the `@property` or `@cached_property` applied to your function before `@computed_field`,
mypy may throw a `Decorated property not supported` error.
See [mypy issue #1362](https://github.com/python/mypy/issues/1362), for more information.
To avoid this error message, add `# type: ignore[misc]` to the `@computed_field` line.

[pyright](https://github.com/microsoft/pyright) supports `@computed_field` without error.

```py
import random

from pydantic import BaseModel, computed_field

class Square(BaseModel):
width: float

@computed_field
def area(self) -> float:  # converted to a `property` by `computed_field`
return round(self.width**2, 2)

@area.setter
def area(self, new_area: float) -> None:
self.width = new_area**0.5

@computed_field(alias='the magic number', repr=False)
def random_number(self) -> int:
return random.randint(0, 1_000)

square = Square(width=1.3)

# `random_number` does not appear in representation
print(repr(square))
#> Square(width=1.3, area=1.69)

print(square.random_number)
#> 3

square.area = 4

print(square.model_dump_json(by_alias=True))
#> {"width":2.0,"area":4.0,"the magic number":3}
```

!!! warning "Overriding with `computed_field`"
You can't override a field from a parent class with a `computed_field` in the child class.
`mypy` complains about this behavior if allowed, and `dataclasses` doesn't allow this pattern either.
See the example below:

```py
from pydantic import BaseModel, computed_field

class Parent(BaseModel):
a: str

try:

class Child(Parent):
@computed_field
@property
def a(self) -> str:
return 'new a'

except ValueError as e:
print(repr(e))
#> ValueError("you can't override a field with a computed field")
```

Private properties decorated with `@computed_field` have `repr=False` by default.

```py
from functools import cached_property

from pydantic import BaseModel, computed_field

class Model(BaseModel):
foo: int

@computed_field
@cached_property
def _private_cached_property(self) -> int:
return -self.foo

@computed_field
@property
def _private_property(self) -> int:
return -self.foo

m = Model(foo=1)
print(repr(m))
#> M(foo=1)
```

Args:
__f: the function to wrap.
alias: alias to use when serializing this computed field, only used when `by_alias=True`
alias_priority: priority of the alias. This affects whether an alias generator is used
title: Title to use when including this computed field in JSON Schema
description: Description to use when including this computed field in JSON Schema, defaults to the function's
docstring
examples: Example values to use when including this computed field in JSON Schema
json_schema_extra: Dictionary of extra JSON schema properties.
repr: whether to include this computed field in model repr.
Default is `False` for private properties and `True` for public properties.
return_type: optional return for serialization logic to expect when serializing to JSON, if included
this must be correct, otherwise a `TypeError` is raised.
If you don't include a return type Any is used, which does runtime introspection to handle arbitrary
objects.

Returns:
A proxy wrapper for the property.

**Line:** 1019

---


## Module: venv2.libthon3.12.site-packagesdantic.functional_serializers
**File:** `venv2/lib/python3.12/site-packages/pydantic/functional_serializers.py`

**Imports:**
- __future__.annotations
- _internal._decorators
- _internal._internal_dataclass
- annotated_handlers.GetCoreSchemaHandler
- dataclasses
- functools.partialmethod
- pydantic_core.PydanticUndefined
- pydantic_core.core_schema
- typing.Any
- typing.Callable
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.Union
- typing.overload
- typing_extensions.Annotated
- typing_extensions.Literal
- typing_extensions.TypeAlias

**Functions:**

### `def field_serializer(__field: str, return_type: Any = Ellipsis, when_used: Literal[('always', 'unless-none', 'json', 'json-unless-none')] = Ellipsis, check_fields: bool | None = Ellipsis, *fields: str) -> Callable[([_PlainSerializeMethodType], _PlainSerializeMethodType)]`

**Decorators:**
- `@overload`

**Line:** 111

---

### `def field_serializer(__field: str, mode: Literal['plain'], return_type: Any = Ellipsis, when_used: Literal[('always', 'unless-none', 'json', 'json-unless-none')] = Ellipsis, check_fields: bool | None = Ellipsis, *fields: str) -> Callable[([_PlainSerializeMethodType], _PlainSerializeMethodType)]`

**Decorators:**
- `@overload`

**Line:** 122

---

### `def field_serializer(__field: str, mode: Literal['wrap'], return_type: Any = Ellipsis, when_used: Literal[('always', 'unless-none', 'json', 'json-unless-none')] = Ellipsis, check_fields: bool | None = Ellipsis, *fields: str) -> Callable[([_WrapSerializeMethodType], _WrapSerializeMethodType)]`

**Decorators:**
- `@overload`

**Line:** 134

---

### `def field_serializer(mode: Literal[('plain', 'wrap')] = 'plain', return_type: Any = PydanticUndefined, when_used: Literal[('always', 'unless-none', 'json', 'json-unless-none')] = 'always', check_fields: bool | None = None, *fields: str) -> Callable[([Any], Any)]`

**Description:**
Decorator that enables custom field serialization.

See [Custom serializers](../concepts/serialization.md#custom-serializers) for more information.

Four signatures are supported:

- `(self, value: Any, info: FieldSerializationInfo)`
- `(self, value: Any, nxt: SerializerFunctionWrapHandler, info: FieldSerializationInfo)`
- `(value: Any, info: SerializationInfo)`
- `(value: Any, nxt: SerializerFunctionWrapHandler, info: SerializationInfo)`

Args:
fields: Which field(s) the method should be called on.
mode: The serialization mode.

- `plain` means the function will be called instead of the default serialization logic,
- `wrap` means the function will be called with an argument to optionally call the
default serialization logic.
return_type: Optional return type for the function, if omitted it will be inferred from the type annotation.
when_used: Determines the serializer will be used for serialization.
check_fields: Whether to check that the fields actually exist on the model.

Returns:
The decorator function.

**Line:** 145

---

### `def model_serializer(__f: FuncType) -> FuncType`

**Decorators:**
- `@overload`

**Line:** 197

---

### `def model_serializer(mode: Literal[('plain', 'wrap')] = Ellipsis, when_used: Literal[('always', 'unless-none', 'json', 'json-unless-none')] = 'always', return_type: Any = Ellipsis) -> Callable[([FuncType], FuncType)]`

**Decorators:**
- `@overload`

**Line:** 202

---

### `def model_serializer(__f: Callable[..., Any] | None = None, mode: Literal[('plain', 'wrap')] = 'plain', when_used: Literal[('always', 'unless-none', 'json', 'json-unless-none')] = 'always', return_type: Any = PydanticUndefined) -> Callable[([Any], Any)]`

**Description:**
Decorator that enables custom model serialization.

See [Custom serializers](../concepts/serialization.md#custom-serializers) for more information.

Args:
__f: The function to be decorated.
mode: The serialization mode.

- `'plain'` means the function will be called instead of the default serialization logic
- `'wrap'` means the function will be called with an argument to optionally call the default
serialization logic.
when_used: Determines when this serializer should be used.
return_type: The return type for the function. If omitted it will be inferred from the type annotation.

Returns:
The decorator function.

**Line:** 211

---


## Module: venv2.libthon3.12.site-packagesdantic.functional_validators
**File:** `venv2/lib/python3.12/site-packages/pydantic/functional_validators.py`

**Imports:**
- __future__.annotations
- _internal._core_metadata
- _internal._decorators
- _internal._generics
- _internal._internal_dataclass
- annotated_handlers.GetCoreSchemaHandler
- dataclasses
- errors.PydanticUserError
- functools.partialmethod
- pydantic.PydanticSchemaGenerationError
- pydantic_core.core_schema
- sys
- types.FunctionType
- typing.Any
- typing.Callable
- typing.Protocol
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- typing_extensions.Annotated
- typing_extensions.Literal
- typing_extensions.Protocol
- typing_extensions.TypeAlias

**Functions:**

### `def field_validator(__field: str, mode: Literal[('before', 'after', 'plain')] = Ellipsis, check_fields: bool | None = Ellipsis, *fields: str) -> Callable[([_V2BeforeAfterOrPlainValidatorType], _V2BeforeAfterOrPlainValidatorType)]`

**Decorators:**
- `@overload`

**Line:** 259

---

### `def field_validator(__field: str, mode: Literal['wrap'], check_fields: bool | None = Ellipsis, *fields: str) -> Callable[([_V2WrapValidatorType], _V2WrapValidatorType)]`

**Decorators:**
- `@overload`

**Line:** 269

---

### `def field_validator(__field: str, mode: FieldValidatorModes = 'after', check_fields: bool | None = None, *fields: str) -> Callable[([Any], Any)]`

**Description:**
Usage docs: https://docs.pydantic.dev/2.5/concepts/validators/#field-validators

Decorate methods on the class indicating that they should be used to validate fields.

Example usage:
```py
from typing import Any

from pydantic import (
BaseModel,
ValidationError,
field_validator,
)

class Model(BaseModel):
a: str

@field_validator('a')
@classmethod
def ensure_foobar(cls, v: Any):
if 'foobar' not in v:
raise ValueError('"foobar" not found in a')
return v

print(repr(Model(a='this is foobar good')))
#> Model(a='this is foobar good')

try:
Model(a='snap')
except ValidationError as exc_info:
print(exc_info)
'''
1 validation error for Model
a
Value error, "foobar" not found in a [type=value_error, input_value='snap', input_type=str]
'''
```

For more in depth examples, see [Field Validators](../concepts/validators.md#field-validators).

Args:
__field: The first field the `field_validator` should be called on; this is separate
from `fields` to ensure an error is raised if you don't pass at least one.
*fields: Additional field(s) the `field_validator` should be called on.
mode: Specifies whether to validate the fields before or after validation.
check_fields: Whether to check that the fields actually exist on the model.

Returns:
A decorator that can be used to decorate a function to be used as a field_validator.

Raises:
PydanticUserError:
- If `@field_validator` is used bare (with no fields).
- If the args passed to `@field_validator` as fields are not strings.
- If `@field_validator` applied to instance methods.

**Line:** 281

---

### `def model_validator(mode: Literal['wrap']) -> Callable[([_AnyModelWrapValidator[_ModelType]], _decorators.PydanticDescriptorProxy[_decorators.ModelValidatorDecoratorInfo])]`

**Decorators:**
- `@overload`

**Line:** 465

---

### `def model_validator(mode: Literal['before']) -> Callable[([_AnyModeBeforeValidator], _decorators.PydanticDescriptorProxy[_decorators.ModelValidatorDecoratorInfo])]`

**Decorators:**
- `@overload`

**Line:** 475

---

### `def model_validator(mode: Literal['after']) -> Callable[([_AnyModelAfterValidator[_ModelType]], _decorators.PydanticDescriptorProxy[_decorators.ModelValidatorDecoratorInfo])]`

**Decorators:**
- `@overload`

**Line:** 483

---

### `def model_validator(mode: Literal[('wrap', 'before', 'after')]) -> Any`

**Description:**
Usage docs: https://docs.pydantic.dev/2.5/concepts/validators/#model-validators

Decorate model methods for validation purposes.

Example usage:
```py
from typing import Optional

from pydantic import BaseModel, ValidationError, model_validator

class Square(BaseModel):
width: float
height: float

@model_validator(mode='after')
def verify_square(self) -> 'Rectangle':
if self.width != self.height:
raise ValueError('width and height do not match')
return self

s = Square(width=1, height=1)
print(repr(s))
#> Square(width=1.0, height=1.0)

try:
Square(width=1, height=2)
except ValidationError as e:
print(e)
'''
1 validation error for Square
__root__
width and height do not match (type=value_error)
'''
```

For more in depth examples, see [Model Validators](../concepts/validators.md#model-validators).

Args:
mode: A required string literal that specifies the validation mode.
It can be one of the following: 'wrap', 'before', or 'after'.

Returns:
A decorator that can be used to decorate a function to be used as a model validator.

**Line:** 492

---


## Module: venv2.libthon3.12.site-packagesdantic.json_schema
**File:** `venv2/lib/python3.12/site-packages/pydantic/json_schema.py`

**Imports:**
- __future__.annotations
- _internal._config
- _internal._core_metadata
- _internal._core_utils
- _internal._core_utils.CoreSchemaField
- _internal._core_utils.CoreSchemaOrField
- _internal._dataclasses.PydanticDataclass
- _internal._decorators
- _internal._internal_dataclass
- _internal._mock_val_ser
- _internal._schema_generation_shared
- _internal._schema_generation_shared.GetJsonSchemaFunction
- _internal._typing_extra
- annotated_handlers.GetJsonSchemaHandler
- collections.defaultdict
- config.JsonDict
- config.JsonSchemaExtraCallable
- config.JsonValue
- copy.deepcopy
- dataclasses
- dataclasses.is_dataclass
- enum.Enum
- errors.PydanticInvalidForJsonSchema
- errors.PydanticUserError
- inspect
- main.BaseModel
- math
- pydantic_core
- pydantic_core.CoreSchema
- pydantic_core.PydanticOmit
- pydantic_core.core_schema
- pydantic_core.core_schema.ComputedField
- pydantic_core.to_jsonable_python
- re
- typing.Any
- typing.Callable
- typing.Counter
- typing.Dict
- typing.Hashable
- typing.Iterable
- typing.NewType
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TypeVar
- typing.Union
- typing.cast
- typing_extensions.Annotated
- typing_extensions.Literal
- typing_extensions.TypeAlias
- typing_extensions.assert_never
- warnings

**Functions:**

### `def update_json_schema(schema: JsonSchemaValue, updates: dict[(str, Any)]) -> JsonSchemaValue`

**Description:**
Update a JSON schema by providing a dictionary of updates.

This function sets the provided key-value pairs in the schema and returns the updated schema.

Args:
schema: The JSON schema to update.
updates: A dictionary of key-value pairs to set in the schema.

Returns:
The updated JSON schema.

**Line:** 90

---

### `def model_json_schema(cls: type[BaseModel] | type[PydanticDataclass], by_alias: bool = True, ref_template: str = DEFAULT_REF_TEMPLATE, schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema, mode: JsonSchemaMode = 'validation') -> dict[(str, Any)]`

**Description:**
Utility function to generate a JSON Schema for a model.

Args:
cls: The model class to generate a JSON Schema for.
by_alias: If `True` (the default), fields will be serialized according to their alias.
If `False`, fields will be serialized according to their attribute name.
ref_template: The template to use for generating JSON Schema references.
schema_generator: The class to use for generating the JSON Schema.
mode: The mode to use for generating the JSON Schema. It can be one of the following:

- 'validation': Generate a JSON Schema for validating data.
- 'serialization': Generate a JSON Schema for serializing data.

Returns:
The generated JSON Schema.

**Line:** 2131

---

### `def models_json_schema(models: Sequence[tuple[(type[BaseModel] | type[PydanticDataclass], JsonSchemaMode)]], by_alias: bool = True, title: str | None = None, description: str | None = None, ref_template: str = DEFAULT_REF_TEMPLATE, schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema) -> tuple[(dict[tuple[type[BaseModel] | type[PydanticDataclass], JsonSchemaMode], JsonSchemaValue], JsonSchemaValue)]`

**Description:**
Utility function to generate a JSON Schema for multiple models.

Args:
models: A sequence of tuples of the form (model, mode).
by_alias: Whether field aliases should be used as keys in the generated JSON Schema.
title: The title of the generated JSON Schema.
description: The description of the generated JSON Schema.
ref_template: The reference template to use for generating JSON Schema references.
schema_generator: The schema generator to use for generating the JSON Schema.

Returns:
A tuple where:
- The first element is a dictionary whose keys are tuples of JSON schema key type and JSON mode, and
whose values are the JSON schema corresponding to that pair of inputs. (These schemas may have
JsonRef references to definitions that are defined in the second returned element.)
- The second element is a JSON schema containing all definitions referenced in the first returned
element, along with the optional title and description keys.

**Line:** 2161

---

### `def _deduplicate_schemas(schemas: Iterable[JsonDict]) -> list[JsonDict]`

**Line:** 2215

---

### `def _make_json_hashable(value: JsonValue) -> _HashableJsonValue`

**Line:** 2219

---

### `def _sort_json_schema(value: JsonSchemaValue, parent_key: str | None = None) -> JsonSchemaValue`

**Line:** 2228

---

### `def _get_all_json_refs(item: Any) -> set[JsonRef]`

**Description:**
Get all the definitions references from a JSON schema.

**Line:** 2308

---

### `def _get_typed_dict_config(schema: core_schema.TypedDictSchema) -> ConfigDict`

**Line:** 2363

---


## Module: venv2.libthon3.12.site-packagesdantic.main
**File:** `venv2/lib/python3.12/site-packages/pydantic/main.py`

**Imports:**
- __future__.annotations
- _internal._config
- _internal._decorators
- _internal._fields
- _internal._forward_ref
- _internal._generics
- _internal._mock_val_ser
- _internal._model_construction
- _internal._repr
- _internal._typing_extra
- _internal._utils
- _internal._utils.AbstractSetIntStr
- _internal._utils.MappingIntStrAny
- _migration.getattr_migration
- annotated_handlers.GetCoreSchemaHandler
- annotated_handlers.GetJsonSchemaHandler
- config.ConfigDict
- copy.copy
- copy.deepcopy
- deprecated.copy_internals
- deprecated.json.pydantic_encoder
- deprecated.parse
- deprecated.parse.Protocol
- errors.PydanticUndefinedAnnotation
- errors.PydanticUserError
- fields.ComputedFieldInfo
- fields.Field
- fields.FieldInfo
- fields.ModelPrivateAttr
- inspect.Signature
- json
- json_schema.DEFAULT_REF_TEMPLATE
- json_schema.GenerateJsonSchema
- json_schema.JsonSchemaMode
- json_schema.JsonSchemaValue
- json_schema.model_json_schema
- pathlib.Path
- pydantic_core
- pydantic_core.CoreSchema
- pydantic_core.PydanticUndefined
- pydantic_core.SchemaSerializer
- pydantic_core.SchemaValidator
- sys
- types
- typing
- typing.Any
- typing.ClassVar
- typing_extensions
- typing_extensions.Literal
- typing_extensions.Unpack
- warnings
- warnings.PydanticDeprecatedSince20

**Functions:**

### `def create_model(__model_name: str, __config__: ConfigDict | None = None, __doc__: str | None = None, __base__: None = None, __module__: str = __name__, __validators__: dict[str, classmethod] | None = None, __cls_kwargs__: dict[str, Any] | None = None, **field_definitions: Any) -> type[BaseModel]`

**Decorators:**
- `@typing.overload`

**Line:** 1321

---

### `def create_model(__model_name: str, __config__: ConfigDict | None = None, __doc__: str | None = None, __base__: type[Model] | tuple[type[Model], ...], __module__: str = __name__, __validators__: dict[str, classmethod] | None = None, __cls_kwargs__: dict[str, Any] | None = None, **field_definitions: Any) -> type[Model]`

**Decorators:**
- `@typing.overload`

**Line:** 1336

---

### `def create_model(__model_name: str, __config__: ConfigDict | None = None, __doc__: str | None = None, __base__: type[Model] | tuple[type[Model], ...] | None = None, __module__: str | None = None, __validators__: dict[str, classmethod] | None = None, __cls_kwargs__: dict[str, Any] | None = None, __slots__: tuple[str, ...] | None = None, **field_definitions: Any) -> type[Model]`

**Description:**
Dynamically creates and returns a new Pydantic model, in other words, `create_model` dynamically creates a
subclass of [`BaseModel`][pydantic.BaseModel].

Args:
__model_name: The name of the newly created model.
__config__: The configuration of the new model.
__doc__: The docstring of the new model.
__base__: The base class for the new model.
__module__: The name of the module that the model belongs to,
if `None` the value is taken from `sys._getframe(1)`
__validators__: A dictionary of methods that validate fields.
__cls_kwargs__: A dictionary of keyword arguments for class creation.
__slots__: Deprecated. Should not be passed to `create_model`.
**field_definitions: Attributes of the new model. They should be passed in the format:
`<name>=(<type>, <default value>)` or `<name>=(<type>, <FieldInfo>)`.

Returns:
The new [model][pydantic.BaseModel].

Raises:
PydanticUserError: If `__base__` and `__config__` are both passed.

**Line:** 1350

---


## Module: venv2.libthon3.12.site-packagesdantic.mypy
**File:** `venv2/lib/python3.12/site-packages/pydantic/mypy.py`

**Imports:**
- __future__.annotations
- configparser.ConfigParser
- mypy.errorcodes.ErrorCode
- mypy.expandtype.expand_type
- mypy.expandtype.expand_type_by_instance
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_NAMED_OPT
- mypy.nodes.ARG_OPT
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR2
- mypy.nodes.Argument
- mypy.nodes.AssignmentStmt
- mypy.nodes.Block
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.Context
- mypy.nodes.Decorator
- mypy.nodes.DictExpr
- mypy.nodes.EllipsisExpr
- mypy.nodes.Expression
- mypy.nodes.FuncDef
- mypy.nodes.IfStmt
- mypy.nodes.JsonDict
- mypy.nodes.MDEF
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.PassStmt
- mypy.nodes.PlaceholderNode
- mypy.nodes.RefExpr
- mypy.nodes.Statement
- mypy.nodes.StrExpr
- mypy.nodes.SymbolTableNode
- mypy.nodes.TempNode
- mypy.nodes.TypeAlias
- mypy.nodes.TypeInfo
- mypy.nodes.Var
- mypy.options.Options
- mypy.plugin.CheckerPluginInterface
- mypy.plugin.ClassDefContext
- mypy.plugin.FunctionContext
- mypy.plugin.MethodContext
- mypy.plugin.Plugin
- mypy.plugin.ReportConfigContext
- mypy.plugin.SemanticAnalyzerPluginInterface
- mypy.plugins.common.deserialize_and_fixup_type
- mypy.plugins.dataclasses
- mypy.semanal.set_callable_name
- mypy.server.trigger.make_wildcard_trigger
- mypy.state.state
- mypy.typeops.map_type_from_supertype
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.TypeVarDef
- mypy.types.TypeVarType
- mypy.types.UnionType
- mypy.types.get_proper_type
- mypy.typevars.fill_typevars
- mypy.util.get_unique_redefinition_name
- mypy.version.__version__
- pydantic._internal._fields
- pydantic.version.parse_mypy_version
- sys
- tomli
- tomllib
- typing.Any
- typing.Callable
- typing.Iterator
- warnings

**Functions:**

### `def plugin(version: str) -> type[Plugin]`

**Description:**
`version` is the mypy version string.

We might want to use this to print a warning if the mypy version being used is
newer, or especially older, than we expect (or need).

Args:
version: The mypy version string.

Return:
The Pydantic mypy plugin type.

**Line:** 114

---

### `def from_attributes_callback(ctx: MethodContext) -> Type`

**Description:**
Raise an error if from_attributes is not enabled.

**Line:** 293

---

### `def error_from_attributes(model_name: str, api: CheckerPluginInterface, context: Context) -> None`

**Description:**
Emits an error when the model does not have `from_attributes=True`.

**Line:** 1066

---

### `def error_invalid_config_value(name: str, api: SemanticAnalyzerPluginInterface, context: Context) -> None`

**Description:**
Emits an error when the config value is invalid.

**Line:** 1071

---

### `def error_required_dynamic_aliases(api: SemanticAnalyzerPluginInterface, context: Context) -> None`

**Description:**
Emits required dynamic aliases error.

This will be called when `warn_required_dynamic_aliases=True`.

**Line:** 1076

---

### `def error_unexpected_behavior(detail: str, api: CheckerPluginInterface | SemanticAnalyzerPluginInterface, context: Context) -> None`

**Description:**
Emits unexpected behavior error.

**Line:** 1084

---

### `def error_untyped_fields(api: SemanticAnalyzerPluginInterface, context: Context) -> None`

**Description:**
Emits an error when there is an untyped field in the model.

**Line:** 1095

---

### `def error_extra_fields_on_root_model(api: CheckerPluginInterface, context: Context) -> None`

**Description:**
Emits an error when there is more than just a root field defined for a subclass of RootModel.

**Line:** 1100

---

### `def error_default_and_default_factory_specified(api: CheckerPluginInterface, context: Context) -> None`

**Description:**
Emits an error when `Field` has both `default` and `default_factory` together.

**Line:** 1105

---

### `def add_method(api: SemanticAnalyzerPluginInterface | CheckerPluginInterface, cls: ClassDef, name: str, args: list[Argument], return_type: Type, self_type: Type | None = None, tvar_def: TypeVarDef | None = None, is_classmethod: bool = False) -> None`

**Description:**
Very closely related to `mypy.plugins.common.add_method_to_class`, with a few pydantic-specific changes.

**Line:** 1110

---

### `def parse_toml(config_file: str) -> dict[str, Any] | None`

**Description:**
Returns a dict of config keys to values.

It reads configs from toml file and returns `None` if the file is not a toml file.

**Line:** 1188

---


## Module: venv2.libthon3.12.site-packagesdantic.networks
**File:** `venv2/lib/python3.12/site-packages/pydantic/networks.py`

**Imports:**
- __future__.annotations
- _internal._fields
- _internal._repr
- _internal._schema_generation_shared
- _migration.getattr_migration
- annotated_handlers.GetCoreSchemaHandler
- dataclasses
- email_validator
- ipaddress.IPv4Address
- ipaddress.IPv4Interface
- ipaddress.IPv4Network
- ipaddress.IPv6Address
- ipaddress.IPv6Interface
- ipaddress.IPv6Network
- json_schema.JsonSchemaValue
- pydantic_core.MultiHostUrl
- pydantic_core.PydanticCustomError
- pydantic_core.Url
- pydantic_core.core_schema
- re
- typing.Any
- typing.TYPE_CHECKING
- typing_extensions.Annotated
- typing_extensions.TypeAlias

**Functions:**

### `def import_email_validator() -> None`

**Line:** 349

---

### `def _build_pretty_email_regex() -> re.Pattern[str]`

**Line:** 637

---

### `def validate_email(value: str) -> tuple[(str, str)]`

**Description:**
Email address validation using [email-validator](https://pypi.org/project/email-validator/).

Note:
Note that:

* Raw IP address (literal) domain parts are not allowed.
* `"John Doe <local_part@domain.com>"` style "pretty" email addresses are processed.
* Spaces are striped from the beginning and end of addresses, but no error is raised.

**Line:** 653

---


## Module: venv2.libthon3.12.site-packagesdantic.plugin._loader
**File:** `venv2/lib/python3.12/site-packages/pydantic/plugin/_loader.py`

**Imports:**
- __future__.annotations
- importlib.metadata
- importlib_metadata
- sys
- typing.Iterable
- typing.TYPE_CHECKING
- typing_extensions.Final
- warnings

**Functions:**

### `def get_plugins() -> Iterable[PydanticPluginProtocol]`

**Description:**
Load plugins for Pydantic.

Inspired by: https://github.com/pytest-dev/pluggy/blob/1.3.0/src/pluggy/_manager.py#L376-L402

**Line:** 28

---


## Module: venv2.libthon3.12.site-packagesdantic.plugin._schema_validator
**File:** `venv2/lib/python3.12/site-packages/pydantic/plugin/_schema_validator.py`

**Imports:**
- __future__.annotations
- _loader.get_plugins
- functools
- pydantic_core.CoreConfig
- pydantic_core.CoreSchema
- pydantic_core.SchemaValidator
- pydantic_core.ValidationError
- typing.Any
- typing.Callable
- typing.Iterable
- typing.TYPE_CHECKING
- typing.TypeVar
- typing_extensions.Literal
- typing_extensions.ParamSpec

**Functions:**

### `def create_schema_validator(schema: CoreSchema, schema_type: Any, schema_type_module: str, schema_type_name: str, schema_kind: SchemaKind, config: CoreConfig | None = None, plugin_settings: dict[str, Any] | None = None) -> SchemaValidator`

**Description:**
Create a `SchemaValidator` or `PluggableSchemaValidator` if plugins are installed.

Returns:
If plugins are installed then return `PluggableSchemaValidator`, otherwise return `SchemaValidator`.

**Line:** 20

---

### `def build_wrapper(func: Callable[(P, R)], event_handlers: list[BaseValidateHandlerProtocol]) -> Callable[(P, R)]`

**Line:** 94

---

### `def filter_handlers(handler_cls: BaseValidateHandlerProtocol, method_name: str) -> bool`

**Description:**
Filter out handler methods which are not implemented by the plugin directly - e.g. are missing
or are inherited from the protocol.

**Line:** 126

---


## Module: venv2.libthon3.12.site-packagesdantic.type_adapter
**File:** `venv2/lib/python3.12/site-packages/pydantic/type_adapter.py`

**Imports:**
- __future__.annotations
- _internal._config
- _internal._generate_schema
- _internal._typing_extra
- config.ConfigDict
- dataclasses.is_dataclass
- json_schema.DEFAULT_REF_TEMPLATE
- json_schema.GenerateJsonSchema
- json_schema.JsonSchemaKeyT
- json_schema.JsonSchemaMode
- json_schema.JsonSchemaValue
- plugin._schema_validator.create_schema_validator
- pydantic.errors.PydanticUserError
- pydantic.main.BaseModel
- pydantic_core.CoreSchema
- pydantic_core.SchemaSerializer
- pydantic_core.SchemaValidator
- pydantic_core.Some
- sys
- typing.Any
- typing.Dict
- typing.Generic
- typing.Iterable
- typing.Set
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- typing_extensions.Literal
- typing_extensions.is_typeddict

**Functions:**

### `def _get_schema(type_: Any, config_wrapper: _config.ConfigWrapper, parent_depth: int) -> CoreSchema`

**Description:**
`BaseModel` uses its own `__module__` to find out where it was defined
and then look for symbols to resolve forward references in those globals.
On the other hand this function can be called with arbitrary objects,
including type aliases where `__module__` (always `typing.py`) is not useful.
So instead we look at the globals in our parent stack frame.

This works for the case where this function is called in a module that
has the target of forward references in its scope, but
does not work for more complex cases.

For example, take the following:

a.py
```python
from typing import Dict, List

IntList = List[int]
OuterDict = Dict[str, 'IntList']
```

b.py
```python test="skip"
from a import OuterDict

from pydantic import TypeAdapter

IntList = int  # replaces the symbol the forward reference is looking for
v = TypeAdapter(OuterDict)
v({'x': 1})  # should fail but doesn't
```

If OuterDict were a `BaseModel`, this would work because it would resolve
the forward reference within the `a.py` namespace.
But `TypeAdapter(OuterDict)`
can't know what module OuterDict came from.

In other words, the assumption that _all_ forward references exist in the
module we are being called from is not technically always true.
Although most of the time it is and it works fine for recursive models and such,
`BaseModel`'s behavior isn't perfect either and _can_ break in similar ways,
so there is no right or wrong between the two.

But at the very least this behavior is _subtly_ different from `BaseModel`'s.

**Line:** 32

---

### `def _getattr_no_parents(obj: Any, attribute: str) -> Any`

**Description:**
Returns the attribute value without attempting to look up attributes from parent types.

**Line:** 86

---


## Module: venv2.libthon3.12.site-packagesdantic.types
**File:** `venv2/lib/python3.12/site-packages/pydantic/types.py`

**Imports:**
- __future__.annotations
- _internal._core_utils
- _internal._fields
- _internal._internal_dataclass
- _internal._typing_extra
- _internal._utils
- _internal._validators
- _migration.getattr_migration
- annotated_handlers.GetCoreSchemaHandler
- annotated_handlers.GetJsonSchemaHandler
- annotated_types
- annotated_types.BaseMetadata
- annotated_types.MaxLen
- annotated_types.MinLen
- base64
- dataclasses
- datetime.date
- datetime.datetime
- decimal.Decimal
- enum.Enum
- errors.PydanticUserError
- json_schema.JsonSchemaValue
- pathlib.Path
- pydantic.Field
- pydantic_core.CoreSchema
- pydantic_core.PydanticCustomError
- pydantic_core.core_schema
- re
- types.ModuleType
- typing.Any
- typing.Callable
- typing.ClassVar
- typing.Dict
- typing.FrozenSet
- typing.Generic
- typing.Hashable
- typing.Iterator
- typing.List
- typing.Set
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.Union
- typing.cast
- typing_extensions.Annotated
- typing_extensions.Literal
- typing_extensions.Protocol
- typing_extensions.TypeAlias
- typing_extensions.TypeAliasType
- typing_extensions.deprecated
- uuid.UUID
- warnings.PydanticDeprecatedSince20

**Functions:**

### `def conint(strict: bool | None = None, gt: int | None = None, ge: int | None = None, lt: int | None = None, le: int | None = None, multiple_of: int | None = None) -> type[int]`

**Description:**
!!! warning "Discouraged"
This function is **discouraged** in favor of using
[`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated) with
[`Field`][pydantic.fields.Field] instead.

This function will be **deprecated** in Pydantic 3.0.

The reason is that `conint` returns a type, which doesn't play well with static analysis tools.

=== ":x: Don't do this"
```py
from pydantic import BaseModel, conint

class Foo(BaseModel):
bar: conint(strict=True, gt=0)
```

=== ":white_check_mark: Do this"
```py
from typing_extensions import Annotated

from pydantic import BaseModel, Field

class Foo(BaseModel):
bar: Annotated[int, Field(strict=True, gt=0)]
```

A wrapper around `int` that allows for additional constraints.

Args:
strict: Whether to validate the integer in strict mode. Defaults to `None`.
gt: The value must be greater than this.
ge: The value must be greater than or equal to this.
lt: The value must be less than this.
le: The value must be less than or equal to this.
multiple_of: The value must be a multiple of this.

Returns:
The wrapped integer type.

```py
from pydantic import BaseModel, ValidationError, conint

class ConstrainedExample(BaseModel):
constrained_int: conint(gt=1)

m = ConstrainedExample(constrained_int=2)
print(repr(m))
#> ConstrainedExample(constrained_int=2)

try:
ConstrainedExample(constrained_int=0)
except ValidationError as e:
print(e.errors())
'''
[
{
'type': 'greater_than',
'loc': ('constrained_int',),
'msg': 'Input should be greater than 1',
'input': 0,
'ctx': {'gt': 1},
'url': 'https://errors.pydantic.dev/2/v/greater_than',
}
]
'''
```

**Line:** 143

---

### `def confloat(strict: bool | None = None, gt: float | None = None, ge: float | None = None, lt: float | None = None, le: float | None = None, multiple_of: float | None = None, allow_inf_nan: bool | None = None) -> type[float]`

**Description:**
!!! warning "Discouraged"
This function is **discouraged** in favor of using
[`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated) with
[`Field`][pydantic.fields.Field] instead.

This function will be **deprecated** in Pydantic 3.0.

The reason is that `confloat` returns a type, which doesn't play well with static analysis tools.

=== ":x: Don't do this"
```py
from pydantic import BaseModel, confloat

class Foo(BaseModel):
bar: confloat(strict=True, gt=0)
```

=== ":white_check_mark: Do this"
```py
from typing_extensions import Annotated

from pydantic import BaseModel, Field

class Foo(BaseModel):
bar: Annotated[float, Field(strict=True, gt=0)]
```

A wrapper around `float` that allows for additional constraints.

Args:
strict: Whether to validate the float in strict mode.
gt: The value must be greater than this.
ge: The value must be greater than or equal to this.
lt: The value must be less than this.
le: The value must be less than or equal to this.
multiple_of: The value must be a multiple of this.
allow_inf_nan: Whether to allow `-inf`, `inf`, and `nan`.

Returns:
The wrapped float type.

```py
from pydantic import BaseModel, ValidationError, confloat

class ConstrainedExample(BaseModel):
constrained_float: confloat(gt=1.0)

m = ConstrainedExample(constrained_float=1.1)
print(repr(m))
#> ConstrainedExample(constrained_float=1.1)

try:
ConstrainedExample(constrained_float=0.9)
except ValidationError as e:
print(e.errors())
'''
[
{
'type': 'greater_than',
'loc': ('constrained_float',),
'msg': 'Input should be greater than 1',
'input': 0.9,
'ctx': {'gt': 1.0},
'url': 'https://errors.pydantic.dev/2/v/greater_than',
}
]
'''
```

**Line:** 388

---

### `def conbytes(min_length: int | None = None, max_length: int | None = None, strict: bool | None = None) -> type[bytes]`

**Description:**
A wrapper around `bytes` that allows for additional constraints.

Args:
min_length: The minimum length of the bytes.
max_length: The maximum length of the bytes.
strict: Whether to validate the bytes in strict mode.

Returns:
The wrapped bytes type.

**Line:** 640

---

### `def constr(strip_whitespace: bool | None = None, to_upper: bool | None = None, to_lower: bool | None = None, strict: bool | None = None, min_length: int | None = None, max_length: int | None = None, pattern: str | None = None) -> type[str]`

**Description:**
!!! warning "Discouraged"
This function is **discouraged** in favor of using
[`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated) with
[`StringConstraints`][pydantic.types.StringConstraints] instead.

This function will be **deprecated** in Pydantic 3.0.

The reason is that `constr` returns a type, which doesn't play well with static analysis tools.

=== ":x: Don't do this"
```py
from pydantic import BaseModel, constr

class Foo(BaseModel):
bar: constr(strip_whitespace=True, to_upper=True, pattern=r'^[A-Z]+$')
```

=== ":white_check_mark: Do this"
```py
from typing_extensions import Annotated

from pydantic import BaseModel, StringConstraints

class Foo(BaseModel):
bar: Annotated[str, StringConstraints(strip_whitespace=True, to_upper=True, pattern=r'^[A-Z]+$')]
```

A wrapper around `str` that allows for additional constraints.

```py
from pydantic import BaseModel, constr

class Foo(BaseModel):
bar: constr(strip_whitespace=True, to_upper=True, pattern=r'^[A-Z]+$')


foo = Foo(bar='  hello  ')
print(foo)
#> bar='HELLO'
```

Args:
strip_whitespace: Whether to remove leading and trailing whitespace.
to_upper: Whether to turn all characters to uppercase.
to_lower: Whether to turn all characters to lowercase.
strict: Whether to validate the string in strict mode.
min_length: The minimum length of the string.
max_length: The maximum length of the string.
pattern: A regex pattern to validate the string against.

Returns:
The wrapped string type.

**Line:** 715

---

### `def conset(item_type: type[HashableItemType], min_length: int | None = None, max_length: int | None = None) -> type[set[HashableItemType]]`

**Description:**
A wrapper around `typing.Set` that allows for additional constraints.

Args:
item_type: The type of the items in the set.
min_length: The minimum length of the set.
max_length: The maximum length of the set.

Returns:
The wrapped set type.

**Line:** 801

---

### `def confrozenset(item_type: type[HashableItemType], min_length: int | None = None, max_length: int | None = None) -> type[frozenset[HashableItemType]]`

**Description:**
A wrapper around `typing.FrozenSet` that allows for additional constraints.

Args:
item_type: The type of the items in the frozenset.
min_length: The minimum length of the frozenset.
max_length: The maximum length of the frozenset.

Returns:
The wrapped frozenset type.

**Line:** 817

---

### `def conlist(item_type: type[AnyItemType], min_length: int | None = None, max_length: int | None = None, unique_items: bool | None = None) -> type[list[AnyItemType]]`

**Description:**
A wrapper around typing.List that adds validation.

Args:
item_type: The type of the items in the list.
min_length: The minimum length of the list. Defaults to None.
max_length: The maximum length of the list. Defaults to None.
unique_items: Whether the items in the list must be unique. Defaults to None.
!!! warning Deprecated
The `unique_items` parameter is deprecated, use `Set` instead.
See [this issue](https://github.com/pydantic/pydantic-core/issues/296) for more details.

Returns:
The wrapped list type.

**Line:** 836

---

### `def condecimal(strict: bool | None = None, gt: int | Decimal | None = None, ge: int | Decimal | None = None, lt: int | Decimal | None = None, le: int | Decimal | None = None, multiple_of: int | Decimal | None = None, max_digits: int | None = None, decimal_places: int | None = None, allow_inf_nan: bool | None = None) -> type[Decimal]`

**Description:**
!!! warning "Discouraged"
This function is **discouraged** in favor of using
[`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated) with
[`Field`][pydantic.fields.Field] instead.

This function will be **deprecated** in Pydantic 3.0.

The reason is that `condecimal` returns a type, which doesn't play well with static analysis tools.

=== ":x: Don't do this"
```py
from pydantic import BaseModel, condecimal

class Foo(BaseModel):
bar: condecimal(strict=True, allow_inf_nan=True)
```

=== ":white_check_mark: Do this"
```py
from decimal import Decimal

from typing_extensions import Annotated

from pydantic import BaseModel, Field

class Foo(BaseModel):
bar: Annotated[Decimal, Field(strict=True, allow_inf_nan=True)]
```

A wrapper around Decimal that adds validation.

Args:
strict: Whether to validate the value in strict mode. Defaults to `None`.
gt: The value must be greater than this. Defaults to `None`.
ge: The value must be greater than or equal to this. Defaults to `None`.
lt: The value must be less than this. Defaults to `None`.
le: The value must be less than or equal to this. Defaults to `None`.
multiple_of: The value must be a multiple of this. Defaults to `None`.
max_digits: The maximum number of digits. Defaults to `None`.
decimal_places: The number of decimal places. Defaults to `None`.
allow_inf_nan: Whether to allow infinity and NaN. Defaults to `None`.

```py
from decimal import Decimal

from pydantic import BaseModel, ValidationError, condecimal

class ConstrainedExample(BaseModel):
constrained_decimal: condecimal(gt=Decimal('1.0'))

m = ConstrainedExample(constrained_decimal=Decimal('1.1'))
print(repr(m))
#> ConstrainedExample(constrained_decimal=Decimal('1.1'))

try:
ConstrainedExample(constrained_decimal=Decimal('0.9'))
except ValidationError as e:
print(e.errors())
'''
[
{
'type': 'greater_than',
'loc': ('constrained_decimal',),
'msg': 'Input should be greater than 1.0',
'input': Decimal('0.9'),
'ctx': {'gt': Decimal('1.0')},
'url': 'https://errors.pydantic.dev/2/v/greater_than',
}
]
'''
```

**Line:** 981

---

### `def _secret_display(value: str | bytes) -> str`

**Line:** 1507

---

### `def _check_annotated_type(annotated_type: str, expected_type: str, annotation: str) -> None`

**Line:** 1813

---

### `def condate(strict: bool | None = None, gt: date | None = None, ge: date | None = None, lt: date | None = None, le: date | None = None) -> type[date]`

**Description:**
A wrapper for date that adds constraints.

Args:
strict: Whether to validate the date value in strict mode. Defaults to `None`.
gt: The value must be greater than this. Defaults to `None`.
ge: The value must be greater than or equal to this. Defaults to `None`.
lt: The value must be less than this. Defaults to `None`.
le: The value must be less than or equal to this. Defaults to `None`.

Returns:
A date type with the specified constraints.

**Line:** 1862

---

### `def _get_type_name(x: Any) -> str`

**Line:** 2698

---


## Module: venv2.libthon3.12.site-packagesdantic.v1._hypothesis_plugin
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/_hypothesis_plugin.py`

**Imports:**
- contextlib
- datetime
- email_validator
- fractions.Fraction
- hypothesis.strategies
- ipaddress
- json
- math
- pydantic
- pydantic.color
- pydantic.types
- pydantic.utils.lenient_issubclass
- typing.Callable
- typing.Dict
- typing.Type
- typing.Union
- typing.cast
- typing.overload

**Functions:**

### `def is_valid_email(s: str) -> bool`

**Line:** 58

---

### `def add_luhn_digit(card_number: str) -> str`

**Line:** 122

---

### `def _registered(typ: Type[pydantic.types.T]) -> Type[pydantic.types.T]`

**Decorators:**
- `@overload`

**Line:** 185

---

### `def _registered(typ: pydantic.types.ConstrainedNumberMeta) -> pydantic.types.ConstrainedNumberMeta`

**Decorators:**
- `@overload`

**Line:** 190

---

### `def _registered(typ: Union[(Type[pydantic.types.T], pydantic.types.ConstrainedNumberMeta)]) -> Union[(Type[pydantic.types.T], pydantic.types.ConstrainedNumberMeta)]`

**Line:** 194

---

### `def resolves(typ: Union[(type, pydantic.types.ConstrainedNumberMeta)]) -> Callable[([Callable[..., st.SearchStrategy]], Callable[..., st.SearchStrategy])]`

**Line:** 208

---

### `def resolve_json(cls)`

**Decorators:**
- `@resolves(...)`

**Line:** 223

---

### `def resolve_conbytes(cls)`

**Decorators:**
- `@resolves(...)`

**Line:** 243

---

### `def resolve_condecimal(cls)`

**Decorators:**
- `@resolves(...)`

**Line:** 264

---

### `def resolve_confloat(cls)`

**Decorators:**
- `@resolves(...)`

**Line:** 282

---

### `def resolve_conint(cls)`

**Decorators:**
- `@resolves(...)`

**Line:** 314

---

### `def resolve_condate(cls)`

**Decorators:**
- `@resolves(...)`

**Line:** 337

---

### `def resolve_constr(cls)`

**Decorators:**
- `@resolves(...)`

**Line:** 356

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.annotated_types
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/annotated_types.py`

**Imports:**
- fields.Required
- main.BaseModel
- main.create_model
- sys
- typing.Any
- typing.Dict
- typing.FrozenSet
- typing.NamedTuple
- typing.TYPE_CHECKING
- typing.Type
- typing.is_typeddict
- typing.is_typeddict_special
- typing_extensions.TypedDict

**Functions:**

### `def is_legacy_typeddict(typeddict_cls: Type['TypedDict']) -> bool`

**Line:** 13

---

### `def is_legacy_typeddict(_: Any) -> Any`

**Line:** 18

---

### `def create_model_from_typeddict(typeddict_cls: Type['TypedDict'], **kwargs: Any) -> Type['BaseModel']`

**Description:**
Create a `BaseModel` based on the fields of a `TypedDict`.
Since `typing.TypedDict` in Python 3.8 does not store runtime information about optional keys,
we raise an error if this happens (see https://bugs.python.org/issue38834).

**Line:** 22

---

### `def create_model_from_namedtuple(namedtuple_cls: Type['NamedTuple'], **kwargs: Any) -> Type['BaseModel']`

**Description:**
Create a `BaseModel` based on the fields of a named tuple.
A named tuple can be created with `typing.NamedTuple` and declared annotations
but also with `collections.namedtuple`, in this case we consider all fields
to have type `Any`.

**Line:** 58

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.class_validators
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/class_validators.py`

**Imports:**
- collections.ChainMap
- config.BaseConfig
- errors.ConfigError
- fields.ModelField
- functools.partial
- functools.partialmethod
- functools.wraps
- inspect.Signature
- inspect.signature
- itertools.chain
- types.FunctionType
- types.ModelOrDc
- typing.Any
- typing.AnyCallable
- typing.AnyClassMethod
- typing.Callable
- typing.Dict
- typing.Iterable
- typing.List
- typing.Optional
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.Union
- typing.overload
- utils.ROOT_KEY
- utils.in_ipython
- warnings

**Functions:**

### `def validator(pre: bool = False, each_item: bool = False, always: bool = False, check_fields: bool = True, whole: Optional[bool] = None, allow_reuse: bool = False, *fields: str) -> Callable[([AnyCallable], 'AnyClassMethod')]`

**Description:**
Decorate methods on the class indicating that they should be used to validate fields
:param fields: which field(s) the method should be called on
:param pre: whether or not this validator should be called before the standard validators (else after)
:param each_item: for complex objects (sets, lists etc.) whether to validate individual elements rather than the
whole object
:param always: whether this method and other validators should be called even if the value is missing
:param check_fields: whether to check that the fields actually exist on the model
:param allow_reuse: whether to track and raise an error if another validator refers to the decorated function

**Line:** 52

---

### `def root_validator(_func: AnyCallable) -> 'AnyClassMethod'`

**Decorators:**
- `@overload`

**Line:** 108

---

### `def root_validator(pre: bool = False, allow_reuse: bool = False, skip_on_failure: bool = False) -> Callable[([AnyCallable], 'AnyClassMethod')]`

**Decorators:**
- `@overload`

**Line:** 113

---

### `def root_validator(_func: Optional[AnyCallable] = None, pre: bool = False, allow_reuse: bool = False, skip_on_failure: bool = False) -> Union[('AnyClassMethod', Callable[[AnyCallable], 'AnyClassMethod'])]`

**Description:**
Decorate methods on a model indicating that they should be used to validate (and perhaps modify) data either
before or after standard model parsing/validation is performed.

**Line:** 119

---

### `def _prepare_validator(function: AnyCallable, allow_reuse: bool) -> 'AnyClassMethod'`

**Description:**
Avoid validators with duplicated names since without this, validators can be overwritten silently
which generally isn't the intended behaviour, don't run in ipython (see #312) or if allow_reuse is False.

**Line:** 143

---

### `def extract_validators(namespace: Dict[(str, Any)]) -> Dict[(str, List[Validator])]`

**Line:** 195

---

### `def extract_root_validators(namespace: Dict[(str, Any)]) -> Tuple[(List[AnyCallable], List[Tuple[bool, AnyCallable]])]`

**Line:** 209

---

### `def inherit_validators(base_validators: 'ValidatorListDict', validators: 'ValidatorListDict') -> 'ValidatorListDict'`

**Line:** 234

---

### `def make_generic_validator(validator: AnyCallable) -> 'ValidatorCallable'`

**Description:**
Make a generic function which calls a validator with the right arguments.

Unfortunately other approaches (eg. return a partial of a function that builds the arguments) is slow,
hence this laborious way of doing things.

It's done like this so validators don't all need **kwargs in their signature, eg. any combination of
the arguments "values", "fields" and/or "config" are permitted.

**Line:** 242

---

### `def prep_validators(v_funcs: Iterable[AnyCallable]) -> 'ValidatorsList'`

**Line:** 281

---

### `def _generic_validator_cls(validator: AnyCallable, sig: 'Signature', args: Set[str]) -> 'ValidatorCallable'`

**Line:** 288

---

### `def _generic_validator_basic(validator: AnyCallable, sig: 'Signature', args: Set[str]) -> 'ValidatorCallable'`

**Line:** 322

---

### `def gather_all_validators(type_: 'ModelOrDc') -> Dict[(str, 'AnyClassMethod')]`

**Line:** 355

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.color
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/color.py`

**Imports:**
- colorsys.hls_to_rgb
- colorsys.rgb_to_hls
- errors.ColorError
- math
- re
- typing.Any
- typing.CallableGenerator
- typing.Dict
- typing.Optional
- typing.ReprArgs
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- typing.cast
- utils.Representation
- utils.almost_equal_floats

**Functions:**

### `def parse_tuple(value: Tuple[(Any, ...)]) -> RGBA`

**Description:**
Parse a tuple or list as a color.

**Line:** 208

---

### `def parse_str(value: str) -> RGBA`

**Description:**
Parse a string to an RGBA tuple, trying the following formats (in this order):
* named color, see COLORS_BY_NAME below
* hex short eg. `<prefix>fff` (prefix can be `#`, `0x` or nothing)
* hex long eg. `<prefix>ffffff` (prefix can be `#`, `0x` or nothing)
* `rgb(<r>, <g>, <b>) `
* `rgba(<r>, <g>, <b>, <a>)`

**Line:** 222

---

### `def ints_to_rgba(r: Union[(int, str)], g: Union[(int, str)], b: Union[(int, str)], alpha: Optional[float]) -> RGBA`

**Line:** 280

---

### `def parse_color_value(value: Union[(int, str)], max_val: int = 255) -> float`

**Description:**
Parse a value checking it's a valid int in the range 0 to max_val and divide by max_val to give a number
in the range 0 to 1

**Line:** 284

---

### `def parse_float_alpha(value: Union[(None, str, float, int)]) -> Optional[float]`

**Description:**
Parse a value checking it's a valid float in the range 0 to 1

**Line:** 299

---

### `def parse_hsl(h: str, h_units: str, sat: str, light: str, alpha: Optional[float] = None) -> RGBA`

**Description:**
Parse raw hue, saturation, lightness and alpha values and convert to RGBA.

**Line:** 321

---

### `def float_to_255(c: float) -> int`

**Line:** 340

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.config
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/config.py`

**Imports:**
- enum.Enum
- fields.ModelField
- json
- main.BaseModel
- typing.Any
- typing.AnyArgTCallable
- typing.AnyCallable
- typing.Callable
- typing.Dict
- typing.ForwardRef
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.Union
- typing.overload
- typing_extensions.Literal
- typing_extensions.Protocol
- typing_extensions.TypedDict
- utils.GetterDict
- version.compiled

**Functions:**

### `def get_config(config: Union[(ConfigDict, Type[object], None)]) -> Type[BaseConfig]`

**Line:** 150

---

### `def inherit_config(self_config: 'ConfigType', parent_config: 'ConfigType', **namespace: Any) -> 'ConfigType'`

**Line:** 169

---

### `def prepare_config(config: Type[BaseConfig], cls_name: str) -> None`

**Line:** 186

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.dataclasses
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/dataclasses.py`

**Imports:**
- class_validators.gather_all_validators
- config.BaseConfig
- config.ConfigDict
- config.Extra
- config.get_config
- contextlib.contextmanager
- copy
- dataclasses
- error_wrappers.ValidationError
- errors.DataclassTypeError
- fields.Field
- fields.FieldInfo
- fields.Required
- fields.Undefined
- functools.wraps
- main.BaseModel
- main.create_model
- main.validate_model
- sys
- typing.Any
- typing.Callable
- typing.CallableGenerator
- typing.ClassVar
- typing.Dict
- typing.Generator
- typing.NoArgAnyCallable
- typing.Optional
- typing.TYPE_CHECKING
- typing.Type
- typing.TypeVar
- typing.Union
- typing.overload
- typing_extensions.dataclass_transform
- utils.ClassAttribute

**Functions:**

### `def dataclass(init: bool = True, repr: bool = True, eq: bool = True, order: bool = False, unsafe_hash: bool = False, frozen: bool = False, config: Union[(ConfigDict, Type[object], None)] = None, validate_on_init: Optional[bool] = None, use_proxy: Optional[bool] = None, kw_only: bool = Ellipsis) -> Callable[([Type[_T]], 'DataclassClassOrWrapper')]`

**Decorators:**
- `@dataclass_transform(...)`
- `@overload`

**Line:** 99

---

### `def dataclass(_cls: Type[_T], init: bool = True, repr: bool = True, eq: bool = True, order: bool = False, unsafe_hash: bool = False, frozen: bool = False, config: Union[(ConfigDict, Type[object], None)] = None, validate_on_init: Optional[bool] = None, use_proxy: Optional[bool] = None, kw_only: bool = Ellipsis) -> 'DataclassClassOrWrapper'`

**Decorators:**
- `@dataclass_transform(...)`
- `@overload`

**Line:** 116

---

### `def dataclass(init: bool = True, repr: bool = True, eq: bool = True, order: bool = False, unsafe_hash: bool = False, frozen: bool = False, config: Union[(ConfigDict, Type[object], None)] = None, validate_on_init: Optional[bool] = None, use_proxy: Optional[bool] = None) -> Callable[([Type[_T]], 'DataclassClassOrWrapper')]`

**Decorators:**
- `@dataclass_transform(...)`
- `@overload`

**Line:** 136

---

### `def dataclass(_cls: Type[_T], init: bool = True, repr: bool = True, eq: bool = True, order: bool = False, unsafe_hash: bool = False, frozen: bool = False, config: Union[(ConfigDict, Type[object], None)] = None, validate_on_init: Optional[bool] = None, use_proxy: Optional[bool] = None) -> 'DataclassClassOrWrapper'`

**Decorators:**
- `@dataclass_transform(...)`
- `@overload`

**Line:** 152

---

### `def dataclass(_cls: Optional[Type[_T]] = None, init: bool = True, repr: bool = True, eq: bool = True, order: bool = False, unsafe_hash: bool = False, frozen: bool = False, config: Union[(ConfigDict, Type[object], None)] = None, validate_on_init: Optional[bool] = None, use_proxy: Optional[bool] = None, kw_only: bool = False) -> Union[(Callable[[Type[_T]], 'DataclassClassOrWrapper'], 'DataclassClassOrWrapper')]`

**Decorators:**
- `@dataclass_transform(...)`

**Description:**
Like the python standard lib dataclasses but with type validation.
The result is either a pydantic dataclass that will validate input data
or a wrapper that will trigger validation around a stdlib dataclass
to avoid modifying it directly

**Line:** 169

---

### `def set_validation(cls: Type['DataclassT'], value: bool) -> Generator[(Type['DataclassT'], None, None)]`

**Decorators:**
- `@contextmanager`

**Line:** 235

---

### `def _add_pydantic_validation_attributes(dc_cls: Type['Dataclass'], config: Type[BaseConfig], validate_on_init: bool, dc_cls_doc: str) -> None`

**Description:**
We need to replace the right method. If no `__post_init__` has been set in the stdlib dataclass
it won't even exist (code is generated on the fly by `dataclasses`)
By default, we run validation after `__init__` or `__post_init__` if defined

**Line:** 270

---

### `def _get_validators(cls: 'DataclassClassOrWrapper') -> 'CallableGenerator'`

**Line:** 356

---

### `def _validate_dataclass(cls: Type['DataclassT'], v: Any) -> 'DataclassT'`

**Line:** 360

---

### `def create_pydantic_model_from_dataclass(dc_cls: Type['Dataclass'], config: Type[Any] = BaseConfig, dc_cls_doc: Optional[str] = None) -> Type['BaseModel']`

**Line:** 373

---

### `def _dataclass_validate_values(self: 'Dataclass') -> None`

**Line:** 412

---

### `def _dataclass_validate_assignment_setattr(self: 'Dataclass', name: str, value: Any) -> None`

**Line:** 430

---

### `def is_builtin_dataclass(_cls: Type[Any]) -> bool`

**Description:**
Whether a class is a stdlib dataclass
(useful to discriminated a pydantic dataclass that is actually a wrapper around a stdlib dataclass)

we check that
- `_cls` is a dataclass
- `_cls` is not a processed pydantic dataclass (with a basemodel attached)
- `_cls` is not a pydantic dataclass inheriting directly from a stdlib dataclass
e.g.
```
@dataclasses.dataclass
class A:
x: int

@pydantic.dataclasses.dataclass
class B(A):
y: int
```
In this case, when we first check `B`, we make an extra check and look at the annotations ('y'),
which won't be a superset of all the dataclass fields (only the stdlib fields i.e. 'x')

**Line:** 443

---

### `def make_dataclass_validator(dc_cls: Type['Dataclass'], config: Type[BaseConfig]) -> 'CallableGenerator'`

**Description:**
Create a pydantic.dataclass from a builtin dataclass to add type validation
and yield the validators
It retrieves the parameters of the dataclass and forwards them to the newly created dataclass

**Line:** 472

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.datetime_parse
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/datetime_parse.py`

**Imports:**
- datetime.date
- datetime.datetime
- datetime.time
- datetime.timedelta
- datetime.timezone
- re
- typing.Dict
- typing.Optional
- typing.Type
- typing.Union

**Functions:**

### `def get_numeric(value: StrBytesIntFloat, native_expected_type: str) -> Union[(None, int, float)]`

**Line:** 66

---

### `def from_unix_seconds(seconds: Union[(int, float)]) -> datetime`

**Line:** 77

---

### `def _parse_timezone(value: Optional[str], error: Type[Exception]) -> Union[(None, int, timezone)]`

**Line:** 89

---

### `def parse_date(value: Union[(date, StrBytesIntFloat)]) -> date`

**Description:**
Parse a date/int/float/string and return a datetime.date.

Raise ValueError if the input is well formatted but not a valid date.
Raise ValueError if the input isn't well formatted.

**Line:** 105

---

### `def parse_time(value: Union[(time, StrBytesIntFloat)]) -> time`

**Description:**
Parse a time/string and return a datetime.time.

Raise ValueError if the input is well formatted but not a valid time.
Raise ValueError if the input isn't well formatted, in particular if it contains an offset.

**Line:** 137

---

### `def parse_datetime(value: Union[(datetime, StrBytesIntFloat)]) -> datetime`

**Description:**
Parse a datetime/int/float/string and return a datetime.datetime.

This function supports time zone offsets. When the input contains one,
the output uses a timezone with a fixed offset from UTC.

Raise ValueError if the input is well formatted but not a valid datetime.
Raise ValueError if the input isn't well formatted.

**Line:** 175

---

### `def parse_duration(value: StrBytesIntFloat) -> timedelta`

**Description:**
Parse a duration int/float/string and return a datetime.timedelta.

The preferred format for durations in Django is '%d %H:%M:%S.%f'.

Also supports ISO 8601 representation.

**Line:** 213

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.decorator
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/decorator.py`

**Imports:**
- config.Extra
- errors.ConfigError
- functools.wraps
- inspect.Parameter
- inspect.signature
- main.BaseModel
- main.create_model
- typing.Any
- typing.AnyCallable
- typing.Callable
- typing.Dict
- typing.List
- typing.Mapping
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.get_all_type_hints
- typing.overload
- utils.to_camel

**Functions:**

### `def validate_arguments(func: None = None, config: 'ConfigType' = None) -> Callable[(['AnyCallableT'], 'AnyCallableT')]`

**Decorators:**
- `@overload`

**Line:** 21

---

### `def validate_arguments(func: 'AnyCallableT') -> 'AnyCallableT'`

**Decorators:**
- `@overload`

**Line:** 26

---

### `def validate_arguments(func: Optional['AnyCallableT'] = None, config: 'ConfigType' = None) -> Any`

**Description:**
Decorator to validate the arguments passed to a function.

**Line:** 30

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.env_settings
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/env_settings.py`

**Imports:**
- config.BaseConfig
- config.Extra
- dotenv.dotenv_values
- fields.ModelField
- main.BaseModel
- os
- pathlib.Path
- types.JsonWrapper
- typing.AbstractSet
- typing.Any
- typing.Callable
- typing.ClassVar
- typing.Dict
- typing.List
- typing.Mapping
- typing.Optional
- typing.StrPath
- typing.Tuple
- typing.Type
- typing.Union
- typing.display_as_type
- typing.get_origin
- typing.is_union
- utils.deep_update
- utils.lenient_issubclass
- utils.path_type
- utils.sequence_like
- warnings

**Functions:**

### `def read_env_file(file_path: StrPath, encoding: str = None, case_sensitive: bool = False) -> Dict[(str, Optional[str])]`

**Line:** 326

---

### `def find_case_path(dir_path: Path, file_name: str, case_sensitive: bool) -> Optional[Path]`

**Description:**
Find a file within path's directory matching filename, optionally ignoring case.

**Line:** 341

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.error_wrappers
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/error_wrappers.py`

**Imports:**
- config.BaseConfig
- json
- json.pydantic_encoder
- types.ModelOrDc
- typing.Any
- typing.Dict
- typing.Generator
- typing.List
- typing.Optional
- typing.ReprArgs
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.Union
- typing_extensions.TypedDict
- utils.Representation

**Functions:**

### `def display_errors(errors: List['ErrorDict']) -> str`

**Line:** 82

---

### `def _display_error_loc(error: 'ErrorDict') -> str`

**Line:** 86

---

### `def _display_error_type_and_ctx(error: 'ErrorDict') -> str`

**Line:** 90

---

### `def flatten_errors(errors: Sequence[Any], config: Type['BaseConfig'], loc: Optional['Loc'] = None) -> Generator[('ErrorDict', None, None)]`

**Line:** 99

---

### `def error_dict(exc: Exception, config: Type['BaseConfig'], loc: 'Loc') -> 'ErrorDict'`

**Line:** 120

---

### `def get_exc_type(cls: Type[Exception]) -> str`

**Line:** 140

---

### `def _get_exc_type(cls: Type[Exception]) -> str`

**Line:** 150

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.errors
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/errors.py`

**Imports:**
- decimal.Decimal
- pathlib.Path
- typing.Any
- typing.Callable
- typing.DictStrAny
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.Union
- typing.display_as_type

**Functions:**

### `def cls_kwargs(cls: Type['PydanticErrorMixin'], ctx: 'DictStrAny') -> 'PydanticErrorMixin'`

**Description:**
For built-in exceptions like ValueError or TypeError, we need to implement
__reduce__ to override the default behaviour (instead of __getstate__/__setstate__)
By default pickle protocol 2 calls `cls.__new__(cls, *args)`.
Since we only use kwargs, we need a little constructor to change that.
Note: the callable can't be a lambda as pickle looks in the namespace to find it

**Line:** 108

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.fields
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/fields.py`

**Imports:**
- class_validators.Validator
- class_validators.ValidatorsList
- class_validators.make_generic_validator
- class_validators.prep_validators
- collections.Counter
- collections.abc.Callable
- collections.abc.Hashable
- collections.abc.Iterable
- collections.defaultdict
- collections.deque
- config.BaseConfig
- copy
- error_wrappers.ErrorList
- error_wrappers.ErrorWrapper
- errors.ConfigError
- errors.InvalidDiscriminator
- errors.MissingDiscriminator
- errors.NoneIsNotAllowedError
- main.BaseModel
- re
- schema.get_annotation_from_field_info
- types.Json
- types.JsonWrapper
- types.ModelOrDc
- typing.AbstractSetIntStr
- typing.Any
- typing.Counter
- typing.DefaultDict
- typing.Deque
- typing.Dict
- typing.ForwardRef
- typing.FrozenSet
- typing.Generator
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.MappingIntStrAny
- typing.NoArgAnyCallable
- typing.Optional
- typing.Pattern
- typing.ReprArgs
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.convert_generics
- typing.display_as_type
- typing.get_args
- typing.get_origin
- typing.is_finalvar
- typing.is_literal_type
- typing.is_new_type
- typing.is_none_type
- typing.is_typeddict
- typing.is_typeddict_special
- typing.is_union
- typing.new_type_supertype
- typing_extensions.Annotated
- typing_extensions.Final
- utils.PyObjectStr
- utils.Representation
- utils.ValueItems
- utils.get_discriminator_alias_and_values
- utils.get_unique_discriminator_alias
- utils.lenient_isinstance
- utils.lenient_issubclass
- utils.sequence_like
- utils.smart_deepcopy
- validators.constant_validator
- validators.dict_validator
- validators.find_validators
- validators.validate_json

**Functions:**

### `def Field(default: Any = Undefined, default_factory: Optional[NoArgAnyCallable] = None, alias: Optional[str] = None, title: Optional[str] = None, description: Optional[str] = None, exclude: Optional[Union[('AbstractSetIntStr', 'MappingIntStrAny', Any)]] = None, include: Optional[Union[('AbstractSetIntStr', 'MappingIntStrAny', Any)]] = None, const: Optional[bool] = None, gt: Optional[float] = None, ge: Optional[float] = None, lt: Optional[float] = None, le: Optional[float] = None, multiple_of: Optional[float] = None, allow_inf_nan: Optional[bool] = None, max_digits: Optional[int] = None, decimal_places: Optional[int] = None, min_items: Optional[int] = None, max_items: Optional[int] = None, unique_items: Optional[bool] = None, min_length: Optional[int] = None, max_length: Optional[int] = None, allow_mutation: bool = True, regex: Optional[str] = None, discriminator: Optional[str] = None, repr: bool = True, **extra: Any) -> Any`

**Description:**
Used to provide extra information about a field, either for the model schema or complex validation. Some arguments
apply only to number fields (``int``, ``float``, ``Decimal``) and some apply only to ``str``.

:param default: since this is replacing the fields default, its first argument is used
to set the default, use ellipsis (``...``) to indicate the field is required
:param default_factory: callable that will be called when a default value is needed for this field
If both `default` and `default_factory` are set, an error is raised.
:param alias: the public name of the field
:param title: can be any string, used in the schema
:param description: can be any string, used in the schema
:param exclude: exclude this field while dumping.
Takes same values as the ``include`` and ``exclude`` arguments on the ``.dict`` method.
:param include: include this field while dumping.
Takes same values as the ``include`` and ``exclude`` arguments on the ``.dict`` method.
:param const: this field is required and *must* take it's default value
:param gt: only applies to numbers, requires the field to be "greater than". The schema
will have an ``exclusiveMinimum`` validation keyword
:param ge: only applies to numbers, requires the field to be "greater than or equal to". The
schema will have a ``minimum`` validation keyword
:param lt: only applies to numbers, requires the field to be "less than". The schema
will have an ``exclusiveMaximum`` validation keyword
:param le: only applies to numbers, requires the field to be "less than or equal to". The
schema will have a ``maximum`` validation keyword
:param multiple_of: only applies to numbers, requires the field to be "a multiple of". The
schema will have a ``multipleOf`` validation keyword
:param allow_inf_nan: only applies to numbers, allows the field to be NaN or infinity (+inf or -inf),
which is a valid Python float. Default True, set to False for compatibility with JSON.
:param max_digits: only applies to Decimals, requires the field to have a maximum number
of digits within the decimal. It does not include a zero before the decimal point or trailing decimal zeroes.
:param decimal_places: only applies to Decimals, requires the field to have at most a number of decimal places
allowed. It does not include trailing decimal zeroes.
:param min_items: only applies to lists, requires the field to have a minimum number of
elements. The schema will have a ``minItems`` validation keyword
:param max_items: only applies to lists, requires the field to have a maximum number of
elements. The schema will have a ``maxItems`` validation keyword
:param unique_items: only applies to lists, requires the field not to have duplicated
elements. The schema will have a ``uniqueItems`` validation keyword
:param min_length: only applies to strings, requires the field to have a minimum length. The
schema will have a ``minLength`` validation keyword
:param max_length: only applies to strings, requires the field to have a maximum length. The
schema will have a ``maxLength`` validation keyword
:param allow_mutation: a boolean which defaults to True. When False, the field raises a TypeError if the field is
assigned on an instance.  The BaseModel Config must set validate_assignment to True
:param regex: only applies to strings, requires the field match against a regular expression
pattern string. The schema will have a ``pattern`` validation keyword
:param discriminator: only useful with a (discriminated a.k.a. tagged) `Union` of sub models with a common field.
The `discriminator` is the name of this common field to shorten validation and improve generated schema
:param repr: show this field in the representation
:param **extra: any additional keyword arguments will be added as is to the schema

**Line:** 222

---

### `def PrivateAttr(default: Any = Undefined, default_factory: Optional[NoArgAnyCallable] = None) -> Any`

**Description:**
Indicates that attribute is only used internally and never mixed with regular fields.

Types or values of private attrs are not checked by pydantic and it's up to you to keep them relevant.

Private attrs are stored in model __slots__.

:param default: the attributes default value
:param default_factory: callable that will be called when a default value is needed for this attribute
If both `default` and `default_factory` are set, an error is raised.

**Line:** 1224

---

### `def is_finalvar_with_default_val(type_: Type[Any], val: Any) -> bool`

**Line:** 1255

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.generics
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/generics.py`

**Imports:**
- class_validators.gather_all_validators
- fields.DeferredType
- main.BaseModel
- main.create_model
- sys
- types
- types.JsonWrapper
- typing
- typing.Any
- typing.ClassVar
- typing.Dict
- typing.ForwardRef
- typing.Generic
- typing.Iterator
- typing.List
- typing.Literal
- typing.Mapping
- typing.Optional
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing._UnionGenericAlias
- typing.cast
- typing.display_as_type
- typing.get_all_type_hints
- typing.get_args
- typing.get_origin
- typing.typing_base
- typing_extensions.Annotated
- typing_extensions.Literal
- utils.all_identical
- utils.lenient_issubclass
- weakref.WeakKeyDictionary
- weakref.WeakValueDictionary

**Functions:**

### `def replace_types(type_: Any, type_map: Mapping[(Any, Any)]) -> Any`

**Description:**
Return type with all occurrences of `type_map` keys recursively replaced with their values.

:param type_: Any type, class or generic alias
:param type_map: Mapping from `TypeVar` instance to concrete types.
:return: New type representing the basic structure of `type_` with all
`typevar_map` keys recursively replaced.

>>> replace_types(Tuple[str, Union[List[str], float]], {str: int})
Tuple[int, Union[List[int], float]]

**Line:** 251

---

### `def check_parameters_count(cls: Type[GenericModel], parameters: Tuple[(Any, ...)]) -> None`

**Line:** 333

---

### `def iter_contained_typevars(v: Any) -> Iterator[TypeVarType]`

**Description:**
Recursively iterate through all subtypes and type args of `v` and yield any typevars that are found.

**Line:** 344

---

### `def get_caller_frame_info() -> Tuple[(Optional[str], bool)]`

**Description:**
Used inside a function to check whether it was called globally

Will only work against non-compiled code, therefore used only in pydantic.generics

:returns Tuple[module_name, called_globally]

**Line:** 359

---

### `def _prepare_model_fields(created_model: Type[GenericModel], fields: Mapping[(str, Any)], instance_type_hints: Mapping[(str, type)], typevars_map: Mapping[(Any, type)]) -> None`

**Description:**
Replace DeferredType fields with concrete type hints and prepare them.

**Line:** 377

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.json
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/json.py`

**Imports:**
- collections.deque
- color.Color
- dataclasses.asdict
- dataclasses.is_dataclass
- datetime
- decimal.Decimal
- enum.Enum
- ipaddress.IPv4Address
- ipaddress.IPv4Interface
- ipaddress.IPv4Network
- ipaddress.IPv6Address
- ipaddress.IPv6Interface
- ipaddress.IPv6Network
- main.BaseModel
- networks.NameEmail
- pathlib.Path
- re.Pattern
- types.GeneratorType
- types.SecretBytes
- types.SecretStr
- typing.Any
- typing.Callable
- typing.Dict
- typing.Type
- typing.Union
- uuid.UUID

**Functions:**

### `def isoformat(o: Union[(datetime.date, datetime.time)]) -> str`

**Line:** 19

---

### `def decimal_encoder(dec_value: Decimal) -> Union[(int, float)]`

**Description:**
Encodes a Decimal as int of there's no exponent, otherwise float

This is useful when we use ConstrainedDecimal to represent Numeric(x,0)
where a integer (but not int typed) is used. Encoding this as a float
results in failed round-tripping between encode and parse.
Our Id type is a prime example of this.

>>> decimal_encoder(Decimal("1.0"))
1.0

>>> decimal_encoder(Decimal("1"))
1

**Line:** 23

---

### `def pydantic_encoder(obj: Any) -> Any`

**Line:** 72

---

### `def custom_pydantic_encoder(type_encoders: Dict[(Any, Callable[[Type[Any]], Any])], obj: Any) -> Any`

**Line:** 93

---

### `def timedelta_isoformat(td: datetime.timedelta) -> str`

**Description:**
ISO 8601 encoding for Python timedelta object.

**Line:** 106

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.main
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/main.py`

**Imports:**
- abc.ABCMeta
- class_validators.ValidatorGroup
- class_validators.ValidatorListDict
- class_validators.extract_root_validators
- class_validators.extract_validators
- class_validators.inherit_validators
- config.BaseConfig
- config.Extra
- config.inherit_config
- config.prepare_config
- copy.deepcopy
- enum.Enum
- error_wrappers.ErrorWrapper
- error_wrappers.ValidationError
- errors.ConfigError
- errors.DictError
- errors.ExtraError
- errors.MissingError
- fields.Field
- fields.MAPPING_LIKE_SHAPES
- fields.ModelField
- fields.ModelPrivateAttr
- fields.PrivateAttr
- fields.Undefined
- fields.is_finalvar_with_default_val
- functools.partial
- inspect.Signature
- json.custom_pydantic_encoder
- json.pydantic_encoder
- parse.Protocol
- parse.load_file
- parse.load_str_bytes
- pathlib.Path
- schema.default_ref_template
- schema.model_schema
- types.FunctionType
- types.ModelOrDc
- types.PyObject
- types.StrBytes
- types.prepare_class
- types.resolve_bases
- typing.AbstractSet
- typing.AbstractSetIntStr
- typing.Any
- typing.AnyCallable
- typing.AnyClassMethod
- typing.Callable
- typing.CallableGenerator
- typing.ClassVar
- typing.Dict
- typing.DictAny
- typing.DictStrAny
- typing.List
- typing.Mapping
- typing.MappingIntStrAny
- typing.Optional
- typing.ReprArgs
- typing.SetStr
- typing.TYPE_CHECKING
- typing.Tuple
- typing.TupleGenerator
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.get_args
- typing.get_origin
- typing.is_classvar
- typing.is_namedtuple
- typing.is_union
- typing.no_type_check
- typing.overload
- typing.resolve_annotations
- typing.update_model_forward_refs
- typing_extensions.dataclass_transform
- utils.ClassAttribute
- utils.DUNDER_ATTRIBUTES
- utils.GetterDict
- utils.ROOT_KEY
- utils.Representation
- utils.ValueItems
- utils.generate_model_signature
- utils.is_valid_field
- utils.is_valid_private_name
- utils.lenient_issubclass
- utils.sequence_like
- utils.smart_deepcopy
- utils.unique_list
- utils.validate_field_name
- warnings

**Functions:**

### `def validate_custom_root_type(fields: Dict[(str, ModelField)]) -> None`

**Line:** 97

---

### `def generate_hash_function(frozen: bool) -> Optional[Callable[([Any], int)]]`

**Line:** 102

---

### `def create_model(__model_name: str, __config__: Optional[Type[BaseConfig]] = None, __base__: None = None, __module__: str = __name__, __validators__: Dict[(str, 'AnyClassMethod')] = None, __cls_kwargs__: Dict[(str, Any)] = None, **field_definitions: Any) -> Type['BaseModel']`

**Decorators:**
- `@overload`

**Line:** 925

---

### `def create_model(__model_name: str, __config__: Optional[Type[BaseConfig]] = None, __base__: Union[(Type['Model'], Tuple[Type['Model'], ...])], __module__: str = __name__, __validators__: Dict[(str, 'AnyClassMethod')] = None, __cls_kwargs__: Dict[(str, Any)] = None, **field_definitions: Any) -> Type['Model']`

**Decorators:**
- `@overload`

**Line:** 939

---

### `def create_model(__model_name: str, __config__: Optional[Type[BaseConfig]] = None, __base__: Union[(None, Type['Model'], Tuple[Type['Model'], ...])] = None, __module__: str = __name__, __validators__: Dict[(str, 'AnyClassMethod')] = None, __cls_kwargs__: Dict[(str, Any)] = None, __slots__: Optional[Tuple[(str, ...)]] = None, **field_definitions: Any) -> Type['Model']`

**Description:**
Dynamically create a model.
:param __model_name: name of the created model
:param __config__: config class to use for the new model
:param __base__: base class for the new model to inherit from
:param __module__: module of the created model
:param __validators__: a dict of method names and @validator class methods
:param __cls_kwargs__: a dict for class creation
:param __slots__: Deprecated, `__slots__` should not be passed to `create_model`
:param field_definitions: fields of the model (or extra fields if a base is supplied)
in the format `<name>=(<type>, <default default>)` or `<name>=<default value>, e.g.
`foobar=(str, ...)` or `foobar=123`, or, for complex use-cases, in the format
`<name>=<Field>` or `<name>=(<type>, <FieldInfo>)`, e.g.
`foo=Field(datetime, default_factory=datetime.utcnow, alias='bar')` or
`foo=(str, FieldInfo(title='Foo'))`

**Line:** 952

---

### `def validate_model(model: Type[BaseModel], input_data: 'DictStrAny', cls: 'ModelOrDc' = None) -> Tuple[('DictStrAny', 'SetStr', Optional[ValidationError])]`

**Description:**
validate data against a model.

**Line:** 1032

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.mypy
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/mypy.py`

**Imports:**
- configparser.ConfigParser
- mypy.errorcodes.ErrorCode
- mypy.nodes.ARG_NAMED
- mypy.nodes.ARG_NAMED_OPT
- mypy.nodes.ARG_OPT
- mypy.nodes.ARG_POS
- mypy.nodes.ARG_STAR2
- mypy.nodes.Argument
- mypy.nodes.AssignmentStmt
- mypy.nodes.Block
- mypy.nodes.CallExpr
- mypy.nodes.ClassDef
- mypy.nodes.Context
- mypy.nodes.Decorator
- mypy.nodes.EllipsisExpr
- mypy.nodes.FuncBase
- mypy.nodes.FuncDef
- mypy.nodes.JsonDict
- mypy.nodes.MDEF
- mypy.nodes.MemberExpr
- mypy.nodes.NameExpr
- mypy.nodes.PassStmt
- mypy.nodes.PlaceholderNode
- mypy.nodes.RefExpr
- mypy.nodes.StrExpr
- mypy.nodes.SymbolNode
- mypy.nodes.SymbolTableNode
- mypy.nodes.TempNode
- mypy.nodes.TypeInfo
- mypy.nodes.TypeVarExpr
- mypy.nodes.Var
- mypy.options.Options
- mypy.plugin.CheckerPluginInterface
- mypy.plugin.ClassDefContext
- mypy.plugin.FunctionContext
- mypy.plugin.MethodContext
- mypy.plugin.Plugin
- mypy.plugin.ReportConfigContext
- mypy.plugin.SemanticAnalyzerPluginInterface
- mypy.plugins.dataclasses
- mypy.semanal.set_callable_name
- mypy.server.trigger.make_wildcard_trigger
- mypy.types.AnyType
- mypy.types.CallableType
- mypy.types.Instance
- mypy.types.NoneType
- mypy.types.Overloaded
- mypy.types.ProperType
- mypy.types.Type
- mypy.types.TypeOfAny
- mypy.types.TypeType
- mypy.types.TypeVarDef
- mypy.types.TypeVarType
- mypy.types.UnionType
- mypy.types.get_proper_type
- mypy.typevars.fill_typevars
- mypy.util.get_unique_redefinition_name
- mypy.version.__version__
- pydantic.utils.is_valid_field
- sys
- toml
- tomli
- tomllib
- typing.Any
- typing.Callable
- typing.Dict
- typing.List
- typing.Optional
- typing.Set
- typing.Tuple
- typing.Type
- typing.Union
- warnings

**Functions:**

### `def parse_mypy_version(version: str) -> Tuple[(int, ...)]`

**Line:** 86

---

### `def plugin(version: str) -> 'TypingType[Plugin]'`

**Description:**
`version` is the mypy version string

We might want to use this to print a warning if the mypy version being used is
newer, or especially older, than we expect (or need).

**Line:** 97

---

### `def from_orm_callback(ctx: MethodContext) -> Type`

**Description:**
Raise an error if orm_mode is not enabled

**Line:** 261

---

### `def error_from_orm(model_name: str, api: CheckerPluginInterface, context: Context) -> None`

**Line:** 789

---

### `def error_invalid_config_value(name: str, api: SemanticAnalyzerPluginInterface, context: Context) -> None`

**Line:** 793

---

### `def error_required_dynamic_aliases(api: SemanticAnalyzerPluginInterface, context: Context) -> None`

**Line:** 797

---

### `def error_unexpected_behavior(detail: str, api: Union[(CheckerPluginInterface, SemanticAnalyzerPluginInterface)], context: Context) -> None`

**Line:** 801

---

### `def error_untyped_fields(api: SemanticAnalyzerPluginInterface, context: Context) -> None`

**Line:** 811

---

### `def error_default_and_default_factory_specified(api: CheckerPluginInterface, context: Context) -> None`

**Line:** 815

---

### `def add_method(ctx: ClassDefContext, name: str, args: List[Argument], return_type: Type, self_type: Optional[Type] = None, tvar_def: Optional[TypeVarDef] = None, is_classmethod: bool = False, is_new: bool = False) -> None`

**Description:**
Adds a new method to a class.

This can be dropped if/when https://github.com/python/mypy/issues/7301 is merged

**Line:** 819

---

### `def get_fullname(x: Union[(FuncBase, SymbolNode)]) -> str`

**Description:**
Used for compatibility with mypy 0.740; can be dropped once support for 0.740 is dropped.

**Line:** 902

---

### `def get_name(x: Union[(FuncBase, SymbolNode)]) -> str`

**Description:**
Used for compatibility with mypy 0.740; can be dropped once support for 0.740 is dropped.

**Line:** 912

---

### `def parse_toml(config_file: str) -> Optional[Dict[(str, Any)]]`

**Line:** 922

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.networks
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/networks.py`

**Imports:**
- config.BaseConfig
- email_validator
- fields.ModelField
- ipaddress.IPv4Address
- ipaddress.IPv4Interface
- ipaddress.IPv4Network
- ipaddress.IPv6Address
- ipaddress.IPv6Interface
- ipaddress.IPv6Network
- ipaddress._BaseAddress
- ipaddress._BaseNetwork
- re
- typing.Any
- typing.AnyCallable
- typing.Collection
- typing.Dict
- typing.Generator
- typing.List
- typing.Match
- typing.Optional
- typing.Pattern
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.Union
- typing.cast
- typing.no_type_check
- typing_extensions.TypedDict
- utils.Representation
- utils.update_not_none
- validators.constr_length_validator
- validators.str_validator

**Functions:**

### `def url_regex() -> Pattern[str]`

**Line:** 113

---

### `def multi_host_url_regex() -> Pattern[str]`

**Description:**
Compiled multi host url regex.

Additionally to `url_regex` it allows to match multiple hosts.
E.g. host1.db.net,host2.db.net

**Line:** 123

---

### `def ascii_domain_regex() -> Pattern[str]`

**Line:** 141

---

### `def int_domain_regex() -> Pattern[str]`

**Line:** 152

---

### `def host_regex() -> Pattern[str]`

**Line:** 161

---

### `def stricturl(strip_whitespace: bool = True, min_length: int = 1, max_length: int = 2 ** 16, tld_required: bool = True, host_required: bool = True, allowed_schemes: Optional[Collection[str]] = None) -> Type[AnyUrl]`

**Line:** 554

---

### `def import_email_validator() -> None`

**Line:** 575

---

### `def validate_email(value: Union[str]) -> Tuple[(str, str)]`

**Description:**
Email address validation using https://pypi.org/project/email-validator/
Notes:
* raw ip address (literal) domain parts are not allowed.
* "John Doe <local_part@domain.com>" style "pretty" email addresses are processed
* spaces are striped from the beginning and end of addresses but no error is raised

**Line:** 711

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.parse
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/parse.py`

**Imports:**
- enum.Enum
- json
- pathlib.Path
- pickle
- types.StrBytes
- typing.Any
- typing.Callable
- typing.Union

**Functions:**

### `def load_str_bytes(b: StrBytes, content_type: str = None, encoding: str = 'utf8', proto: Protocol = None, allow_pickle: bool = False, json_loads: Callable[([str], Any)] = json.loads) -> Any`

**Line:** 15

---

### `def load_file(path: Union[(str, Path)], content_type: str = None, encoding: str = 'utf8', proto: Protocol = None, allow_pickle: bool = False, json_loads: Callable[([str], Any)] = json.loads) -> Any`

**Line:** 47

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.schema
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/schema.py`

**Imports:**
- collections.defaultdict
- dataclasses.Dataclass
- dataclasses.is_dataclass
- datetime.date
- datetime.datetime
- datetime.time
- datetime.timedelta
- decimal.Decimal
- enum.Enum
- fields.FieldInfo
- fields.MAPPING_LIKE_SHAPES
- fields.ModelField
- fields.SHAPE_DEQUE
- fields.SHAPE_FROZENSET
- fields.SHAPE_GENERIC
- fields.SHAPE_ITERABLE
- fields.SHAPE_LIST
- fields.SHAPE_SEQUENCE
- fields.SHAPE_SET
- fields.SHAPE_SINGLETON
- fields.SHAPE_TUPLE
- fields.SHAPE_TUPLE_ELLIPSIS
- inspect
- inspect.getdoc
- inspect.signature
- ipaddress.IPv4Address
- ipaddress.IPv4Interface
- ipaddress.IPv4Network
- ipaddress.IPv6Address
- ipaddress.IPv6Interface
- ipaddress.IPv6Network
- json.pydantic_encoder
- main.BaseModel
- networks.AnyUrl
- networks.EmailStr
- pathlib.Path
- re
- types.ConstrainedDecimal
- types.ConstrainedFloat
- types.ConstrainedFrozenSet
- types.ConstrainedInt
- types.ConstrainedList
- types.ConstrainedSet
- types.ConstrainedStr
- types.SecretBytes
- types.SecretStr
- types.StrictBytes
- types.StrictStr
- types.conbytes
- types.condecimal
- types.confloat
- types.confrozenset
- types.conint
- types.conlist
- types.conset
- types.constr
- typing.Any
- typing.Callable
- typing.Dict
- typing.ForwardRef
- typing.FrozenSet
- typing.Generic
- typing.Iterable
- typing.List
- typing.Optional
- typing.Pattern
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.all_literal_values
- typing.cast
- typing.get_args
- typing.get_origin
- typing.get_sub_types
- typing.is_callable_type
- typing.is_literal_type
- typing.is_namedtuple
- typing.is_none_type
- typing.is_union
- typing_extensions.Annotated
- typing_extensions.Literal
- utils.ROOT_KEY
- utils.get_model
- utils.lenient_issubclass
- uuid.UUID
- warnings

**Functions:**

### `def _apply_modify_schema(modify_schema: Callable[(..., None)], field: Optional[ModelField], field_schema: Dict[(str, Any)]) -> None`

**Line:** 96

---

### `def schema(models: Sequence[Union[(Type['BaseModel'], Type['Dataclass'])]], by_alias: bool = True, title: Optional[str] = None, description: Optional[str] = None, ref_prefix: Optional[str] = None, ref_template: str = default_ref_template) -> Dict[(str, Any)]`

**Description:**
Process a list of models and generate a single JSON Schema with all of them defined in the ``definitions``
top-level JSON key, including their sub-models.

:param models: a list of models to include in the generated JSON Schema
:param by_alias: generate the schemas using the aliases defined, if any
:param title: title for the generated schema that includes the definitions
:param description: description for the generated schema
:param ref_prefix: the JSON Pointer prefix for schema references with ``$ref``, if None, will be set to the
default of ``#/definitions/``. Update it if you want the schemas to reference the definitions somewhere
else, e.g. for OpenAPI use ``#/components/schemas/``. The resulting generated schemas will still be at the
top-level key ``definitions``, so you can extract them from there. But all the references will have the set
prefix.
:param ref_template: Use a ``string.format()`` template for ``$ref`` instead of a prefix. This can be useful
for references that cannot be represented by ``ref_prefix`` such as a definition stored in another file. For
a sibling json file in a ``/schemas`` directory use ``"/schemas/${model}.json#"``.
:return: dict with the JSON Schema with a ``definitions`` top-level key including the schema definitions for
the models and sub-models passed in ``models``.

**Line:** 109

---

### `def model_schema(model: Union[(Type['BaseModel'], Type['Dataclass'])], by_alias: bool = True, ref_prefix: Optional[str] = None, ref_template: str = default_ref_template) -> Dict[(str, Any)]`

**Description:**
Generate a JSON Schema for one model. With all the sub-models defined in the ``definitions`` top-level
JSON key.

:param model: a Pydantic model (a class that inherits from BaseModel)
:param by_alias: generate the schemas using the aliases defined, if any
:param ref_prefix: the JSON Pointer prefix for schema references with ``$ref``, if None, will be set to the
default of ``#/definitions/``. Update it if you want the schemas to reference the definitions somewhere
else, e.g. for OpenAPI use ``#/components/schemas/``. The resulting generated schemas will still be at the
top-level key ``definitions``, so you can extract them from there. But all the references will have the set
prefix.
:param ref_template: Use a ``string.format()`` template for ``$ref`` instead of a prefix. This can be useful for
references that cannot be represented by ``ref_prefix`` such as a definition stored in another file. For a
sibling json file in a ``/schemas`` directory use ``"/schemas/${model}.json#"``.
:return: dict with the JSON Schema for the passed ``model``

**Line:** 162

---

### `def get_field_info_schema(field: ModelField, schema_overrides: bool = False) -> Tuple[(Dict[str, Any], bool)]`

**Line:** 200

---

### `def field_schema(field: ModelField, by_alias: bool = True, model_name_map: Dict[(TypeModelOrEnum, str)], ref_prefix: Optional[str] = None, ref_template: str = default_ref_template, known_models: Optional[TypeModelSet] = None) -> Tuple[(Dict[str, Any], Dict[str, Any], Set[str])]`

**Description:**
Process a Pydantic field and return a tuple with a JSON Schema for it as the first item.
Also return a dictionary of definitions with models as keys and their schemas as values. If the passed field
is a model and has sub-models, and those sub-models don't have overrides (as ``title``, ``default``, etc), they
will be included in the definitions and referenced in the schema instead of included recursively.

:param field: a Pydantic ``ModelField``
:param by_alias: use the defined alias (if any) in the returned schema
:param model_name_map: used to generate the JSON Schema references to other models included in the definitions
:param ref_prefix: the JSON Pointer prefix to use for references to other schemas, if None, the default of
#/definitions/ will be used
:param ref_template: Use a ``string.format()`` template for ``$ref`` instead of a prefix. This can be useful for
references that cannot be represented by ``ref_prefix`` such as a definition stored in another file. For a
sibling json file in a ``/schemas`` directory use ``"/schemas/${model}.json#"``.
:param known_models: used to solve circular references
:return: tuple of the schema for this field and additional definitions

**Line:** 223

---

### `def get_field_schema_validations(field: ModelField) -> Dict[(str, Any)]`

**Description:**
Get the JSON Schema validation keywords for a ``field`` with an annotation of
a Pydantic ``FieldInfo`` with validation arguments.

**Line:** 290

---

### `def get_model_name_map(unique_models: TypeModelSet) -> Dict[(TypeModelOrEnum, str)]`

**Description:**
Process a set of models and generate unique names for them to be used as keys in the JSON Schema
definitions. By default the names are the same as the class name. But if two models in different Python
modules have the same name (e.g. "users.Model" and "items.Model"), the generated names will be
based on the Python module path for those conflicting models to prevent name collisions.

:param unique_models: a Python set of models
:return: dict mapping models to names

**Line:** 323

---

### `def get_flat_models_from_model(model: Type['BaseModel'], known_models: Optional[TypeModelSet] = None) -> TypeModelSet`

**Description:**
Take a single ``model`` and generate a set with itself and all the sub-models in the tree. I.e. if you pass
model ``Foo`` (subclass of Pydantic ``BaseModel``) as ``model``, and it has a field of type ``Bar`` (also
subclass of ``BaseModel``) and that model ``Bar`` has a field of type ``Baz`` (also subclass of ``BaseModel``),
the return value will be ``set([Foo, Bar, Baz])``.

:param model: a Pydantic ``BaseModel`` subclass
:param known_models: used to solve circular references
:return: a set with the initial model and all its sub-models

**Line:** 350

---

### `def get_flat_models_from_field(field: ModelField, known_models: TypeModelSet) -> TypeModelSet`

**Description:**
Take a single Pydantic ``ModelField`` (from a model) that could have been declared as a subclass of BaseModel
(so, it could be a submodel), and generate a set with its model and all the sub-models in the tree.
I.e. if you pass a field that was declared to be of type ``Foo`` (subclass of BaseModel) as ``field``, and that
model ``Foo`` has a field of type ``Bar`` (also subclass of ``BaseModel``) and that model ``Bar`` has a field of
type ``Baz`` (also subclass of ``BaseModel``), the return value will be ``set([Foo, Bar, Baz])``.

:param field: a Pydantic ``ModelField``
:param known_models: used to solve circular references
:return: a set with the model used in the declaration for this field, if any, and all its sub-models

**Line:** 370

---

### `def get_flat_models_from_fields(fields: Sequence[ModelField], known_models: TypeModelSet) -> TypeModelSet`

**Description:**
Take a list of Pydantic  ``ModelField``s (from a model) that could have been declared as subclasses of ``BaseModel``
(so, any of them could be a submodel), and generate a set with their models and all the sub-models in the tree.
I.e. if you pass a the fields of a model ``Foo`` (subclass of ``BaseModel``) as ``fields``, and on of them has a
field of type ``Bar`` (also subclass of ``BaseModel``) and that model ``Bar`` has a field of type ``Baz`` (also
subclass of ``BaseModel``), the return value will be ``set([Foo, Bar, Baz])``.

:param fields: a list of Pydantic ``ModelField``s
:param known_models: used to solve circular references
:return: a set with any model declared in the fields, and all their sub-models

**Line:** 399

---

### `def get_flat_models_from_models(models: Sequence[Type['BaseModel']]) -> TypeModelSet`

**Description:**
Take a list of ``models`` and generate a set with them and all their sub-models in their trees. I.e. if you pass
a list of two models, ``Foo`` and ``Bar``, both subclasses of Pydantic ``BaseModel`` as models, and ``Bar`` has
a field of type ``Baz`` (also subclass of ``BaseModel``), the return value will be ``set([Foo, Bar, Baz])``.

**Line:** 417

---

### `def get_long_model_name(model: TypeModelOrEnum) -> str`

**Line:** 429

---

### `def field_type_schema(field: ModelField, by_alias: bool, model_name_map: Dict[(TypeModelOrEnum, str)], ref_template: str, schema_overrides: bool = False, ref_prefix: Optional[str] = None, known_models: TypeModelSet) -> Tuple[(Dict[str, Any], Dict[str, Any], Set[str])]`

**Description:**
Used by ``field_schema()``, you probably should be using that function.

Take a single ``field`` and generate the schema for its type only, not including additional
information as title, etc. Also return additional schema definitions, from sub-models.

**Line:** 433

---

### `def model_process_schema(model: TypeModelOrEnum, by_alias: bool = True, model_name_map: Dict[(TypeModelOrEnum, str)], ref_prefix: Optional[str] = None, ref_template: str = default_ref_template, known_models: Optional[TypeModelSet] = None, field: Optional[ModelField] = None) -> Tuple[(Dict[str, Any], Dict[str, Any], Set[str])]`

**Description:**
Used by ``model_schema()``, you probably should be using that function.

Take a single ``model`` and generate its schema. Also return additional schema definitions, from sub-models. The
sub-models of the returned schema will be referenced, but their definitions will not be included in the schema. All
the definitions are returned as the second value.

**Line:** 552

---

### `def model_type_schema(model: Type['BaseModel'], by_alias: bool, model_name_map: Dict[(TypeModelOrEnum, str)], ref_template: str, ref_prefix: Optional[str] = None, known_models: TypeModelSet) -> Tuple[(Dict[str, Any], Dict[str, Any], Set[str])]`

**Description:**
You probably should be using ``model_schema()``, this function is indirectly used by that function.

Take a single ``model`` and generate the schema for its type only, not including additional
information as title, etc. Also return additional schema definitions, from sub-models.

**Line:** 602

---

### `def enum_process_schema(enum: Type[Enum], field: Optional[ModelField] = None) -> Dict[(str, Any)]`

**Description:**
Take a single `enum` and generate its schema.

This is similar to the `model_process_schema` function, but applies to ``Enum`` objects.

**Line:** 656

---

### `def field_singleton_sub_fields_schema(field: ModelField, by_alias: bool, model_name_map: Dict[(TypeModelOrEnum, str)], ref_template: str, schema_overrides: bool = False, ref_prefix: Optional[str] = None, known_models: TypeModelSet) -> Tuple[(Dict[str, Any], Dict[str, Any], Set[str])]`

**Description:**
This function is indirectly used by ``field_schema()``, you probably should be using that function.

Take a list of Pydantic ``ModelField`` from the declaration of a type with parameters, and generate their
schema. I.e., fields used as "type parameters", like ``str`` and ``int`` in ``Tuple[str, int]``.

**Line:** 682

---

### `def add_field_type_to_schema(field_type: Any, schema_: Dict[(str, Any)]) -> None`

**Description:**
Update the given `schema` with the type-specific metadata for the given `field_type`.

This function looks through `field_class_to_schema` for a class that matches the given `field_type`,
and then modifies the given `schema` with the information from that type.

**Line:** 805

---

### `def get_schema_ref(name: str, ref_prefix: Optional[str], ref_template: str, schema_overrides: bool) -> Dict[(str, Any)]`

**Line:** 819

---

### `def field_singleton_schema(field: ModelField, by_alias: bool, model_name_map: Dict[(TypeModelOrEnum, str)], ref_template: str, schema_overrides: bool = False, ref_prefix: Optional[str] = None, known_models: TypeModelSet) -> Tuple[(Dict[str, Any], Dict[str, Any], Set[str])]`

**Description:**
This function is indirectly used by ``field_schema()``, you should probably be using that function.

Take a single Pydantic ``ModelField``, and return its schema and any additional definitions from sub-models.

**Line:** 827

---

### `def multitypes_literal_field_for_schema(values: Tuple[(Any, ...)], field: ModelField) -> ModelField`

**Description:**
To support `Literal` with values of different types, we split it into multiple `Literal` with same type
e.g. `Literal['qwe', 'asd', 1, 2]` becomes `Union[Literal['qwe', 'asd'], Literal[1, 2]]`

**Line:** 955

---

### `def encode_default(dft: Any) -> Any`

**Line:** 977

---

### `def get_annotation_from_field_info(annotation: Any, field_info: FieldInfo, field_name: str, validate_assignment: bool = False) -> Type[Any]`

**Description:**
Get an annotation with validation implemented for numbers and strings based on the field_info.
:param annotation: an annotation from a field specification, as ``str``, ``ConstrainedStr``
:param field_info: an instance of FieldInfo, possibly with declarations for validations and JSON Schema
:param field_name: name of the field for use in error messages
:param validate_assignment: default False, flag for BaseModel Config value of validate_assignment
:return: the same ``annotation`` if unmodified or a new annotation with validation in place

**Line:** 1002

---

### `def get_annotation_with_constraints(annotation: Any, field_info: FieldInfo) -> Tuple[(Type[Any], Set[str])]`

**Description:**
Get an annotation with used constraints implemented for numbers and strings based on the field_info.

:param annotation: an annotation from a field specification, as ``str``, ``ConstrainedStr``
:param field_info: an instance of FieldInfo, possibly with declarations for validations and JSON Schema
:return: the same ``annotation`` if unmodified or a new annotation along with the used constraints.

**Line:** 1031

---

### `def normalize_name(name: str) -> str`

**Description:**
Normalizes the given name. This can be applied to either a model *or* enum.

**Line:** 1151

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.tools
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/tools.py`

**Imports:**
- functools.lru_cache
- json
- main.create_model
- parse.Protocol
- parse.load_file
- parse.load_str_bytes
- pathlib.Path
- types.StrBytes
- typing.Any
- typing.Callable
- typing.DictStrAny
- typing.Optional
- typing.TYPE_CHECKING
- typing.Type
- typing.TypeVar
- typing.Union
- typing.display_as_type

**Functions:**

### `def _generate_parsing_type_name(type_: Any) -> str`

**Line:** 18

---

### `def _get_parsing_type(type_: Any, type_name: Optional[NameFactory] = None) -> Any`

**Decorators:**
- `@lru_cache(...)`

**Line:** 23

---

### `def parse_obj_as(type_: Type[T], obj: Any, type_name: Optional[NameFactory] = None) -> T`

**Line:** 36

---

### `def parse_file_as(type_: Type[T], path: Union[(str, Path)], content_type: str = None, encoding: str = 'utf8', proto: Protocol = None, allow_pickle: bool = False, json_loads: Callable[([str], Any)] = json.loads, type_name: Optional[NameFactory] = None) -> T`

**Line:** 41

---

### `def parse_raw_as(type_: Type[T], b: StrBytes, content_type: str = None, encoding: str = 'utf8', proto: Protocol = None, allow_pickle: bool = False, json_loads: Callable[([str], Any)] = json.loads, type_name: Optional[NameFactory] = None) -> T`

**Line:** 63

---

### `def schema_of(type_: Any, title: Optional[NameFactory] = None, **schema_kwargs: Any) -> 'DictStrAny'`

**Description:**
Generate a JSON schema (as dict) for the passed model or dynamically generated one

**Line:** 85

---

### `def schema_json_of(type_: Any, title: Optional[NameFactory] = None, **schema_json_kwargs: Any) -> str`

**Description:**
Generate a JSON schema (as JSON) for the passed model or dynamically generated one

**Line:** 90

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.types
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/types.py`

**Imports:**
- abc
- dataclasses.Dataclass
- datetime.date
- datetime_parse.parse_date
- decimal.Decimal
- decimal.InvalidOperation
- enum.Enum
- main.BaseModel
- math
- pathlib.Path
- re
- types.new_class
- typing.Any
- typing.Callable
- typing.CallableGenerator
- typing.ClassVar
- typing.Dict
- typing.FrozenSet
- typing.List
- typing.Optional
- typing.Pattern
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.cast
- typing.overload
- typing_extensions.Annotated
- utils.import_string
- utils.update_not_none
- uuid.UUID
- validators.bytes_validator
- validators.constr_length_validator
- validators.constr_lower
- validators.constr_strip_whitespace
- validators.constr_upper
- validators.decimal_validator
- validators.float_finite_validator
- validators.float_validator
- validators.frozenset_validator
- validators.int_validator
- validators.list_validator
- validators.number_multiple_validator
- validators.number_size_validator
- validators.path_exists_validator
- validators.path_validator
- validators.set_validator
- validators.str_validator
- validators.strict_bytes_validator
- validators.strict_float_validator
- validators.strict_int_validator
- validators.strict_str_validator
- warnings
- weakref.WeakSet

**Functions:**

### `def _registered(typ: Type[T]) -> Type[T]`

**Decorators:**
- `@overload`

**Line:** 137

---

### `def _registered(typ: 'ConstrainedNumberMeta') -> 'ConstrainedNumberMeta'`

**Decorators:**
- `@overload`

**Line:** 142

---

### `def _registered(typ: Union[(Type[T], 'ConstrainedNumberMeta')]) -> Union[(Type[T], 'ConstrainedNumberMeta')]`

**Line:** 146

---

### `def conint(strict: bool = False, gt: Optional[int] = None, ge: Optional[int] = None, lt: Optional[int] = None, le: Optional[int] = None, multiple_of: Optional[int] = None) -> Type[int]`

**Line:** 228

---

### `def confloat(strict: bool = False, gt: float = None, ge: float = None, lt: float = None, le: float = None, multiple_of: float = None, allow_inf_nan: Optional[bool] = None) -> Type[float]`

**Line:** 306

---

### `def conbytes(strip_whitespace: bool = False, to_upper: bool = False, to_lower: bool = False, min_length: Optional[int] = None, max_length: Optional[int] = None, strict: bool = False) -> Type[bytes]`

**Line:** 373

---

### `def constr(strip_whitespace: bool = False, to_upper: bool = False, to_lower: bool = False, strict: bool = False, min_length: Optional[int] = None, max_length: Optional[int] = None, curtail_length: Optional[int] = None, regex: Optional[str] = None) -> Type[str]`

**Line:** 449

---

### `def conset(item_type: Type[T], min_items: Optional[int] = None, max_items: Optional[int] = None) -> Type[Set[T]]`

**Line:** 519

---

### `def confrozenset(item_type: Type[T], min_items: Optional[int] = None, max_items: Optional[int] = None) -> Type[FrozenSet[T]]`

**Line:** 561

---

### `def conlist(item_type: Type[T], min_items: Optional[int] = None, max_items: Optional[int] = None, unique_items: bool = None) -> Type[List[T]]`

**Line:** 621

---

### `def condecimal(gt: Decimal = None, ge: Decimal = None, lt: Decimal = None, le: Decimal = None, max_digits: Optional[int] = None, decimal_places: Optional[int] = None, multiple_of: Decimal = None) -> Type[Decimal]`

**Line:** 733

---

### `def condate(gt: date = None, ge: date = None, lt: date = None, le: date = None) -> Type[date]`

**Line:** 1197

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.typing
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/typing.py`

**Imports:**
- collections.abc.Callable
- fields.ModelField
- os.PathLike
- sys
- types
- types.UnionType
- typing
- typing.AbstractSet
- typing.Any
- typing.Callable
- typing.ClassVar
- typing.Dict
- typing.ForwardRef
- typing.Generator
- typing.GenericAlias
- typing.Iterable
- typing.List
- typing.Mapping
- typing.NewType
- typing.Optional
- typing.Sequence
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing._Final
- typing._GenericAlias
- typing._TypingBase
- typing._UnionGenericAlias
- typing._eval_type
- typing.cast
- typing.get_args
- typing.get_origin
- typing.get_type_hints
- typing_extensions.Annotated
- typing_extensions.Final
- typing_extensions.Literal
- typing_extensions.NotRequired
- typing_extensions.Required
- typing_extensions._AnnotatedAlias
- utils.lenient_issubclass

**Functions:**

### `def evaluate_forwardref(type_: ForwardRef, globalns: Any, localns: Any) -> Any`

**Line:** 58

---

### `def evaluate_forwardref(type_: ForwardRef, globalns: Any, localns: Any) -> Any`

**Line:** 63

---

### `def get_all_type_hints(obj: Any, globalns: Any = None, localns: Any = None) -> Any`

**Line:** 77

---

### `def get_origin(t: Type[Any]) -> Optional[Type[Any]]`

**Line:** 102

---

### `def get_origin(tp: Type[Any]) -> Optional[Type[Any]]`

**Description:**
We can't directly use `typing.get_origin` since we need a fallback to support
custom generic classes like `ConstrainedList`
It should be useless once https://github.com/cython/cython/issues/3537 is
solved and https://github.com/pydantic/pydantic/pull/1753 is merged.

**Line:** 111

---

### `def get_args(t: Type[Any]) -> Tuple[(Any, ...)]`

**Description:**
Compatibility version of get_args for python 3.7.

Mostly compatible with the python 3.8 `typing` module version
and able to handle almost all use cases.

**Line:** 126

---

### `def _generic_get_args(tp: Type[Any]) -> Tuple[(Any, ...)]`

**Description:**
In python 3.9, `typing.Dict`, `typing.List`, ...
do have an empty `__args__` by default (instead of the generic ~T for example).
In order to still support `Dict` for example and consider it as `Dict[Any, Any]`,
we retrieve the `_nparams` value that tells us how many parameters it needs.

**Line:** 144

---

### `def get_args(tp: Type[Any]) -> Tuple[(Any, ...)]`

**Description:**
Get type arguments with all substitutions performed.

For unions, basic simplifications used by Union constructor are performed.
Examples::
get_args(Dict[str, int]) == (str, int)
get_args(int) == ()
get_args(Union[int, Union[T, int], str][int]) == (int, str)
get_args(Union[int, Tuple[T, int]][str]) == (int, Tuple[str, int])
get_args(Callable[[], T][int]) == ([], int)

**Line:** 164

---

### `def convert_generics(tp: Type[Any]) -> Type[Any]`

**Description:**
Python 3.9 and older only supports generics from `typing` module.
They convert strings to ForwardRef automatically.

Examples::
typing.List['Hero'] == typing.List[ForwardRef('Hero')]

**Line:** 183

---

### `def convert_generics(tp: Type[Any]) -> Type[Any]`

**Description:**
Recursively searches for `str` type hints and replaces them with ForwardRef.

Examples::
convert_generics(list['Hero']) == list[ForwardRef('Hero')]
convert_generics(dict['Hero', 'Team']) == dict[ForwardRef('Hero'), ForwardRef('Team')]
convert_generics(typing.Dict['Hero', 'Team']) == typing.Dict[ForwardRef('Hero'), ForwardRef('Team')]
convert_generics(list[str | 'Hero'] | int) == list[str | ForwardRef('Hero')] | int

**Line:** 197

---

### `def is_union(tp: Optional[Type[Any]]) -> bool`

**Line:** 240

---

### `def is_union(tp: Optional[Type[Any]]) -> bool`

**Line:** 249

---

### `def is_none_type(type_: Any) -> bool`

**Line:** 336

---

### `def is_none_type(type_: Any) -> bool`

**Line:** 341

---

### `def is_none_type(type_: Any) -> bool`

**Line:** 354

---

### `def display_as_type(v: Type[Any]) -> str`

**Line:** 358

---

### `def resolve_annotations(raw_annotations: Dict[(str, Type[Any])], module_name: Optional[str]) -> Dict[(str, Type[Any])]`

**Description:**
Partially taken from typing.get_type_hints.

Resolve string or ForwardRef annotations into type objects if possible.

**Line:** 376

---

### `def is_callable_type(type_: Type[Any]) -> bool`

**Line:** 408

---

### `def is_literal_type(type_: Type[Any]) -> bool`

**Line:** 412

---

### `def literal_values(type_: Type[Any]) -> Tuple[(Any, ...)]`

**Line:** 416

---

### `def all_literal_values(type_: Type[Any]) -> Tuple[(Any, ...)]`

**Description:**
This method is used to retrieve all Literal values as
Literal can be used recursively (see https://www.python.org/dev/peps/pep-0586)
e.g. `Literal[Literal[Literal[1, 2, 3], "foo"], 5, None]`

**Line:** 420

---

### `def is_namedtuple(type_: Type[Any]) -> bool`

**Description:**
Check if a given class is a named tuple.
It can be either a `typing.NamedTuple` or `collections.namedtuple`

**Line:** 433

---

### `def is_typeddict(type_: Type[Any]) -> bool`

**Description:**
Check if a given class is a typed dict (from `typing` or `typing_extensions`)
In 3.10, there will be a public method (https://docs.python.org/3.10/library/typing.html#typing.is_typeddict)

**Line:** 443

---

### `def _check_typeddict_special(type_: Any) -> bool`

**Line:** 453

---

### `def is_typeddict_special(type_: Any) -> bool`

**Description:**
Check if type is a TypedDict special form (Required or NotRequired).

**Line:** 457

---

### `def is_new_type(type_: Type[Any]) -> bool`

**Description:**
Check whether type_ was created using typing.NewType

**Line:** 467

---

### `def new_type_supertype(type_: Type[Any]) -> Type[Any]`

**Line:** 474

---

### `def _check_classvar(v: Optional[Type[Any]]) -> bool`

**Line:** 480

---

### `def _check_finalvar(v: Optional[Type[Any]]) -> bool`

**Description:**
Check if a given type is a `typing.Final` type.

**Line:** 487

---

### `def is_classvar(ann_type: Type[Any]) -> bool`

**Line:** 497

---

### `def is_finalvar(ann_type: Type[Any]) -> bool`

**Line:** 509

---

### `def update_field_forward_refs(field: 'ModelField', globalns: Any, localns: Any) -> None`

**Description:**
Try to update ForwardRefs on fields based on this ModelField, globalns and localns.

**Line:** 513

---

### `def update_model_forward_refs(model: Type[Any], fields: Iterable['ModelField'], json_encoders: Dict[(Union[Type[Any], str, ForwardRef], AnyCallable)], localns: 'DictStrAny', exc_to_suppress: Tuple[(Type[BaseException], ...)] = ()) -> None`

**Description:**
Try to update model fields ForwardRefs based on model and localns.

**Line:** 535

---

### `def get_class(type_: Type[Any]) -> Union[(None, bool, Type[Any])]`

**Description:**
Tries to get the class of a Type[T] annotation. Returns True if Type is used
without brackets. Otherwise returns None.

**Line:** 574

---

### `def get_sub_types(tp: Any) -> List[Any]`

**Description:**
Return all the types that are allowed by type `tp`
`tp` can be a `Union` of allowed types or an `Annotated` type

**Line:** 592

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.utils
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/utils.py`

**Imports:**
- collections.OrderedDict
- collections.defaultdict
- collections.deque
- config.BaseConfig
- config.Extra
- copy.deepcopy
- dataclasses.Dataclass
- errors.ConfigError
- fields.ModelField
- importlib.import_module
- inspect.Parameter
- inspect.Signature
- inspect.signature
- itertools.islice
- itertools.zip_longest
- keyword
- main.BaseModel
- pathlib.Path
- types.BuiltinFunctionType
- types.CodeType
- types.FunctionType
- types.GeneratorType
- types.LambdaType
- types.ModuleType
- typing.AbstractSet
- typing.AbstractSetIntStr
- typing.Any
- typing.Callable
- typing.Collection
- typing.Dict
- typing.DictIntStrAny
- typing.Generator
- typing.IntStr
- typing.Iterable
- typing.Iterator
- typing.List
- typing.Mapping
- typing.MappingIntStrAny
- typing.NoReturn
- typing.NoneType
- typing.Optional
- typing.ReprArgs
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.WithArgsTypes
- typing.all_literal_values
- typing.display_as_type
- typing.get_args
- typing.get_origin
- typing.is_literal_type
- typing.is_union
- typing_extensions.Annotated
- version.version_info
- warnings
- weakref

**Functions:**

### `def import_string(dotted_path: str) -> Any`

**Description:**
Stolen approximately from django. Import a dotted module path and return the attribute/class designated by the
last name in the path. Raise ImportError if the import fails.

**Line:** 121

---

### `def truncate(v: Union[str], max_len: int = 80) -> str`

**Description:**
Truncate a value and add a unicode ellipsis (three dots) to the end if it was too long

**Line:** 140

---

### `def sequence_like(v: Any) -> bool`

**Line:** 157

---

### `def validate_field_name(bases: List[Type['BaseModel']], field_name: str) -> None`

**Description:**
Ensure that the field's name does not shadow an existing attribute of the model.

**Line:** 161

---

### `def lenient_isinstance(o: Any, class_or_tuple: Union[(Type[Any], Tuple[Type[Any], ...], None)]) -> bool`

**Line:** 173

---

### `def lenient_issubclass(cls: Any, class_or_tuple: Union[(Type[Any], Tuple[Type[Any], ...], None)]) -> bool`

**Line:** 180

---

### `def in_ipython() -> bool`

**Description:**
Check whether we're in an ipython environment, including jupyter notebooks.

**Line:** 189

---

### `def is_valid_identifier(identifier: str) -> bool`

**Description:**
Checks that a string is a valid identifier and not a Python keyword.
:param identifier: The identifier to test.
:return: True if the identifier is valid.

**Line:** 201

---

### `def deep_update(mapping: Dict[(KeyType, Any)], *updating_mappings: Dict[(KeyType, Any)]) -> Dict[(KeyType, Any)]`

**Line:** 213

---

### `def update_not_none(mapping: Dict[(Any, Any)], **update: Any) -> None`

**Line:** 224

---

### `def almost_equal_floats(value_1: float, value_2: float, delta: float = 1e-08) -> bool`

**Description:**
Return True if two floats are almost equal

**Line:** 228

---

### `def generate_model_signature(init: Callable[(..., None)], fields: Dict[(str, 'ModelField')], config: Type['BaseConfig']) -> 'Signature'`

**Description:**
Generate signature for model based on its fields

**Line:** 235

---

### `def get_model(obj: Union[(Type['BaseModel'], Type['Dataclass'])]) -> Type['BaseModel']`

**Line:** 300

---

### `def to_camel(string: str) -> str`

**Line:** 313

---

### `def to_lower_camel(string: str) -> str`

**Line:** 317

---

### `def unique_list(input_list: Union[(List[T], Tuple[T, ...])], name_factory: Callable[([T], str)] = str) -> List[T]`

**Description:**
Make a list unique while maintaining order.
We update the list if another one with the same name is set
(e.g. root validator overridden in subclass)

**Line:** 327

---

### `def path_type(p: 'Path') -> str`

**Description:**
Find out what sort of thing a path is.

**Line:** 660

---

### `def smart_deepcopy(obj: Obj) -> Obj`

**Description:**
Return type as is for immutable built-in types
Use obj.copy() for built-in empty collections
Use copy.deepcopy() for non-empty collections and unknown objects

**Line:** 675

---

### `def is_valid_field(name: str) -> bool`

**Line:** 696

---

### `def is_valid_private_name(name: str) -> bool`

**Line:** 713

---

### `def all_identical(left: Iterable[Any], right: Iterable[Any]) -> bool`

**Description:**
Check that the items of `left` are the same objects as those in `right`.

>>> a, b = object(), object()
>>> all_identical([a, b, a], [a, b, a])
True
>>> all_identical([a, b, [a]], [a, b, [a]])  # new list object, while "equal" is not "identical"
False

**Line:** 720

---

### `def assert_never(obj: NoReturn, msg: str) -> NoReturn`

**Description:**
Helper to make sure that we have covered all possible types.

This is mostly useful for ``mypy``, docs:
https://mypy.readthedocs.io/en/latest/literal_types.html#exhaustive-checks

**Line:** 736

---

### `def get_unique_discriminator_alias(all_aliases: Collection[str], discriminator_key: str) -> str`

**Description:**
Validate that all aliases are the same and if that's the case return the alias

**Line:** 746

---

### `def get_discriminator_alias_and_values(tp: Any, discriminator_key: str) -> Tuple[(str, Tuple[str, ...])]`

**Description:**
Get alias and all valid values in the `Literal` type of the discriminator field
`tp` can be a `BaseModel` class or directly an `Annotated` `Union` of many.

**Line:** 756

---

### `def _get_union_alias_and_all_values(union_type: Type[Any], discriminator_key: str) -> Tuple[(str, Tuple[Tuple[str, ...], ...])]`

**Line:** 797

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.validators
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/validators.py`

**Imports:**
- annotated_types.create_model_from_namedtuple
- annotated_types.create_model_from_typeddict
- collections.OrderedDict
- collections.abc.Hashable
- collections.deque
- config.BaseConfig
- dataclasses.is_builtin_dataclass
- dataclasses.make_dataclass_validator
- datetime.date
- datetime.datetime
- datetime.time
- datetime.timedelta
- datetime_parse.parse_date
- datetime_parse.parse_datetime
- datetime_parse.parse_duration
- datetime_parse.parse_time
- decimal.Decimal
- decimal.DecimalException
- enum.Enum
- enum.IntEnum
- fields.ModelField
- ipaddress.IPv4Address
- ipaddress.IPv4Interface
- ipaddress.IPv4Network
- ipaddress.IPv6Address
- ipaddress.IPv6Interface
- ipaddress.IPv6Network
- math
- pathlib.Path
- re
- types.ConstrainedDecimal
- types.ConstrainedFloat
- types.ConstrainedInt
- typing.Any
- typing.AnyCallable
- typing.Callable
- typing.Deque
- typing.Dict
- typing.ForwardRef
- typing.FrozenSet
- typing.Generator
- typing.Hashable
- typing.List
- typing.NamedTuple
- typing.Pattern
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeVar
- typing.Union
- typing.all_literal_values
- typing.display_as_type
- typing.get_class
- typing.is_callable_type
- typing.is_literal_type
- typing.is_namedtuple
- typing.is_none_type
- typing.is_typeddict
- typing_extensions.Literal
- typing_extensions.TypedDict
- utils.almost_equal_floats
- utils.lenient_issubclass
- utils.sequence_like
- uuid.UUID

**Functions:**

### `def str_validator(v: Any) -> Union[str]`

**Line:** 59

---

### `def strict_str_validator(v: Any) -> Union[str]`

**Line:** 74

---

### `def bytes_validator(v: Any) -> Union[bytes]`

**Line:** 80

---

### `def strict_bytes_validator(v: Any) -> Union[bytes]`

**Line:** 93

---

### `def bool_validator(v: Any) -> bool`

**Line:** 106

---

### `def int_validator(v: Any) -> int`

**Line:** 127

---

### `def strict_int_validator(v: Any) -> int`

**Line:** 146

---

### `def float_validator(v: Any) -> float`

**Line:** 152

---

### `def strict_float_validator(v: Any) -> float`

**Line:** 162

---

### `def float_finite_validator(v: 'Number', field: 'ModelField', config: 'BaseConfig') -> 'Number'`

**Line:** 168

---

### `def number_multiple_validator(v: 'Number', field: 'ModelField') -> 'Number'`

**Line:** 178

---

### `def number_size_validator(v: 'Number', field: 'ModelField') -> 'Number'`

**Line:** 187

---

### `def constant_validator(v: 'Any', field: 'ModelField') -> 'Any'`

**Description:**
Validate ``const`` fields.

The value provided for a ``const`` field must be equal to the default value
of the field. This is to support the keyword of the same name in JSON
Schema.

**Line:** 202

---

### `def anystr_length_validator(v: 'StrBytes', config: 'BaseConfig') -> 'StrBytes'`

**Line:** 215

---

### `def anystr_strip_whitespace(v: 'StrBytes') -> 'StrBytes'`

**Line:** 229

---

### `def anystr_upper(v: 'StrBytes') -> 'StrBytes'`

**Line:** 233

---

### `def anystr_lower(v: 'StrBytes') -> 'StrBytes'`

**Line:** 237

---

### `def ordered_dict_validator(v: Any) -> 'AnyOrderedDict'`

**Line:** 241

---

### `def dict_validator(v: Any) -> Dict[(Any, Any)]`

**Line:** 251

---

### `def list_validator(v: Any) -> List[Any]`

**Line:** 261

---

### `def tuple_validator(v: Any) -> Tuple[(Any, ...)]`

**Line:** 270

---

### `def set_validator(v: Any) -> Set[Any]`

**Line:** 279

---

### `def frozenset_validator(v: Any) -> FrozenSet[Any]`

**Line:** 288

---

### `def deque_validator(v: Any) -> Deque[Any]`

**Line:** 297

---

### `def enum_member_validator(v: Any, field: 'ModelField', config: 'BaseConfig') -> Enum`

**Line:** 306

---

### `def uuid_validator(v: Any, field: 'ModelField') -> UUID`

**Line:** 315

---

### `def decimal_validator(v: Any) -> Decimal`

**Line:** 339

---

### `def hashable_validator(v: Any) -> Hashable`

**Line:** 358

---

### `def ip_v4_address_validator(v: Any) -> IPv4Address`

**Line:** 365

---

### `def ip_v6_address_validator(v: Any) -> IPv6Address`

**Line:** 375

---

### `def ip_v4_network_validator(v: Any) -> IPv4Network`

**Description:**
Assume IPv4Network initialised with a default ``strict`` argument

See more:
https://docs.python.org/library/ipaddress.html#ipaddress.IPv4Network

**Line:** 385

---

### `def ip_v6_network_validator(v: Any) -> IPv6Network`

**Description:**
Assume IPv6Network initialised with a default ``strict`` argument

See more:
https://docs.python.org/library/ipaddress.html#ipaddress.IPv6Network

**Line:** 401

---

### `def ip_v4_interface_validator(v: Any) -> IPv4Interface`

**Line:** 417

---

### `def ip_v6_interface_validator(v: Any) -> IPv6Interface`

**Line:** 427

---

### `def path_validator(v: Any) -> Path`

**Line:** 437

---

### `def path_exists_validator(v: Any) -> Path`

**Line:** 447

---

### `def callable_validator(v: Any) -> AnyCallable`

**Description:**
Perform a simple check if the value is callable.

Note: complete matching of argument type hints and return types is not performed

**Line:** 454

---

### `def enum_validator(v: Any) -> Enum`

**Line:** 466

---

### `def int_enum_validator(v: Any) -> IntEnum`

**Line:** 473

---

### `def make_literal_validator(type_: Any) -> Callable[([Any], Any)]`

**Line:** 480

---

### `def constr_length_validator(v: 'StrBytes', field: 'ModelField', config: 'BaseConfig') -> 'StrBytes'`

**Line:** 497

---

### `def constr_strip_whitespace(v: 'StrBytes', field: 'ModelField', config: 'BaseConfig') -> 'StrBytes'`

**Line:** 511

---

### `def constr_upper(v: 'StrBytes', field: 'ModelField', config: 'BaseConfig') -> 'StrBytes'`

**Line:** 519

---

### `def constr_lower(v: 'StrBytes', field: 'ModelField', config: 'BaseConfig') -> 'StrBytes'`

**Line:** 527

---

### `def validate_json(v: Any, config: 'BaseConfig') -> Any`

**Line:** 534

---

### `def make_arbitrary_type_validator(type_: Type[T]) -> Callable[([T], T)]`

**Line:** 549

---

### `def make_class_validator(type_: Type[T]) -> Callable[([Any], Type[T])]`

**Line:** 558

---

### `def any_class_validator(v: Any) -> Type[T]`

**Line:** 567

---

### `def none_validator(v: Any) -> 'Literal[None]'`

**Line:** 573

---

### `def pattern_validator(v: Any) -> Pattern[str]`

**Line:** 579

---

### `def make_namedtuple_validator(namedtuple_cls: Type[NamedTupleT], config: Type['BaseConfig']) -> Callable[([Tuple[Any, ...]], NamedTupleT)]`

**Line:** 594

---

### `def make_typeddict_validator(typeddict_cls: Type['TypedDict'], config: Type['BaseConfig']) -> Callable[([Any], Dict[str, Any])]`

**Line:** 619

---

### `def find_validators(type_: Type[Any], config: Type['BaseConfig']) -> Generator[(AnyCallable, None, None)]`

**Line:** 698

---


## Module: venv2.libthon3.12.site-packagesdantic.v1.version
**File:** `venv2/lib/python3.12/site-packages/pydantic/v1/version.py`

**Imports:**
- cython
- importlib.import_module
- pathlib.Path
- platform
- sys

**Functions:**

### `def version_info() -> str`

**Line:** 16

---


## Module: venv2.libthon3.12.site-packagesdantic.validate_call_decorator
**File:** `venv2/lib/python3.12/site-packages/pydantic/validate_call_decorator.py`

**Imports:**
- __future__.annotations
- _internal._validate_call
- config.ConfigDict
- typing.Any
- typing.Callable
- typing.TYPE_CHECKING
- typing.TypeVar
- typing.overload

**Functions:**

### `def validate_call(config: ConfigDict | None = None, validate_return: bool = False) -> Callable[([AnyCallableT], AnyCallableT)]`

**Decorators:**
- `@overload`

**Line:** 17

---

### `def validate_call(__func: AnyCallableT) -> AnyCallableT`

**Decorators:**
- `@overload`

**Line:** 24

---

### `def validate_call(__func: AnyCallableT | None = None, config: ConfigDict | None = None, validate_return: bool = False) -> AnyCallableT | Callable[[AnyCallableT], AnyCallableT]`

**Description:**
Usage docs: https://docs.pydantic.dev/2.5/concepts/validation_decorator/

Returns a decorated wrapper around the function that validates the arguments and, optionally, the return value.

Usage may be either as a plain decorator `@validate_call` or with arguments `@validate_call(...)`.

Args:
__func: The function to be decorated.
config: The configuration dictionary.
validate_return: Whether to validate the return value.

Returns:
The decorated function.

**Line:** 28

---


## Module: venv2.libthon3.12.site-packagesdantic.version
**File:** `venv2/lib/python3.12/site-packages/pydantic/version.py`

**Imports:**
- __future__.annotations
- importlib.metadata
- importlib_metadata
- pathlib.Path
- platform
- pydantic_core._pydantic_core
- sys

**Functions:**

### `def version_short() -> str`

**Description:**
Return the `major.minor` part of Pydantic version.

It returns '2.1' if Pydantic version is '2.1.1'.

**Line:** 10

---

### `def version_info() -> str`

**Description:**
Return complete version information for Pydantic and its dependencies.

**Line:** 18

---

### `def parse_mypy_version(version: str) -> tuple[(int, ...)]`

**Description:**
Parse mypy string version to tuple of ints.

This function is included here rather than the mypy plugin file because the mypy plugin file cannot be imported
outside a mypy run.

It parses normal version like `0.930` and dev version
like `0.940+dev.04cac4b5d911c4f9529e6ce86a27b44f28846f5d.dirty`.

Args:
version: The mypy version string.

Returns:
A tuple of ints. e.g. (0, 930).

**Line:** 60

---


## Module: venv2.libthon3.12.site-packagesdantic_core.core_schema
**File:** `venv2/lib/python3.12/site-packages/pydantic_core/core_schema.py`

**Imports:**
- __future__.annotations
- collections.abc.Mapping
- datetime.date
- datetime.datetime
- datetime.time
- datetime.timedelta
- decimal.Decimal
- pydantic_core.PydanticUndefined
- sys
- typing.Any
- typing.Callable
- typing.Dict
- typing.Hashable
- typing.List
- typing.Literal
- typing.Protocol
- typing.Required
- typing.Set
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Type
- typing.TypeAlias
- typing.TypedDict
- typing.Union
- typing_extensions.Literal
- typing_extensions.Protocol
- typing_extensions.Required
- typing_extensions.TypeAlias
- typing_extensions.TypedDict
- typing_extensions.deprecated
- warnings

**Functions:**

### `def simple_ser_schema(type: ExpectedSerializationTypes) -> SimpleSerSchema`

**Description:**
Returns a schema for serialization with a custom type.

Args:
type: The type to use for serialization

**Line:** 230

---

### `def plain_serializer_function_ser_schema(function: SerializerFunction, is_field_serializer: bool | None = None, info_arg: bool | None = None, return_schema: CoreSchema | None = None, when_used: WhenUsed = 'always') -> PlainSerializerFunctionSerSchema`

**Description:**
Returns a schema for serialization with a function, can be either a "general" or "field" function.

Args:
function: The function to use for serialization
is_field_serializer: Whether the serializer is for a field, e.g. takes `model` as the first argument,
and `info` includes `field_name`
info_arg: Whether the function takes an `__info` argument
return_schema: Schema to use for serializing return value
when_used: When the function should be called

**Line:** 275

---

### `def wrap_serializer_function_ser_schema(function: WrapSerializerFunction, is_field_serializer: bool | None = None, info_arg: bool | None = None, schema: CoreSchema | None = None, return_schema: CoreSchema | None = None, when_used: WhenUsed = 'always') -> WrapSerializerFunctionSerSchema`

**Description:**
Returns a schema for serialization with a wrap function, can be either a "general" or "field" function.

Args:
function: The function to use for serialization
is_field_serializer: Whether the serializer is for a field, e.g. takes `model` as the first argument,
and `info` includes `field_name`
info_arg: Whether the function takes an `__info` argument
schema: The schema to use for the inner serialization
return_schema: Schema to use for serializing return value
when_used: When the function should be called

**Line:** 338

---

### `def format_ser_schema(formatting_string: str, when_used: WhenUsed = 'json-unless-none') -> FormatSerSchema`

**Description:**
Returns a schema for serialization using python's `format` method.

Args:
formatting_string: String defining the format to use
when_used: Same meaning as for [general_function_plain_ser_schema], but with a different default

**Line:** 379

---

### `def to_string_ser_schema(when_used: WhenUsed = 'json-unless-none') -> ToStringSerSchema`

**Description:**
Returns a schema for serialization using python's `str()` / `__str__` method.

Args:
when_used: Same meaning as for [general_function_plain_ser_schema], but with a different default

**Line:** 398

---

### `def model_ser_schema(cls: Type[Any], schema: CoreSchema) -> ModelSerSchema`

**Description:**
Returns a schema for serialization using a model.

Args:
cls: The expected class type, used to generate warnings if the wrong type is passed
schema: Internal schema to use to serialize the model dict

**Line:** 418

---

### `def computed_field(property_name: str, return_schema: CoreSchema, alias: str | None = None, metadata: Any = None) -> ComputedField`

**Description:**
ComputedFields are properties of a model or dataclass that are included in serialization.

Args:
property_name: The name of the property on the model or dataclass
return_schema: The schema used for the type returned by the computed field
alias: The name to use in the serialized output
metadata: Any other information you want to include with the schema, not used by pydantic-core

**Line:** 447

---

### `def any_schema(ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> AnySchema`

**Description:**
Returns a schema that matches any value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.any_schema()
v = SchemaValidator(schema)
assert v.validate_python(1) == 1
```

Args:
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 471

---

### `def none_schema(ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> NoneSchema`

**Description:**
Returns a schema that matches a None value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.none_schema()
v = SchemaValidator(schema)
assert v.validate_python(None) is None
```

Args:
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 498

---

### `def bool_schema(strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> BoolSchema`

**Description:**
Returns a schema that matches a bool value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.bool_schema()
v = SchemaValidator(schema)
assert v.validate_python('True') is True
```

Args:
strict: Whether the value should be a bool or a value that can be converted to a bool
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 526

---

### `def int_schema(multiple_of: int | None = None, le: int | None = None, ge: int | None = None, lt: int | None = None, gt: int | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> IntSchema`

**Description:**
Returns a schema that matches a int value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.int_schema(multiple_of=2, le=6, ge=2)
v = SchemaValidator(schema)
assert v.validate_python('4') == 4
```

Args:
multiple_of: The value must be a multiple of this number
le: The value must be less than or equal to this number
ge: The value must be greater than or equal to this number
lt: The value must be strictly less than this number
gt: The value must be strictly greater than this number
strict: Whether the value should be a int or a value that can be converted to a int
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 562

---

### `def float_schema(allow_inf_nan: bool | None = None, multiple_of: float | None = None, le: float | None = None, ge: float | None = None, lt: float | None = None, gt: float | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> FloatSchema`

**Description:**
Returns a schema that matches a float value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.float_schema(le=0.8, ge=0.2)
v = SchemaValidator(schema)
assert v.validate_python('0.5') == 0.5
```

Args:
allow_inf_nan: Whether to allow inf and nan values
multiple_of: The value must be a multiple of this number
le: The value must be less than or equal to this number
ge: The value must be greater than or equal to this number
lt: The value must be strictly less than this number
gt: The value must be strictly greater than this number
strict: Whether the value should be a float or a value that can be converted to a float
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 624

---

### `def decimal_schema(allow_inf_nan: bool = None, multiple_of: Decimal | None = None, le: Decimal | None = None, ge: Decimal | None = None, lt: Decimal | None = None, gt: Decimal | None = None, max_digits: int | None = None, decimal_places: int | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> DecimalSchema`

**Description:**
Returns a schema that matches a decimal value, e.g.:

```py
from decimal import Decimal
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.decimal_schema(le=0.8, ge=0.2)
v = SchemaValidator(schema)
assert v.validate_python('0.5') == Decimal('0.5')
```

Args:
allow_inf_nan: Whether to allow inf and nan values
multiple_of: The value must be a multiple of this number
le: The value must be less than or equal to this number
ge: The value must be greater than or equal to this number
lt: The value must be strictly less than this number
gt: The value must be strictly greater than this number
max_digits: The maximum number of decimal digits allowed
decimal_places: The maximum number of decimal places allowed
strict: Whether the value should be a float or a value that can be converted to a float
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 691

---

### `def str_schema(pattern: str | None = None, max_length: int | None = None, min_length: int | None = None, strip_whitespace: bool | None = None, to_lower: bool | None = None, to_upper: bool | None = None, regex_engine: Literal['rust-regex', 'python-re'] | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> StringSchema`

**Description:**
Returns a schema that matches a string value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.str_schema(max_length=10, min_length=2)
v = SchemaValidator(schema)
assert v.validate_python('hello') == 'hello'
```

Args:
pattern: A regex pattern that the value must match
max_length: The value must be at most this length
min_length: The value must be at least this length
strip_whitespace: Whether to strip whitespace from the value
to_lower: Whether to convert the value to lowercase
to_upper: Whether to convert the value to uppercase
regex_engine: The regex engine to use for pattern validation. Default is 'rust-regex'.
- `rust-regex` uses the [`regex`](https://docs.rs/regex) Rust
crate, which is non-backtracking and therefore more DDoS
resistant, but does not support all regex features.
- `python-re` use the [`re`](https://docs.python.org/3/library/re.html) module,
which supports all regex features, but may be slower.
strict: Whether the value should be a string or a value that can be converted to a string
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 764

---

### `def bytes_schema(max_length: int | None = None, min_length: int | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> BytesSchema`

**Description:**
Returns a schema that matches a bytes value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.bytes_schema(max_length=10, min_length=2)
v = SchemaValidator(schema)
assert v.validate_python(b'hello') == b'hello'
```

Args:
max_length: The value must be at most this length
min_length: The value must be at least this length
strict: Whether the value should be a bytes or a value that can be converted to a bytes
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 833

---

### `def date_schema(strict: bool | None = None, le: date | None = None, ge: date | None = None, lt: date | None = None, gt: date | None = None, now_op: Literal['past', 'future'] | None = None, now_utc_offset: int | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> DateSchema`

**Description:**
Returns a schema that matches a date value, e.g.:

```py
from datetime import date
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.date_schema(le=date(2020, 1, 1), ge=date(2019, 1, 1))
v = SchemaValidator(schema)
assert v.validate_python(date(2019, 6, 1)) == date(2019, 6, 1)
```

Args:
strict: Whether the value should be a date or a value that can be converted to a date
le: The value must be less than or equal to this date
ge: The value must be greater than or equal to this date
lt: The value must be strictly less than this date
gt: The value must be strictly greater than this date
now_op: The value must be in the past or future relative to the current date
now_utc_offset: The value must be in the past or future relative to the current date with this utc offset
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 888

---

### `def time_schema(strict: bool | None = None, le: time | None = None, ge: time | None = None, lt: time | None = None, gt: time | None = None, tz_constraint: Literal['aware', 'naive'] | int | None = None, microseconds_precision: Literal[('truncate', 'error')] = 'truncate', ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> TimeSchema`

**Description:**
Returns a schema that matches a time value, e.g.:

```py
from datetime import time
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.time_schema(le=time(12, 0, 0), ge=time(6, 0, 0))
v = SchemaValidator(schema)
assert v.validate_python(time(9, 0, 0)) == time(9, 0, 0)
```

Args:
strict: Whether the value should be a time or a value that can be converted to a time
le: The value must be less than or equal to this time
ge: The value must be greater than or equal to this time
lt: The value must be strictly less than this time
gt: The value must be strictly greater than this time
tz_constraint: The value must be timezone aware or naive, or an int to indicate required tz offset
microseconds_precision: The behavior when seconds have more than 6 digits or microseconds is too large
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 954

---

### `def datetime_schema(strict: bool | None = None, le: datetime | None = None, ge: datetime | None = None, lt: datetime | None = None, gt: datetime | None = None, now_op: Literal['past', 'future'] | None = None, tz_constraint: Literal['aware', 'naive'] | int | None = None, now_utc_offset: int | None = None, microseconds_precision: Literal[('truncate', 'error')] = 'truncate', ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> DatetimeSchema`

**Description:**
Returns a schema that matches a datetime value, e.g.:

```py
from datetime import datetime
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.datetime_schema()
v = SchemaValidator(schema)
now = datetime.now()
assert v.validate_python(str(now)) == now
```

Args:
strict: Whether the value should be a datetime or a value that can be converted to a datetime
le: The value must be less than or equal to this datetime
ge: The value must be greater than or equal to this datetime
lt: The value must be strictly less than this datetime
gt: The value must be strictly greater than this datetime
now_op: The value must be in the past or future relative to the current datetime
tz_constraint: The value must be timezone aware or naive, or an int to indicate required tz offset
TODO: use of a tzinfo where offset changes based on the datetime is not yet supported
now_utc_offset: The value must be in the past or future relative to the current datetime with this utc offset
microseconds_precision: The behavior when seconds have more than 6 digits or microseconds is too large
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1024

---

### `def timedelta_schema(strict: bool | None = None, le: timedelta | None = None, ge: timedelta | None = None, lt: timedelta | None = None, gt: timedelta | None = None, microseconds_precision: Literal[('truncate', 'error')] = 'truncate', ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> TimedeltaSchema`

**Description:**
Returns a schema that matches a timedelta value, e.g.:

```py
from datetime import timedelta
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.timedelta_schema(le=timedelta(days=1), ge=timedelta(days=0))
v = SchemaValidator(schema)
assert v.validate_python(timedelta(hours=12)) == timedelta(hours=12)
```

Args:
strict: Whether the value should be a timedelta or a value that can be converted to a timedelta
le: The value must be less than or equal to this timedelta
ge: The value must be greater than or equal to this timedelta
lt: The value must be strictly less than this timedelta
gt: The value must be strictly greater than this timedelta
microseconds_precision: The behavior when seconds have more than 6 digits or microseconds is too large
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1097

---

### `def literal_schema(expected: list[Any], ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> LiteralSchema`

**Description:**
Returns a schema that matches a literal value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.literal_schema(['hello', 'world'])
v = SchemaValidator(schema)
assert v.validate_python('hello') == 'hello'
```

Args:
expected: The value must be one of these values
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1154

---

### `def is_instance_schema(cls: Any, cls_repr: str | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> IsInstanceSchema`

**Description:**
Returns a schema that checks if a value is an instance of a class, equivalent to python's `isinstnace` method, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

class A:
pass

schema = core_schema.is_instance_schema(cls=A)
v = SchemaValidator(schema)
v.validate_python(A())
```

Args:
cls: The value must be an instance of this class
cls_repr: If provided this string is used in the validator name instead of `repr(cls)`
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1190

---

### `def is_subclass_schema(cls: Type[Any], cls_repr: str | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> IsInstanceSchema`

**Description:**
Returns a schema that checks if a value is a subtype of a class, equivalent to python's `issubclass` method, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

class A:
pass

class B(A):
pass

schema = core_schema.is_subclass_schema(cls=A)
v = SchemaValidator(schema)
v.validate_python(B)
```

Args:
cls: The value must be a subclass of this class
cls_repr: If provided this string is used in the validator name instead of `repr(cls)`
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1233

---

### `def callable_schema(ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> CallableSchema`

**Description:**
Returns a schema that checks if a value is callable, equivalent to python's `callable` method, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.callable_schema()
v = SchemaValidator(schema)
v.validate_python(min)
```

Args:
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1277

---

### `def uuid_schema(version: Literal[1, 3, 4, 5] | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> UuidSchema`

**Line:** 1308

---

### `def filter_seq_schema(include: Set[int] | None = None, exclude: Set[int] | None = None) -> IncExSeqSerSchema`

**Line:** 1327

---

### `def list_schema(items_schema: CoreSchema | None = None, min_length: int | None = None, max_length: int | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: IncExSeqOrElseSerSchema | None = None) -> ListSchema`

**Description:**
Returns a schema that matches a list value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.list_schema(core_schema.int_schema(), min_length=0, max_length=10)
v = SchemaValidator(schema)
assert v.validate_python(['4']) == [4]
```

Args:
items_schema: The value must be a list of items that match this schema
min_length: The value must be a list with at least this many items
max_length: The value must be a list with at most this many items
strict: The value must be a list with exactly this many items
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1345

---

### `def tuple_positional_schema(items_schema: list[CoreSchema], extras_schema: CoreSchema | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: IncExSeqOrElseSerSchema | None = None) -> TuplePositionalSchema`

**Description:**
Returns a schema that matches a tuple of schemas, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.tuple_positional_schema(
[core_schema.int_schema(), core_schema.str_schema()]
)
v = SchemaValidator(schema)
assert v.validate_python((1, 'hello')) == (1, 'hello')
```

Args:
items_schema: The value must be a tuple with items that match these schemas
extras_schema: The value must be a tuple with items that match this schema
This was inspired by JSON schema's `prefixItems` and `items` fields.
In python's `typing.Tuple`, you can't specify a type for "extra" items -- they must all be the same type
if the length is variable. So this field won't be set from a `typing.Tuple` annotation on a pydantic model.
strict: The value must be a tuple with exactly this many items
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1397

---

### `def tuple_variable_schema(items_schema: CoreSchema | None = None, min_length: int | None = None, max_length: int | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: IncExSeqOrElseSerSchema | None = None) -> TupleVariableSchema`

**Description:**
Returns a schema that matches a tuple of a given schema, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.tuple_variable_schema(
items_schema=core_schema.int_schema(), min_length=0, max_length=10
)
v = SchemaValidator(schema)
assert v.validate_python(('1', 2, 3)) == (1, 2, 3)
```

Args:
items_schema: The value must be a tuple with items that match this schema
min_length: The value must be a tuple with at least this many items
max_length: The value must be a tuple with at most this many items
strict: The value must be a tuple with exactly this many items
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1452

---

### `def set_schema(items_schema: CoreSchema | None = None, min_length: int | None = None, max_length: int | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> SetSchema`

**Description:**
Returns a schema that matches a set of a given schema, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.set_schema(
items_schema=core_schema.int_schema(), min_length=0, max_length=10
)
v = SchemaValidator(schema)
assert v.validate_python({1, '2', 3}) == {1, 2, 3}
```

Args:
items_schema: The value must be a set with items that match this schema
min_length: The value must be a set with at least this many items
max_length: The value must be a set with at most this many items
strict: The value must be a set with exactly this many items
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1507

---

### `def frozenset_schema(items_schema: CoreSchema | None = None, min_length: int | None = None, max_length: int | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> FrozenSetSchema`

**Description:**
Returns a schema that matches a frozenset of a given schema, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.frozenset_schema(
items_schema=core_schema.int_schema(), min_length=0, max_length=10
)
v = SchemaValidator(schema)
assert v.validate_python(frozenset(range(3))) == frozenset({0, 1, 2})
```

Args:
items_schema: The value must be a frozenset with items that match this schema
min_length: The value must be a frozenset with at least this many items
max_length: The value must be a frozenset with at most this many items
strict: The value must be a frozenset with exactly this many items
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1562

---

### `def generator_schema(items_schema: CoreSchema | None = None, min_length: int | None = None, max_length: int | None = None, ref: str | None = None, metadata: Any = None, serialization: IncExSeqOrElseSerSchema | None = None) -> GeneratorSchema`

**Description:**
Returns a schema that matches a generator value, e.g.:

```py
from typing import Iterator
from pydantic_core import SchemaValidator, core_schema

def gen() -> Iterator[int]:
yield 1

schema = core_schema.generator_schema(items_schema=core_schema.int_schema())
v = SchemaValidator(schema)
v.validate_python(gen())
```

Unlike other types, validated generators do not raise ValidationErrors eagerly,
but instead will raise a ValidationError when a violating value is actually read from the generator.
This is to ensure that "validated" generators retain the benefit of lazy evaluation.

Args:
items_schema: The value must be a generator with items that match this schema
min_length: The value must be a generator that yields at least this many items
max_length: The value must be a generator that yields at most this many items
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1616

---

### `def filter_dict_schema(include: IncExDict | None = None, exclude: IncExDict | None = None) -> IncExDictSerSchema`

**Line:** 1672

---

### `def dict_schema(keys_schema: CoreSchema | None = None, values_schema: CoreSchema | None = None, min_length: int | None = None, max_length: int | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> DictSchema`

**Description:**
Returns a schema that matches a dict value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.dict_schema(
keys_schema=core_schema.str_schema(), values_schema=core_schema.int_schema()
)
v = SchemaValidator(schema)
assert v.validate_python({'a': '1', 'b': 2}) == {'a': 1, 'b': 2}
```

Args:
keys_schema: The value must be a dict with keys that match this schema
values_schema: The value must be a dict with values that match this schema
min_length: The value must be a dict with at least this many items
max_length: The value must be a dict with at most this many items
strict: Whether the keys and values should be validated with strict mode
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1691

---

### `def no_info_before_validator_function(function: NoInfoValidatorFunction, schema: CoreSchema, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> BeforeValidatorFunctionSchema`

**Description:**
Returns a schema that calls a validator function before validating, no `info` argument is provided, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

def fn(v: bytes) -> str:
return v.decode() + 'world'

func_schema = core_schema.no_info_before_validator_function(
function=fn, schema=core_schema.str_schema()
)
schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})

v = SchemaValidator(schema)
assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}
```

Args:
function: The validator function to call
schema: The schema to validate the output of the validator function
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1772

---

### `def with_info_before_validator_function(function: WithInfoValidatorFunction, schema: CoreSchema, field_name: str | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> BeforeValidatorFunctionSchema`

**Description:**
Returns a schema that calls a validator function before validation, the function is called with
an `info` argument, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

def fn(v: bytes, info: core_schema.ValidationInfo) -> str:
assert info.data is not None
assert info.field_name is not None
return v.decode() + 'world'

func_schema = core_schema.with_info_before_validator_function(
function=fn, schema=core_schema.str_schema(), field_name='a'
)
schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})

v = SchemaValidator(schema)
assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}
```

Args:
function: The validator function to call
field_name: The name of the field
schema: The schema to validate the output of the validator function
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1815

---

### `def no_info_after_validator_function(function: NoInfoValidatorFunction, schema: CoreSchema, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> AfterValidatorFunctionSchema`

**Description:**
Returns a schema that calls a validator function after validating, no `info` argument is provided, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

def fn(v: str) -> str:
return v + 'world'

func_schema = core_schema.no_info_after_validator_function(fn, core_schema.str_schema())
schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})

v = SchemaValidator(schema)
assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}
```

Args:
function: The validator function to call after the schema is validated
schema: The schema to validate before the validator function
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1867

---

### `def with_info_after_validator_function(function: WithInfoValidatorFunction, schema: CoreSchema, field_name: str | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> AfterValidatorFunctionSchema`

**Description:**
Returns a schema that calls a validator function after validation, the function is called with
an `info` argument, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

def fn(v: str, info: core_schema.ValidationInfo) -> str:
assert info.data is not None
assert info.field_name is not None
return v + 'world'

func_schema = core_schema.with_info_after_validator_function(
function=fn, schema=core_schema.str_schema(), field_name='a'
)
schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})

v = SchemaValidator(schema)
assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}
```

Args:
function: The validator function to call after the schema is validated
schema: The schema to validate before the validator function
field_name: The name of the field this validators is applied to, if any
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1908

---

### `def no_info_wrap_validator_function(function: NoInfoWrapValidatorFunction, schema: CoreSchema, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> WrapValidatorFunctionSchema`

**Description:**
Returns a schema which calls a function with a `validator` callable argument which can
optionally be used to call inner validation with the function logic, this is much like the
"onion" implementation of middleware in many popular web frameworks, no `info` argument is passed, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

def fn(
v: str,
validator: core_schema.ValidatorFunctionWrapHandler,
) -> str:
return validator(input_value=v) + 'world'

schema = core_schema.no_info_wrap_validator_function(
function=fn, schema=core_schema.str_schema()
)
v = SchemaValidator(schema)
assert v.validate_python('hello ') == 'hello world'
```

Args:
function: The validator function to call
schema: The schema to validate the output of the validator function
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 1992

---

### `def with_info_wrap_validator_function(function: WithInfoWrapValidatorFunction, schema: CoreSchema, field_name: str | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> WrapValidatorFunctionSchema`

**Description:**
Returns a schema which calls a function with a `validator` callable argument which can
optionally be used to call inner validation with the function logic, this is much like the
"onion" implementation of middleware in many popular web frameworks, an `info` argument is also passed, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

def fn(
v: str,
validator: core_schema.ValidatorFunctionWrapHandler,
info: core_schema.ValidationInfo,
) -> str:
return validator(input_value=v) + 'world'

schema = core_schema.with_info_wrap_validator_function(
function=fn, schema=core_schema.str_schema()
)
v = SchemaValidator(schema)
assert v.validate_python('hello ') == 'hello world'
```

Args:
function: The validator function to call
schema: The schema to validate the output of the validator function
field_name: The name of the field this validators is applied to, if any
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 2038

---

### `def no_info_plain_validator_function(function: NoInfoValidatorFunction, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> PlainValidatorFunctionSchema`

**Description:**
Returns a schema that uses the provided function for validation, no `info` argument is passed, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

def fn(v: str) -> str:
assert 'hello' in v
return v + 'world'

schema = core_schema.no_info_plain_validator_function(function=fn)
v = SchemaValidator(schema)
assert v.validate_python('hello ') == 'hello world'
```

Args:
function: The validator function to call
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 2095

---

### `def with_info_plain_validator_function(function: WithInfoValidatorFunction, field_name: str | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> PlainValidatorFunctionSchema`

**Description:**
Returns a schema that uses the provided function for validation, an `info` argument is passed, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

def fn(v: str, info: core_schema.ValidationInfo) -> str:
assert 'hello' in v
return v + 'world'

schema = core_schema.with_info_plain_validator_function(function=fn)
v = SchemaValidator(schema)
assert v.validate_python('hello ') == 'hello world'
```

Args:
function: The validator function to call
field_name: The name of the field this validators is applied to, if any
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 2132

---

### `def with_default_schema(schema: CoreSchema, default: Any = PydanticUndefined, default_factory: Callable[[], Any] | None = None, on_error: Literal['raise', 'omit', 'default'] | None = None, validate_default: bool | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> WithDefaultSchema`

**Description:**
Returns a schema that adds a default value to the given schema, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.with_default_schema(core_schema.str_schema(), default='hello')
wrapper_schema = core_schema.typed_dict_schema(
{'a': core_schema.typed_dict_field(schema)}
)
v = SchemaValidator(wrapper_schema)
assert v.validate_python({}) == v.validate_python({'a': 'hello'})
```

Args:
schema: The schema to add a default value to
default: The default value to use
default_factory: A function that returns the default value to use
on_error: What to do if the schema validation fails. One of 'raise', 'omit', 'default'
validate_default: Whether the default value should be validated
strict: Whether the underlying schema should be validated with strict mode
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 2184

---

### `def nullable_schema(schema: CoreSchema, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> NullableSchema`

**Description:**
Returns a schema that matches a nullable value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.nullable_schema(core_schema.str_schema())
v = SchemaValidator(schema)
assert v.validate_python(None) is None
```

Args:
schema: The schema to wrap
strict: Whether the underlying schema should be validated with strict mode
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 2246

---

### `def union_schema(choices: list[CoreSchema | tuple[CoreSchema, str]], auto_collapse: bool | None = None, custom_error_type: str | None = None, custom_error_message: str | None = None, custom_error_context: dict[str, str | int] | None = None, mode: Literal['smart', 'left_to_right'] | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> UnionSchema`

**Description:**
Returns a schema that matches a union value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.union_schema([core_schema.str_schema(), core_schema.int_schema()])
v = SchemaValidator(schema)
assert v.validate_python('hello') == 'hello'
assert v.validate_python(1) == 1
```

Args:
choices: The schemas to match. If a tuple, the second item is used as the label for the case.
auto_collapse: whether to automatically collapse unions with one element to the inner validator, default true
custom_error_type: The custom error type to use if the validation fails
custom_error_message: The custom error message to use if the validation fails
custom_error_context: The custom error context to use if the validation fails
mode: How to select which choice to return
* `smart` (default) will try to return the choice which is the closest match to the input value
* `left_to_right` will return the first choice in `choices` which succeeds validation
strict: Whether the underlying schemas should be validated with strict mode
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 2292

---

### `def tagged_union_schema(choices: Dict[(Hashable, CoreSchema)], discriminator: str | list[str | int] | list[list[str | int]] | Callable[[Any], Hashable], custom_error_type: str | None = None, custom_error_message: str | None = None, custom_error_context: dict[str, int | str | float] | None = None, strict: bool | None = None, from_attributes: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> TaggedUnionSchema`

**Description:**
Returns a schema that matches a tagged union value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

apple_schema = core_schema.typed_dict_schema(
{
'foo': core_schema.typed_dict_field(core_schema.str_schema()),
'bar': core_schema.typed_dict_field(core_schema.int_schema()),
}
)
banana_schema = core_schema.typed_dict_schema(
{
'foo': core_schema.typed_dict_field(core_schema.str_schema()),
'spam': core_schema.typed_dict_field(
core_schema.list_schema(items_schema=core_schema.int_schema())
),
}
)
schema = core_schema.tagged_union_schema(
choices={
'apple': apple_schema,
'banana': banana_schema,
},
discriminator='foo',
)
v = SchemaValidator(schema)
assert v.validate_python({'foo': 'apple', 'bar': '123'}) == {'foo': 'apple', 'bar': 123}
assert v.validate_python({'foo': 'banana', 'spam': [1, 2, 3]}) == {
'foo': 'banana',
'spam': [1, 2, 3],
}
```

Args:
choices: The schemas to match
When retrieving a schema from `choices` using the discriminator value, if the value is a str,
it should be fed back into the `choices` map until a schema is obtained
(This approach is to prevent multiple ownership of a single schema in Rust)
discriminator: The discriminator to use to determine the schema to use
* If `discriminator` is a str, it is the name of the attribute to use as the discriminator
* If `discriminator` is a list of int/str, it should be used as a "path" to access the discriminator
* If `discriminator` is a list of lists, each inner list is a path, and the first path that exists is used
* If `discriminator` is a callable, it should return the discriminator when called on the value to validate;
the callable can return `None` to indicate that there is no matching discriminator present on the input
custom_error_type: The custom error type to use if the validation fails
custom_error_message: The custom error message to use if the validation fails
custom_error_context: The custom error context to use if the validation fails
strict: Whether the underlying schemas should be validated with strict mode
from_attributes: Whether to use the attributes of the object to retrieve the discriminator value
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 2360

---

### `def chain_schema(steps: list[CoreSchema], ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> ChainSchema`

**Description:**
Returns a schema that chains the provided validation schemas, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

def fn(v: str, info: core_schema.ValidationInfo) -> str:
assert 'hello' in v
return v + ' world'

fn_schema = core_schema.with_info_plain_validator_function(function=fn)
schema = core_schema.chain_schema(
[fn_schema, fn_schema, fn_schema, core_schema.str_schema()]
)
v = SchemaValidator(schema)
assert v.validate_python('hello') == 'hello world world world'
```

Args:
steps: The schemas to chain
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 2451

---

### `def lax_or_strict_schema(lax_schema: CoreSchema, strict_schema: CoreSchema, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> LaxOrStrictSchema`

**Description:**
Returns a schema that uses the lax or strict schema, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

def fn(v: str, info: core_schema.ValidationInfo) -> str:
assert 'hello' in v
return v + ' world'

lax_schema = core_schema.int_schema(strict=False)
strict_schema = core_schema.int_schema(strict=True)

schema = core_schema.lax_or_strict_schema(
lax_schema=lax_schema, strict_schema=strict_schema, strict=True
)
v = SchemaValidator(schema)
assert v.validate_python(123) == 123

schema = core_schema.lax_or_strict_schema(
lax_schema=lax_schema, strict_schema=strict_schema, strict=False
)
v = SchemaValidator(schema)
assert v.validate_python('123') == 123
```

Args:
lax_schema: The lax schema to use
strict_schema: The strict schema to use
strict: Whether the strict schema should be used
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 2491

---

### `def json_or_python_schema(json_schema: CoreSchema, python_schema: CoreSchema, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> JsonOrPythonSchema`

**Description:**
Returns a schema that uses the Json or Python schema depending on the input:

```py
from pydantic_core import SchemaValidator, ValidationError, core_schema

v = SchemaValidator(
core_schema.json_or_python_schema(
json_schema=core_schema.int_schema(),
python_schema=core_schema.int_schema(strict=True),
)
)

assert v.validate_json('"123"') == 123

try:
v.validate_python('123')
except ValidationError:
pass
else:
raise AssertionError('Validation should have failed')
```

Args:
json_schema: The schema to use for Json inputs
python_schema: The schema to use for Python inputs
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 2554

---

### `def typed_dict_field(schema: CoreSchema, required: bool | None = None, validation_alias: str | list[str | int] | list[list[str | int]] | None = None, serialization_alias: str | None = None, serialization_exclude: bool | None = None, metadata: Any = None) -> TypedDictField`

**Description:**
Returns a schema that matches a typed dict field, e.g.:

```py
from pydantic_core import core_schema

field = core_schema.typed_dict_field(schema=core_schema.int_schema(), required=True)
```

Args:
schema: The schema to use for the field
required: Whether the field is required
validation_alias: The alias(es) to use to find the field in the validation data
serialization_alias: The alias to use as a key when serializing
serialization_exclude: Whether to exclude the field when serializing
metadata: Any other information you want to include with the schema, not used by pydantic-core

**Line:** 2612

---

### `def typed_dict_schema(fields: Dict[(str, TypedDictField)], computed_fields: list[ComputedField] | None = None, strict: bool | None = None, extras_schema: CoreSchema | None = None, extra_behavior: ExtraBehavior | None = None, total: bool | None = None, populate_by_name: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None, config: CoreConfig | None = None) -> TypedDictSchema`

**Description:**
Returns a schema that matches a typed dict, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

wrapper_schema = core_schema.typed_dict_schema(
{'a': core_schema.typed_dict_field(core_schema.str_schema())}
)
v = SchemaValidator(wrapper_schema)
assert v.validate_python({'a': 'hello'}) == {'a': 'hello'}
```

Args:
fields: The fields to use for the typed dict
computed_fields: Computed fields to use when serializing the model, only applies when directly inside a model
strict: Whether the typed dict is strict
extras_schema: The extra validator to use for the typed dict
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
extra_behavior: The extra behavior to use for the typed dict
total: Whether the typed dict is total
populate_by_name: Whether the typed dict should populate by name
serialization: Custom serialization schema

**Line:** 2665

---

### `def model_field(schema: CoreSchema, validation_alias: str | list[str | int] | list[list[str | int]] | None = None, serialization_alias: str | None = None, serialization_exclude: bool | None = None, frozen: bool | None = None, metadata: Any = None) -> ModelField`

**Description:**
Returns a schema for a model field, e.g.:

```py
from pydantic_core import core_schema

field = core_schema.model_field(schema=core_schema.int_schema())
```

Args:
schema: The schema to use for the field
validation_alias: The alias(es) to use to find the field in the validation data
serialization_alias: The alias to use as a key when serializing
serialization_exclude: Whether to exclude the field when serializing
frozen: Whether the field is frozen
metadata: Any other information you want to include with the schema, not used by pydantic-core

**Line:** 2730

---

### `def model_fields_schema(fields: Dict[(str, ModelField)], model_name: str | None = None, computed_fields: list[ComputedField] | None = None, strict: bool | None = None, extras_schema: CoreSchema | None = None, extra_behavior: ExtraBehavior | None = None, populate_by_name: bool | None = None, from_attributes: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> ModelFieldsSchema`

**Description:**
Returns a schema that matches a typed dict, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

wrapper_schema = core_schema.model_fields_schema(
{'a': core_schema.model_field(core_schema.str_schema())}
)
v = SchemaValidator(wrapper_schema)
print(v.validate_python({'a': 'hello'}))
#> ({'a': 'hello'}, None, {'a'})
```

Args:
fields: The fields to use for the typed dict
model_name: The name of the model, used for error messages, defaults to "Model"
computed_fields: Computed fields to use when serializing the model, only applies when directly inside a model
strict: Whether the typed dict is strict
extras_schema: The extra validator to use for the typed dict
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
extra_behavior: The extra behavior to use for the typed dict
populate_by_name: Whether the typed dict should populate by name
from_attributes: Whether the typed dict should be populated from attributes
serialization: Custom serialization schema

**Line:** 2783

---

### `def model_schema(cls: Type[Any], schema: CoreSchema, custom_init: bool | None = None, root_model: bool | None = None, post_init: str | None = None, revalidate_instances: Literal['always', 'never', 'subclass-instances'] | None = None, strict: bool | None = None, frozen: bool | None = None, extra_behavior: ExtraBehavior | None = None, config: CoreConfig | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> ModelSchema`

**Description:**
A model schema generally contains a typed-dict schema.
It will run the typed dict validator, then create a new class
and set the dict and fields set returned from the typed dict validator
to `__dict__` and `__pydantic_fields_set__` respectively.

Example:

```py
from pydantic_core import CoreConfig, SchemaValidator, core_schema

class MyModel:
__slots__ = (
'__dict__',
'__pydantic_fields_set__',
'__pydantic_extra__',
'__pydantic_private__',
)

schema = core_schema.model_schema(
cls=MyModel,
config=CoreConfig(str_max_length=5),
schema=core_schema.model_fields_schema(
fields={'a': core_schema.model_field(core_schema.str_schema())},
),
)
v = SchemaValidator(schema)
assert v.isinstance_python({'a': 'hello'}) is True
assert v.isinstance_python({'a': 'too long'}) is False
```

Args:
cls: The class to use for the model
schema: The schema to use for the model
custom_init: Whether the model has a custom init method
root_model: Whether the model is a `RootModel`
post_init: The call after init to use for the model
revalidate_instances: whether instances of models and dataclasses (including subclass instances)
should re-validate defaults to config.revalidate_instances, else 'never'
strict: Whether the model is strict
frozen: Whether the model is frozen
extra_behavior: The extra behavior to use for the model, used in serialization
config: The config to use for the model
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 2857

---

### `def dataclass_field(name: str, schema: CoreSchema, kw_only: bool | None = None, init_only: bool | None = None, validation_alias: str | list[str | int] | list[list[str | int]] | None = None, serialization_alias: str | None = None, serialization_exclude: bool | None = None, metadata: Any = None, frozen: bool | None = None) -> DataclassField`

**Description:**
Returns a schema for a dataclass field, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

field = core_schema.dataclass_field(
name='a', schema=core_schema.str_schema(), kw_only=False
)
schema = core_schema.dataclass_args_schema('Foobar', [field])
v = SchemaValidator(schema)
assert v.validate_python({'a': 'hello'}) == ({'a': 'hello'}, None)
```

Args:
name: The name to use for the argument parameter
schema: The schema to use for the argument parameter
kw_only: Whether the field can be set with a positional argument as well as a keyword argument
init_only: Whether the field should be omitted  from `__dict__` and passed to `__post_init__`
validation_alias: The alias(es) to use to find the field in the validation data
serialization_alias: The alias to use as a key when serializing
serialization_exclude: Whether to exclude the field when serializing
metadata: Any other information you want to include with the schema, not used by pydantic-core
frozen: Whether the field is frozen

**Line:** 2951

---

### `def dataclass_args_schema(dataclass_name: str, fields: list[DataclassField], computed_fields: List[ComputedField] | None = None, populate_by_name: bool | None = None, collect_init_only: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None, extra_behavior: ExtraBehavior | None = None) -> DataclassArgsSchema`

**Description:**
Returns a schema for validating dataclass arguments, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

field_a = core_schema.dataclass_field(
name='a', schema=core_schema.str_schema(), kw_only=False
)
field_b = core_schema.dataclass_field(
name='b', schema=core_schema.bool_schema(), kw_only=False
)
schema = core_schema.dataclass_args_schema('Foobar', [field_a, field_b])
v = SchemaValidator(schema)
assert v.validate_python({'a': 'hello', 'b': True}) == ({'a': 'hello', 'b': True}, None)
```

Args:
dataclass_name: The name of the dataclass being validated
fields: The fields to use for the dataclass
computed_fields: Computed fields to use when serializing the dataclass
populate_by_name: Whether to populate by name
collect_init_only: Whether to collect init only fields into a dict to pass to `__post_init__`
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema
extra_behavior: How to handle extra fields

**Line:** 3015

---

### `def dataclass_schema(cls: Type[Any], schema: CoreSchema, fields: List[str], cls_name: str | None = None, post_init: bool | None = None, revalidate_instances: Literal['always', 'never', 'subclass-instances'] | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None, frozen: bool | None = None, slots: bool | None = None, config: CoreConfig | None = None) -> DataclassSchema`

**Description:**
Returns a schema for a dataclass. As with `ModelSchema`, this schema can only be used as a field within
another schema, not as the root type.

Args:
cls: The dataclass type, used to perform subclass checks
schema: The schema to use for the dataclass fields
fields: Fields of the dataclass, this is used in serialization and in validation during re-validation
and while validating assignment
cls_name: The name to use in error locs, etc; this is useful for generics (default: `cls.__name__`)
post_init: Whether to call `__post_init__` after validation
revalidate_instances: whether instances of models and dataclasses (including subclass instances)
should re-validate defaults to config.revalidate_instances, else 'never'
strict: Whether to require an exact instance of `cls`
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema
frozen: Whether the dataclass is frozen
slots: Whether `slots=True` on the dataclass, means each field is assigned independently, rather than
simply setting `__dict__`, default false

**Line:** 3086

---

### `def arguments_parameter(name: str, schema: CoreSchema, mode: Literal['positional_only', 'positional_or_keyword', 'keyword_only'] | None = None, alias: str | list[str | int] | list[list[str | int]] | None = None) -> ArgumentsParameter`

**Description:**
Returns a schema that matches an argument parameter, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

param = core_schema.arguments_parameter(
name='a', schema=core_schema.str_schema(), mode='positional_only'
)
schema = core_schema.arguments_schema([param])
v = SchemaValidator(schema)
assert v.validate_python(('hello',)) == (('hello',), {})
```

Args:
name: The name to use for the argument parameter
schema: The schema to use for the argument parameter
mode: The mode to use for the argument parameter
alias: The alias to use for the argument parameter

**Line:** 3148

---

### `def arguments_schema(arguments: list[ArgumentsParameter], populate_by_name: bool | None = None, var_args_schema: CoreSchema | None = None, var_kwargs_schema: CoreSchema | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> ArgumentsSchema`

**Description:**
Returns a schema that matches an arguments schema, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

param_a = core_schema.arguments_parameter(
name='a', schema=core_schema.str_schema(), mode='positional_only'
)
param_b = core_schema.arguments_parameter(
name='b', schema=core_schema.bool_schema(), mode='positional_only'
)
schema = core_schema.arguments_schema([param_a, param_b])
v = SchemaValidator(schema)
assert v.validate_python(('hello', True)) == (('hello', True), {})
```

Args:
arguments: The arguments to use for the arguments schema
populate_by_name: Whether to populate by name
var_args_schema: The variable args schema to use for the arguments schema
var_kwargs_schema: The variable kwargs schema to use for the arguments schema
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 3189

---

### `def call_schema(arguments: CoreSchema, function: Callable[(..., Any)], function_name: str | None = None, return_schema: CoreSchema | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> CallSchema`

**Description:**
Returns a schema that matches an arguments schema, then calls a function, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

param_a = core_schema.arguments_parameter(
name='a', schema=core_schema.str_schema(), mode='positional_only'
)
param_b = core_schema.arguments_parameter(
name='b', schema=core_schema.bool_schema(), mode='positional_only'
)
args_schema = core_schema.arguments_schema([param_a, param_b])

schema = core_schema.call_schema(
arguments=args_schema,
function=lambda a, b: a + str(not b),
return_schema=core_schema.str_schema(),
)
v = SchemaValidator(schema)
assert v.validate_python((('hello', True))) == 'helloFalse'
```

Args:
arguments: The arguments to use for the arguments schema
function: The function to use for the call schema
function_name: The function name to use for the call schema, if not provided `function.__name__` is used
return_schema: The return schema to use for the call schema
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 3248

---

### `def custom_error_schema(schema: CoreSchema, custom_error_type: str, custom_error_message: str | None = None, custom_error_context: dict[str, Any] | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> CustomErrorSchema`

**Description:**
Returns a schema that matches a custom error value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.custom_error_schema(
schema=core_schema.int_schema(),
custom_error_type='MyError',
custom_error_message='Error msg',
)
v = SchemaValidator(schema)
v.validate_python(1)
```

Args:
schema: The schema to use for the custom error schema
custom_error_type: The custom error type to use for the custom error schema
custom_error_message: The custom error message to use for the custom error schema
custom_error_context: The custom error context to use for the custom error schema
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 3313

---

### `def json_schema(schema: CoreSchema | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> JsonSchema`

**Description:**
Returns a schema that matches a JSON value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

dict_schema = core_schema.model_fields_schema(
{
'field_a': core_schema.model_field(core_schema.str_schema()),
'field_b': core_schema.model_field(core_schema.bool_schema()),
},
)

class MyModel:
__slots__ = (
'__dict__',
'__pydantic_fields_set__',
'__pydantic_extra__',
'__pydantic_private__',
)
field_a: str
field_b: bool

json_schema = core_schema.json_schema(schema=dict_schema)
schema = core_schema.model_schema(cls=MyModel, schema=json_schema)
v = SchemaValidator(schema)
m = v.validate_python('{"field_a": "hello", "field_b": true}')
assert isinstance(m, MyModel)
```

Args:
schema: The schema to use for the JSON schema
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 3367

---

### `def url_schema(max_length: int | None = None, allowed_schemes: list[str] | None = None, host_required: bool | None = None, default_host: str | None = None, default_port: int | None = None, default_path: str | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> UrlSchema`

**Description:**
Returns a schema that matches a URL value, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.url_schema()
v = SchemaValidator(schema)
print(v.validate_python('https://example.com'))
#> https://example.com/
```

Args:
max_length: The maximum length of the URL
allowed_schemes: The allowed URL schemes
host_required: Whether the URL must have a host
default_host: The default host to use if the URL does not have a host
default_port: The default port to use if the URL does not have a port
default_path: The default path to use if the URL does not have a path
strict: Whether to use strict URL parsing
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 3427

---

### `def multi_host_url_schema(max_length: int | None = None, allowed_schemes: list[str] | None = None, host_required: bool | None = None, default_host: str | None = None, default_port: int | None = None, default_path: str | None = None, strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> MultiHostUrlSchema`

**Description:**
Returns a schema that matches a URL value with possibly multiple hosts, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.multi_host_url_schema()
v = SchemaValidator(schema)
print(v.validate_python('redis://localhost,0.0.0.0,127.0.0.1'))
#> redis://localhost,0.0.0.0,127.0.0.1
```

Args:
max_length: The maximum length of the URL
allowed_schemes: The allowed URL schemes
host_required: Whether the URL must have a host
default_host: The default host to use if the URL does not have a host
default_port: The default port to use if the URL does not have a port
default_path: The default path to use if the URL does not have a path
strict: Whether to use strict URL parsing
ref: optional unique identifier of the schema, used to reference the schema in other places
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 3493

---

### `def definitions_schema(schema: CoreSchema, definitions: list[CoreSchema]) -> DefinitionsSchema`

**Description:**
Build a schema that contains both an inner schema and a list of definitions which can be used
within the inner schema.

```py
from pydantic_core import SchemaValidator, core_schema

schema = core_schema.definitions_schema(
core_schema.list_schema(core_schema.definition_reference_schema('foobar')),
[core_schema.int_schema(ref='foobar')],
)
v = SchemaValidator(schema)
assert v.validate_python([1, 2, '3']) == [1, 2, 3]
```

Args:
schema: The inner schema
definitions: List of definitions which can be referenced within inner schema

**Line:** 3553

---

### `def definition_reference_schema(schema_ref: str, metadata: Any = None, serialization: SerSchema | None = None) -> DefinitionReferenceSchema`

**Description:**
Returns a schema that points to a schema stored in "definitions", this is useful for nested recursive
models and also when you want to define validators separately from the main schema, e.g.:

```py
from pydantic_core import SchemaValidator, core_schema

schema_definition = core_schema.definition_reference_schema('list-schema')
schema = core_schema.definitions_schema(
schema=schema_definition,
definitions=[
core_schema.list_schema(items_schema=schema_definition, ref='list-schema'),
],
)
v = SchemaValidator(schema)
assert v.validate_python([()]) == [[]]
```

Args:
schema_ref: The schema ref to use for the definition reference schema
metadata: Any other information you want to include with the schema, not used by pydantic-core
serialization: Custom serialization schema

**Line:** 3583

---

### `def _dict_not_none(**kwargs: Any) -> Any`

**Line:** 3826

---

### `def field_before_validator_function(function: WithInfoValidatorFunction, field_name: str, schema: CoreSchema, **kwargs)`

**Decorators:**
- `@deprecated(...)`

**Line:** 3836

---

### `def general_before_validator_function(*args, **kwargs)`

**Decorators:**
- `@deprecated(...)`

**Line:** 3845

---

### `def field_after_validator_function(function: WithInfoValidatorFunction, field_name: str, schema: CoreSchema, **kwargs)`

**Decorators:**
- `@deprecated(...)`

**Line:** 3854

---

### `def general_after_validator_function(*args, **kwargs)`

**Decorators:**
- `@deprecated(...)`

**Line:** 3863

---

### `def field_wrap_validator_function(function: WithInfoWrapValidatorFunction, field_name: str, schema: CoreSchema, **kwargs)`

**Decorators:**
- `@deprecated(...)`

**Line:** 3872

---

### `def general_wrap_validator_function(*args, **kwargs)`

**Decorators:**
- `@deprecated(...)`

**Line:** 3883

---

### `def field_plain_validator_function(function: WithInfoValidatorFunction, field_name: str, **kwargs)`

**Decorators:**
- `@deprecated(...)`

**Line:** 3892

---

### `def general_plain_validator_function(*args, **kwargs)`

**Decorators:**
- `@deprecated(...)`

**Line:** 3901

---

### `def __getattr__(attr_name: str) -> object`

**Line:** 3920

---


## Module: venv2.libthon3.12.site-packagesdantic_settings.sources
**File:** `venv2/lib/python3.12/site-packages/pydantic_settings/sources.py`

**Imports:**
- __future__.annotations
- abc.ABC
- abc.abstractmethod
- collections.deque
- dataclasses.is_dataclass
- dotenv.dotenv_values
- json
- os
- pathlib.Path
- pydantic.AliasChoices
- pydantic.AliasPath
- pydantic.BaseModel
- pydantic.Json
- pydantic._internal._typing_extra.origin_is_union
- pydantic._internal._utils.deep_update
- pydantic._internal._utils.lenient_issubclass
- pydantic.fields.FieldInfo
- pydantic_settings.main.BaseSettings
- pydantic_settings.utils.path_type_label
- typing.Any
- typing.List
- typing.Mapping
- typing.Sequence
- typing.TYPE_CHECKING
- typing.Tuple
- typing.Union
- typing.cast
- typing_extensions.get_args
- typing_extensions.get_origin
- warnings

**Functions:**

### `def read_env_file(file_path: Path, encoding: str | None = None, case_sensitive: bool = False) -> Mapping[(str, str | None)]`

**Line:** 621

---

### `def _annotation_is_complex(annotation: type[Any] | None, metadata: list[Any]) -> bool`

**Line:** 631

---

### `def _annotation_is_complex_inner(annotation: type[Any] | None) -> bool`

**Line:** 643

---


## Module: venv2.libthon3.12.site-packagesdantic_settings.utils
**File:** `venv2/lib/python3.12/site-packages/pydantic_settings/utils.py`

**Imports:**
- pathlib.Path

**Functions:**

### `def path_type_label(p: Path) -> str`

**Description:**
Find out what sort of thing a path is.

**Line:** 15

---


## Module: venv2.libthon3.12.site-packagesgments.__init__
**File:** `venv2/lib/python3.12/site-packages/pygments/__init__.py`

**Imports:**
- io.BytesIO
- io.StringIO
- pygments.formatter.Formatter
- pygments.lexer.RegexLexer

**Functions:**

### `def lex(code, lexer)`

**Description:**
Lex `code` with the `lexer` (must be a `Lexer` instance)
and return an iterable of tokens. Currently, this only calls
`lexer.get_tokens()`.

**Line:** 35

---

### `def format(tokens, formatter, outfile = None)`

**Description:**
Format ``tokens`` (an iterable of tokens) with the formatter ``formatter``
(a `Formatter` instance).

If ``outfile`` is given and a valid file object (an object with a
``write`` method), the result will be written to it, otherwise it
is returned as a string.

**Line:** 52

---

### `def highlight(code, lexer, formatter, outfile = None)`

**Description:**
This is the most high-level highlighting function. It combines `lex` and
`format` in one function.

**Line:** 77

---


## Module: venv2.libthon3.12.site-packagesgments.cmdline
**File:** `venv2/lib/python3.12/site-packages/pygments/cmdline.py`

**Imports:**
- argparse
- colorama.initialise
- json
- os
- pygments.__version__
- pygments.filters.find_filter_class
- pygments.filters.get_all_filters
- pygments.formatters.find_formatter_class
- pygments.formatters.get_all_formatters
- pygments.formatters.get_formatter_by_name
- pygments.formatters.get_formatter_for_filename
- pygments.formatters.latex.LatexEmbeddedLexer
- pygments.formatters.latex.LatexFormatter
- pygments.formatters.load_formatter_from_file
- pygments.formatters.terminal.TerminalFormatter
- pygments.formatters.terminal256.Terminal256Formatter
- pygments.formatters.terminal256.TerminalTrueColorFormatter
- pygments.highlight
- pygments.lexers.find_lexer_class_for_filename
- pygments.lexers.get_all_lexers
- pygments.lexers.get_lexer_by_name
- pygments.lexers.get_lexer_for_filename
- pygments.lexers.guess_lexer
- pygments.lexers.load_lexer_from_file
- pygments.lexers.special.TextLexer
- pygments.styles.get_all_styles
- pygments.styles.get_style_by_name
- pygments.util.ClassNotFound
- pygments.util.OptionError
- pygments.util.UnclosingTextIOWrapper
- pygments.util.docstring_headline
- pygments.util.guess_decode
- pygments.util.guess_decode_from_terminal
- pygments.util.terminal_encoding
- shutil
- sys
- textwrap.dedent
- traceback

**Functions:**

### `def _parse_options(o_strs)`

**Line:** 33

---

### `def _parse_filters(f_strs)`

**Line:** 54

---

### `def _print_help(what, name)`

**Line:** 67

---

### `def _print_list(what)`

**Line:** 87

---

### `def _print_list_as_json(requested_items)`

**Line:** 138

---

### `def main_inner(parser, argns)`

**Line:** 182

---

### `def main(args = sys.argv)`

**Description:**
Main command line entry point.

**Line:** 528

---


## Module: venv2.libthon3.12.site-packagesgments.console
**File:** `venv2/lib/python3.12/site-packages/pygments/console.py`

**Functions:**

### `def reset_color()`

**Line:** 40

---

### `def colorize(color_key, text)`

**Line:** 44

---

### `def ansiformat(attr, text)`

**Description:**
Format ``text`` with a color and/or some attributes::

color       normal color
*color*     bold color
_color_     underlined color
+color+     blinking color

**Line:** 48

---


## Module: venv2.libthon3.12.site-packagesgments.filter
**File:** `venv2/lib/python3.12/site-packages/pygments/filter.py`

**Functions:**

### `def apply_filters(stream, filters, lexer = None)`

**Description:**
Use this method to apply an iterable of filters to
a stream. If lexer is given it's forwarded to the
filter, otherwise the filter receives `None`.

**Line:** 12

---

### `def simplefilter(f)`

**Description:**
Decorator that converts a function into a filter::

@simplefilter
def lowercase(self, lexer, stream, options):
for ttype, value in stream:
yield ttype, value.lower()

**Line:** 25

---


## Module: venv2.libthon3.12.site-packagesgments.filters.__init__
**File:** `venv2/lib/python3.12/site-packages/pygments/filters/__init__.py`

**Imports:**
- pygments.filter.Filter
- pygments.plugin.find_plugin_filters
- pygments.token.Comment
- pygments.token.Error
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.String
- pygments.token.Whitespace
- pygments.token.string_to_tokentype
- pygments.util.ClassNotFound
- pygments.util.OptionError
- pygments.util.get_bool_opt
- pygments.util.get_choice_opt
- pygments.util.get_int_opt
- pygments.util.get_list_opt
- re

**Functions:**

### `def find_filter_class(filtername)`

**Description:**
Lookup a filter by name. Return None if not found.

**Line:** 22

---

### `def get_filter_by_name(filtername, **options)`

**Description:**
Return an instantiated filter.

Options are passed to the filter initializer if wanted.
Raise a ClassNotFound if not found.

**Line:** 32

---

### `def get_all_filters()`

**Description:**
Return a generator of all filter names.

**Line:** 45

---

### `def _replace_special(ttype, value, regex, specialttype, replacefunc = lambda x: x)`

**Line:** 52

---


## Module: venv2.libthon3.12.site-packagesgments.formatter
**File:** `venv2/lib/python3.12/site-packages/pygments/formatter.py`

**Imports:**
- codecs
- pygments.styles.get_style_by_name
- pygments.util.get_bool_opt

**Functions:**

### `def _lookup_style(style)`

**Line:** 19

---


## Module: venv2.libthon3.12.site-packagesgments.formatters.__init__
**File:** `venv2/lib/python3.12/site-packages/pygments/formatters/__init__.py`

**Imports:**
- fnmatch
- os.path.basename
- pygments.formatters._mapping.FORMATTERS
- pygments.plugin.find_plugin_formatters
- pygments.util.ClassNotFound
- re
- sys
- types

**Functions:**

### `def _fn_matches(fn, glob)`

**Description:**
Return whether the supplied file name fn matches pattern filename.

**Line:** 28

---

### `def _load_formatters(module_name)`

**Description:**
Load a formatter (and all others in the module too).

**Line:** 36

---

### `def get_all_formatters()`

**Description:**
Return a generator for all formatter classes.

**Line:** 44

---

### `def find_formatter_class(alias)`

**Description:**
Lookup a formatter by alias.

Returns None if not found.

**Line:** 55

---

### `def get_formatter_by_name(_alias, **options)`

**Description:**
Return an instance of a :class:`.Formatter` subclass that has `alias` in its
aliases list. The formatter is given the `options` at its instantiation.

Will raise :exc:`pygments.util.ClassNotFound` if no formatter with that
alias is found.

**Line:** 70

---

### `def load_formatter_from_file(filename, formattername = 'CustomFormatter', **options)`

**Description:**
Return a `Formatter` subclass instance loaded from the provided file, relative
to the current directory.

The file is expected to contain a Formatter class named ``formattername``
(by default, CustomFormatter). Users should be very careful with the input, because
this method is equivalent to running ``eval()`` on the input file. The formatter is
given the `options` at its instantiation.

:exc:`pygments.util.ClassNotFound` is raised if there are any errors loading
the formatter.

.. versionadded:: 2.2

**Line:** 84

---

### `def get_formatter_for_filename(fn, **options)`

**Description:**
Return a :class:`.Formatter` subclass instance that has a filename pattern
matching `fn`. The formatter is given the `options` at its instantiation.

Will raise :exc:`pygments.util.ClassNotFound` if no formatter for that filename
is found.

**Line:** 118

---


## Module: venv2.libthon3.12.site-packagesgments.formatters.html
**File:** `venv2/lib/python3.12/site-packages/pygments/formatters/html.py`

**Imports:**
- ctags
- functools
- io.StringIO
- os
- os.path
- pygments.formatter.Formatter
- pygments.token.STANDARD_TYPES
- pygments.token.Text
- pygments.token.Token
- pygments.util.get_bool_opt
- pygments.util.get_int_opt
- pygments.util.get_list_opt
- sys

**Functions:**

### `def escape_html(text, table = _escape_html_table)`

**Description:**
Escape &, <, > as well as single and double quotes for HTML.

**Line:** 38

---

### `def webify(color)`

**Line:** 43

---

### `def _get_ttype_class(ttype)`

**Line:** 58

---


## Module: venv2.libthon3.12.site-packagesgments.formatters.irc
**File:** `venv2/lib/python3.12/site-packages/pygments/formatters/irc.py`

**Imports:**
- pygments.formatter.Formatter
- pygments.token.Comment
- pygments.token.Error
- pygments.token.Generic
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.String
- pygments.token.Token
- pygments.token.Whitespace
- pygments.util.get_choice_opt

**Functions:**

### `def ircformat(color, text)`

**Line:** 76

---


## Module: venv2.libthon3.12.site-packagesgments.formatters.latex
**File:** `venv2/lib/python3.12/site-packages/pygments/formatters/latex.py`

**Imports:**
- io.StringIO
- pygments.formatter.Formatter
- pygments.lexer.Lexer
- pygments.lexer.do_insertions
- pygments.token.STANDARD_TYPES
- pygments.token.Token
- pygments.util.get_bool_opt
- pygments.util.get_int_opt

**Functions:**

### `def escape_tex(text, commandprefix)`

**Line:** 22

---

### `def _get_ttype_name(ttype)`

**Line:** 135

---


## Module: venv2.libthon3.12.site-packagesgments.formatters.pangomarkup
**File:** `venv2/lib/python3.12/site-packages/pygments/formatters/pangomarkup.py`

**Imports:**
- pygments.formatter.Formatter

**Functions:**

### `def escape_special_chars(text, table = _escape_table)`

**Description:**
Escape & and < for Pango Markup.

**Line:** 23

---


## Module: venv2.libthon3.12.site-packagesgments.formatters.svg
**File:** `venv2/lib/python3.12/site-packages/pygments/formatters/svg.py`

**Imports:**
- pygments.formatter.Formatter
- pygments.token.Comment
- pygments.util.get_bool_opt
- pygments.util.get_int_opt

**Functions:**

### `def escape_html(text)`

**Description:**
Escape &, <, > as well as single and double quotes for HTML.

**Line:** 18

---


## Module: venv2.libthon3.12.site-packagesgments.lexer
**File:** `venv2/lib/python3.12/site-packages/pygments/lexer.py`

**Imports:**
- chardet
- pygments.filter.Filter
- pygments.filter.apply_filters
- pygments.filters.get_filter_by_name
- pygments.regexopt.regex_opt
- pygments.token.Error
- pygments.token.Other
- pygments.token.Text
- pygments.token.Whitespace
- pygments.token._TokenType
- pygments.util.Future
- pygments.util.get_bool_opt
- pygments.util.get_int_opt
- pygments.util.get_list_opt
- pygments.util.guess_decode
- pygments.util.make_analysator
- re
- sys
- time

**Functions:**

### `def bygroups(*args)`

**Description:**
Callback that yields multiple actions for each group in the match.

**Line:** 385

---

### `def using(_other, **kwargs)`

**Description:**
Callback that processes the match with a different lexer.

The keyword arguments are forwarded to the lexer, except `state` which
is handled separately.

`state` specifies the state that the new lexer will start in, and can
be an enumerable such as ('root', 'inline', 'string') or a simple
string which is assumed to be on top of the root state.

Note: For that to work, `_other` must not be an `ExtendedRegexLexer`.

**Line:** 420

---

### `def do_insertions(insertions, tokens)`

**Description:**
Helper for lexers which must combine the results of several
sublexers.

``insertions`` is a list of ``(index, itokens)`` pairs.
Each ``itokens`` iterable should be inserted at position
``index`` into the token stream given by the ``tokens``
argument.

The result is a combined token stream.

TODO: clean up the code here.

**Line:** 849

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.__init__
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/__init__.py`

**Imports:**
- fnmatch
- os.path.basename
- pygments.lexers._mapping.LEXERS
- pygments.modeline.get_filetype_from_buffer
- pygments.plugin.find_plugin_lexers
- pygments.util.ClassNotFound
- pygments.util.guess_decode
- re
- sys
- types

**Functions:**

### `def _fn_matches(fn, glob)`

**Description:**
Return whether the supplied file name fn matches pattern filename.

**Line:** 35

---

### `def _load_lexers(module_name)`

**Description:**
Load a lexer (and all others in the module too).

**Line:** 43

---

### `def get_all_lexers(plugins = True)`

**Description:**
Return a generator of tuples in the form ``(name, aliases,
filenames, mimetypes)`` of all know lexers.

If *plugins* is true (the default), plugin lexers supplied by entrypoints
are also returned.  Otherwise, only builtin ones are considered.

**Line:** 51

---

### `def find_lexer_class(name)`

**Description:**
Return the `Lexer` subclass that with the *name* attribute as given by
the *name* argument.

**Line:** 65

---

### `def find_lexer_class_by_name(_alias)`

**Description:**
Return the `Lexer` subclass that has `alias` in its aliases list, without
instantiating it.

Like `get_lexer_by_name`, but does not instantiate the class.

Will raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is
found.

.. versionadded:: 2.2

**Line:** 83

---

### `def get_lexer_by_name(_alias, **options)`

**Description:**
Return an instance of a `Lexer` subclass that has `alias` in its
aliases list. The lexer is given the `options` at its
instantiation.

Will raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is
found.

**Line:** 110

---

### `def load_lexer_from_file(filename, lexername = 'CustomLexer', **options)`

**Description:**
Load a lexer from a file.

This method expects a file located relative to the current working
directory, which contains a Lexer class. By default, it expects the
Lexer to be name CustomLexer; you can specify your own class name
as the second argument to this function.

Users should be very careful with the input, because this method
is equivalent to running eval on the input file.

Raises ClassNotFound if there are any problems importing the Lexer.

.. versionadded:: 2.2

**Line:** 135

---

### `def find_lexer_class_for_filename(_fn, code = None)`

**Description:**
Get a lexer for a filename.

If multiple lexers match the filename pattern, use ``analyse_text()`` to
figure out which one is more appropriate.

Returns None if not found.

**Line:** 169

---

### `def get_lexer_for_filename(_fn, code = None, **options)`

**Description:**
Get a lexer for a filename.

Return a `Lexer` subclass instance that has a filename pattern
matching `fn`. The lexer is given the `options` at its
instantiation.

Raise :exc:`pygments.util.ClassNotFound` if no lexer for that filename
is found.

If multiple lexers match the filename pattern, use their ``analyse_text()``
methods to figure out which one is more appropriate.

**Line:** 212

---

### `def get_lexer_for_mimetype(_mime, **options)`

**Description:**
Return a `Lexer` subclass instance that has `mime` in its mimetype
list. The lexer is given the `options` at its instantiation.

Will raise :exc:`pygments.util.ClassNotFound` if not lexer for that mimetype
is found.

**Line:** 231

---

### `def _iter_lexerclasses(plugins = True)`

**Description:**
Return an iterator over all lexer classes.

**Line:** 250

---

### `def guess_lexer_for_filename(_fn, _text, **options)`

**Description:**
As :func:`guess_lexer()`, but only lexers which have a pattern in `filenames`
or `alias_filenames` that matches `filename` are taken into consideration.

:exc:`pygments.util.ClassNotFound` is raised if no lexer thinks it can
handle the content.

**Line:** 261

---

### `def guess_lexer(_text, **options)`

**Description:**
Return a `Lexer` subclass instance that's guessed from the text in
`text`. For that, the :meth:`.analyse_text()` method of every known lexer
class is called with the text as argument, and the lexer which returned the
highest value will be instantiated and returned.

:exc:`pygments.util.ClassNotFound` is raised if no lexer thinks it can
handle the content.

**Line:** 304

---


## Module: venv2.libthon3.12.site-packagesgments.lexers._lua_builtins
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/_lua_builtins.py`

**Imports:**
- pprint
- re
- urllib.request.urlopen

**Functions:**

### `def module_callbacks()`

**Line:** 185

---

### `def get_newest_version()`

**Line:** 224

---

### `def get_lua_functions(version)`

**Line:** 232

---

### `def get_function_module(name)`

**Line:** 242

---

### `def regenerate(filename, modules)`

**Line:** 251

---

### `def run()`

**Line:** 264

---


## Module: venv2.libthon3.12.site-packagesgments.lexers._mysql_builtins
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/_mysql_builtins.py`

**Imports:**
- pygments.util.format_lines
- re
- urllib.request.urlopen

**Functions:**

### `def update_myself()`

**Line:** 1246

---

### `def parse_lex_keywords(f)`

**Description:**
Parse keywords in lex.h.

**Line:** 1265

---

### `def parse_lex_optimizer_hints(f)`

**Description:**
Parse optimizer hints in lex.h.

**Line:** 1278

---

### `def parse_lex_functions(f)`

**Description:**
Parse MySQL function names from lex.h.

**Line:** 1291

---

### `def parse_item_create_functions(f)`

**Description:**
Parse MySQL function names from item_create.cc.

**Line:** 1304

---

### `def update_content(field_name, content)`

**Description:**
Overwrite this file with content parsed from MySQL's source code.

**Line:** 1317

---


## Module: venv2.libthon3.12.site-packagesgments.lexers._php_builtins
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/_php_builtins.py`

**Imports:**
- glob
- os
- pprint
- re
- shutil
- tarfile
- urllib.request.urlretrieve

**Functions:**

### `def get_php_functions()`

**Line:** 3263

---

### `def get_php_references()`

**Line:** 3298

---

### `def regenerate(filename, modules)`

**Line:** 3305

---

### `def run()`

**Line:** 3317

---


## Module: venv2.libthon3.12.site-packagesgments.lexers._postgres_builtins
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/_postgres_builtins.py`

**Imports:**
- pygments.util.format_lines
- re
- urllib.request.urlopen

**Functions:**

### `def update_myself()`

**Line:** 641

---

### `def parse_keywords(f)`

**Line:** 654

---

### `def parse_datatypes(f)`

**Line:** 665

---

### `def parse_pseudos(f)`

**Line:** 694

---

### `def update_consts(filename, constname, content)`

**Line:** 723

---


## Module: venv2.libthon3.12.site-packagesgments.lexers._scilab_builtins
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/_scilab_builtins.py`

**Imports:**
- pygments.util.duplicates_removed
- pygments.util.format_lines
- subprocess

**Functions:**

### `def extract_completion(var_type)`

**Line:** 3060

---


## Module: venv2.libthon3.12.site-packagesgments.lexers._sourcemod_builtins
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/_sourcemod_builtins.py`

**Imports:**
- pygments.util.format_lines
- re
- urllib.request.FancyURLopener

**Functions:**

### `def get_version()`

**Line:** 1105

---

### `def get_sm_functions()`

**Line:** 1114

---

### `def regenerate(filename, natives)`

**Line:** 1124

---

### `def run()`

**Line:** 1137

---


## Module: venv2.libthon3.12.site-packagesgments.lexers._vim_builtins
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/_vim_builtins.py`

**Functions:**

### `def _getauto()`

**Line:** 14

---

### `def _getcommand()`

**Line:** 109

---

### `def _getoption()`

**Line:** 676

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.asm
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/asm.py`

**Imports:**
- pygments.lexer.DelegatingLexer
- pygments.lexer.RegexLexer
- pygments.lexer.bygroups
- pygments.lexer.default
- pygments.lexer.include
- pygments.lexer.using
- pygments.lexer.words
- pygments.lexers.c_cpp.CLexer
- pygments.lexers.c_cpp.CppLexer
- pygments.lexers.d.DLexer
- pygments.token.Comment
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.Other
- pygments.token.Punctuation
- pygments.token.String
- pygments.token.Text
- pygments.token.Whitespace
- re

**Functions:**

### `def _objdump_lexer_tokens(asm_lexer)`

**Description:**
Common objdump lexer tokens to wrap an ASM lexer.

**Line:** 111

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.asn1
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/asn1.py`

**Imports:**
- pygments.lexer.RegexLexer
- pygments.lexer.bygroups
- pygments.lexer.words
- pygments.token.Comment
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.Punctuation
- pygments.token.String
- pygments.token.Whitespace
- re

**Functions:**

### `def word_sequences(tokens)`

**Line:** 113

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.configs
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/configs.py`

**Imports:**
- pygments.lexer.ExtendedRegexLexer
- pygments.lexer.RegexLexer
- pygments.lexer.bygroups
- pygments.lexer.default
- pygments.lexer.include
- pygments.lexer.line_re
- pygments.lexer.using
- pygments.lexer.words
- pygments.lexers.data.JsonLexer
- pygments.lexers.shell.BashLexer
- pygments.token.Comment
- pygments.token.Error
- pygments.token.Generic
- pygments.token.Keyword
- pygments.token.Literal
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.Punctuation
- pygments.token.String
- pygments.token.Text
- pygments.token.Whitespace
- re

**Functions:**

### `def _rx_indent(level)`

**Line:** 254

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.css
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/css.py`

**Imports:**
- copy
- pygments.lexer.ExtendedRegexLexer
- pygments.lexer.RegexLexer
- pygments.lexer.bygroups
- pygments.lexer.default
- pygments.lexer.include
- pygments.lexer.inherit
- pygments.lexer.words
- pygments.lexers._css_builtins._css_properties
- pygments.token.Comment
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.Punctuation
- pygments.token.String
- pygments.token.Whitespace
- re

**Functions:**

### `def _indentation(lexer, match, ctx)`

**Line:** 415

---

### `def _starts_block(token, state)`

**Line:** 431

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.erlang
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/erlang.py`

**Imports:**
- pygments.lexer.Lexer
- pygments.lexer.RegexLexer
- pygments.lexer.bygroups
- pygments.lexer.default
- pygments.lexer.do_insertions
- pygments.lexer.include
- pygments.lexer.line_re
- pygments.lexer.words
- pygments.token.Comment
- pygments.token.Generic
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.Punctuation
- pygments.token.String
- pygments.token.Whitespace
- re

**Functions:**

### `def gen_elixir_string_rules(name, symbol, token)`

**Line:** 190

---

### `def gen_elixir_sigstr_rules(term, term_class, token, interpol = True)`

**Line:** 202

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.graphics
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/graphics.py`

**Imports:**
- pygments.lexer.RegexLexer
- pygments.lexer.bygroups
- pygments.lexer.default
- pygments.lexer.include
- pygments.lexer.this
- pygments.lexer.using
- pygments.lexer.words
- pygments.lexers._asy_builtins.ASYFUNCNAME
- pygments.lexers._asy_builtins.ASYVARNAME
- pygments.token.Comment
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.Punctuation
- pygments.token.String
- pygments.token.Text
- pygments.token.Whitespace

**Functions:**

### `def _shortened(word)`

**Line:** 516

---

### `def _shortened_many(*words)`

**Line:** 522

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.json5
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/json5.py`

**Imports:**
- pygments.lexer.RegexLexer
- pygments.lexer.include
- pygments.lexer.words
- pygments.token.Comment
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Number
- pygments.token.Punctuation
- pygments.token.String
- pygments.token.Whitespace

**Functions:**

### `def string_rules(quote_mark)`

**Line:** 18

---

### `def quoted_field_name(quote_mark)`

**Line:** 27

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.jsonnet
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/jsonnet.py`

**Imports:**
- pygments.lexer.RegexLexer
- pygments.lexer.include
- pygments.lexer.words
- pygments.token.Comment
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.Punctuation
- pygments.token.String
- pygments.token.Text
- pygments.token.Whitespace

**Functions:**

### `def string_rules(quote_mark)`

**Line:** 21

---

### `def quoted_field_name(quote_mark)`

**Line:** 29

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.lilypond
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/lilypond.py`

**Imports:**
- pygments.lexer.bygroups
- pygments.lexer.default
- pygments.lexer.inherit
- pygments.lexer.words
- pygments.lexers._lilypond_builtins.articulations
- pygments.lexers._lilypond_builtins.chord_modifiers
- pygments.lexers._lilypond_builtins.clefs
- pygments.lexers._lilypond_builtins.context_properties
- pygments.lexers._lilypond_builtins.contexts
- pygments.lexers._lilypond_builtins.dynamics
- pygments.lexers._lilypond_builtins.grob_properties
- pygments.lexers._lilypond_builtins.grobs
- pygments.lexers._lilypond_builtins.header_variables
- pygments.lexers._lilypond_builtins.keywords
- pygments.lexers._lilypond_builtins.markup_commands
- pygments.lexers._lilypond_builtins.music_commands
- pygments.lexers._lilypond_builtins.music_functions
- pygments.lexers._lilypond_builtins.paper_variables
- pygments.lexers._lilypond_builtins.pitch_language_names
- pygments.lexers._lilypond_builtins.pitches
- pygments.lexers._lilypond_builtins.repeat_types
- pygments.lexers._lilypond_builtins.scales
- pygments.lexers._lilypond_builtins.scheme_functions
- pygments.lexers._lilypond_builtins.translators
- pygments.lexers._lilypond_builtins.units
- pygments.lexers.lisp.SchemeLexer
- pygments.token.Token
- re

**Functions:**

### `def builtin_words(names, backslash, suffix = NAME_END_RE)`

**Line:** 36

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.objective
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/objective.py`

**Imports:**
- pygments.lexer.RegexLexer
- pygments.lexer.bygroups
- pygments.lexer.default
- pygments.lexer.include
- pygments.lexer.inherit
- pygments.lexer.this
- pygments.lexer.using
- pygments.lexer.words
- pygments.lexers._cocoa_builtins.COCOA_INTERFACES
- pygments.lexers._cocoa_builtins.COCOA_PRIMITIVES
- pygments.lexers._cocoa_builtins.COCOA_PROTOCOLS
- pygments.lexers.c_cpp.CLexer
- pygments.lexers.c_cpp.CppLexer
- pygments.token.Comment
- pygments.token.Keyword
- pygments.token.Literal
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.Punctuation
- pygments.token.String
- pygments.token.Text
- pygments.token.Whitespace
- re

**Functions:**

### `def objective(baselexer)`

**Description:**
Generate a subclass of baselexer that accepts the Objective-C syntax
extensions.

**Line:** 23

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.robotframework
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/robotframework.py`

**Imports:**
- pygments.lexer.Lexer
- pygments.token.Token
- re

**Functions:**

### `def normalize(string, remove = '')`

**Line:** 47

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.scripting
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/scripting.py`

**Imports:**
- pygments.lexer.RegexLexer
- pygments.lexer.bygroups
- pygments.lexer.combined
- pygments.lexer.default
- pygments.lexer.include
- pygments.lexer.words
- pygments.lexers._lua_builtins.MODULES
- pygments.lexers._luau_builtins.LUAU_BUILTINS
- pygments.lexers._luau_builtins.ROBLOX_BUILTINS
- pygments.token.Comment
- pygments.token.Error
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.Other
- pygments.token.Punctuation
- pygments.token.String
- pygments.token.Text
- pygments.token.Whitespace
- pygments.util.get_bool_opt
- pygments.util.get_list_opt
- re

**Functions:**

### `def all_lua_builtins()`

**Line:** 24

---

### `def _luau_make_expression(should_pop, _s)`

**Line:** 181

---

### `def _luau_make_expression_special(should_pop)`

**Line:** 203

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.sql
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/sql.py`

**Imports:**
- collections
- pygments.lexer.Lexer
- pygments.lexer.RegexLexer
- pygments.lexer.bygroups
- pygments.lexer.do_insertions
- pygments.lexer.words
- pygments.lexers.ClassNotFound
- pygments.lexers._googlesql_builtins
- pygments.lexers._mysql_builtins.MYSQL_CONSTANTS
- pygments.lexers._mysql_builtins.MYSQL_DATATYPES
- pygments.lexers._mysql_builtins.MYSQL_FUNCTIONS
- pygments.lexers._mysql_builtins.MYSQL_KEYWORDS
- pygments.lexers._mysql_builtins.MYSQL_OPTIMIZER_HINTS
- pygments.lexers._postgres_builtins.DATATYPES
- pygments.lexers._postgres_builtins.EXPLAIN_KEYWORDS
- pygments.lexers._postgres_builtins.KEYWORDS
- pygments.lexers._postgres_builtins.PLPGSQL_KEYWORDS
- pygments.lexers._postgres_builtins.PSEUDO_TYPES
- pygments.lexers._tsql_builtins
- pygments.lexers.get_lexer_by_name
- pygments.token.Comment
- pygments.token.Generic
- pygments.token.Keyword
- pygments.token.Literal
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.Punctuation
- pygments.token.String
- pygments.token.Text
- pygments.token.Whitespace
- re

**Functions:**

### `def language_callback(lexer, match)`

**Description:**
Parse the content of a $-string using a lexer

The lexer is chosen looking for a nearby LANGUAGE or assumed as
plpgsql if inside a DO statement and no LANGUAGE has been found.

**Line:** 89

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.usd
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/usd.py`

**Imports:**
- pygments.lexer.RegexLexer
- pygments.lexer.bygroups
- pygments.lexer.words
- pygments.lexers._usd_builtins.COMMON_ATTRIBUTES
- pygments.lexers._usd_builtins.KEYWORDS
- pygments.lexers._usd_builtins.OPERATORS
- pygments.lexers._usd_builtins.SPECIAL_NAMES
- pygments.lexers._usd_builtins.TYPES
- pygments.token.Comment
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.Punctuation
- pygments.token.String
- pygments.token.Text
- pygments.token.Whitespace

**Functions:**

### `def _keywords(words, type_)`

**Line:** 21

---


## Module: venv2.libthon3.12.site-packagesgments.lexers.wowtoc
**File:** `venv2/lib/python3.12/site-packages/pygments/lexers/wowtoc.py`

**Imports:**
- pygments.lexer.RegexLexer
- pygments.lexer.bygroups
- pygments.token.Comment
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Punctuation
- pygments.token.String
- pygments.token.Text
- re

**Functions:**

### `def _create_tag_line_pattern(inner_pattern, ignore_case = False)`

**Line:** 20

---

### `def _create_tag_line_token(inner_pattern, inner_token, ignore_case = False)`

**Line:** 27

---


## Module: venv2.libthon3.12.site-packagesgments.modeline
**File:** `venv2/lib/python3.12/site-packages/pygments/modeline.py`

**Imports:**
- re

**Functions:**

### `def get_filetype_from_line(l)`

**Line:** 22

---

### `def get_filetype_from_buffer(buf, max_lines = 5)`

**Description:**
Scan the buffer for modelines and return filetype if one is found.

**Line:** 28

---


## Module: venv2.libthon3.12.site-packagesgments.plugin
**File:** `venv2/lib/python3.12/site-packages/pygments/plugin.py`

**Imports:**
- importlib.metadata.entry_points

**Functions:**

### `def iter_entry_points(group_name)`

**Line:** 43

---

### `def find_plugin_lexers()`

**Line:** 55

---

### `def find_plugin_formatters()`

**Line:** 60

---

### `def find_plugin_styles()`

**Line:** 65

---

### `def find_plugin_filters()`

**Line:** 70

---


## Module: venv2.libthon3.12.site-packagesgments.regexopt
**File:** `venv2/lib/python3.12/site-packages/pygments/regexopt.py`

**Imports:**
- itertools.groupby
- operator.itemgetter
- os.path.commonprefix
- re
- re.escape

**Functions:**

### `def make_charset(letters)`

**Line:** 22

---

### `def regex_opt_inner(strings, open_paren)`

**Description:**
Return a regex that matches any string in the sorted list of strings.

**Line:** 26

---

### `def regex_opt(strings, prefix = '', suffix = '')`

**Description:**
Return a compiled regex that matches any string in the given list.

The strings to match must be literal strings, not regexes.  They will be
regex-escaped.

*prefix* and *suffix* are pre- and appended to the final regex.

**Line:** 82

---


## Module: venv2.libthon3.12.site-packagesgments.sphinxext
**File:** `venv2/lib/python3.12/site-packages/pygments/sphinxext.py`

**Imports:**
- docutils.nodes
- docutils.parsers.rst.Directive
- docutils.statemachine.ViewList
- inspect
- pathlib
- pygments
- pygments.filters.FILTERS
- pygments.formatters.FORMATTERS
- pygments.lexers
- pygments.lexers._mapping.LEXERS
- sphinx.util.nodes.nested_parse_with_titles
- sys

**Functions:**

### `def setup(app)`

**Line:** 246

---


## Module: venv2.libthon3.12.site-packagesgments.styles.__init__
**File:** `venv2/lib/python3.12/site-packages/pygments/styles/__init__.py`

**Imports:**
- pygments.plugin.find_plugin_styles
- pygments.styles._mapping.STYLES
- pygments.util.ClassNotFound

**Functions:**

### `def get_style_by_name(name)`

**Description:**
Return a style class by its short name. The names of the builtin styles
are listed in :data:`pygments.styles.STYLE_MAP`.

Will raise :exc:`pygments.util.ClassNotFound` if no style of that name is
found.

**Line:** 24

---

### `def get_all_styles()`

**Description:**
Return a generator for all styles by name, both builtin and plugin.

**Line:** 56

---


## Module: venv2.libthon3.12.site-packagesgments.styles.solarized
**File:** `venv2/lib/python3.12/site-packages/pygments/styles/solarized.py`

**Imports:**
- pygments.style.Style
- pygments.token.Comment
- pygments.token.Error
- pygments.token.Generic
- pygments.token.Keyword
- pygments.token.Name
- pygments.token.Number
- pygments.token.Operator
- pygments.token.String
- pygments.token.Token

**Functions:**

### `def make_style(colors)`

**Line:** 22

---


## Module: venv2.libthon3.12.site-packagesgments.token
**File:** `venv2/lib/python3.12/site-packages/pygments/token.py`

**Functions:**

### `def is_token_subtype(ttype, other)`

**Description:**
Return True if ``ttype`` is a subtype of ``other``.

exists for backwards compatibility. use ``ttype in other`` now.

**Line:** 85

---

### `def string_to_tokentype(s)`

**Description:**
Convert a string into a token type::

>>> string_to_token('String.Double')
Token.Literal.String.Double
>>> string_to_token('Token.Literal.Number')
Token.Literal.Number
>>> string_to_token('')
Token

Tokens that are already tokens are returned unchanged:

>>> string_to_token(String)
Token.Literal.String

**Line:** 94

---


## Module: venv2.libthon3.12.site-packagesgments.unistring
**File:** `venv2/lib/python3.12/site-packages/pygments/unistring.py`

**Imports:**
- unicodedata

**Functions:**

### `def combine(*args)`

**Line:** 82

---

### `def allexcept(*args)`

**Line:** 86

---

### `def _handle_runs(char_list)`

**Line:** 93

---


## Module: venv2.libthon3.12.site-packagesgments.util
**File:** `venv2/lib/python3.12/site-packages/pygments/util.py`

**Imports:**
- io.TextIOWrapper
- locale
- re

**Functions:**

### `def get_choice_opt(options, optname, allowed, default = None, normcase = False)`

**Description:**
If the key `optname` from the dictionary is not in the sequence
`allowed`, raise an error, otherwise return it.

**Line:** 40

---

### `def get_bool_opt(options, optname, default = None)`

**Description:**
Intuitively, this is `options.get(optname, default)`, but restricted to
Boolean value. The Booleans can be represented as string, in order to accept
Boolean value from the command line arguments. If the key `optname` is
present in the dictionary `options` and is not associated with a Boolean,
raise an `OptionError`. If it is absent, `default` is returned instead.

The valid string values for ``True`` are ``1``, ``yes``, ``true`` and
``on``, the ones for ``False`` are ``0``, ``no``, ``false`` and ``off``
(matched case-insensitively).

**Line:** 53

---

### `def get_int_opt(options, optname, default = None)`

**Description:**
As :func:`get_bool_opt`, but interpret the value as an integer.

**Line:** 82

---

### `def get_list_opt(options, optname, default = None)`

**Description:**
If the key `optname` from the dictionary `options` is a string,
split it at whitespace and return it. If it is already a list
or a tuple, it is returned as a list.

**Line:** 94

---

### `def docstring_headline(obj)`

**Line:** 110

---

### `def make_analysator(f)`

**Description:**
Return a static text analyser function that returns float values.

**Line:** 122

---

### `def shebang_matches(text, regex)`

**Description:**
Check if the given regular expression matches the last part of the
shebang if one exists.

>>> from pygments.util import shebang_matches
>>> shebang_matches('#!/usr/bin/env python', r'python(2\.\d)?')
True
>>> shebang_matches('#!/usr/bin/python2.4', r'python(2\.\d)?')
True
>>> shebang_matches('#!/usr/bin/python-ruby', r'python(2\.\d)?')
False
>>> shebang_matches('#!/usr/bin/python/ruby', r'python(2\.\d)?')
False
>>> shebang_matches('#!/usr/bin/startsomethingwith python',
...                 r'python(2\.\d)?')
True

It also checks for common windows executable file extensions::

>>> shebang_matches('#!C:\\Python2.4\\Python.exe', r'python(2\.\d)?')
True

Parameters (``'-f'`` or ``'--foo'`` are ignored so ``'perl'`` does
the same as ``'perl -e'``)

Note that this method automatically searches the whole string (eg:
the regular expression is wrapped in ``'^$'``)

**Line:** 139

---

### `def doctype_matches(text, regex)`

**Description:**
Check if the doctype matches a regular expression (if present).

Note that this method only checks the first part of a DOCTYPE.
eg: 'html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"'

**Line:** 184

---

### `def html_doctype_matches(text)`

**Description:**
Check if the file looks like it has a html doctype.

**Line:** 197

---

### `def looks_like_xml(text)`

**Description:**
Check if a doctype exists or if we have some tags.

**Line:** 205

---

### `def surrogatepair(c)`

**Description:**
Given a unicode character code with length greater than 16 bits,
return the two 16 bit surrogate pair.

**Line:** 221

---

### `def format_lines(var_name, seq, raw = False, indent_level = 0)`

**Description:**
Formats a sequence of strings for output.

**Line:** 230

---

### `def duplicates_removed(it, already_seen = ())`

**Description:**
Returns a list with duplicates removed from the iterable `it`.

Order is preserved.

**Line:** 249

---

### `def guess_decode(text)`

**Description:**
Decode *text* with guessed encoding.

First try UTF-8; this should fail for non-UTF-8 encodings.
Then try the preferred locale encoding.
Fall back to latin-1, which always works.

**Line:** 275

---

### `def guess_decode_from_terminal(text, term)`

**Description:**
Decode *text* coming from terminal *term*.

First try the terminal encoding, if given.
Then try UTF-8.  Then try the preferred locale encoding.
Fall back to latin-1, which always works.

**Line:** 296

---

### `def terminal_encoding(term)`

**Description:**
Return our best guess of encoding for the given *term*.

**Line:** 313

---


## Module: venv2.libthon3.12.site-packagestest.__init__
**File:** `venv2/lib/python3.12/site-packages/pytest/__init__.py`

**Imports:**
- _pytest.__version__
- _pytest._code.ExceptionInfo
- _pytest.assertion.register_assert_rewrite
- _pytest.cacheprovider.Cache
- _pytest.capture.CaptureFixture
- _pytest.config.Config
- _pytest.config.ExitCode
- _pytest.config.PytestPluginManager
- _pytest.config.UsageError
- _pytest.config.argparsing.OptionGroup
- _pytest.config.argparsing.Parser
- _pytest.config.cmdline
- _pytest.config.console_main
- _pytest.config.hookimpl
- _pytest.config.hookspec
- _pytest.config.main
- _pytest.debugging.pytestPDB
- _pytest.doctest.DoctestItem
- _pytest.fixtures.FixtureLookupError
- _pytest.fixtures.FixtureRequest
- _pytest.fixtures.fixture
- _pytest.fixtures.yield_fixture
- _pytest.freeze_support.freeze_includes
- _pytest.legacypath.TempdirFactory
- _pytest.legacypath.Testdir
- _pytest.logging.LogCaptureFixture
- _pytest.main.Session
- _pytest.mark.MARK_GEN
- _pytest.mark.Mark
- _pytest.mark.MarkDecorator
- _pytest.mark.MarkGenerator
- _pytest.mark.param
- _pytest.monkeypatch.MonkeyPatch
- _pytest.nodes.Collector
- _pytest.nodes.File
- _pytest.nodes.Item
- _pytest.outcomes.exit
- _pytest.outcomes.fail
- _pytest.outcomes.importorskip
- _pytest.outcomes.skip
- _pytest.outcomes.xfail
- _pytest.pytester.HookRecorder
- _pytest.pytester.LineMatcher
- _pytest.pytester.Pytester
- _pytest.pytester.RecordedHookCall
- _pytest.pytester.RunResult
- _pytest.python.Class
- _pytest.python.Function
- _pytest.python.Instance
- _pytest.python.Metafunc
- _pytest.python.Module
- _pytest.python.Package
- _pytest.python_api.approx
- _pytest.python_api.raises
- _pytest.recwarn.WarningsRecorder
- _pytest.recwarn.deprecated_call
- _pytest.recwarn.warns
- _pytest.reports.CollectReport
- _pytest.reports.TestReport
- _pytest.runner.CallInfo
- _pytest.stash.Stash
- _pytest.stash.StashKey
- _pytest.terminal.TestShortLogReport
- _pytest.tmpdir.TempPathFactory
- _pytest.version_tuple
- _pytest.warning_types.PytestAssertRewriteWarning
- _pytest.warning_types.PytestCacheWarning
- _pytest.warning_types.PytestCollectionWarning
- _pytest.warning_types.PytestConfigWarning
- _pytest.warning_types.PytestDeprecationWarning
- _pytest.warning_types.PytestExperimentalApiWarning
- _pytest.warning_types.PytestRemovedIn8Warning
- _pytest.warning_types.PytestReturnNotNoneWarning
- _pytest.warning_types.PytestUnhandledCoroutineWarning
- _pytest.warning_types.PytestUnhandledThreadExceptionWarning
- _pytest.warning_types.PytestUnknownMarkWarning
- _pytest.warning_types.PytestUnraisableExceptionWarning
- _pytest.warning_types.PytestWarning

**Functions:**

### `def __getattr__(name: str) -> object`

**Line:** 165

---


## Module: venv2.libthon3.12.site-packagestest_flask._internal
**File:** `venv2/lib/python3.12/site-packages/pytest_flask/_internal.py`

**Imports:**
- functools
- warnings

**Functions:**

### `def deprecated(reason)`

**Description:**
Decorator which can be used to mark function or method as deprecated.
It will result a warning being emitted when the function is called.

**Line:** 5

---

### `def _rewrite_server_name(server_name, new_port)`

**Description:**
Rewrite server port in ``server_name`` with ``new_port`` value.

**Line:** 22

---

### `def _determine_scope(fixture_name, config)`

**Line:** 30

---

### `def _make_accept_header(mimetype)`

**Line:** 34

---


## Module: venv2.libthon3.12.site-packagestest_flask.fixtures
**File:** `venv2/lib/python3.12/site-packages/pytest_flask/fixtures.py`

**Imports:**
- _internal._determine_scope
- _internal._make_accept_header
- _internal._rewrite_server_name
- live_server.LiveServer
- pytest
- socket

**Functions:**

### `def client(app)`

**Decorators:**
- `@pytest.fixture`

**Description:**
A Flask test client. An instance of :class:`flask.testing.TestClient`
by default.

**Line:** 13

---

### `def client_class(request, client)`

**Decorators:**
- `@pytest.fixture`

**Description:**
Uses to set a ``client`` class attribute to current Flask test client::

@pytest.mark.usefixtures('client_class')
class TestView:

def login(self, email, password):
credentials = {'email': email, 'password': password}
return self.client.post(url_for('login'), data=credentials)

def test_login(self):
assert self.login('foo@example.com', 'pass').status_code == 200

**Line:** 22

---

### `def live_server(request, app, pytestconfig)`

**Decorators:**
- `@pytest.fixture(...)`

**Description:**
Run application in a separate process.

When the ``live_server`` fixture is applied, the ``url_for`` function
works as expected::

def test_server_is_up_and_running(live_server):
index_url = url_for('index', _external=True)
assert index_url == 'http://localhost:5000/'

res = urllib2.urlopen(index_url)
assert res.code == 200

**Line:** 41

---

### `def config(app)`

**Decorators:**
- `@pytest.fixture`

**Description:**
An application config.

**Line:** 88

---

### `def mimetype(request)`

**Decorators:**
- `@pytest.fixture(...)`

**Line:** 94

---

### `def accept_mimetype(mimetype)`

**Decorators:**
- `@pytest.fixture`

**Line:** 99

---

### `def accept_json(request)`

**Decorators:**
- `@pytest.fixture`

**Line:** 104

---

### `def accept_jsonp()`

**Decorators:**
- `@pytest.fixture`

**Line:** 109

---

### `def accept_any(request)`

**Decorators:**
- `@pytest.fixture(...)`

**Line:** 114

---


## Module: venv2.libthon3.12.site-packagestest_flask.plugin
**File:** `venv2/lib/python3.12/site-packages/pytest_flask/plugin.py`

**Imports:**
- fixtures.accept_any
- fixtures.accept_json
- fixtures.accept_jsonp
- fixtures.accept_mimetype
- fixtures.client
- fixtures.client_class
- fixtures.config
- fixtures.live_server
- pytest
- pytest_compat.getfixturevalue

**Functions:**

### `def pytest_assertrepr_compare(op, left, right)`

**Line:** 33

---

### `def _make_test_response_class(response_class)`

**Description:**
Extends the response class with special attribute to test JSON
responses. Don't override user-defined `json` attribute if any.

:param response_class: An original response class.

**Line:** 45

---

### `def _monkeypatch_response_class(request, monkeypatch)`

**Decorators:**
- `@pytest.fixture(...)`

**Description:**
Set custom response class before test suite and restore the original
after. Custom response has `json` property to easily test JSON responses::

@app.route('/ping')
def ping():
return jsonify(ping='pong')

def test_json(client):
res = client.get(url_for('ping'))
assert res.json == {'ping': 'pong'}

**Line:** 58

---

### `def _push_request_context(request)`

**Decorators:**
- `@pytest.fixture(...)`

**Description:**
During tests execution request context has been pushed, e.g. `url_for`,
`session`, etc. can be used in tests as is::

def test_app(app, client):
assert client.get(url_for('myview')).status_code == 200

**Line:** 82

---

### `def _configure_application(request, monkeypatch)`

**Decorators:**
- `@pytest.fixture(...)`

**Description:**
Use `pytest.mark.options` decorator to pass options to your application
factory::

@pytest.mark.options(debug=False)
def test_something(app):
assert not app.debug, 'the application works not in debug mode!'

**Line:** 112

---

### `def pytest_addoption(parser)`

**Line:** 130

---

### `def pytest_configure(config)`

**Line:** 189

---


## Module: venv2.libthon3.12.site-packagestest_flasktest_compat
**File:** `venv2/lib/python3.12/site-packages/pytest_flask/pytest_compat.py`

**Functions:**

### `def getfixturevalue(request, value)`

**Line:** 1

---

